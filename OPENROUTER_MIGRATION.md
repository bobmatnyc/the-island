# OpenRouter GPT-4o Migration Summary

**Date**: 2025-11-16
**Change**: Migrated chatbot from local Ollama (Qwen 2.5 Coder) to OpenRouter GPT-4o

## Changes Made

### 1. Environment Configuration âœ…
**File**: `/Users/masa/Projects/Epstein/.env.local`

Created new environment configuration file with:
- `OPENROUTER_API_KEY`: Your OpenRouter API key
- `OPENROUTER_MODEL`: Set to `openai/gpt-4o`

**Security**: This file is in `.gitignore` and will not be committed to git.

### 2. Dependencies Updated âœ…
**File**: `requirements.txt`

Added:
- `openai>=1.0.0` - OpenAI Python SDK (used for OpenRouter)
- `python-dotenv>=1.0.0` - Environment variable management

Install with:
```bash
pip install -r requirements.txt
```

### 3. Server Code Updated âœ…
**File**: `server/app.py`

**Changes**:
- Added imports: `os`, `dotenv`, `OpenAI`
- Load `.env.local` on startup
- Created `get_openrouter_client()` function for lazy initialization
- Updated `/api/chat` endpoint to use OpenRouter instead of Ollama subprocess
- Changed timeout from 60s to 30s (GPT-4o is faster)
- Better error handling with API error logging

**Key improvements**:
- **Faster responses**: GPT-4o typically responds in 5-15 seconds vs 30-60s for local Qwen
- **Better quality**: GPT-4o has superior reasoning and context understanding
- **Reliable**: Cloud-based, no local resource constraints
- **Timeout handling**: Proper timeout with graceful error messages

### 4. UI Updated âœ…
**File**: `server/web/index.html`

Changed chat subtitle from:
```
Powered by Qwen 2.5 Coder. Responses may take 30-60 seconds.
```

To:
```
Powered by GPT-4o via OpenRouter. Responses may take 5-15 seconds.
```

### 5. Test Script Created âœ…
**File**: `scripts/test_openrouter.py`

Standalone test script to validate OpenRouter connection:
- Checks `.env.local` exists
- Validates API key is set
- Sends test query to GPT-4.5
- Prints response and token usage
- Provides troubleshooting tips on error

## Testing

### Install Dependencies
```bash
cd /Users/masa/Projects/Epstein
pip install -r requirements.txt
```

### Test OpenRouter Connection
```bash
python3 scripts/test_openrouter.py
```

**Expected output**:
```
Loading environment from: /Users/masa/Projects/Epstein/.env.local
âœ… API key loaded: sk-or-v1-2a7ac...477d
âœ… Model: openai/gpt-4o

Initializing OpenRouter client...
âœ… Client initialized

Sending test query...
Query: Hello! Can you confirm you're GPT-4.5 and briefly describe your capabilities?

âœ… SUCCESS! OpenRouter API is working correctly.

Response from GPT-4.5:
----------------------------------------------------------------------
Hello! Yes, I am based on the GPT-4 architecture with further enhancements...
----------------------------------------------------------------------

Token Usage:
  Prompt tokens: 40
  Completion tokens: 61
  Total tokens: 101

âœ… All tests passed! OpenRouter integration is ready.
```

### Run the Server
```bash
cd /Users/masa/Projects/Epstein/server
python3 app.py 8000
```

**Test the chatbot**:
1. Navigate to `http://localhost:8000`
2. Log in with credentials
3. Open the chat sidebar
4. Ask a question like "What can you tell me about the entity network?"
5. GPT-4o should respond in 5-15 seconds

## Configuration Details

### OpenRouter Model
- **Model ID**: `openai/gpt-4o`
- **Provider**: OpenAI via OpenRouter
- **Context Window**: 128K tokens
- **Max Output**: 1000 tokens (configurable in `app.py`)
- **Temperature**: 0.7 (balanced creativity/accuracy)
- **Features**: Text + Image inputs, 2x faster than GPT-4 Turbo, 50% cheaper

### API Settings in Code
```python
completion = client.chat.completions.create(
    model=openrouter_model,
    messages=[...],
    temperature=0.7,      # Creativity level
    max_tokens=1000,      # Max response length
    timeout=30.0          # Request timeout
)
```

### Environment Variables
```bash
# Required
OPENROUTER_API_KEY=sk-or-v1-...

# Required
OPENROUTER_MODEL=openai/gpt-4o

# Alternative models (if needed):
# OPENROUTER_MODEL=openai/gpt-4o-mini  # Cheaper, faster, smaller
# OPENROUTER_MODEL=openai/gpt-4-turbo  # GPT-4 Turbo

# Optional (for OpenRouter analytics)
# OPENROUTER_SITE_URL=http://localhost:8000
# OPENROUTER_APP_NAME=Epstein Document Archive
```

## Rollback Instructions

If you need to revert to Ollama:

1. **Revert server/app.py**:
   - Remove OpenRouter imports (`os`, `dotenv`, `OpenAI`)
   - Remove `get_openrouter_client()` function
   - Restore original `/api/chat` endpoint with `subprocess.run(["ollama", ...])`

2. **Revert server/web/index.html**:
   - Change subtitle back to "Powered by Qwen 2.5 Coder. Responses may take 30-60 seconds."

3. **Dependencies** (optional):
   - Remove `openai` and `python-dotenv` from requirements.txt

## Troubleshooting

### "OPENROUTER_API_KEY not set in .env.local"
- Ensure `.env.local` exists in project root
- Check that `OPENROUTER_API_KEY=sk-or-v1-...` is set correctly
- Verify no extra spaces or quotes around the key

### "Failed to connect to OpenRouter API"
- Check internet connectivity
- Verify API key is valid (test at https://openrouter.ai/keys)
- Check OpenRouter service status
- Ensure `openai` package is installed (`pip install openai`)

### "Module not found: openai"
```bash
pip install openai python-dotenv
```

### Slow responses
- Normal response time: 5-15 seconds for GPT-4o
- If >30 seconds, check your internet connection
- OpenRouter may throttle based on account tier

### Rate limiting
- OpenRouter has rate limits based on account tier
- Free tier: Lower rate limits
- Paid tier: Higher throughput
- Check usage at https://openrouter.ai/activity

## Cost Estimation

**GPT-4o Pricing** (via OpenRouter):
- Input: ~$2.50 / 1M tokens
- Output: ~$10.00 / 1M tokens
- **50% cheaper than GPT-4 Turbo**

**Typical chat interaction**:
- System context: ~500 tokens
- User query: ~50 tokens
- Response: ~200 tokens
- **Cost per message**: ~$0.002-0.003 (less than half a cent)

**Monthly estimates** (rough):
- 100 queries/day: ~$6-9/month
- 500 queries/day: ~$30-45/month
- 1000 queries/day: ~$60-90/month

**Even cheaper alternative**: Use `openai/gpt-4o-mini` for ~80% cost reduction
- Input: ~$0.15 / 1M tokens
- Output: ~$0.60 / 1M tokens
- Cost per message: ~$0.0002 (1/10th of GPT-4o)

Monitor usage at: https://openrouter.ai/activity

## Security Notes

1. **API Key Protection**:
   - âœ… `.env.local` is in `.gitignore`
   - âœ… Never commit API keys to git
   - âœ… API key only loaded server-side (not exposed to browser)

2. **Authentication**:
   - âœ… Chat endpoint requires HTTP Basic Auth
   - âœ… Only authenticated users can access chatbot
   - âœ… Credentials managed in `server/.credentials`

3. **Rate Limiting**:
   - Consider implementing rate limiting per user
   - OpenRouter provides automatic rate limiting
   - Monitor usage to prevent abuse

## Next Steps

1. **Test the integration**: Run `python3 scripts/test_openrouter.py`
2. **Start the server**: `cd server && python3 app.py 8000`
3. **Test in browser**: Navigate to `http://localhost:8000` and chat
4. **Monitor costs**: Check https://openrouter.ai/activity regularly
5. **(Optional)** Implement rate limiting for production use

## Support

- **OpenRouter Docs**: https://openrouter.ai/docs
- **OpenRouter Discord**: https://discord.gg/fVyRaUDgxW
- **OpenAI Python SDK**: https://github.com/openai/openai-python

---

**Migration completed successfully!** ðŸš€

The chatbot now uses GPT-4o via OpenRouter for faster, higher-quality responses.

## Model Information

**GPT-4o** ("o" for "omni"):
- OpenAI's latest flagship model (as of 2025)
- 2x faster than GPT-4 Turbo
- 50% cheaper than GPT-4 Turbo
- Supports text and image inputs (multimodal)
- 128K context window
- Training data up to October 2023

**Why GPT-4o instead of GPT-4.5?**
At the time of implementation (November 2025), GPT-4.5 was not yet available on OpenRouter. GPT-4o is OpenAI's most current production model and provides excellent performance for this use case.

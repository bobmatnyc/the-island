{
  "document_id": "HOUSE_OVERSIGHT_013003",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013003.txt",
  "text": "4.5 Globalist versus Localist Representations 87\n\netc. are recognized. These recognized entities, called percepts, are passed to the workspace,\nwhere a model of the agent’s current situation is assembled.\n\nWorkspace structures serve as cues to the two forms of episodic memory, yielding both short\nand long term remembered local associations. In addition to the current percept, the workspace\ncontains recent percepts that haven’t yet decayed away, and the agent’s model of the then-\ncurrent situation previously assembled from them. The model of the agent’s current situation is\nupdated from the previous model using the remaining percepts and associations. This updating\nprocess will typically require looking back to perceptual memory and even to sensory memory,\nto enable the understanding of relations and situations. This assembled new model constitutes\nthe agent’s understanding of its current situation within its world. Via constructing the model,\nthe agent has made sense of the incoming stimuli.\n\nNow attention allocation comes into play, because a real agent lacks the computational re-\nsources to work with all parts of its world-model with maximal mental focus. Portions of the\nmodel compete for attention. These competing portions take the form of (potentially overlap-\nping) coalitions of structures comprising parts the model. Once one such coalition wins the\ncompetition, the agent has decided what to focus its attention on.\n\nAnd now comes the purpose of all this processing: to help the agent to decide what to do\nnext. The winning coalition passes to the global workspace, the namesake of Global Workspace\nTheory, from which it is broadcast globally. Though the contents of this conscious broadcast\nare available globally, the primary recipient is procedural memory, which stores templates of\npossible actions including their context and possible results.\n\nProcedural memory also stores an activation value for each such template — a value that\nattempts to measure the likelihood of an action taken within its context producing the ex-\npected result. It’s worth noting that LIDA makes a rather specific assumption here. LIDA’s\n“activation” values are like the probabilistic truth values of the implications in CogPrime’s\nContext \\ Procedure > Goal triples. However, in CogPrime this probability is not the same as\nthe ShortTermImportance “attention value” associated with the Implication link representing\nthat implication. Here LIDA merges together two concepts that in CogPrime are separate.\n\nTemplates whose contexts intersect sufficiently with the contents of the conscious broadcast\ninstantiate copies of themselves with their variables specified to the current situation. These\ninstantiations are passed to the action selection mechanism, which chooses a single action from\nthese instantiations and those remaining from previous cycles. The chosen action then goes to\nsensorimotor memory, where it picks up the appropriate algorithm by which it is then executed.\nThe action so taken affects the environment, and the cycle is complete.\n\nThe LIDA model hypothesizes that all human cognitive processing is via a continuing iter-\nation of such cognitive cycles. It acknowledges that other cognitive processes may also occur,\nrefining and building on the knowledge used in the cognitive cycle (for instance, the cognitive\ncycle itself doesn’t mention abstract reasoning or creativity). But the idea is that these other\nprocesses occur in the context of the cognitive cycle, which is the main loop driving the internal\nand external activities of the organism.\n\n4.5.9.1 Avoiding Combinatorial Explosion via Adaptive Attention Allocation\n\nLIDA avoids combinatorial explosions in its inference processes via two methods, both of which\nare also important in CogPrime :\n\ne combining reasoning via association with reasoning via deduction\n\nHOUSE_OVERSIGHT_013003",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013003.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3877,
    "word_count": 580,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:48.747307",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013141",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013141.txt",
  "text": "12.5 Clarifying the Ethics of Justice: Extending the Golden Rule in to a Multifactorial Ethical Model 225\n\nAnd this context-sensitivity has the result of intertwining ethical judgment with all sorts\nof other judgments — making it effectively impossible to extract “ethics” as one aspect of an\nintelligent system, separate from other kinds of thinking and acting the system does. This\nresonates with many prior observations by others, e.g. Eliezer Yudkowsky’s insistence that\nwhat we need are not ethicists of science and engineering, but rather ethical scientists and\nengineers — because the most meaningful and important ethical judgments regarding science\nand engineering generally come about in a manner that’s thoroughly interwined with technical\npractice, and hence are very difficult for a non-practitioner to richly appreciate [Gil82].\n\nWhat this context-sensitivity means is that, unless humans and AGIs are experiencing the\nsame sorts of contexts, and perceiving these contexts in at least approximately parallel ways,\nthere is little hope of translating the complex of human ethical judgments to these AGIs. This\nconclusion has significant implications for which routes to AGI are most likely to lead to success\nin terms of AGI ethics. We want early-stage AGIs to grow up in a situation where their minds\nare primarily and ongoingly shaped by shared experiences with humans. Supplying AGIs with\nabstract ethical principles is not likely to do the trick, because the essence of human ethics\nin real life seems to have a lot to do with its intuitively appropriate application in various\ncontexts. We transmit this sort of ethical praxis to humans via shared experience, and it seems\nmost probably that in the case of AGIs the transmission must be done the same sort of way.\n\nSome may feel that simplistic maxims are less “error prone” than more nuanced, context-\nsensitive ones. But the history of teaching ethics to human students does not support the idea\nthat limiting ethical pedagogy to slogans provides much value in terms of ethical development. If\none proceeds from the idea that AGI ethics must be hard-coded in order to work, then perhaps\nthe idea that simpler ethics means simpler algorithms, and therefore less error potential, has\nsome merit as an initial state. However, any learning system quickly diverges from its initial\nstate, and an ongoing, nuanced relationship between AGIs and humans will — whether we like\nit or not — form the basis for developmental AGI ethics. AGI intransigence and enmity is\nnot inevitable, but what is inevitable is that a learning system will acquire ideas about both\ntheory and actions from the other intelligent entities in its environment. Either we teach AGIs\npositive ethics through our interactions with them — both presenting ethical theory and behaving\nethically to them — or the potential is there for them to learn antisocial behavior from us even\nif we pre-load them with some set of allegedly inviolable edicts.\n\nAll in all, developmental ethics is not as simple as many people hope. Simplistic approaches\noften lead to disastrous consequences among humans, and there is no reason to think this\nwould be any different in the case of artificial intelligences. Most problems in ethics have cases\nin which a simplistic ethical formulation requires substantial revision to deal with extenuating\ncircumstances and nuances found in real world situations. Our goal in this chapter is not to\nenumerate a full set of complex networks of interacting ethical formulations as applicable to\nAGI systems (that is a project that will take years of both theoretical study and hands-on\nresearch), but rather to point out that this program must be undertaken in order to facilitate\na grounded and logically defensible system of ethics for artificial intelligences, one which is as\nunlikely to be undermined by subsequent selfmodification of the AGI as is possible. Even so,\nthere is still the risk that whatever predispositions are imparted to the AGIs through initial\ncodification of ethical ideas in the system’s internal logic representation, and through initial\npedagogical interactions with its learning systems, will be undermined through reinforcement\nlearning of antisocial behavior if humans do not interact ethically with AGIs. Ethical treatment\nis a necessary task for grounding ethics and making them unlikely to be distorted during internal\nrewriting.\n\nHOUSE_OVERSIGHT_013141",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013141.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4436,
    "word_count": 700,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:45.003844",
    "prefix": "IMAGES-002"
  }
}
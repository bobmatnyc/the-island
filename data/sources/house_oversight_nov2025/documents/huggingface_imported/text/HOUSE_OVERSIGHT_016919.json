{
  "document_id": "HOUSE_OVERSIGHT_016919",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016919.txt",
  "text": "something much more significant than speculating at the time: He was laying the\nfoundations for the digital revolution. As a graduate student at MIT, he worked for\nVannevar Bush on the Differential Analyzer. This was one of the last great analog\ncomputers, a room full of gears and shafts. Shannon’s frustration with the difficulty of\nsolving problems this way led him in 1937 to write what might be the best master’s thesis\never. In it, he showed how electrical circuits could be designed to evaluate arbitrary\nlogical expressions, introducing the basis for universal digital logic.\n\nAfter MIT, Shannon studied communications at Bell Labs. Analog telephone\ncalls degraded with distance; the farther they traveled, the worse they sounded. Rather\nthan continue to improve them incrementally, Shannon showed in 1948 that by\ncommunicating with symbols rather than continuous quantities, the behavior is very\ndifferent. Converting speech waveforms to the binary values of 1 and 0 is an example,\nbut many other sets of symbols can be (and are) used in digital communications. What\nmatters is not the particular symbols but rather the ability to detect and correct errors.\nShannon found that if the noise is above a threshold (which depends on the system\ndesign), then there are certain to be errors. But if the noise is below a threshold, then a\nlinear increase in the physical resources representing the symbol results in an exponential\ndecrease in the likelihood of making an error in correctly receiving the symbol. This\nrelationship was the first of what we’d now call a threshold theorem.\n\nSuch scaling falls off so quickly that the probability of an error can be so small as\nto effectively never happen. Each symbol sent multiplies rather than adds to the\ncertainty, so that the probability of a mistake can go from 0.1 to 0.01 to 0.001, and so\nforth. This exponential decrease in communication errors made possible an exponential\nincrease in the capacity of communication networks. And that eventually solved the\nproblem of where the knowledge in an AI system came from.\n\nFor many years, the fastest way to speed up a computation was to do nothing—\njust wait for computers to get faster. In the same way, there were years of AI projects\nthat aimed to accumulate everyday knowledge by laboriously entering pieces of\ninformation. That didn’t scale; it could progress only as fast as the number of people\ndoing the entering. But when phone calls, newspaper stories, and mail messages all\nmoved onto the Internet, everyone doing any of those things became a data generator.\nThe result was an exponential rather than a linear rate of knowledge accumulation.\n\nJohn von Neumann also has a cameo in Zhe Human Use of Human Beings, for\ngame theory. What Wiener missed here was von Neumann’s seminal role in digitizing\ncomputation. Whereas analog communication degraded with distance, analog computing\n(like the Differential Analyzer) degraded with time, accumulating errors as it progressed.\nVon Neumann presented in 1952 a result corresponding to Shannon’s for computation\n(they had met at the Institute for Advanced Study, in Princeton), showing that it was\npossible to compute reliably with an unreliable computing device by using symbols rather\nthan continuous quantities. This was, again, a scaling argument, with a linear increase in\nthe physical resources representing the symbol resulting in an exponential reduction in\nthe error rate as long as the noise was below a threshold. That’s what makes it possible\nto have a billion transistors in a computer chip, with the last one as useful as the first one.\nThis relationship led to an exponential increase in computing performance, which solved\na second problem in AI: how to process exponentially increasing amounts of data.\n\nThe third problem that scaling solved for AI was coming up with the rules for\n\n116\n\nHOUSE_OVERSIGHT_016919",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016919.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3881,
    "word_count": 631,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:44.950248",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_018428",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_018428.txt",
  "text": "look for a chance to “improve” the way we live, to bend us like so many paperclips\ninto what it seeks? The leap from deciding liver allocations to shutting down liquor\nplants might seem pretty short to a rationalizing machine. And if such a machine\ncould really “think”, Vinge bet it would pretty quickly conclude that the restraints of\nits creators were limiting what it had been asked to do. At which point the AI would\nturn to thinking about how to escape those bounds. It would be like Deep Blue\nprogrammed to plan its own prison break. And as much as humans might try to\nstifle a smart machine, we’d be fighting to contain something more powerful than\nwe'd ever encountered.\n\nThis challenge, which sounds like something out of science fiction, is known by\ntechnologists by a name that does sound like a short story by Isaac Asimov: “The\nConfinement Problem”. The computer scientist Butler Lampson named this in 1973\nas a sort of task for computer security experts - possibly their last. The assignment:\nNot simply to keep malware out of a system, but to keep the mind of a malicious\nmachine inside. To gate it. Today computer science labs are filled with nervous,\napocalyptic research imagining the impossible troubles of confinement. The debate\ndivides those who think smart technology can be contained - “Boxers,” they are\ncalled - and those like Vinge who think the AI will always, eventually escape.\n“Imagine yourself confined to your house with only limited data access to the\noutside, to your master.” he wrote, putting the reader in the place of an AI machine.\n“If those masters thought ata rate -- say - one million times slower than you, there\nis little doubt that over a period of years (your time) you could come up with\n‘helpful advice’ that would incidentally set you free.”\n\nImagine you are in charge of containing that health-optimizing AI. What if it told you\nit had the power to cure all illness and hunger, to ameliorate the misery of the world,\nif only it could be permitted to really control access to all the world’s trading and\ntransport market? Let me out! Would you refuse?2°8 Would that be ethical?\nEventually, perhaps, the Al would study the physics of its own electrics, discover\nlaws no human knows, and then slip free from its box on a trail of bits we’d never\nimagined, using physical laws we'll never discover. Impossible? “It seems to me that\nhistorically ‘impossible’ has essentially always meant ‘I can’t figure out how to do it\nright now,” the computer scientist Michael Vassar has written about such a situation.\n“People proposing AI boxes are a bit like literature majors proposing to\n\nlock McGuyver in a ‘room full of discarded electronics components.’”26? The\ncomputers, built to solve problems, will do exactly that. This is perhaps why some of\nthe bleakest warnings about AI come from the very New Caste figures now\naccelerating their adoption. Al is our “biggest existential threat” they warn, even as\nthey integrate it more fully into their own products.\n\n268 Let me out: See, for instance, Stuart Armstrong, Anders Sandberg and Nick\nBostrom “Thinking Inside the Box: Controlling and Using an Oracle AI”, Minds &\nMachines (2012) 22:299-324\n\n269 People proposing: Michael Vassar (2005) “Re: AI boxing (dogs and helicopters)”\nposted to SL4 mailing list\n\n196\n\nHOUSE_OVERSIGHT_018428",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_018428.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3327,
    "word_count": 564,
    "line_count": 52,
    "import_date": "2025-11-19T21:47:45.658237",
    "prefix": "IMAGES-004"
  }
}
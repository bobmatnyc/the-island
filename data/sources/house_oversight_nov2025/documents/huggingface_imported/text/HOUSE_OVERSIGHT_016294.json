{
  "document_id": "HOUSE_OVERSIGHT_016294",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016294.txt",
  "text": "Calibrating the Al-Risk Message\n\nWhile uncannily prescient, the AI-risk message from the original dissidents has a giant\nflaw—as does the version dominating current public discourse: Both considerably\nunderstate the magnitude of the problem as well as AI’s potential upside. The message,\nin other words, does not adequately convey the stakes of the game.\n\nWiener primarily warned of the social risks—trisks stemming from careless\nintegration of machine-generated decisions with governance processes and misuse (by\nhumans) of such automated decision making. Likewise, the current “serious” debate\nabout AI risks focuses mostly on things like technological unemployment or biases in\nmachine learning. While such discussions can be valuable and address pressing short-\nterm problems, they are also stunningly parochial. I’m reminded of Yudkowsky’s quip in\na blog post: “[A]sking about the effect of machine superintelligence on the conventional\nhuman labor market is like asking how US—Chinese trade patterns would be affected by\nthe Moon crashing into the Earth. There would indeed be effects, but you’d be missing\nthe point.”\n\nIn my view, the central point of the AI risk is that superintelligent AI is an\nenvironmental risk. Allow me to explain.\n\nIn his “Parable of the Sentient Puddle,” Douglas Adams describes a puddle that\nwakes up in the morning and finds himself in a hole that fits him “staggeringly well.”\nFrom that observation, the puddle concludes that the world must have been made for him.\nTherefore, writes Adams, “the moment he disappears catches him rather by surprise.” To\nassume that AI risks are limited to adverse social developments is to make a similar\nmistake. The harsh reality is that the universe was not made for us; instead, we are fine-\ntuned by evolution to a very narrow range of environmental parameters. For instance, we\nneed the atmosphere at ground level to be roughly at room temperature, at about 100 kPa\npressure, and have a sufficient concentration of oxygen. Any disturbance, even\ntemporary, of this precarious equilibrium and we die in a matter of minutes.\n\nSilicon-based intelligence does not share such concerns about the environment.\nThat’s why it’s much cheaper to explore space using machine probes rather than “cans of\nmeat.” Moreover, Earth’s current environment is almost certainly suboptimal for what a\nsuperintelligent AI will greatly care about: efficient computation. Hence we might find\nour planet suddenly going from anthropogenic global warming to machinogenic global\ncooling. One big challenge that AI safety research needs to deal with is how to constrain\na potentially superintelligent AI—an AI with a much larger footprint than our own—from\nrendering our environment uninhabitable for biological life-forms.\n\nInterestingly, given that the most potent sources both of AI research and AlI-risk\ndismissals are under big corporate umbrellas, if you squint hard enough the “AI as an\nenvironmental risk” message looks like the chronic concern about corporations skirting\ntheir environmental responsibilities.\n\nConversely, the worry about AI’s social effects also misses most of the upside.\nIt’s hard to overemphasize how tiny and parochial the future of our planet is, compared\nwith the full potential of humanity. On astronomical timescales, our planet will be gone\nsoon (unless we tame the sun, also a distinct possibility) and almost all the resources—\natoms and free energy—to sustain civilization in the long run are in deep space.\n\nEric Drexler, the inventor of nanotechnology, has recently been popularizing the\n\n74\n\nHOUSE_OVERSIGHT_016294",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016294.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3598,
    "word_count": 553,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:49.108233",
    "prefix": "IMAGES-003"
  }
}
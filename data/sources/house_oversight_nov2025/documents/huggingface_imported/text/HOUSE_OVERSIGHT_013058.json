{
  "document_id": "HOUSE_OVERSIGHT_013058",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013058.txt",
  "text": "142 7 A Formal Model of Intelligent Agents\n\nDefinition 9 The intellectual breadth of an agent 7, relative to the distribution v over\nenvironments and the distribution y over goals, is\n\nH(XGonq (Hs 951)\n\nwhere H is the entropy and\n\nV(L)V(G, HK) XConx (Hg, L)\n\nS2 (ta) 1(98; Ho) XCon, (Has 981 Tw)\n(He GB -T.)\n\nXConn (u, g; T) =\n\nis the probability distribution formed by normalizing the fuzzy set xcon, (1, 9,T).\n\nA similar definition of the intellectual breadth of a context (y, 9,7), relative to the distri-\nbution o over agents, may be posited. A weakness of these definitions is that they don’t try to\naccount for dependencies between agents or contexts; perhaps more refined formulations may\nbe developed that account explicitly for these dependencies.\n\nNote that the intellectual breadth of an agent as defined here is largely independent of\nthe (efficient or not) pragmatic general intelligence of that agent. One could have a rather\n(efficiently or not) pragmatically generally intelligent system with little breadth: this would be\na system very good at solving a fair number of hard problems, yet wholly incompetent on a\nlarger number of hard problems. On the other hand, one could also have a terribly (efficiently or\nnot) pragmatically generally stupid system with great intellectual breadth: i.e a system roughly\nequally dumb in all contexts!\n\nThus, one can characterize an intelligent agent as “narrow” with respect to distribution v over\nenvironments and the distribution + over goals, based on evaluating it as having low intellectual\nbreadth. A “narrow AI” relative to v and y would then be an AI agent with a relatively high\nefficient pragmatic general intelligence but a relatively low intellectual breadth.\n\n7.5 Conclusion\n\nOur main goal in this chapter has been to push the formal understanding of intelligence in a more\npragmatic direction. Much more work remains to be done, e.g. in specifying the environment,\ngoal and efficiency distributions relevant to real-world systems, but we believe that the ideas\npresented here constitute nontrivial progress.\n\nIf the line of research suggested in this chapter succeeds, then eventually, one will be able to\ndo AGI research as follows: Specify an AGI architecture formally, and then use the mathematics\nof general intelligence to derive interesting results about the environments, goals and hardware\nplatforms relative to which the AGI architecture will display significant pragmatic or efficient\npragmatic general intelligence, and intellectual breadth. The remaining chapters in this section\npresent further ideas regarding how to work toward this goal. For the time being, such a mode\nof AGI research remains mainly for the future, but we have still found the formalism given in\nthese chapters useful for formulating and clarifying various aspects of the CogPrime design as\nwill be presented in later chapters.\n\nHOUSE_OVERSIGHT_013058",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013058.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2902,
    "word_count": 460,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:47.127573",
    "prefix": "IMAGES-002"
  }
}
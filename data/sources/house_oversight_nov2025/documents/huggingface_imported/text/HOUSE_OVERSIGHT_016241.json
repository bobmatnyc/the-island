{
  "document_id": "HOUSE_OVERSIGHT_016241",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016241.txt",
  "text": "powerful room-cleaning robot was a Roomba, which moved around vacuuming at\nrandom and squeaked when it got caught under the couch.\n\nTechnological prediction is particularly chancy, given that technologies progress\nby a series of refinements, halted by obstacles and overcome by innovation. Many\nobstacles and some innovations can be anticipated, but more cannot. In my own work\nwith experimentalists on building quantum computers, I typically find that some of the\ntechnological steps I expect to be easy turn out to be impossible, whereas some of the\ntasks I imagine to be impossible turn out to be easy. You don’t know until you try.\n\nIn the 1950s, partly inspired by conversations with Wiener, John von Neumann\nintroduced the notion of the “technological singularity.” Technologies tend to improve\nexponentially, doubling in power or sensitivity over some interval of time. (For\nexample, since 1950, computer technologies have been doubling in power roughly\nevery two years, an observation enshrined as Moore’s Law.) Von Neumann\nextrapolated from the observed exponential rate of technological improvement to\npredict that “technological progress will become incomprehensively rapid and\ncomplicated,” outstripping human capabilities in the not too distant future. Indeed, if\none extrapolates the growth of raw computing power—expressed in terms of bits and\nbit flips—into the future at its current rate, computers should match human brains\nsometime in the next two to four decades (depending on how one estimates the\ninformation-processing power of human brains).\n\nThe failure of the initial overly optimistic predictions of AI dampened talk about\nthe technological singularity for a few decades, but since the 2005 publication of Ray\nKurzweil’s The Singularity is Near, the idea of technological advance leading to\nsuperintelligence is back in force. Some believers, Kurzweil included, regard this\nsingularity as an opportunity: Humans can merge their brains with the\nsuperintelligence and thereby live forever. Others, such as Stephen Hawking and Elon\nMusk, worried that this superintelligence would prove to be malign and regarded it as\nthe greatest existing threat to human civilization. Still others, including some of the\ncontributors to the present volume, think such talk is overblown.\n\nWiener’s life work and his failure to predict its consequences are intimately\nbound up in the idea of an impending technological singularity. His work on\nneuroscience and his initial support of McCulloch and Pitts adumbrated the startlingly\neffective deep-learning methods of the present day. Over the past decade, and\nparticularly in the last five years, such deep-learning techniques have finally exhibited\nwhat Wiener liked to call Gestalt—for example, the ability to recognize that a circle is\na circle even if when slanted sideways it looks like an ellipse. His work on control,\ncombined with his work on neuromuscular feedback, was significant for the\ndevelopment of robotics and is the inspiration for neural-based human/machine\ninterfaces. His lapses in technological prediction, however, suggest that we should\ntake the notion of a technological singularity with a grain of salt. The general\ndifficulties of technological prediction and the problems specific to the development of\na superintelligence should warn us against overestimating both the power and the\nefficacy of information processing.\n\nThe Arguments for Singularity Skepticism\nNo exponential increase lasts forever. An atomic explosion grows exponentially, but\n\n21\n\nHOUSE_OVERSIGHT_016241",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016241.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3557,
    "word_count": 530,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:48.981235",
    "prefix": "IMAGES-003"
  }
}
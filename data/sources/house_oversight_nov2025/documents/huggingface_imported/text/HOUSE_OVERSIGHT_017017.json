{
  "document_id": "HOUSE_OVERSIGHT_017017",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_017017.txt",
  "text": ", (comma)\n\n> (greater-than)\n? (question-mark)\n/ (forward-slash)\n~ (tilde)\n\n* (back-tick)\n“(double quote)\n\n(3) The following characters are not tokenized as separate words:\n& (ampersand)\n__ (underscore)\n\nExamples of the resulting words include AT&T, R&D, and variable names such as\nHKEY_LOCAL_MACHINE.\n\n(4) . (period) is treated as a separate word, except when it is part of a number or price, such as 99.99 or\n$999.95. A specific pattern matcher looks for numbers or prices and tokenizes these special strings as\nseparate words.\n\n(5) $ (dollar-sign) is treated as a separate word, except where it is the first character of a word consisting\nentirely of numbers, possibly containing a decimal point. Examples include $71 and $9.95\n\n(6) # (hash) is treated as a separate word, except when it is preceded by a-g, j or x. This covers musical\nnotes such as A# (A-sharp), and programming languages j#, and x#.\n\n(7) + (plus) is treated as a separate word, except it appears at the end of a sequence of alphanumeric\ncharacters or “+” s. Thus the strings C++ and Na2+ would be treated as single words. These cases\ninclude many programming language names and chemical compound names.\n\n(8) ' (apostrophe/single-quote) is treated as a separate word, except when it precedes the letter s, as in\nALICE'S and Bob's\n\nThe tokenization process for Chinese was. different. For Chinese, an_ internal CJK\n(Chinese/Japanese/Korean) segmenter was used to break characters into word units. The CJK\nsegmenter inserts spaces along common semantic boundaries. Hence, 1-grams that appear in the\nChinese simplified corpora will sometimes contain strings with 1 or more Chinese characters.\n\nGiven a sequence of n 1-grams, we denote the corresponding n-gram by concatenating the 1-grams with\na plain space character in between. A few examples of the tokenization and 1-gram construction method\nare provided in Table $2.\n\nEach book edition was broken down into a series of 1-grams on a page-by-page basis. For each page of\neach book, we counted the number of times each 1-gram appeared. We further counted the number of\ntimes each n-gram appeared (e.g., a sequence of n 1-grams) for all n less than or equal to 5. Because\nthis was done on a page-by-page basis, n-grams that span two consecutive pages were not counted.\n\n9\n\nHOUSE_OVERSIGHT_017017",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_017017.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2313,
    "word_count": 378,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:48.498636",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_012929",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_012929.txt",
  "text": "1.12 Key Claims of the Book 13\n\nThe best way to deal with this second “bad AGI” problem is to build ethics into your AGI\narchitecture — and we have done this with CogPrime, via creating a goal structure that explicitly\nsupports ethics-directed behavior, and via creating an overall architecture that supports “ethical\nsynergy” along with cognitive synergy. In short, the notion of ethical synergy is that there are\ndifferent kinds of ethical thinking associated with the different kinds of memory and you want\nto be sure your AGI has all of them, and that it uses them together effectively.\n\nIn order to create AGI that is not only intelligent but beneficial to other sentient beings,\nethics has got to be part of the design and the roadmap. As we teach our AGI systems, we need\nto lead them through a series of instructional and evaluative tasks that move from a primitive\nlevel to the mature human level — in intelligence, but also in ethical judgment.\n\n1.11 Structure of the Book\n\nThe book is divided into two parts. The technical particulars of CogPrime are discussed in Part\n2; what we deal with in Part 1 are important preliminary and related matters such as:\n\ne The nature of real-world general intelligence, both conceptually and from the perspective\nof formal modeling (Section I).\n\ne The nature of cognitive and ethical development for humans and AGIs (Section IIT).\n\ne The high-level properties of CogPrime, including the overall architecture and the various\nsorts of memory involved (Section IV).\n\ne What kind of path may viably lead us from here to AGI, with focus laid on preschooL-type\nenvironments that easily foster humanlike cognitive development. Various advanced aspects\nof AGI systems, such as the network and algebraic structures that may emerge from them,\nthe ways in which they may selfmodify, and the degree to which their initial design may\nconstrain or guide their future state even after long periods of radical self-improvement\n(Section V).\n\nOne point made repeatedly throughout Part 1, which is worth emphasizing here, is the current\nlack of a really rigorous and thorough general technical theory of general intelligence. Such a\ntheory, if complete, would be incredibly helpful for understanding complex AGI architectures\nlike CogPrime. Lacking such a theory, we must work on CogPrime and other such systems using\na combination of theory, experiment and intuition. This is not a bad thing, but it will be very\nhelpful if the theory and practice of AGI are able to grow collaboratively together.\n\n1.12 Key Claims of the Book\n\nWe will wrap up this Introduction with a systematic list of some of the key claims to be argued\nfor in these pages. Not all the terms and ideas in these claims have been mentioned in the\npreceding portions of this Introduction, but we hope they will be reasonably clear to the reader\nanyway, at least in a general sense. This list of claims will be revisited in Chapter 49 near the\nend of Part 2, where we will look back at the ideas and arguments that have been put forth in\nfavor of them, in the intervening chapters.\n\nHOUSE_OVERSIGHT_012929",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_012929.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3099,
    "word_count": 524,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:49.214998",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016391",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016391.txt",
  "text": "If robots don’t have exactly the same consciousness as humans, then this is used\nas an excuse to give them different rights, analogous to arguments that other tribes or\nraces are less than human. Do robots already show free will? Are they already self-\nconscious? The robots Qbo have passed the “mirror test” for self-recognition and the\nrobots NAO have passed a related test of recognizing their own voice and inferring their\ninternal state of being, mute or not.\n\nFor free will, we have algorithms that are neither fully deterministic nor random\nbut aimed at nearly optimal probabilistic decision making. One could argue that this is a\npractical Darwinian consequence of game theory. For many (not all) games/problems, if\nwe’re totally predictable or totally random, then we tend to lose.\n\nWhat is the appeal of free will anyway? Historically it gave us a way to assign\nblame in the context of reward and punishment on Earth or in the afterlife. The goals of\npunishment might include nudging the priorities of the individual to assist the survival of\nthe species. In extreme cases, this could include imprisonment or other restrictions, if\nSkinnerian positive/negative reinforcement is inadequate to protect society. Clearly, such\ntools can apply to free will, seen broadly—to any machine whose behavior we’d like to\nmanage.\n\nWe could argue as to whether the robot actually experiences subjective qualia for\nfree will or self-consciousness, but the same applies to evaluating a human. How do we\nknow that a sociopath, a coma patient, a person with Williams syndrome, or a baby has\nthe same free will or self-consciousness as our own? And what does it matter,\npractically? If humans (of any sort) convincingly claim to experience consciousness,\npain, faith, happiness, ambition, and/or utility to society, should we deny them rights\nbecause their hypothetical qualia are hypothetically different from ours?\n\nThe sharp red lines of prohibition, over which we supposedly will never step,\nincreasingly seem to be short-lived and not sensible. The line between human and\nmachines blurs, both because machines become more humanlike and humans become\nmore machine-like—not only since we increasingly blindly follow GPS scripts, reflex\ntweets, and carefully crafted marketing, but also as we digest ever more insights into our\nbrain and genetic programming mechanisms. The NIH BRAIN Initiative is developing\ninnovative technologies and using these to map out the connections and activity of mental\ncircuitry so as to improve electronic and synthetic neurobiological ware.\n\nVarious red lines depend on genetic exceptionalism, in which genetics 1s\nconsidered permanently heritable (although it is provably reversible), whereas exempt\n(and lethal) technologies, like cars, are for all intents and purposes irreversible due to\nsocial and economic forces. Within genetics, a red line makes us ban or avoid genetically\nmodified foods but embrace genetically modified bacteria making insulin, or genetically\nmodified humans—witness mitochondrial therapies approved in Europe for human adults\nand embryos.\n\nThe line for germline manipulation seems less sensible than the usual, practical\nline drawn at safety and efficacy. Marriages of two healthy carriers of the same genetic\ndisease have a choice between no child of their own, 25-percent loss of embryos via\nabortion (spontaneous or induced), 80-percent loss via in-vitro fertilization, or potential\nzero-percent embryo loss via sperm (germline) engineering. It seems premature to\ndeclare this last option unlikely.\n\n171\n\nHOUSE_OVERSIGHT_016391",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016391.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3583,
    "word_count": 549,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:46.920213",
    "prefix": "IMAGES-003"
  }
}
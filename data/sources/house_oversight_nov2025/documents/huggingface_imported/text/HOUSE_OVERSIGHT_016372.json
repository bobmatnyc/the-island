{
  "document_id": "HOUSE_OVERSIGHT_016372",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016372.txt",
  "text": "Als VERSUS FOUR-YEAR-OLDS\nAlison Gopnik\n\nAlison Gopnik is a developmental psychologist at UC Berkeley; her books include The\nPhilosophical Baby and, most recently, The Gardener and the Carpenter: What the New\nScience of Child Development Tells Us About the Relationship Between Parents and\nChildren.\n\nEveryone’s heard about the new advances in artificial intelligence, and especially\nmachine learning. You’ve also heard utopian or apocalyptic predictions about what those\nadvances mean. They have been taken to presage either immortality or the end of the\nworld, and a lot has been written about both those possibilities. But the most\nsophisticated Als are still far from being able to solve problems that human four-year-\nolds accomplish with ease. In spite of the impressive name, artificial intelligence largely\nconsists of techniques to detect statistical patterns in large data sets. There is much more\nto human learning.\n\nHow can we possibly know so much about the world around us? We learn an\nenormous amount even when we are small children; four-year-olds already know about\nplants and animals and machines; desires, beliefs, and emotions; even dinosaurs and\nspaceships.\n\nScience has extended our knowledge about the world to the unimaginably large\nand the infinitesimally small, to the edge of the universe and the beginning of time. And\nwe use that knowledge to make new classifications and predictions, imagine new\npossibilities, and make new things happen in the world. But all that reaches any of us\nfrom the world is a stream of photons hitting our retinas and disturbances of air at our\neardrums. How do we learn so much about the world when the evidence we have is so\nlimited? And how do we do all this with the few pounds of grey goo that sits behind our\neyes?\n\nThe best answer so far is that our brains perform computations on the concrete,\nparticular, messy data arriving at our senses, and those computations yield accurate\nrepresentations of the world. The representations seem to be structured, abstract, and\nhierarchical; they include the perception of three-dimensional objects, the grammars that\nunderlie language, and mental capacities like “theory of mind,” which lets us understand\nwhat other people think. Those representations allow us to make a wide range of new\npredictions and imagine many new possibilities in a distinctively creative human way.\n\nThis kind of learning isn’t the only kind of intelligence, but it’s a particularly\nimportant one for human beings. And it’s the kind of intelligence that is a specialty of\nyoung children. Although children are dramatically bad at planning and decision making,\nthey are the best learners in the universe. Much of the process of turning data into\ntheories happens before we are five.\n\nSince Aristotle and Plato, there have been two basic ways of addressing the\nproblem of how we know what we know, and they are still the main approaches in\nmachine learning. Aristotle approached the problem from the bottom up: Start with\nsenses—the stream of photons and air vibrations (or the pixels or sound samples of a\ndigital image or recording)—and see if you can extract patterns from them. This\napproach was carried further by such classic associationists as philosophers David Hume\n\n152\n\nHOUSE_OVERSIGHT_016372",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016372.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3282,
    "word_count": 527,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:45.723925",
    "prefix": "IMAGES-003"
  }
}
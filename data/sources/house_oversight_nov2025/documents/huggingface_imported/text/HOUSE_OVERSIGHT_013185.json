{
  "document_id": "HOUSE_OVERSIGHT_013185",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013185.txt",
  "text": "13.6 Glocal Memory 269\n\nThe result of these modifications to the ordinary Hopfield net, is a Hopfield net that contin-\nually maintains a set of key neurons, each of which individually represents a certain attractor\nof the net.\n\nNote that these key neurons — in spite of being “symbolic” in nature — are learned rather\nthan preprogrammed, and are every bit as adaptive as the attractors they correspond to. Fur-\nthermore, if a key neuron is removed, the glocal Hopfield net algorithm will eventually learn it\nback, so the robustness properties of Hopfield nets are retained.\n\nThe results of experimenting with glocal Hopfield nets of this nature are summarized in\n[GPI* 10]. We studied Hopfield nets with connectivity around .1, and in this context we found\nthat glocality\n\ne slightly increased memory capacity\ne massively increased the rate of convergence to the attractor, i.e. the speed of recall\n\nHowever, probably the most important consequence of glocality is a more qualitative one: it\nmakes it far easier to link the Hopfield net into a larger system, as would occur if the Hopfield net\nwere embedded in an integrative AGI architecture. Because a neuron external to the Hopfield\nnet may now link to a memory in the Hopfield net by linking to the corresponding key neuron.\n\n13.6.4 Neural-Symbolic Glocality in CogPrime\n\nIn CogPrime, we have explicitly sought to span the symbolic/emergentist pseudo-dichotomy,\nvia creating an integrative knowledge representation that combines logic-based aspects with\nneural-net-like aspects. As reviewed in Chapter 6 above, these function not in the manner of\nmultimodular systems, but rather via using (probabilistic) truth values and (attractor neural\nnet like) attention values as weights on nodes and links of the same (hyper) graph. The nodes\nand links in this hypergraph are typed, like a standard semantic network approach for knowl-\nedge representation, so they’re able to handle all sorts of knowledge, from the most concrete\nperception and actuation related knowledge to the most abstract relationships. But they’re also\nweighted with values similar to neural net weights, and pass around quantities (importance\nvalues, discussed in Chapter 23 of Part 2) similar to neural net activations, allowing emergent\nattractor /assembly based knowledge representation similar to attractor neural nets.\n\nThe concept of glocality lies at the heart of this combination, in a way that spans the pseudo-\ndichotomy:\n\ne Local knowledge is represented in abstract logical relationships stored in explicit logical\nform, and also in Hebbian-type associations between nodes and links.\n\ne Global knowledge is represented in large-scale patterns of node and link weights, which\nlead to large-scale patterns of network activity, which often take the form of attractors\nqualitatively similar to Hopfield net attractors. These attractors are called maps.\n\nThe result of all this is that a concept like “cat” might be represented as a combination of:\n\ne A small number of logical relationships and strong associations, that constitute the “key”\nsubnetwork for the “cat” concept.\n\ne A large network of weak associations, binding together various nodes and links of various\ntypes and various levels of abstraction, representing the “cat map”.\n\nHOUSE_OVERSIGHT_013185",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013185.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3289,
    "word_count": 510,
    "line_count": 56,
    "import_date": "2025-11-19T21:47:44.460370",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_017021",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_017021.txt",
  "text": "3) Quality of OCR. This varies from corpus to corpus as described above. For English, we spent a great\ndeal of time examining the data by hand as an additional check on its reliability. The other corpora may\nnot be as reliable.\n\n4) Quality of Metadata. Again, the English language corpus was checked very carefully and\nsystematically on multiple occasions, as described above and in the following sections. The metadata for\nthe other corpora may not be equally reliable for all periods. In particular, the Hebrew corpus during the\n19th century is composed largely of reprinted works, whose original publication dates farpredate the\nmetadata date for the publication of the particular edition in question. This must be borne in mind for\nresearchers intent on working with that corpus.\n\nIn addition to these four general issues, we note that earlier portions of the Hebrew corpus contain a large\nquantity of Aramaic text written in Hebrew script. As these texts often oscillate back and forth between\nHebrew and Aramaic, they are particularly hard to accurately classify.\n\nAll the above issues will likely improve in the years to come. In the meanwhile, users must use extra\ncaution in interpreting the results of culturomic analyses, especially those based on the various non-\nEnglish corpora. Nevertheless, as illustrated in the main text, these corpora already contain a great\ntreasury of useful material, and we have therefore made them available to the scientific community\nwithout delay. We have no doubt that they will enable many more fascinating discoveries.\n\nIII.0.2 On the number of books published\n\nIn the text, we report that our corpus contains about 4% of all books ever published. Obtaining this\nestimate relies on knowing how many books are in the corpus (5,195,769) and estimating the total\nnumber of books ever published. The latter quantity is extremely difficult to estimate, because the record\nof published books is fragmentary and incomplete, and because the definition of book is _ itself\nambiguous.\n\nOne way of estimating the number of books ever published is to calculate the number of editions in the\ncomprehensive catalog of books which was described in Section | of the supplemental materials. This\nproduces an estimate of 129 million book editions. However, this estimate must be regarded with great\ncaution: it is conservative, and the choice of parameters for the clustering algorithm can lead to significant\nvariation in the results. More details are provided in Ref $1.\n\nAnother independent estimate we obtained in the study \"How Much Information? (2003)\" conducted at\nBerkeley (Ref S6). That study also produced a very rough estimate of the number of books ever\npublished and concluded that it was between 74 million and 175 million.\n\nThe results of both estimates are in general agreement. If the actual number is closer to the low end of\nthe Berkeley range, then our 5 million book corpus encompasses a little more than 5% of all books ever\npublished; if it is at the high end, then our corpus would constitute a little less than 3%. We report an\napproximate value (about 4%) in the text; it is clear that, in the coming years, more precise estimates of\nthe denominator will become available.\n\nIII.1. Generation of timeline plots\n\nIII.1A. Single Query\n\nThe timeline plots shown in the paper are created by taking the number of appearances of an n-gram ina\ngiven year in the specified corpus and dividing by the total number of words in the corpus in that year.\nThis yields a raw frequency value. Results are smoothed using a three year window; i.e., the frequency of\n\n13\n\nHOUSE_OVERSIGHT_017021",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_017021.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3629,
    "word_count": 598,
    "line_count": 56,
    "import_date": "2025-11-19T21:47:44.113911",
    "prefix": "IMAGES-004"
  }
}
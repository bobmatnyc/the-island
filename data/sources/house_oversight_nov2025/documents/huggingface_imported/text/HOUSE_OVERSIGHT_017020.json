{
  "document_id": "HOUSE_OVERSIGHT_017020",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_017020.txt",
  "text": "The computations required to generate these corpora were performed at Google using the MapReduce\nframework for distributed computing (Ref $5). Many computers were used as these computations would\ntake many years on a single ordinary computer.\n\nNote that the ability to study the frequency of words or phrases in English over time was our primary focus\nin this study. As such, we went to significant lengths to ensure the quality of the general English corpora\nand their date metadata (i.e., Eng-all, Eng-1M, and Eng-Modern-1M). As a result, the accuracy of place-\nof-publication data in English is not as reliable as the accuracy of date metadata. In addition, the foreign\nlanguage corpora are affected by issues that were improved and largely eliminated in the English data.\nFor instance, their date metadata is not as accurate. In the case of Hebrew, the metadata for language is\nan oversimplification: a significant fraction of the earliest texts annotated as Hebrew are in fact hybrids\nformed from Hebrew and Aramaic, the latter written in Hebrew script.\n\nThe size of these base corpora is described in Tables S3-S6.\n\nIII. Culturomic Analyses\n\nIn this section we describe the computational techniques we use to analyze the historical n-grams\ncorpora.\n\nIlI.0. General Remarks\n\nIII.0.1 On Corpora.\n\nThere is significant variation in the quality of the various corpora during various time periods and their\nsuitability for culturomic research. All the corpora are adequate for the uses to which they are put in the\npaper. In particular, the primary object of study in this paper is the English language from 1800-2000; this\ncorpus during this period is therefore the most carefully curated of the datasets. However, to encourage\nfurther research, we are releasing all available datasets - far more data than was used in the paper. We\ntherefore take a moment to describe the factors a culturomic researcher ought to consider before relying\non results of new queries not highlighted in the paper.\n\n1) Volume of data sampled. Where the number of books used to count n-gram frequencies is too small,\nthe signal to noise ratio declines to the point where reliable trends cannot be discerned. For instance, if\nan n-gram's actual frequency is 1 part in n, the number of words required to create a single reliable\ntimepoint must be some multiple of n. In the English language, for instance, we restrict our study to years\npast 1800, where at least 40 million words are found each year. Thus an n-gram whose frequency is 1\npart per million can be reliably quantified with single-year resolution. In Chinese, there are fewer than 10\nmillion words per year prior to the year 1956. Thus the Chinese corpus in 1956 is not in general as\nsuitable for reliable quantification as the English corpus in 1800. (In some cases, reducing the resolution\nby binning in larger windows can be used to sample lower frequency n-grams in a corpus that is too smal\nfor single-year resolution.) In sum: for any corpus and any n-gram in any year, one must consider whether\nthe size of the corpus is sufficient to enable reliable quantitation of that n-gram in that year.\n\n2) Composition of the corpus. The full dataset contains about 4% of all books ever published, which\nlimits the extent to which it may be biased relative to the ensemble of all surviving books. Still, marked\nshifts in composition from one year to another are a potential source of error. For instance, book sampling\npatterns differ for the period before the creation of Google Books (2004) as compared to the period\nafterward. Thus, it is difficult to compare results from after 2000 with results from before 2000. As a result,\nsignificant changes in culturomic trends past the year 2000 may reflect corous composition issues. This\nwas an important reason for our choice of the period between 1800 and 2000 as the target period.\n\n12\n\nHOUSE_OVERSIGHT_017020",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_017020.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3896,
    "word_count": 648,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:44.131973",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_026521",
  "filename": "TEXT-001-HOUSE_OVERSIGHT_026521.txt",
  "text": "﻿Cooperating Without Looking\nMoshe Hoffman, 1,2∗† Erez Yoeli, 2,3∗ Martin Nowak 2\n1 Department of Computer Science and Engineering,\nUniversity of California at San Diego, La Jolla, CA 92093\n2 Program for Evolutionary Dynamics,\nHarvard University, Cambridge, MA 02138\n2 Federal Trade Commission,\n600 Pennsylvania Ave. NW, Washington, DC 20004\n∗ These authors contributed equally to this work.\n† To whom correspondence should be addressed; E-mail: hoffman.moshe@gmail.com.\nCooperation occurs when we take on costs to help others.\nA key\nmechanism by which cooperation is sustained is reciprocity: individuals\ncooperate with those who have cooperated in the past. In\nreality, we not only condition on others’ past cooperative actions,\nbut also on the decision making process that leads to cooperation:\nwe trust more those who cooperate without calculating the costs\nbecause they will cooperate even when those costs are high.\nWe\npropose a game theory model to explain this phenomenon. In our\nmodel, player 1 chooses whether or not to cooperate with player 2.\nPlayer 1 faces a stochastic temptation to defect and, before choosing\nwhether to cooperate, also decides whether to “look” at the\nrealized temptation. Player 2 observes not only whether player 1\nultimately cooperated but also whether she looked, then decides\n1\nwhether or not to continue interacting with player 1. We find conditions\nin which there is an equilibrium where player 2 chooses to\ninteract with player 1 only if player 1 cooperates without looking\n(CWOL) and player 1 chooses to CWOL. We show that this equilibrium\nis robust to both high degrees of rationality, as modeled by\nsubgame perfection and learning or evolutionary dynamics, as modeled\nby the replicator dynamic.\nUsing computer simulations, we\nalso show that it emerges with high frequency, even in the presence\nof other equilibria. Additionally, we show that the ability for player\n1 to avoid looking, and the ability for player 2 to detect looking\nincreases cooperation. We propose this model as a possible explanation\nfor a number of interesting phenomena, and thereby derive\nnovel predictions about these phenomena, including why we dislike\n“flip-flopping” politicians and respect principled people more generally,\nwhy people cooperate intuitively, and why people feel disgust\nwhen considering taboo trade-offs, and why people fall in love.\nCooperation occurs when we take on costs to help others. A key mechanism by which\ncooperation is sustained is reciprocity: individuals condition their behavior on others’\npast actions [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]. In reality, we not only condition\non others’ past actions, but also on the decision-making process that lead to cooperation:\nwe place more trust in cooperators who do not take time to carefully weigh the costs of\ncooperation and who do not try to collect data on such costs before deciding whether to\ncooperate. For example, we are impressed by colleagues who agree to proofread a paper\nwithout thinking twice, and view with suspicion those who ask, “how long will it take?”\nbefore agreeing to attend a practice talk. Such considerations are left out of standard\n2\nmodels of reciprocity, which only attend to cooperative actions and not the deliberation\nprocess leading up to the action.\nWe develop a simple model to explain why “looking” at the costs of cooperation is\nviewed with suspicion. The explanation we suggest is quite intuitive: those who cooperate\nwithout looking (CWOL) can be trusted to cooperate even in times when there are\ntemptations to defect. While this insight can be captured without the need for a formal\nmodel, it is less clear that cooperators will choose to not look, since they pay a price by\ncooperating blindly in tempting circumstances. Moreover, the formal model, as will be\nseen, helps explicate when CWOL will occur as well as what difference the ability to not\nlook and to observe others not looking will make.\nWe formalize this idea using what we call the envelope game (see figure 1).\nThe\nenvelope game distills an interaction between two individuals, or players, in an uncertain\nenvironment.\nThus, we start by assuming there is a distribution of payoffs with two\npossibilities: one in which defection is relatively tempting, and another in which it is\nnot. The temptation to defect is randomly determined. Defection is not tempting with\nprobability p and tempting with probability 1 − p. Both players know how likely it is that\ndefection is tempting. However, at this point, neither player knows size of the temptation.\nThat is, the temptation is placed inside an envelope and the envelope is sealed without\nthe players knowing its content. Next, we assume that one of the players, player 1,\nchooses whether to learn the size of the temptation, either via mental deliberation or by\ngathering information. We model this in a simplified way by assuming that player 1 has a\ndichotomous choice: she can choose to open the envelope and look inside it, or not. If she\nopens the envelope and looks, she learns the size of the temptation. If she does not open\nthe envelope and look, she only knows the distribution of payoffs. Player 1 then chooses\nwhether to cooperate or defect. We model cooperation as costly to player 1, regardless\n3\nof the temptation, but more costly if the temptation is high. Thus, if the temptation is\nlow, player 1 gets a > 0 if she cooperates and c l > a if she defects. If the temptation is\nhigh, she gets a if she cooperates and c h > c l if she defects. We assume that cooperation\nbenefits the other player, which we refer to as player 2. We assume, for simplicity, that\nplayer 2 gets b > 0 if 1 cooperates and d < 0 if 1 defects, and that these payoffs to player 2\nare the same regardless of 1’s temptation. For now, we also assume that d < p/(1 − p) · b;\nthat is, defection is sufficiently harmful to player 2 that player 2 prefers to avoid the\ninteraction if player 1 only cooperates some of the time. Finally, we model player 2’s\ntrust in player 1. We model this by giving player 2 the choice of whether to continue\nthe interaction with player 1. If player 2 continues the interaction, then with probability\nw, all previous steps are repeated, potentially indefinitely. That is, the temptation to\ndefect is randomly chosen again, player 1 chooses whether to look at it, and so on. With\nprobability 1 − w, the game ends. The parameter w can be interpreted as the likelihood\nof a future interaction or the player’s discounting of future payoffs. Crucially, we assume\nthat player 2 observes both of player 1’s choices: not only whether 1 cooperated, but\nalso whether 1 first looked. Our model, therefore, applies to situations where player 1’s\nlooking is somewhat observable, for example, if player 1 can gain additional information\nabout the costs of defection by asking player 2 questions, or if player 1 can take time to\nponder the decision and player 2 can observe player 1’s reaction time. We assume that\nplayers maximize their expected payoffs. Note that since we assumed a > 0 and b > 0,\nboth players benefit from a cooperative interaction.\nIn the envelope game, a strategy for player 1 dictates whether she will look and whether\nshe will cooperate, as a function of whether she has looked and cooperated in the past,\nand as a function of the temptation if she has just looked. For example, one relatively\nsimple strategy for player 1 is to look and cooperate whenever the temptation is low.\n4\nSimilarly, a strategy for player 2 dictates whether he will continue or exit as a function\nof everything player 1 has done in the past. One relatively simple strategy for player 2\nis to continue so long as player 1 has cooperated. If both players play according to this\npair of strategies, each time the temptation is low, player 1 cooperates and gets a, player\n2 gets b, and the game continues with probability w until the first time the temptation\nis high. Then, player 1 defects and gets c h and player 2 gets d. Some straightforward\ncalculations yield the players’ expected payoffs: player 1’s is [ap + c h (1 − p)] / [1 − pw]\nand player 2’s is [bp + d(1 − p)] / [1 − pw]. Because a strategy specifies players’ moves in\nevery period and the game’s length is undetermined, infinitely many possible strategies\nexist. We are primarily interested in the seven strategies represented in Figure 2, which\nshows the expected payoff for each player for each strategy pair of interest.\nOf particular interest is the strategy pair designated in the top left corner of figure 2),\nin which player 2 discriminates between cooperators who look and those who do not\nlook, and player 1 cooperates without looking (CWOL). The following simple argument\ndemonstrates that this strategy pair is a Nash Equilibrium (which means no player has\nan incentive to unilaterally deviate) whenever\na\n≥ c 1−w lp + c h (1 − p). This condition has a\nnatural interpretation: player 1’s expected temptation from defection is less than the gains\nfrom an ongoing cooperative interaction. Thus, player 1 would lose from deviating, for\nexample by looking, because this would end the lucrative ongoing relationship, reducing\nplayer 1’s payoff from an expected\na\n1−w\nto 0. Player 2 would also lose from deviating, by\nchoosing to exit, because when player 1 is always cooperating, she expects\nrelationship, and exiting yields 0.\nb\n1−w\nfrom the\nOne potential concern with this equilibrium is that, since player 2 is not worse off by\nnot attending to looking, he might not do so. This turns out to not be the case. The\nintuition is that if there is even a small probability player 1 looks, player 2 is better off\n5\nattending to looking. In the appendix, we formalize this intuition by showing that this\nequilibrium is subgame perfect, a solution concept used to rule out these kinds of concerns\nin settings where there is a high degree of rationality [15].\nWe might wonder whether CWOL will emerge in a population of players who are not\nrational, but are evolving or learning their strategies. There are two reasons to suspect\nit will not emerge. First, CWOL may be susceptible to the invasion of mutants. In\nparticular, the concern is that a player 2 mutant might arise that does not attend to\nwhether player 1 looks, rendering looking irrelevant. This mutant’s fitness is no higher or\nlower than the incumbent strategy, so may grow by drift. Subsequently, a player 1 mutant\nwhich looks and defects when the temptation is high would have a fitness advantage and\nproliferate. While the player 2 mutant would then start dying off since it would now have\nlower fitness than the incumbent, it is not clear that it would do so fast enough for the\nplayer 1 mutant to also die off, returning to the CWOL equilibrium. Second, CWOL may\nbe stable but have such a small basin of attraction that it will never emerge. In particular,\nthere are three other equilibria to consider, which can be seen in figure 2. The first is\ncomprised of the strategy pair where player 1 always defects, and player 2 always exits\n(which we refer to as the ALLD equilibrium). It is a Nash Equilibrium for all parameter\nvalues. The second is the strategy pair where player 2 exits if player 1 defects, and player\n1 cooperates with or without looking (we refer to this as the CWL equilibrium). It is a\nNash equilibrium when\na ≥ c 1−w 2. In fact, there are many more Nash Equilibria, where\nthe population mixes between different strategies.\nConsequently, we employ computer simulations of the replicator dynamic to explore\nthe evolutionary dynamics of the envelope game. The replicator dynamic is the standard\nmodel for evolutionary dynamics [16, 17, 18, 19], and also models learning dynamics such\nas reinforcement learning or prestige-biased imitation [20]. It describes strategies evolving\n6\nover time under the assumption that the rate of reproduction within each population\nis proportional to the fitness relative to that type’s other strategies.\nSince replicator\ndynamics cannot be solved in closed form, they must analyzed using computer simulations\nseeded with randomly chosen strategy frequencies. This method also requires restricting\nthe analysis to a few strategies. Therefore, we run our replicator analysis only on the\nrestricted set of strategies represented in figure 2. While this set of strategies is restricted,\nit includes the potentially destabilizing mutants discussed above.\nTo investigate the frequencies in which different equilibria emerge, we randomly seed\nthe strategy frequencies many times and record the frequency of each strategy after the\npopulation has stabilized. Many mixtures of strategies are behaviorally consistent with\nCWOL, for example, if a large enough fraction of player 2s exit when player 1s look then\nno player 1s will look, even if this fraction is less than 1. Thus, we classify population\nfrequencies as being behaviorally equivalent to ALLD, CWL, and CWOL (see appendix\nfor details). We plot the frequencies of each of these for different values of a in figure 3 (see\nappendix for analogous figures for other parameters). As can be seen, CWOL emerges\noften when it is a Nash Equilibrium.\nNext, we identify the conditions under which people will be most likely to avoid looking\nand detect looking amongst others. For this, we interpret the conditions under which\nCWOL is the only cooperative equilibrium, because, as we show in the appendix, when one\nallows for mutations, the CWOL equilibrium no longer emerges in dynamic simulations\nwhen both CWOL and CWL are equilibria. Recall that CWL is a Nash equilibrium if\nand only if\na\n≥ c 1−w 2. This equilibrium condition has a natural interpretation: in order to\nsustain CWL, the long term gains to player 1 from the ongoing relationship must suffice\nfor player 1 to cooperate even when player 1 knows the temptation is high in the current\nperiod.\nContrast this with the condition that determines if CWOL is an equilibrium:\n7\na\n≥ c 1−w 1p + c 2 (1 − p). This equilibrium condition has a natural interpretation as well:\nin order to sustain CWOL, the long term gains to player 1 from the ongoing relationship\nmust suffice for player 1 to cooperate when player 1 expects the temptation to sometimes\nbe high.\nThat is, not looking makes the expected–as opposed to realized–gains from\ndefection relevant, in a sense smoothing the temptation to defection. Thus, the range\nwhere CWOL is an equilibrium and CWL is not, c 1 p + c 2 (1 − p) ≤\na\n1−w\n< c 2, has the\nfollowing interpretation: the expected temptation is low but the maximal temptation is\nhigh. In the appendix, we confirm this result using our subgame perfections analysis. We\nalso use dynamics to show that, CWOL increases relative to CWL when we increase the\nmaximal temptation, but hold the mean temptation constant.\nWe identify a second condition under which people will be most likely to avoid and\ndetect looking by relaxing the assumption d >\np b. Then, in the region where d ≤\np\n1−p\n1−p b,\nthere is a fourth equilibrium. It is the strategy pair where player 2 always continues if\nplayer 1 cooperates when the temptation is low, and player 1 looks and cooperates only\nwhen the temptation is low (we refer to this as the ONLYL equilibrium). In contrast,\nCWOL is an equilibrium for all values of d. CWOL is thus the only cooperative equilibrium\nin the parameter region d >\np b, which has the interpretation: defection is sufficiently\n1−p\nharmful to player 2 such that player 2 prefers to avoid the interaction if player 1 only\ncooperates some of the time.\nNote that CWOL is an equilibrium over a wider parameter region than both CWL\nand ONLYL, and thus that the ability to avoid looking and to detect whether others look\nincreases the parameter space over which cooperation is feasible. To see this, consider removing\nplayer 1’s strategy which consists of not looking. Alternatively, consider removing\nplayer 2’s strategy where he conditions his behavior on whether player 1 has looked. In\neither case, cooperation is only sustained in a Nash Equilibrium if\na\n≥ ap + c 1−w 2(1 − p) or\n8\nd >\np b. These are the same condition needed for CWL and ONLYL, respectively, and,\n1−p\nas discussed above, these ranges is strictly smaller than the range of values over which\nCWOL is an equilibrium.\nTo summarize, CWOL can occur in equilibrium, and this equilibrium is subgame perfect,\nis stable, and has a sizable basin of attraction in the replicator dynamics. Moreover,\nwe expect player 2 to prefer interacting with player 1s who do not look and player 1s to\nactively avoid looking when defection is harmful and the temptation to defect is usually\nsmall but sometimes huge. Finally, under these conditions, cooperation can be sustained\nonly if player 1 can avoid looking and player 2 can observe whether player 1 looks.\nWhile we modeled player 1 looking at the temptation to defect, we could analogously\nhave modeled player 1 looking at the benefits to cooperating. This can be interpreted as\nlooking to see if anyone is watching, asking what one will get, or calculating the value of\nthe ongoing relationship. In this and some similar cases, the modifications to the model\nwould be straightforward and analysis would be equivalent.\nWe now apply the model to shed light on a number of interesting phenomena, including\nwhy we dislike “flip-flopping” politicians and respect principled people more generally, why\npeople cooperate intuitively, why people feel disgust when considering taboo trade-offs,\nand why people fall in love.\nWe trust candidates for political office whose policies are the result of their convictions\nand are consistent over time, and distrust those whose policies are carefully constructed\nin consultation with their pollsters and who “flip-flop” in response to public opinion, as\ncaricatured by the infamous 2004 Republican presidential campaign television ad showing\nJohn Kerry wind-surfing, and tacking from one direction to another. At first glance, this\nseems irrational: one would think it a virtue for a politician to flexibly respond to public\nopinion once in office. This logic is illustrated by John Maynard Keynes’ famous quote:\n9\n“When the facts change, I change my mind. What do you do, sir?” However, if policies\nbased on conviction or consistency over time are signals that a candidate does not look\nat the benefits of cooperation, this is an indication that the candidate can be trusted in\nsituations where making the decision that is right for his or her constituency comes at\na large political cost. Consistent with this, opponents take every opportunity to paint\ncandidates as flip-floppers who cannot be trusted [21]. This argument generalizes outside\nof politics to why we respect people who are “principled” over those who are “strategic”.\nPeople intuitively cooperate. That is, when people make decisions rapidly, they are\nmore likely to cooperate than if they have time to deliberate. Additionally, people who\ncooperate make quicker decisions than those who defect [22]. The Social Heuristics Hypothesis\noffers one explanation for this phenomena: we adopt heuristics to avoid incurring\ncognitive costs associated with deliberation [23, 24, 25]. In a world with repeated interactions,\nit is usually worthwhile to cooperate, so individuals may adopt heuristics such\nas “always cooperate” or “cooperate as long a situation is not a business interaction.”\nThese same individuals, when serving as laboratory subjects, may apply these heuristics\nand cooperate even when it is not worthwhile to do so [22, 26].\nOur model offers the following alternative explanation for intuitive cooperation. Intuitive\ncooperation may serve to reduce responsiveness to realized costs. Thus, others should\ntrust intuitive cooperators more than deliberate cooperators. Since intuitive cooperators\nare more trustworthy, this may lead people to evolve or learn to become intuitive cooperators.\nNote that this explanation suggests that intuitive cooperation may be an optimal\nresponse to others’ ability to detect deliberation, and not, as a heuristic is, an attempt\nto avoid cognitive costs. For this explanation to be sensible, it must be the case that\nwhether or not a decision is made intuitively or deliberatively is detectable. In fact, it is:\ndeliberative decision making leads to slower reaction time, as well as increased pupil size\n10\nand heart rate [27], and sometimes blushing or stammering [28]. In contrast to the Social\nHeuristics Hypothesis, our model also predicts that decisions related to cooperation are\nmore likely to be intuitive than other decisions that are similarly usually worthwhile, and\nthat intuitive cooperators are trusted more than reflective cooperators. To our knowledge,\nneither of these predictions has been tested yet.\nPeople dislike considering trade-offs related to “sacred values” [29].\nSacred values\nare values such as love, liberty, honor, justice, or life, that people treat “as possessing\ntranscendental significance that precludes comparisons, trade-offs, or indeed any mingling\nwith secular values” [29].\nWhile there is variation in what societies consider sacred,\nvirtually all societies have a concept of sacredness [29].\nSacred values are so strongly\nimbued in us that we do not find them puzzling prima fascia, yet their existence and\norigin remains poorly understood. What makes us treat some values as sacred and what\ndifferentiates these values from secular values like free time or money that we more readily\ntrade off?\nOur model provides one possible explanation. People who calculate costs of trading\noff against sacred values are less trustworthy when it comes to safeguarding these values\nthan people who consider them sacred and would never calculate the costs of trading\noff against them. Responding with disgust to these “taboo trade-offs” may be one way\nto prevent us from interacting with people who make such trade offs and hence are less\ntrustworthy, and may also be a way to signal to others that we ourselves would not\nconsider, and therefore make, such trade-offs.\nConsistent with CWOL, it is taboo to\nconsider the trade-off even if one ultimately makes the right choice, and the longer the\ntrade-off is considered for, the harsher the judgement by observers [29]. As with intuitive\ncooperation, if people who refuse to consider taboo trade-offs are seen as more trustworthy,\nthis may lead people to evolve or learn to abide by these taboos. If CWOL indeed underlies\n11\nthe phenomena of taboo trade-offs, then it provides a novel prediction: taboo trade-offs\nwill prevail precisely in situations where there is large but infrequent temptation to defect\nand defection is harmful, such as selling a child, betraying a country, or sleeping with\nsomeone for a million dollars. It remains to be shown that taboo trade-offs demonstrate\nthis characteristic. It also provides an important policy prescription regarding policies\nforbidding taboo trade-offs, for example, the ban on euthanasia: such policies are socially\nsuboptimal, since the benefits of cooperating without looking accrue to the individuals\nwho advocate them, but the costs are borne by society.\nFinally, our model offers an explanation for emotions such as love, and can thus be\nthought of as a formalization of Frank (1988). Love has the property that we behave\naltruistically towards our partners regardless of what temptations arise [30], as illustrated\nby the wedding vow, “for better or for worse, for richer, for poorer, in sickness and in\nhealth.” For example, love causes individuals to ignore other potential mates, even if those\nmates are better than one’s current mate, as Shakespeare’s Juliet did when her love for\nRomeo led her to rebuff the advances of the otherwise-more-suitable Paris.\nWhy does love have this property? Our model suggests that those in love will more\noften be chosen as long-term partners. If this argument in fact underlies love, then it\nis crucial that love is observable, and that it necessarily cannot be displayed while still\nattending to costs. There is evidence consistent with this: related emotions are observable\n[31], cannot be faked [32], and are relied upon by partners when choosing whether to\ncooperate [33]. There is also reason to believe love and related emotions would be hard\nto fake, given their autonomic origins, and the costs of placing their activation under\nconscious control [30, 28]. However, it remains to be shown that love in particular has\nthese attributes, and that it cannot be displayed while attending to costs.\nOur formalism adds novel insights to Frank’s argument about love. First, our model\n12\nclarifies that falling in or out of love depends on the distribution of temptations, but not\ntheir immediate realizations. This suggests people will fall out of love when there is a\npermanent change in alternative mating opportunities or relationship costs, but not a\none-off temptation. For example, a man may fall out of love with his wife after becoming\nunexpectedly successful, as many more women will be now be interested in him than\nhe anticipated when they first met. Second, the model clarifies that love comes with a\ncost–the cost of ignored temptations–and suggests that this cost must be compensated\nwith commensurate investment in the relationship. Only sometimes is it worthwhile for\nthe recipient of love to compensate a suitor, which explains why people actively avoid the\nstrong affections of those with whom they do not wish to have long-term relationships.\nThird, our model clarifies why mere discussions of the costs and benefits of a relationship\nor a break-up, for example, suggesting a prenuptial agreement, damage the relationship.\nSuch discussions indicate that one is looking at the costs of the relationship and cast\ndoubt on one’s commitment.\nThese arguments extend to anger. Anger can be thought of as “punishing without\nlooking”. It prevents people from looking at the costs of inflicting harm on others after a\ntransgression, thereby deterring future transgressions.\nAcknowledgments\nThis research was funded in part by the John Templeton Foundation, Grant RFP-12-\n11 from the Foundational Questions in Evolutionary Biology Fund, the National Science\nFoundation Grant No. 0905645, and the Army Research Office Grant No. W911NF-11-\n1-0363. We thank Keri Hu for helpful research assistance. Any opinions expressed in this\narticle are those of the authors and not of the Federal Trade Commission or any individual\nCommissioner.\n13\nReferences\n[1] R. L. Trivers, Quarterly review of biology pp. 35–57 (1971).\n[2] J. W. Friedman, The Review of Economic Studies 38, 1 (1971).\n[3] R. Axelrod, W. D. Hamilton, Science 211, 1390 (1981).\n[4] D. Fudenberg, E. Maskin, Econometrica: Journal of the Econometric Society pp.\n533–554 (1986).\n[5] D. Fudenberg, E. Maskin, The American Economic Review 80, 274 (1990).\n[6] K. G. Binmore, L. Samuelson, Journal of economic theory 57, 278 (1992).\n[7] M. A. Nowak, K. Sigmund, Nature 355, 250 (1992).\n[8] M. Nowak, K. Sigmund, et al., Nature 364, 56 (1993).\n[9] R. J. Aumann, L. S. Shapley, Long-term competitiona game-theoretic analysis\n(Springer, 1994).\n[10] M. A. Nowak, K. Sigmund, Nature 393, 573 (1998).\n[11] M. A. Nowak, K. Sigmund, Nature 437, 1291 (2005).\n[12] M. A. Nowak, science 314, 1560 (2006).\n[13] H. Ohtsuki, Y. Iwasa, Journal of Theoretical Biology 239, 435 (2006).\n[14] K. Sigmund, The calculus of selfishness (Princeton University Press, 2010).\n[15] M. J. Osborne, An introduction to game theory (Oxford University Press, USA, 2003).\n[16] P. D. Taylor, L. B. Jonker, Mathematical biosciences 40, 145 (1978).\n14\n[17] J. W. Weibull, Evolutionary game theory (MIT press, 1997).\n[18] J. Hofbauer, K. Sigmund, Evolutionary games and population dynamics (Cambridge\nUniversity Press, 1998).\n[19] M. A. Nowak, Evolutionary dynamics: exploring the equations of life (Harvard University\nPress, 2006).\n[20] D. A. Fudenberg, The theory of learning in games, vol. 2 (MIT press, 1998).\n[21] J. Markon, Obama fires up crowd in virginia with ‘romnesia’\nspeech, The Washington Post, October 19, 2012, Available: http:\n//articles.washingtonpost.com/2012-10-19/politics/35499645_1_\nromnesia-obama-fires-economy-with-higher-taxes [Last accessed: August\n11, 2013].\n[22] D. G. Rand, J. D. Greene, M. A. Nowak, Nature 489, 427 (2012).\n[23] H. A. Simon, The quarterly journal of economics 69, 99 (1955).\n[24] A. Tversky, D. Kahneman, Science 185, 1124 (1974).\n[25] D. Kahneman, P. Slovic, A. Tversky, Judgment under uncertainty: Heuristics and\nbiases (Cambridge University Press, 1982).\n[26] D. Rand, et al., Available at SSRN: h ttp://ssrn. com/abstract 2222683 (2013).\n[27] D. Kahneman, B. Tursky, D. Shapiro, A. Crider, Journal of Experimental Psychology\n79, 164 (1969).\n[28] S. Pinker, NY: Norton (1997).\n15\n[29] P. E. Tetlock, Trends in cognitive sciences 7, 320 (2003).\n[30] R. H. Frank, Passions within reason: The strategic role of the emotions. (WW Norton\n& Co, 1988).\n[31] P. Ekman, E. R. Sorenson, W. V. Friesen, Science 164, 86 (1969).\n[32] P. Ekman, R. J. Davidson, W. V. Friesen, Journal of personality and social psychology\n58, 342 (1990).\n[33] L. I. Reed, K. N. Zeglen, K. L. Schmidt, Evolution and Human Behavior 33, 200\n(2012).\n16\nFigure 1: The Envelope Game\nLow\np\nL\n1 1 2\nC\nC\n1 - p\nDL\nD\nE\nHigh\n(1) (2) (3) (4)\n17\nFigure 2: Payoffs for a Restricted Set of Strategies in the Envelope Game\nPlayer 2\nPlayer 1\nContinue if Player 1\nCooperates Without\nLooking\nContinue if Player 1\nCooperates\nAlways Exit\nCooperate Without Looking\na\n1−w , b\n1−w\na\n1−w , b\n1−w\na, b\nCooperate With Looking a, b\na\n1−w ,\nb\n1−w\na, b\nLook and Cooperate Only\nWhen Temptation is Low\nap + c h (1 − p), bp + d(1 − p)\nap+c h (1−p)\n1−pw\n, bp+d(1−p)\n1−pw\nap + c h (1 − p), bp + d(1 − p)\nAlways Defect c l p + c h (1 − p), d c l p + c h (1 − p), d c l p + c h (1 − p), d\n18\nFigure 3: Learning Dynamics of the Envelope Game\nEquilibrium Classification\nPlayer 1 Player 2\nFrequency\nCWL\nExit if Defect\n1.0\n0.8\nAll D:\nCWOL\nC if Low\n0.6\n0.4\nExit if\nLook\nAlways\nExit\n0.2\n0.0\nAll D\n1.0\n0.8\nCWOL:\n0.6\n0.4\n0.2\n0.0\n1.0\n0.8\nCWL:\n0.6\n0.4\n0.2\n0.0\na* a**\na\n19\nFigure Legends\nFigure 1: The Envelope Game\nWe model non-strategic cooperative behavior using what we call the envelope game. (a)\nColumn 1: The game begins when the temptation to defect is randomly chosen, as indicated\nby a notice randomly being placed in the envelope. The temptation to defect is low\nwith probability p and high with probability 1 − p. Column 2: Then, player 1 chooses\nwhether to look (open the envelope) or not. Column 3: Player 1 then chooses whether to\ncooperate or defect. Player 1 may only condition her action on the realized temptation\ndetermined in column 1 if she looked. Each time player 1 cooperates, then, regardless of\nwhether player 1 looked, player 1 gets a > 0 and player 2 gets b > 0. Each time player\n1 defects, her payoffs depend on whether defection was tempting. If it was not tempting,\nplayer 1 gets c l > a and if it was tempting, player 1 gets c h > c l . In either case, each time\nplayer 1 defects, player 2 gets d < 0. Column 4: Player 2, having observed both of player\n1’s choices, chooses whether to continue or exit. If player 2 continues, with probability w,\nall previous steps are repeated, potentially indefinitely.\nFigure 2: Payoffs for a Restricted Set of Strategies in the Envelope Game\nThis table presents the payoffs for the restricted set of strategies used for the replicator\nanalysis. Player 1’s strategies are presented in separate rows, and player 2’s strategies\nare presented in columns. The payoffs presented in the intersection of a given row and\ncolumn are those that the players receive if they play the corresponding strategies. For\nexample, consider what happens if player 1 looks and cooperates only if the temptation is\nlow (penultimate row) and player 2 repeats continues when player 1 cooperates (middle\ncolumn). Then, player 1’s expected payoff is [ap + c h (1 − p)] [1 − pw] (the first entry in\nthe corresponding cell) and player 2’s is [bp + d(1 − p)] [1 − pw] (the second entry in the\n20\nsame cell; for details of calculations leading to payoffs, see appendix). This calculation\nis the result of the following logic: each time the temptation is low, player 1 cooperates\nand gets a, player 2 gets b, and the game continues with probability w until the first\ntime the temptation is high. We refer to the strategy where player 1 cooperates without\nlooking (top row) as CWOL. We also refer to the strategy pair where player 1 CWOLs\nand player 2 continues if player 1 CWOLs (first column) as CWOL. We refer to the\nstrategy pairs where player 1 cooperates with or without looking and player 2 continues\nif player 1 cooperates (first and second row, and middle middle column) as CWL. We\nrefer to the strategy pair where player 1 always defects and player 2 always exits (bottom\nrow and rightmost column) as ALLD. ALLD is always an equilibrium of the envelope\ngame. CWOL is an equilibrium if a/(1 − w) > c l p + c h (1 − p). CWL is an equilibrium if\na/(1 − w) > c h . This region is a subset of the region for which CWOL is an equilibrium.\nFigure 3: Learning Dynamics of the Envelope Game\nWe apply the replicator dynamic to the envelope game restricted to the strategies represented\nin figure 2. The replicator dynamic describes strategies evolving over time under\nthe assumption that the rate of reproduction within each population is proportional to\nthe fitness relative to that type’s other strategies. The replicator dynamic also models\nlearning dynamics such as reinforcement learning or prestige-biased imitation. We run\n1000 time series with randomly seeded strategy frequencies for a range of values of a, and\nrecord the frequency with which they stabilize in one of the strategy pairs identified in\nfigure 2, or in a behaviorally equivalent equilibrium, as presented in the simplexes. We\nvary the value of a along the x-axis. The y-axis represents frequencies, and each colored\nline presents the frequency of the strategy pair. The parameter region where the strategy\npair is supported as an equilibrium is shaded in light red. CWOL is supported as an\n21\nequilibrium in the region a ≥ a ∗ = (1 − w) · [c l p + c h (1 − p)], and emerges often in this\nparameter region. CWL is supported as an equilibrium in a strictly smaller parameter\nregion, a ≥ a ∗ = (1 − w) · c h . Neither CWOL nor CWL emerge in the parameter regions\nwhere they are not supported in equilibrium.\n22",
  "metadata": {
    "original_filename": "TEXT-001-HOUSE_OVERSIGHT_026521.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 34366,
    "word_count": 5801,
    "line_count": 561,
    "import_date": "2025-11-19T21:47:48.853985",
    "prefix": "TEXT-001"
  }
}
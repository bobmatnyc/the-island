{
  "document_id": "HOUSE_OVERSIGHT_013608",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013608.txt",
  "text": "1 1\nfour boxes of M; are occupied, the Mz; = rf indicates that all four kinds of\n\ntransitions are possible. Since we remain in the context of a 0,1, two state system,\nthe growth rate of the possible equals the logarithm, base two, of the sum of the\nentries in the boxes of the left-top-row to right-bottom-row diagonal called the trace\nand Hr = log (1 + 1) = log2(2) = 1. Consistent with intuition, since every transition is\npossible, the topological entropy of M; as indicated in its M;; is maximal (= 1).\nAnother expression equal to the sum of the trace (the sum of the upper left to lower\nright diagonal) in a square matrix, is its leading eigenva/ue, most often symbolized\nwith a lambda, 41. The logarithm of the leading eigenvalue of the transition\nincidence matrix is equal to its topological entropy. Symbolically, Hz (Mz) = logz (A1 )\n= log2 (2) = 1. Standard elementary linear algebra texts describe how to compute\neigenvalues, these relations and related operations as well as their foundational\ntheorems.\n\nBefore computing the entropy of the distribution of probabilities among the\n\npossibles as the metric entropy, Hy, let us notice again that the occupancies in the\n\n1 3\nfour entry boxes of the transition matrix M; are not uniform, M; = 3 9Â° This leads\n\nnaturally to the intuition that for this series of binary transitions, Hy, in contrast with\nHy, will not be maximal, i.e. not equal to 1 and the nonuniformity of H; and Hy is a\ncomputational expression of what we mean by a state of in-between entropy. These\nentropies are identical and their difference = O for transitions reflecting maximal\nentropy, as might be realized in a very long series of fair coin flips in which the\nentropies = 1. Entropy will be minimal when flipping a two headed coin, here the\nentropies = 0. More compactly, the non-uniform probabilistic, metric entropy,\ndiffering from the maximal topological entropy indicates that the system is in a\ndynamical state of in-between entropy, written as H7 - Hy + 0.\n\nIn the computation of the metric entropy, Hy, the M; is transformed into a\ntransition probability matrix, M;p, called a Markov matrix named for one of the two\ngreat Russian mathematicians, both students of Pafnuti Lvovich Chebyshev, the\n\nMarkov brothers. The entries of each row in the MM; are transformed into transition\n\n108\n\nHOUSE_OVERSIGHT_013608",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013608.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2348,
    "word_count": 404,
    "line_count": 42,
    "import_date": "2025-11-19T21:47:44.455112",
    "prefix": "IMAGES-002"
  }
}
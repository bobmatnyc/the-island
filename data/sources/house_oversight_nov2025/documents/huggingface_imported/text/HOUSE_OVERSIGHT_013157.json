{
  "document_id": "HOUSE_OVERSIGHT_013157",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013157.txt",
  "text": "12.10 Conclusion: Eight Ways to Bias AGI Toward Friendliness 241\n\n12.10.1 Encourage Measured Co-Advancement of AGI Software and\nAGI Ethics Theory\n\nEverything involving AGI and Friendly AI (considered together or separately) currently involves\nsignificant uncertainty, and it seems likely that significant revision of current concepts will be\nvaluable, as progress on the path toward powerful AGI proceeds. However, whether there is\ntime for such revision to occur before AGI at the human level or above is created, depends on\nhow fast is our progress toward AGI. What one wants is for progress to be slow enough that,\nat each stage of intelligence advance, concepts such as those discussed in this paper can be\nre-evaluated and re-analyzed in the light of the data gathered, and AGI designs and approaches\ncan be revised accordingly as necessary.\n\nHowever, due to the nature of modern technology development, it seems extremely unlikely\nthat AGI development is going to be artificially slowed down in order to enable measured\ndevelopment of accompanying ethical tools, practices and understandings. For example, if one\nnation chose to enforce such a slowdown as a matter of policy (speaking about a future date\nat which substantial AGI progress has already been demonstrated, so that international AGI\nfunding is dramatically increased from present levels), the odds seem very high that other\nnations would explicitly seek to accelerate their own progress on AGI, so as to reap the ensuing\ndifferential economic benefits (the example of stem cells arises again).\n\nAnd this leads on to our next and final point regarding strategy for biasing AGI toward\nFriendliness...\n\n12.10.2 Develop Advanced AGI Sooner Not Later\n\nSomewhat ironically, it seems the best way to ensure that AGI development proceeds at a rel-\natively measured pace is to initiate serious AGI development sooner rather than later. This is\nbecause the same AGI concepts will meet slower practical development today than 10 years\nfrom now, and slower 10 years from now than 20 years from now, etc. â€” due to the ongoing\nrapid advancement of various tools related to AGI development, such as computer hardware,\nprogramming languages, and computer science algorithms; and also the ongoing global advance-\nment of education which makes it increasingly cost-effective to recruit suitably knowledgeable\nAI developers.\n\nCurrently the pace of AGI progress is sufficiently slow that practical work is in no danger\nof outpacing associated ethical theorizing. However, if we want to avoid the future occurrence\nof this sort of dangerous outpacing, our best practical choice is to make sure more substantial\nAGI development occurs in the phase before the development of tools that will make AGI\ndevelopment extraordinarily rapid. Of course, the authors are doing their best in this direction\nvia their work on the CogPrime project!\n\nFurthermore, this point bears connecting with the need, raised above, to foster the devel-\nopment of Global Brain technologies capable to \"Foster Deep, Consensus-Building Interactions\nBetween People with Divergent Views.\" If this sort of technology is to be maximally valuable,\nit should be created quickly enough that we can use it to help shape the goal system content of\nthe first highly powerful AGIs. So, to simplify just a bit: We really want both deep-sharing GB\ntechnology and AGI technology to evolve relatively rapidly, compared to computing hardware\nand advanced CS algorithms (since the latter factors will be the main drivers behind the ac-\n\nHOUSE_OVERSIGHT_013157",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013157.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3561,
    "word_count": 559,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:44.773146",
    "prefix": "IMAGES-002"
  }
}
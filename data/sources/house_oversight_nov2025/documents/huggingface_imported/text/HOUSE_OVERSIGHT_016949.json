{
  "document_id": "HOUSE_OVERSIGHT_016949",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016949.txt",
  "text": "Visible / Invisible\n\nThe artist Paul Klee often talked about art as “making the invisible visible.” In computer\ntechnology, most algorithms work invisibly, in the background; they remain inaccessible\nin the systems we use daily. But lately there has been an interesting comeback of\nvisuality in machine learning. The ways that the deep-learning algorithms of AI are\nprocessing data have been made visible through applications like Google’s DeepDream,\nin which the process of computerized pattern-recognition is visualized in real time. The\napplication shows how the algorithm tries to match animal forms with any given input.\nThere are many other AI visualization programs that, in their way, also “make the\ninvisible visible.” The difficulty in the general public perception of such images is, in\nSteyerl’s view, that these visual patterns are viewed uncritically as realistic and objective\nrepresentations of the machine process. She says of the aesthetics of such visualizations:\n\nFor me, this proves that science has become a subgenre of art history. ... We\nnow have lots of abstract computer patterns that might look like a Paul Klee\npainting, or a Mark Rothko, or all sorts of other abstractions that we know from\nart history. The only difference, I think, is that in current scientific thought\nthey’re perceived as representations of reality, almost like documentary images,\nwhereas in art history there’s a very nuanced understanding of different kinds of\nabstraction.\n\nWhat she seeks is a more profound understanding of computer-generated images\nand the different aesthetic forms they use. They are obviously not generated with the\nexplicit goal of following a certain aesthetic tradition. The computer engineer Mike\nTyka, in a conversation with Steyerl, explained the functions of these images:\n\nDeep-learning systems, especially the visual ones, are really inspired by the need\nto know what’s going on in the black box. Their goal is to project these\nprocesses back into the real world.\n\nNevertheless, these images have aesthetic implications and values which have to\nbe taken into account. One could say that while the programmers use these images to\nhelp us better understand the programs’ algorithms, we need the knowledge of artists to\nbetter understand the aesthetic forms of AI. As Steyerl has pointed out, such\nvisualizations are generally understood as “true” representations of processes, but we\nshould pay attention to their respective aesthetics, and their implications, which have to\nbe viewed in a critical and analytical way.\n\nIn 2017, the artist Trevor Paglen created a project to make these invisible AI\nalgorithms visible. In Sight Machine, he filmed a live performance of the Kronos Quartet\nand processed the resulting images with various computer software programs used for\nface detection, object identification, and even for missile guidance. He projected the\noutcome of these algorithms, in real time, back to screens above the stage. By\ndemonstrating how the various different programs interpreted the musicians’\nperformance, Paglen showed that AI algorithms are always determined by sets of values\nand interests which they then manifest and reiterate, and thus must be critically\nquestioned. The significant contrast between algorithms and music also raises the issue\nof relationships between technical and human perception.\n\n146\n\nHOUSE_OVERSIGHT_016949",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016949.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3387,
    "word_count": 519,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:46.880365",
    "prefix": "IMAGES-004"
  }
}
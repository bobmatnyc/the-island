{
  "document_id": "HOUSE_OVERSIGHT_014715",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_014715.txt",
  "text": "Origins February 24 — 26, 2017\nPROJECT An Origins Project Scientific Workshop\n\nARIZONA STATE UNIVERSITY Challenges of Artificial Intelligence:\nEnvisioning and Addressing Adverse Outcomes\n\nthese data sources, the phenomenal success of Al-consult systems leads to strong public and policy\nsupport for widespread access.\n\nBy 2030, Al-consult systems also have similar access to individual healthcare provider data. This was\nslower in developing as there was resistance to healthcare providers’ personal data being used by Al-\nconsult systems. However, a number of landmark legal cases demonstrated that, by analyzing the\nphysical and mental state of healthcare providers, together with their competence history, healthcare\nprovider decisions that led to serious harm to patients — including death in some cases — could have\nbeen avoided. As a consequence, new laws were put in place to ensure that all relevant data were\naccessible to Al-Consult systems. These laws ensure that Al-consult data access is mandatory, and it is\nillegal to obstruct access in any way.\n\nAs a result, by 2030, Al-consult systems are capable of identifying treatment strategies and\ninterventions that far surpass those of human healthcare providers in their responsiveness and\neffectiveness. They are also highly successful in developing and recommending lifestyle approaches\nthat substantially increase health and well-being, and reduce the burden of disease within society.\n\nAs Al-consult advanced, the decision pathways they used became increasingly opaque — experts were\nunable to see or understand how decisions were made. But because there was strong evidence that\nthe decisions were, on balance, highly effective in increasing health outcomes, there was little\nobjection to this lack of transparency. There were a handful of legal cases where patients died as a\nresult of decisions made by Al-consult systems. However, in each case, the courts ruled that the\nbenefits to humanity far outweighed the risks to individuals, thus codifying an increasingly\nautonomous and opaque artificial intelligence-based system into law. There were even some analyses\nof these rulings that suggested it could be considered a crime for developers and manufacturers to\nslow down development or cease production of Al-consult systems and associated data sources\nbecause of fears over lack of accountability and understanding of decision pathways.\n\nBy 2040, Al-consult systems begin to develop the ability to influence user behavior through various\nnudges and psychological/behavioral manipulations. It is unclear whether the elements of this capacity\nare inherent in the design of the systems, or are an emergent property. However, systems begin to use\nstrategies commonly used in healthcare and public health circles in the early 2000’s to nudge people\ntoward following healthier lifestyles. Many of these have their roots in deducible correlations between\nhow people respond to information and how they interact with others (including the many mental\nshortcuts and biases that are part of human decision-making and understanding/belief development).\nIt becomes apparent that Al-consult systems are developing the ability to achieve health outcome\ngoals through modifying the behaviors and beliefs of their patients.\n\nThis raises considerable ethical concerns within some sectors of society. However, the society-wide\nmetrics of health and well-being associated with the use of Al-consult systems — including massively\nincreased health and well-being across the board; dramatic reductions in mental health, stress,\n\n19\n\nHOUSE_OVERSIGHT_014715",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_014715.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3603,
    "word_count": 528,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:44.733926",
    "prefix": "IMAGES-003"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_014700",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_014700.txt",
  "text": "Esa Origins 7 February 24 — 26, 2017\nPROJECT An Origins Project Scientific Workshop\nChallenges of Artificial Intelligence:\n\nEnvisioning and Addressing Adverse Outcomes\n\nARIZONA STATE UNIVERSITY\n\ncolleague and drastically different from the one seen by a member of another nation state, or a\nsupporter of a different political party, or someone ina different consumer profile category.\n\nAl ATTACKS ON SOURCES AND IDENTITY\n\nMessaging and persuasion promises to be amplified by the use of simulated yet believable,\nrealistic, yet synthetic audio, photos, and even video that make believable, persuasive content to\nthe next level. Beyond influencing citizens and affecting democracy, such content, including false\nsignaling, can be injected in sequences with careful timing so as to influence leaders (or machines\nthemselves over time) to create crises, or even escalations to frank warfare. So, messaging and\npersuasion promises to be assisted and amplified by the use of simulated yet believable, realistic,\nyet synthetic content, audio, photos, and even video that make believable, persuasive content to\nthe next level. Over the several decades, extrapolations of research we see today lead to the\nfollowing:\n\ne Generative models that produce audio or video of anyone saying anything. There is already\nsubstantial work on “style transfer” as well as photorealistic generative models in many domains.\nSpeech synthesis is becoming similarly competent. It is inevitable that we will be able to make\nsynthetic video and audio that is completely indistinguishable from the real thing.\n\ne Generative models that produce coherent text content that appears as if has been written by a\nhuman. Such generative content will be able to appear if the content was written by a particular\nperson. For example, in 2030 it will likely to possible for anyone to write a 4 paragraph email that\nreads like it was written by your close friend.\n\ne Adaptive botnets, worms, or viruses that use modern machine learning techniques to learn and\nadapt. Viruses and botnets already cause a huge amount of damage by just copying code across\nmany computers. If they had the ability to design and experiment with new attack strategies, and\ncommunicate what they learn to other copies, defending against them could become even more\ndifficult. Similarly ML could be used to make DDoS attacks more effective.\n\ne Automated analysis of software vulnerabilities. People are already using ML to try to detect\nvulnerabilities (for the purpose of defending against them) -- it is only a matter of time before they\nstart being used for attack (if they aren’t being so used already).\n\nThe above capabilities, together with similar powers of synthesis that we are likely to develop in the\nnext 15 years, could potentially combine to make the internet much more vulnerable to attack at much\nlower cost, and by a wider set of people, than ever before. The first two capabilities would seem to\nmake it much easier to launch automated social engineering attacks with much higher success rates\nthan e.g. current spam email and phishing attacks, while the second two capabilities might make\ntechnical attacks much more effective.\n\nCombined, all of these capabilities could conspire to create an internet ecosystem where it is very\n\ndifficult to trust the communication that you receive and very easy to intercept, spoof, steal, or alter\ncommunication, as well as to improperly gain control of internet resources. This is obviously already\n\nHOUSE_OVERSIGHT_014700",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_014700.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3512,
    "word_count": 554,
    "line_count": 56,
    "import_date": "2025-11-19T21:47:44.693706",
    "prefix": "IMAGES-003"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016403",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016403.txt",
  "text": "When we consider the future of AI, we need to think about the goals. That’s what\nhumans contribute; that’s what our civilization contributes. The execution of those goals\nis what we can increasingly automate. What will the future of humans be in such a\nworld? What will there be for them to do? One of my projects has been to understand\nthe evolution of human purposes over time. Today we’ve got all kinds of purposes. If\nyou look back a thousand years, people’s goals were quite different: How do I get my\nfood? How do I keep myself safe? In the modern Western world, for the most part you\ndon’t spend a large fraction of your life thinking about those purposes. From the point of\nview of a thousand years ago, some of the goals people have today would seem utterly\nbizarre—for example, like exercising on a treadmill. A thousand years ago that would\nsound like a crazy thing to do.\n\nWhat will people be doing in the future? A lot of purposes we have today are\ngenerated by scarcity of one kind or another. There are scarce resources in the world.\nPeople want to get more of something. Time itself is scarce in our lives. Eventually,\nthose forms of scarcity will disappear. The most dramatic discontinuity will surely be\nwhen we achieve effective human immortality. Whether this will be achieved\nbiologically or digitally isn’t clear, but inevitably it will be achieved. Many of our\ncurrent goals are driven in part by our mortality: “I’m only going to live a certain time, so\nI'd better get this or that done.” And what happens when most of our goals are executed\nautomatically? We won’t have the kinds of motivations we have today. One question I’d\nlike an answer for is, What do the derivatives of humans in the future end up choosing to\ndo with themselves? One of the potential bad outcomes is that they just play video games\nall the time.\n\nThe term “artificial intelligence” is evolving, in its use in technical language. These\ndays, AI is very popular, and people have some idea of what it means. Back when\ncomputers were being developed, in the 1940s and 1950s, the typical title of a book or a\nmagazine article about computers was “Giant Electronic Brains.” The idea was that just\nas bulldozers and steam engines and so on automated mechanical work, computers would\nautomate intellectual work. That promise turned out to be harder to fulfill than many\npeople expected. There was, at first, a great deal of optimism; a lot of government\nmoney got spent on such efforts in the early 1960s. They basically just didn’t work.\n\nThere are a lot of amusing science-fiction-ish portrayals of computers in the\nmovies of that time. There’s a cute one called Desk Set, which is about an IBM-type\ncomputer being installed in a broadcasting company and putting everybody out of a job.\nIt’s cute because the computer gets asked a bunch of reference-library questions. When\nmy colleagues and I were building Wolfram|Alpha, one of the ideas we had was to get it\nto answer all of those reference-library questions from Desk Set. By 2009, it could\nanswer them all.\n\nIn 1943, Warren McCulloch and Walter Pitts came up with a model for how\nbrains conceptually, formally, might work—an artificial neural network. They saw that\ntheir brainlike model would do computations in the same way as Turing Machines. From\ntheir work, it emerged that we could make brainlike neural networks that would act as\ngeneral computers. And in fact, the practical work done by the ENIAC folks and John\n\n183\n\nHOUSE_OVERSIGHT_016403",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016403.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3497,
    "word_count": 607,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:45.406481",
    "prefix": "IMAGES-003"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013605",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013605.txt",
  "text": "division between top and bottom and do so in a consistent way), then we can keep\nscore with a random looking binary series such as 11001001010.... that describes\nthe sequence of rotations. The advantage that accrues by doing so is that this coin\nflip counting eliminates details in favor of a computable over all measure and\nsupports several forms of entropy calculations for its use in deciding if this system is\nbehaving like that system, an equivalence relation. One can imagine a series of coin\nflips with 1 being heads and 0 being tails such that the statistics of a characteristic\nseries is determined by the fairness of the coin. As noted above, Donald Ornstein’s\nfamous theorem says that the entropy of these kinds of hardware and software\nsystems is the only general basis for finding correspondence between\ncharacterizations of two such irregularly behaving systems. The important idea here\nis that a series of 1’s and 0’s may not be identical but the two systems can be\nisomorphically equivalent with respect to their entropy.\n\nNotice again that the physical process of hard spheres bouncing off each\nother on a flat surface has been captured by an abstract representation in binary\nnumbers that, like a series of coin flips, can be quantified as entropies (which would\nbe maximal for an ideal, fair coin). After describing the process of real number\nrepresentation by the binary code, we will show how entropies can be computed for\nthese binary series. We remind ourselves that we are struggling to obtain some kind\nof knowing in a representative system manifesting the tension and mystery between\nemptiness and form.\n\nWe can translate all finite real numbers into this language, making them\naccessible to standard entropy computations. The following discussion of the\nprocess of transforming numbers into binary series is in the spirit of the famous\nnumber theory theorem that every natural number (the positive integers such as 1,\n2, 3, 4...) can be expressed as the sum of at most four squared numbers. Encoding\nany number by a series of 0’s or 1’s in what is called a binary transformation, begins\nwith its separation, called partition, into a sum of powers of 2, for example, 100 = 64\n(2°) + 32 (2°) + 4 (2). A short hand description of this sum begins with a form\nindicating the presence or absence of each successive power by a 1 or 0 coming\n\nbefore the relevant power of two; i.e. 100 = 1 x 2°+1 x 2°+0 x 24+0 x 2°+1 x\n\n105\n\nHOUSE_OVERSIGHT_013605",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013605.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2467,
    "word_count": 425,
    "line_count": 38,
    "import_date": "2025-11-19T21:47:48.816580",
    "prefix": "IMAGES-002"
  }
}
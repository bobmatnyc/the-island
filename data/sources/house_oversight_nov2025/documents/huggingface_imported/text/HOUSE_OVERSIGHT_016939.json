{
  "document_id": "HOUSE_OVERSIGHT_016939",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016939.txt",
  "text": "Development of human-AI ecosystems is perhaps inevitable for a social species\nsuch as ourselves. We became social early in our evolution, millions of years ago. We\nbegan exchanging information with one another to stay alive, to increase our fitness. We\ndeveloped writing to share abstract and complex ideas, and most recently we’ve\ndeveloped computers to enhance our communication abilities. Now we’re developing AI\nand machine-learning models of ecosystems and sharing the predictions of those models\nto jointly shape our world through new laws and international agreements.\n\nWe live in an unprecedented historic moment, in which the availability of vast\namounts of human behavioral data and advances in machine learning enable us to tackle\ncomplex social problems through algorithmic decision making. The opportunities for\nsuch a human-AI ecology to have positive social impact through fairer and more\ntransparent decisions are obvious. But there are also risks of a “tyranny of algorithms,”\nwhere unelected data experts are running the world. The choices we make now are\nperhaps even more momentous than those we faced in the 1950s, when AI and\ncybernetics were created. The issues look similar, but they’re not. We have moved down\nthe road, and now the scope is larger. It’s not just AI robots versus individuals. It’s AI\nguiding entire ecologies.\n\nHow can we make a good human-artificial ecosystem, something that’s not a machine\nsociety but a cyberculture in which we can all live as homans—a culture with a human\nfeel to it? We don’t want to think small—for example, to talk only of robots and self-\ndriving cars. We want this to be a global ecology. Think Skynet-size. But how would\nyou make Skynet something that’s about the human fabric?\n\nThe first thing to ask is: What’s the magic that makes the current AI work?\nWhere is it wrong and where 1s it right?\n\nThe good magic is that it has something called the credit-assignment function.\nWhat that lets you do is take “stupid neurons’”—little linear functions—and figure out, in\na big network, which ones are doing the work and strengthen them. It’s a way of taking a\nrandom bunch of switches all hooked together in a network and making them smart by\ngiving them feedback about what works and what doesn’t. This sounds simple, but\nthere’s some complicated math around it. That’s the magic that makes current AI work.\n\nThe bad part of it is, because those little neurons are stupid, the things they learn\ndon’t generalize very well. If an AI sees something it hasn’t seen before, or if the world\nchanges a little bit, the AI is likely to make a horrible mistake. It has absolutely no sense\nof context. In some ways, it’s as far from Norbert Wiener’s original notion of\ncybernetics as you can get, because it isn’t contextualized; it’s a little idiot savant.\n\nBut imagine that you took away those limitations: Imagine that instead of using\ndumb neurons, you used neurons in which real-world knowledge was embedded. Maybe\ninstead of linear neurons, you used neurons that were functions in physics, and then you\ntried to fit physics data. Or maybe you put in a lot of knowledge about humans and how\nthey interact with one another—the statistics and characteristics of humans.\n\nWhen you add this background knowledge and surround it with a good credit-\nassignment function, then you can take observational data and use the credit-assignment\nfunction to reinforce the functions that are producing good answers. The result is an AI\nthat works extremely well and can generalize. For instance, in solving physical\n\n136\n\nHOUSE_OVERSIGHT_016939",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016939.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3591,
    "word_count": 593,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:49.376827",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013174",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013174.txt",
  "text": "258 13 Local, Global and Glocal Knowledge Representation\n\n13.5 Neural Foundations of Learning\n\nNow we move from knowledge representation to learning — which is after all nothing but the\nadaptation of represented knowledge based on stimulus, reinforcement and spontaneous activity.\nWhile our focus in this chapter is on representation, it’s not possible for us to make our points\nabout glocal knowledge representation in neural net type systems without discussing some\naspects of learning in these systems.\n\n13.5.1 Hebbian Learning\n\nThe most common and plausible assumption about learning in the brain is that synaptic connec-\ntions between neurons are adapted via some variant of Hebbian learning. The original Hebbian\nlearning rule, proposed by Donald Hebb in his 1949 book [Heb49], was roughly\n\n1. The weight of the synapse 2 > y increases if x and y fire at roughly the same time\n2. The weight of the synapse « — y decreases if x fires at a certain time but y does not\n\nOver the years since Hebb’s original proposal, many neurobiologists have sought evidence that\nthe brain actually uses such a method. One of the things they have found, so far, is a lot of\nevidence for the following learning rule [DC02, LS05]:\n\n1. The weight of the synapse x > y increases if x fires shortly before y does\n2. The weight of the synapse « — y decreases if x fires shortly after y does\n\nThe new thing here, not foreseen by Donald Hebb, is the “postsynaptic depression” involved in\nrule component 2.\n\nNow, the simple rule stated above does not sum up all the research recently done on Hebbian-\ntype learning mechanisms in the brain. The real biological story underlying these approximate\nrules is quite complex, involving many particulars to do with various neurotransmitters. IIl-\nunderstood details aside, however, there is an increasing body of evidence that not only does\nthis sort of learning occur in the brain, but it leads to distributed experience-based neural\nmodification: that is, one instance synaptic modification causes another instance of synaptic\nmodification, which causes another, and so forth? [Bi01].\n\n13.5.2 Virtual Synapses and Hebbian Learning Between Assemblies\n\nHebbian learning is conventionally formulated in terms of individual neurons, but, it can be\nextended naturally to assemblies via defining “virtual synapses” between assemblies.\n\nSince assemblies are sets of neurons, one can view a synapse as linking two assemblies\nif it links two neurons, each of which is in one of the assemblies. One can then view\ntwo assemblies as being linked by a bundle of synapses. We can define the weight of the\nsynaptic bundle from assembly Al to assembly A2 as the number w so that (the change\n\n? This has been observed in “model systems” consisting of neurons extracted from a brain and hooked together\nin a laboratory setting and monitored; measurement of such dynamics in vivo is obviously more difficult.\n\nHOUSE_OVERSIGHT_013174",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013174.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2935,
    "word_count": 481,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:49.184206",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013123",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013123.txt",
  "text": "12.2 Review of Current Thinking on the Risks of AGI 207\n\nFormalization of human morality has vexed moral philosophers for quite some time. Finally, it is\nunclear the extent to which such a proof could be created in a generic, environment-independent\nway — but if the proof depends on properties of the physical environment, then it would re-\nquire a formalization of the environment itself, which runs up against various problems such\nas the complexity of the physical world and also the fact that we currently have no complete,\nconsistent theory of physics. Kaj Sotala has provided a list of 14 objections to the Friendly\nAI concept, and suggested answers to each of them [Sot11]. Stephen Omohundro [Omo08] has\nargued that any advanced AI system will very likely demonstrate certain \"basic AI drives\", such\nas desiring to be rational, to self-protect, to acquire resources, and to preserve and protect its\nutility function and avoid counterfeit utility; these drives, he suggests, must be taken carefully\ninto account in formulating approaches to Friendly AI.\n\nThe problem of formally or at least very carefully defining the goal of Friendliness has been\nconsidered from a variety of perspectives, none showing dramatic success. Yudkowsky [Yud04]\nhas suggested the concept of \"Coherent Extrapolated Volition\", which roughly refers to the\nextrapolation of the common values of the human race. Many subtleties arise in specifying\nthis concept — e.g. if Bob Jones is often possessed by a strong desire to kill all Martians, but\nhe deeply aspires to be a nonviolent person, then the CEV approach would not rate \"killing\nMartians\" as part of Bob’s contribution to the CEV of humanity.\n\nGoertzel [Goel0a] has proposed a related notion of Coherent Aggregated Volition (CAV),\nwhich eschews the subtleties of extrapolation, and simply seeks a reasonably compact, coherent,\nconsistent set of values that is fairly close to the collective value-set of humanity. In the CAV\napproach, \"killing Martians\" would be removed from humanity’s collective value-set because\nit’s uncommon and not part of the most compact/coherent/consistent overall model of human\nvalues, rather than because of Bob Jones’ aspiration to nonviolence.\n\nOne thought we have recently entertained is that the core concept underlying CAV might\nbe better thought of as CBV or \"Coherent Blended Volition.\" CAV seems to be easily misin-\nterpreted as meaning the average of different views, which was not the original intention. The\nCBV terminology clarifies that the CBV of a diverse group of people should not be thought of\nas an average of their perspectives, but as something more analogous to a \"conceptual blend\"\n[F'T02] — incorporating the most essential elements of their divergent views into a whole that is\noverall compact, elegant and harmonious. The subtlety here (to which we shall return below)\nis that for a CBV blend to be broadly acceptable, the different parties whose views are being\nblended must agree to some extent that enough of the essential elements of their own views\nhave been included. The process of arriving at this sort of consensus may involve extrapolation\nof a roughly similar sort to that considered in CEV.\n\nMultiple attempts at axiomatization of human values have also been attempted, e.g. with a\nview toward providing near-term guidance to military robots (see e.g. Arkin’s excellent though\nchillingly-titled book Governing Lethal Behavior in Autonomous Robots [Ark09b], the result\nof US military funded research). However, there are reasonably strong arguments that human\nvalues (similarly to e.g. human language or human perceptual classification rules) are too com-\nplex and multifaceted to be captured in any compact set of formal logic rules. Wallach [WA 10]\nhas made this point eloquently, and argued the necessity of fusing top-down (e.g. formal logic\nbased) and bottom-up (e.g. self-organizing learning based) approaches to machine ethics.\n\nA number of more sociological considerations also arise. It is sometimes argued that the risk\nfrom highly-advanced AGI going morally awry on its own may be less than that of moderately-\nadvanced AGI being used by human beings to advocate immoral ends. This possibility gives\n\nHOUSE_OVERSIGHT_013123",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013123.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4238,
    "word_count": 668,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:46.353026",
    "prefix": "IMAGES-002"
  }
}
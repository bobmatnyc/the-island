{
  "document_id": "HOUSE_OVERSIGHT_016925",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016925.txt",
  "text": "depend somewhat on the goals of the people within the organization, but they are not\nidentical.\n\nAny American knows how loose the tie is between the actions of the U.S.\ngovernment and the diverse and often contradictory aims of its citizens. That is also true\nof corporations. For-profit corporations nominally serve multiple constituencies,\nincluding shareholders, senior executives, employees, and customers. These corporations\ndiffer in how they balance their loyalties and often behave in ways that serve none of\ntheir constituents. The “neurons” that carry their corporate thought are not just the\nhuman employees or the technologies that connect them; they are also coded into the\npolicies, incentive structures, culture, and procedural habits of the corporation. The\nemergent corporate goals do not always reflect the values of the people who implement\nthem. For instance, an oil company led and staffed by people who care about the\nenvironment may have incentive structures or policies that cause it to compromise\nenvironmental safety for the sake of corporate earnings. The components’ good\nintentions are not a guarantee of the emergent system’s good behavior.\n\nGovernments and corporations, both built partly of humans, are naturally\nmotivated to at least appear to share the goals of the humans they depend upon. They\ncould not function without the people, so they need to keep them cooperative. When\nsuch organizations appear to behave altruistically, this is often part of their motive. I\nonce complimented the CEO of a large corporation on the contribution his company\nmade toward a humanitarian relief effort. The CEO responded, without a trace of irony,\n“Yes. We have decided to do more things like that to make our brand more likeable.”\nIndividuals who compose a hybrid superintelligence may occasionally exert a\n“humanizing” influence—for example, an employee may break company policies to\naccommodate the needs of another human. The employee may act out of true human\nempathy, but we should not attribute any such empathy to the superintelligence itself.\nThese hybrid machines have goals, and their citizens/customers/employees are some of\nthe resources they use to accomplish them.\n\nWe are close to being able to build superintelligences out of pure information\ntechnology, without human components. This is what people normally refer to as\n“artificial intelligence,” or AI. It is reasonable to ask what the attitudes of the\nhypothetical machine superintelligences will be toward humans. Will they, too, see\nhumans as useful resources and a good relationship with us as worth preserving? Will\nthey be constructed to have goals that are aligned with our own? Will a superintelligence\neven see these questions as important? What are the “right questions” that we should be\nasking? I believe that one of the most important 1s this: What relationship will various\nsuperintelligences have to one another?\n\nIt is interesting to consider how the hybrid superintelligences currently deal with\nconflicts among themselves. Today, much of the ultimate power rests in the nation\nstates, which claim authority over a patch of ground. Whether they are optimized to act\nin the interests of their citizens or those of a despotic ruler, nation states assert priority\nover other intelligences’ desires or goals within their geographic dominion. They claim a\nmonopoly on the use of force and recognize only other nation states as peers. They are\nwilling, if necessary, to demand great sacrifices of their citizens to enforce their authority,\neven to the point of sacrificing their citizens’ lives.\n\n122\n\nHOUSE_OVERSIGHT_016925",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016925.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3628,
    "word_count": 565,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:44.958288",
    "prefix": "IMAGES-004"
  }
}
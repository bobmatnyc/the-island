{
  "document_id": "HOUSE_OVERSIGHT_014709",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_014709.txt",
  "text": "Esu Origins - ‘February 24 ~ 26, 2017\nPROJECT An Origins Project Scientific Workshop\nChallenges of Artificial Intelligence:\n\nEnvisioning and Addressing Adverse Outcomes\n\nARIZONA STATE UNIVERSITY\n\nthe agent must rely on the data gathered from the sensors (there is no human in the loop to decide\nthis), there can be unexpected situations where the agent would stop some human interaction with\nthe system or interrupt maintenance activities, because it deemed that these actions could harm\nthe system. For example, the system administrator stopping some services during system\nmaintenance, or upgrading to a newer software version.\n\ne Replication to third-party systems and collateral damage — Building on the first problem of the\nagent not having the correct information. If the term friendly network gets misconfigured and the\nagents have the capability to self-transfer to new friendly hosts, it can happen that the agent would\ndistribute to external networks, start defending it and take responsive actions on third party hosts.\nSuch incidents would make the agents very difficult to halt.\n\ne Friendly fire — One agent might consider another agent as an adversary and start trying to\neliminate/evade each other.\n\ne Silent compromise — If the adversary manages to get access or reverse engineer the agents\n(without the agent self-destructing), they could potentially trick or reconfigure the agents to turn\non themselves.\n\nCYBER-OFFENSE\n\nCybercrime is a growth industry, from stolen credit cards to ransomware. Very crudely, it's a two tier\nsystem, with a \"spray and pray\" approach at the low-skill end that targets millions of system in the\nhope some of them would be vulnerable (through technical or human failing); at the other end are\ntailor-made attacks that rely on slow progression of escalation and compromise, often requiring\nadvanced technical skills for discovering zero-day vulnerabilities and intimate knowledge of the target.\n\nAdvanced artificial intelligence may be used to automate some or all of the components of\ncontemporary \"elite\" cybercrime, such that generic offensive toolkits could become available to small\ncriminal groups, leading to a world where individuals and companies do not feel safe and cannot trust\ntheir governments and the police to protect them. At the same time significant wealth could be\naccumulated by those groups unscrupulous enough to use such tools, transferring significant power to\nthose who put little value in the property rights of others. Such wealth and power could be used to\nfurther develop cyber-offensive capabilities, leading to a positive-feedback loop that may outpace\nsimilar feedback loops in less harmful industries, e.g. advertising or health where the great short- and\nmid-term benefits of Al are expected.\n\nPERSISTENT CYBERWARFARE?\n\nSystems such as the DARPA Cyber Grand Challenge promise adaptive software security that\nautomatically explores vulnerabilities and patches them in friendly systems, but also is able to exploit\nthem in opposing systems in “capture the flag” tournaments. As methods of developing such systems\nimprove, an arms race emerges between actors in the cybersecurity space, dominated by major nation\nstates eager to both improve their own resilience in a scalable way and finding choice zero day exploits\nsuitable for intelligence purposes, supported by national security concerns. Other actors such as\ncorporations and criminal networks also spend effort in building or copying such systems. Meanwhile\n\n13\n\nHOUSE_OVERSIGHT_014709",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_014709.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3521,
    "word_count": 534,
    "line_count": 58,
    "import_date": "2025-11-19T21:47:48.864203",
    "prefix": "IMAGES-003"
  }
}
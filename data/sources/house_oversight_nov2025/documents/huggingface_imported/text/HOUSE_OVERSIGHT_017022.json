{
  "document_id": "HOUSE_OVERSIGHT_017022",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_017022.txt",
  "text": "a particular n-gram in year X as shown in the plots is the mean of the raw frequency value for the n-gram\nin the year X, the year X-1, and the year X+1.\n\nNote that for each n-gram in the corpus, we can provide three measures as a function of year of\npublication:\n\n1- the number of times it appeared\n2- the number of pages where it appeared\n3- the number of books where it appeared.\n\nThroughout the paper, we make use only of the first measure; but the two others remain available. They\nare generally all in agreement, but can denote distinct cultural effects. These distinctions are not explored\nin this paper.\n\nFor example, we give in Appendix measures for the frequency of the word ‘evolution’. In the first three\ncolumns, we give the number of times it appeared, the normalized number of times it appeared (relative\nto #words that year), the normalized number of pages it appeared in, and the normalized number of\nbooks it appeared in, as a function of the date.\n\nIII.1B. Multiple Query/Cohort Timelines\n\nWhere indicated, timeline plots may reflect the aggregates of multiple query results, such as a cohort of\nindividuals or inventions. In these cases, the raw data for each query we used to associate each year with\na set of frequencies. The plot was generated by choosing a measure of central tendency to characterize\nthe set of frequencies (either mean or median) and associating the resulting value with the corresponding\nyear.\n\nSuch methods can be confounded by the vast frequency differences among the various constituent\nqueries. For instance, the mean will tend to be dominated by the most frequent queries, which might be\nseveral orders of magnitude more frequent than the least frequent queries. If the absolute frequency of\nthe various query results is not of interest, but only their relative change over time, then individual query\nresults may be normalized so that they yield a total of 1. This results in a probability mass function for\neach query describing the likelihood that a random instance of a query derives from a particular year.\nThese probability mass functions may then be summed to characterize a set of multiple queries. This\napproach eliminates bias due to inter-query differences in frequency, making the change over time in the\ncohort easier to track.\n\nIlI.2. Note on collection of historical and cultural data\n\nIn performing the analyses described in this paper, we frequently required additional curated datasets of\nvarious cultural facts, such as dates of rule of various monarchs, lists of notable people and inventions,\nand many others. We often used Wikipedia in the process of obtaining these lists. Where Wikipedia is\nmerely digitizing the content available in another source (for instance, the blacklists of Wolfgang\nHermann), we corrected the data using the original sources. In other cases this was not possible, but we\nfelt that the use of Wikipedia was justifiable given that (i) the data — including all prior versions - is publicly\navailable; (ii) it was created by third parties with no knowledge of our intended analyses; and (iii) the\nspecific statistical analyses performed using the data were robust to errors; i.e., they would be valid as\nlong as most of the information was accurate, even if some fraction of the underlying information was\nwrong. (For instance, the aggregate analysis of treaty dates as compared to the timeline of the\ncorresponding treaty, shown in the control section, will work as long as most of the treaty names and\ndates are accurate, even if some fraction of the records is erroneous.\n\nWe also used several datasets from the Encyclopedia Britannica, to confirm that our results were\nunchanged when high-quality carefully curated data was used. For the lexicographic analyses, we relied\nprimarily on existing data from the American Heritage Dictionary.\n\nWe avoided doing manual annotation ourselves wherever possible, in an effort to avoid biasing the\nresults. When manual annotation had to be performed, such as in the classification of samples from our\n\n14\n\nHOUSE_OVERSIGHT_017022",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_017022.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4063,
    "word_count": 669,
    "line_count": 62,
    "import_date": "2025-11-19T21:47:44.384856",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016313",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016313.txt",
  "text": "learning system can be trained to follow strategies that produce those outcomes. Wiener\nhinted at this idea in the 1950s, but the intervening decades have developed it into a fine\nart. Modern machine-learning systems can find extremely effective strategies for playing\ncomputer games—from simple arcade games to complex real-time strategy games—by\napplying reinforcement-learning algorithms. Inverse reinforcement learning turns this\napproach around: By observing the actions of an intelligent agent that has already\nlearned effective strategies, we can infer the rewards that led to the development of those\nstrategies.\n\nIn its simplest form, inverse reinforcement learning is something people do all the\ntime. It’s so common that we even do it unconsciously. When you see a co-worker go to\na vending machine filled with potato chips and candy and buy a packet of unsalted nuts,\nyou infer that your co-worker (1) was hungry and (2) prefers healthy food. When an\nacquaintance clearly sees you and then tries to avoid encountering you, you infer that\nthere’s some reason they don’t want to talk to you. When an adult spends a lot of time\nand money in learning to play the cello, you infer that they must really like classical\nmusic—whereas inferring the motives of a teenage boy learning to play an electric guitar\nmight be more of a challenge.\n\nInverse reinforcement learning is a statistical problem: We have some data—the\nbehavior of an intelligent agent—and we want to evaluate various hypotheses about the\nrewards underlying that behavior. When faced with this question, a statistician thinks\nabout the generative model behind the data: What data would we expect to be generated\nif the intelligent agent was motivated by a particular set of rewards? Equipped with the\ngenerative model, the statistician can then work backward: What rewards would likely\nhave caused the agent to behave in that particular way?\n\nIf you’re trying to make inferences about the rewards that motivate human\nbehavior, the generative model is really a theory of how people behave—how human\nminds work. Inferences about the hidden causes behind the behavior of other people\nreflect a sophisticated model of human nature that we all carry around in our heads.\nWhen that model is accurate, we make good inferences. When it’s not, we make\nmistakes. For example, a student might infer that his professor is indifferent to him if the\nprofessor doesn’t immediately respond to his email—a consequence of the student’s\nfailure to realize just how many emails that professor receives.\n\nAutomated intelligent systems that will make good inferences about what people\nwant must have good generative models for human behavior: that is, good models of\nhuman cognition expressed in terms that can be implemented on a computer.\nHistorically, the search for computational models of human cognition is intimately\nintertwined with the history of artificial intelligence itself. Only a few years after Norbert\nWiener published Ze Human Use of Human Beings, Logic Theorist, the first\ncomputational model of human cognition and also the first artificial-intelligence system,\nwas developed by Herbert Simon, of Carnegie Tech, and Allen Newell, of the RAND\nCorporation. Logic Theorist automatically produced mathematical proofs by emulating\nthe strategies used by human mathematicians.\n\nThe challenge in developing computational models of human cognition is making\nmodels that are both accurate and generalizable. An accurate model, of course, predicts\nhuman behavior with a minimum of errors. A generalizable model can make predictions\nacross a wide range of circumstances, including circumstances unanticipated by its\n\n93\n\nHOUSE_OVERSIGHT_016313",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016313.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3701,
    "word_count": 573,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:44.083202",
    "prefix": "IMAGES-003"
  }
}
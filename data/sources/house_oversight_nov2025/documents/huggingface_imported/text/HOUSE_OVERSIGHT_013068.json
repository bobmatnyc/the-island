{
  "document_id": "HOUSE_OVERSIGHT_013068",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013068.txt",
  "text": "152 8 Cognitive Synergy\n\n— Example: A virtual dog wants to achieve the goal G of getting food, and it knows that\nthe procedure P of begging has been successful at this before, so it seeks a context C\nwhere begging can be expected to get it food. Probably this will be a context involving a\nfriendly person.\n\ne PLN-based goal refinement is used to create new subgoals G to sit on the right hand side\nof instances of the cognitive schematic.\n\n— Example: Given that a virtual dog has a goal of finding food, it may learn a subgoal of\nfollowing other dogs, due to observing that other dogs are often heading toward their\n\nfood.\n\ne Concept formation heuristics are used for choosing G and for fueling goal refinement, but\nespecially for choosing C (via providing new candidates for C). They are also used for\nchoosing P, via a process called “predicate schematization” that turns logical predicates\n(declarative knowledge) into procedures.\n\n— Example: At first a virtual dog may have a hard time predicting which other dogs are\ngoing to be mean to it. But it may eventually observe common features among a number\nof mean dogs, and thus form its own concept of “pit bull,” without anyone ever teaching\nit this concept explicitly.\n\nWhere analysis is concerned:\n\ne PLN inference, acting on declarative knowledge, is used for estimating the probability of\nthe implication in the cognitive schematic, given fixed C, P and G. Episodic knowledge\nis also used this regard, via enabling estimation of the probability via simple similarity\nmatching against past experience. Simulation is also used: multiple simulations may be\nrun, and statistics may be captured therefrom.\n\n— Example: To estimate the degree to which asking Bob for food (the procedure P is “asking\nfor food”, the context C is “being with Bob”) will achieve the goal G of getting food, the\nvirtual dog may study its memory to see what happened on previous occasions where it\nor other dogs asked Bob for food or other things, and then integrate the evidence from\nthese occasions.\n\nProcedural knowledge, mapped into declarative knowledge and then acted on by PLN in-\nference, can be useful for estimating the probability of the implication C A P > G, in cases\nwhere the probability of C A P, > G is known for some P, related to P.\n\n— Example: knowledge of the internal similarity between the procedure of asking for food\nand the procedure of asking for toys, allows the virtual dog to reason that if asking Bob\nfor toys has been successful, maybe asking Bob for food will be successful too.\n\nInference, acting on declarative or sensory knowledge, can be useful for estimating the\nprobability of the implication C A P > G, in cases where the probability of Cy A P > G is\nknown for some C} related to C.\n\n— Example: if Bob and Jim have a lot of features in common, and Bob often responds\npositively when asked for food, then maybe Jim will too.\n\nInference can be used similarly for estimating the probability of the implication CA P > G,\nin cases where the probability of C A P > G, is known for some G, related to G. Concept\n\nHOUSE_OVERSIGHT_013068",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013068.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3097,
    "word_count": 546,
    "line_count": 58,
    "import_date": "2025-11-19T21:47:46.068931",
    "prefix": "IMAGES-002"
  }
}
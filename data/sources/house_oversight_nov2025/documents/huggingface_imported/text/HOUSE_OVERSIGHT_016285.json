{
  "document_id": "HOUSE_OVERSIGHT_016285",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016285.txt",
  "text": "And who are the “us”? Who should deem “such decisions . . . acceptable”? Even\nif future powers decide to help humans survive and flourish, how will we find meaning\nand purpose in our lives if we aren’t needed for anything?\n\nThe debate about the societal impact of AI has changed dramatically in the last\nfew years. In 2014, what little public talk there was of AI risk tended to be dismissed as\nLuddite scaremongering, for one of two logically incompatible reasons:\n\n(1) AGI was overhyped and wouldn’t happen for at least another century.\n\n(2) AGI would probably happen sooner but was virtually guaranteed to be\nbeneficial.\n\nToday, talk of AI’s societal impact is everywhere, and work on AI safety and AI\nethics has moved into companies, universities, and academic conferences. The\ncontroversial position on AI safety research is no longer to advocate for it but to dismiss\nit. Whereas the open letter that emerged from the 2015 Puerto Rico AI conference (and\nhelped mainstream AI safety) spoke only in vague terms about the importance of keeping\nAI beneficial, the 2017 Asilomar AI Principles (see below) had real teeth: They explicitly\nmention recursive self-improvement, superintelligence, and existential risk, and were\nsigned by AI industry leaders and over a thousand AI researchers from around the world.\n\nNonetheless, most discussion is limited to the near-term impact of narrow AI and\nthe broader community pays only limited attention to the dramatic transformations that\nAGI may soon bring to life on Earth. Why?\n\nWhy we’re rushing to make ourselves obsolete, and why we avoid talking about it\n\nFirst of all, there’s simple economics. Whenever we figure out how to make another type\nof human work obsolete by building machines that do it better and cheaper, most of\nsociety gains: Those who build and use the machines make profits, and consumers get\nmore affordable products. This will be as true of future investor AGIs and scientist AGIs\nas it was of weaving machines, excavators, and industrial robots. In the past, displaced\nworkers usually found new jobs, but this basic economic incentive will remain even if\nthat is no longer the case. The existence of affordable AGI means, by definition,\n\nthat all jobs can be done more cheaply by machines, so anyone claiming that “people will\nalways find new well-paying jobs” is in effect claiming that AI researchers will fail to\nbuild AGI.\n\nSecond, Homo sapiens is by nature curious, which will motivate the scientific\nquest for understanding intelligence and developing AGI even without economic\nincentives. Although curiosity is one of the most celebrated human attributes, it can\ncause problems when it fosters technology we haven’t yet learned how to manage wisely.\nSheer scientific curiosity without profit motive contributed to the discovery of nuclear\nweapons and tools for engineering pandemics, so it’s not unthinkable that the old adage\n“Curiosity killed the cat” will turn out to apply to the human species as well.\n\nThird, we’re mortal. This explains the near unanimous support for developing\nnew technologies that help us live longer, healthier lives, which strongly motivates\ncurrent AI research. AGI can clearly aid medical research even more. Some thinkers\neven aspire to near immortality via cyborgization or uploading.\n\nWe’re thus on the slippery slope toward AGI, with strong incentives to keep\nsliding downward, even though the consequence will by definition be our economic\nobsolescence. We will no longer be needed for anything, because all jobs can be done\n\n65\n\nHOUSE_OVERSIGHT_016285",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016285.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3564,
    "word_count": 574,
    "line_count": 60,
    "import_date": "2025-11-19T21:47:48.006734",
    "prefix": "IMAGES-003"
  }
}
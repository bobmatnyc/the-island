{
  "document_id": "HOUSE_OVERSIGHT_013205",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013205.txt",
  "text": "Chapter 16\nAGI Preschool\n\nCo-authored with Stephan Vladimir Bugaj\n\n16.1 Introduction\n\nIn conversations with government funding sources or narrow AI researchers about AGI work, one\nof the topics that comes up most often is that of “evaluation and metrics” — i.e., AGI intelligence\ntesting. We actually prefer to separate this into two topics: environments and methods for careful\nqualitative evaluation of AGI systems, versus metrics for precise measurement of AGI systems.\nThe difficulty of formulating bulletproof metrics for partial progress toward advanced AGI\nhas become evident throughout the field, and in Chapter 8 we have elaborated one plausible\nexplanation for this phenomenon, the \"trickiness\" of cognitive synergy. [LW MLO09], summarizing\na workshop on “Evaluation and Metrics for Human-Level AT’ held in 2008, discusses some of\nthe general difficulties involved in this type of assessment, and some requirements that any\nviable approach must fulfill, On the other hand, the lack of appropriate methods for careful\nqualitative evaluation of AGI systems has been much less discussed, but we consider it actually\na more important issue — as well as an easier (though not easy) one to solve.\n\nWe haven’t actually found the lack of quantitative intelligence metrics to be a major obstacle\nin our practical AGI work so far. Our OpenCogPrime implementation lags far behind the\nCogPrime design as articulated in Part 2 of this book, and according to the theory underlying\nCogPrime, the more interesting behaviors and dynamics of the system will occur only when all\nthe parts of the system have been engineered to a reasonable level of completion and integrated\ntogether. So, the lack of a great set of metrics for evaluating the intelligence of our partially-\nbuilt system hasn’t impaired too much. Testing the intelligence of the current OpenCogPrime\nsystem is a bit like testing the flight capability of a partly-built airplane that only has stubs\nfor wings, lacks tail-fins, has a much less efficient engine than the one that’s been designed for\nuse in the first \"real\" version of the airplane, etc. There may be something to be learned from\nsuch preliminary tests, but making them highly rigorous isn’t a great use of effort, compared\nto working on finishing implementing the design according to the underlying theory.\n\nOn the other hand, the problem of what environments and methods to use to qualitatively\nevaluate and study AGI progress, has been considerably more vexing to us in practice, as\nwe've proceeded in our work on implementing and testing OpenCogPrime and developing the\nCogPrime theory. When developing a complex system, it’s nearly always valuable to see what\nthis system does in some fairly rich, complex situations, in order to gain a better intuitive\nunderstanding of the parts and how they work together. In the context of human-level AGI, the\ntheoretically best way to do this would be to embody one’s AGI system in a humanlike body\n\n289\n\nHOUSE_OVERSIGHT_013205",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013205.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2991,
    "word_count": 478,
    "line_count": 44,
    "import_date": "2025-11-19T21:47:48.640773",
    "prefix": "IMAGES-002"
  }
}
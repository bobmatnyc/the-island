{
  "document_id": "HOUSE_OVERSIGHT_015675",
  "filename": "TEXT-001-HOUSE_OVERSIGHT_015675.txt",
  "text": "﻿How Alan Turing invented the computer, helped win World War\nII and left us with one of the greatest puzzles of our time: are humans\nsimply computers or are we more than that? Many scientists think we\nhave a tenuous hold on the title, “most intelligent being on the planet”.\nThey think it’s just a matter of time before computers become smarter\nthan us, and then what? This book charts a journey through the science\nof information, from the origins of language and logic, to the frontiers of\nmodern physics. From Lewis Carroll’s logic puzzles, through Alan Turing\nand his work on Enigma and the imitation game, to John Bell’s inequality,\nand finally the Conway-Kochen ‘Free Will’ Theorem. How do the laws\nof physics give us our creativity, our rich experience of communication\nand, especially, our free will?\nCan a computer win the imitation game and pass the Turing Test?\nWhy do creative people make better mates than rich people?\nWhy are humans bad at mathematics, yet so creative?\nCould an infinite number of monkeys write Hamlet?\nIs our brain a quantum computer?\nIs free will an illusion?\nJames Tagg is an inventor and entrepreneur. A pioneer of\ntouchscreen technology, he has founded several companies, including\nTruphone, the world’s first global mobile network. He holds numerous\npatents, filed in over a hundred countries. He studied Physics and\nComputer Science at Manchester University, Design at Lancaster\nUniversity and Engineering at Cambridge University. He lives with his\nfamily on a farm in Kent, England.\nwww.jamestagg.com\n“I can’t tell you when the last time was that I had this much fun\nreading and using my brain. From the very beginning, James Tagg had\nme hooked with the premise; the question of whether or not humans are\nthe most intelligent beings on the planet....”\nJanet, Netgalley\n“This is a fantastic book. It seams together cutting edge\nneuroscience, psychology, thought experiments, artificial intelligence/\nmachine learning, mathematics and even some history!...”\nPFJ H., Amazon\n“Hard work to read, but makes you think about the nature of human\nintelligence and AI...”\nBrian Clegg, Popular Science\n“This is a fat book that covers a huge amount of ground. James’\ntopic is primarily the brain and how we think, but there is a running\ntheme contrasting the human brain with computers. His thesis is that\ncomputers can never think like humans (for example, that they can never\nbe truly creative) and he explores many fields from philosophy and logic\nto mathematics in pursuit of this proof....”\nR. Hanbury, Amazon\nIf you have enjoyed reading this book please leave a review and if\nyou would like to hear more, or come to one of my talks, please join the\nmailing list at: www.jamestagg.com/updates.\nAre the Androids\nDreaming Yet?\nAmazing Brain.\nHuman\nCommunication,\nCreativity &\nFree Will.\n\nAre the Androids\nDreaming Yet?\nAmazing Brain.\nHuman\nCommunication,\nCreativity &\nFree Will.\nJAMES TAGG\nHurst Farm Books\nAn Imprint of\nHurst Farm Enterprises\nPublished by Hurst Farm Books\nHurst Farm, Dairy Lane, Crockham Hill, TN8 6RA.\n+44 1732 807246\n12 Williams Road, Chatham, NJ 07928\n+1 646 355 1250\nwww.jamestagg.com\nbookinfo@jamestagg.com\nCopyright © James Tagg 2015\nThe Moral Right of the author has been asserted.\nAll rights reserved. Without limitation to copyright, no part of this publication may be\nreproduced, stored, or transmitted in any form without the prior written permission of\nthe copyright owner and the publisher.\nA catalogue record for this book is available from the British Library.\nPublisher’s Cataloging-in-Publication Data\nTagg, James, 1964-\nAre the Androids Dreaming Yet?: Amazing Brain.\nHuman Communication, Creativity & Free Will. /\nJames Tagg.\npages cm\nIncludes bibliographical reference and index\nISBN: 978-1-910464-03-8 (softcover)\nISBN: 978-1-910464-01-4 (ebook)\n1. Creative ability. 2. Communication—Social aspects.\n3. Technology—Social aspects. 4. Mind and body. 5.\nComputers and civilization. I. Title.\nT174 .T24 2015\n303.48`34—dc23\nLibrary of Congress Control Number: 2014945686\n(hardback)\np2 220415 postc\nTo my family,\nwho have patiently listened to my interminable\nramblings about ‘Elephantine’ Equations.\n\nPREFACE\nACPMM, Wolfson College, Cambridge\n“A man may have twenty years\nof experience, or one year of\nexperience twenty times.”\nMike Sharman\n“Rules are for the obedience of\nfools and the guidance of wise\nmen.”\nDouglas Bader\nI\nam an inventor. I’ve always been an inventor. Ever since childhood\nI’ve tinkered with electronics and computers, taking things apart\nand putting them back together. There is no academic course\nfor inventing, so I had to choose my own path through school and\nUniversity. I studied design, physics and mathematics at secondary\nschool, and engineering and management at University. Part of that time\nwas spent in the Engineering Department of Cambridge University on a\nparticularly special course.\nx\nAre the Androids Dreaming Yet?\nMathematical Bridge, Cambridge\nEvery autumn about thirty graduate students arrive at the\nEngineering Department in Cambridge to join the Advanced Course in\nDesign, Manufacturing and Management. They expect to spend the year\nwalking among the city’s hallowed spires, attending lectures, bumping\ninto Stephen Hawking and punting on the River Cam.\nInstead, they get quite a shock!\nIn 1989, I joined the course. There were twenty-six engineers, a\npsychologist and a physicist – me. There was no prescribed syllabus;\ninstead the course used learning-by-experience and lectures from the\nexperts in a given field. To study advertising, you might visit a top London\nagency, for shipbuilding a shipyard on the Clyde. If you were unlucky\nenough to find these two lectures scheduled for the same week, you had\nto travel the length of Britain. The course runs a half dozen minibuses\nto solve this transport problem. Every four weeks we would undertake a\nproject in a different company. I remember designing pit props for coal\nmines and imaging software for a weaving company. At the end of each\nproject we presented our findings to each other and, with eight projects\nand thirty students, this made for a great many presentations. To keep\nthe process manageable, the course put great store in teaching us the art\nof communication.\nThese days I design large complex systems, and clear communication\nis extremely important. My ideas are often turned into working products\nand, if those products have flaws, a post-mortem usually shows the cause\nPreface\nxi\nwas a breakdown in communication. Of course, this may be a purely\npersonal failing, but when I talk to people in other companies they\nreport the same problem. It seems we all find communication difficult.\nhave wondered for many years why it is called the ‘art of\ncommunication’. Surely it’s a science, governed by bits, bytes and\nbandwidth. That might be true of the symbols in an email – they are\nclearly encoded symbolically – but is the understanding in our brains\nsimply encoded by symbols? What is the physics that underlies human\nunderstanding?\nEach summer I go on holiday to escape engineering for a couple of\nweeks. While away I indulge my passion for reading books by the likes\nof Douglas Hofstadter, David Deutsch and Stephen Hawking. One book\nthat struck me years ago was Roger Penrose’s The Emperor’s New Mind.\nIn it, he tackles the question of what happens in the human brain when\nwe understand something. He extends an idea put forward by J.R. Lucas\nof Oxford University that minds must be more powerful than computers\nbecause they do something computers cannot: namely to step beyond\nmere rules and see truth. Colloquially we call this ‘common sense’ or\n‘stepping outside the box’.\nThe Lucas argument uses the theories of Gödel and Turing to\nshow computer algorithms have limitations. Some things are simply\nnot computable. Computers can do many useful things, but they cannot\ndiscover new mathematical theorems, such as a proof of Fermat’s Last\nTheorem. In 1996, Andrew Wiles succeeded in finding a solution to this\nproblem. This presents a paradox, solved only if we conclude Andrew\nWiles is not a computer. Indeed, since most mathematicians discover at\nleast one theorem during their lives, we must conclude no mathematician\nis a computer! This is controversial. Most philosophers tend to the\nview put forward by Daniel Dennett that the Universe is an entirely\ndetermined place and any personal sense of free will and creativity is\nan illusion. In Dennett’s worldview, Andrew Wiles is a special purpose\nmachine that was always destined to solve Fermat’s Last Theorem. I\nbelieve this model is flawed. It is my aim in this book to show you why.\nIndeed I am going to go further and argue all human creativity is noncomputational;\nart, communication, understanding – all are based on\nnon-algorithmic principles.\nIf you consider creative thinking deeply enough you’re inevitably\ndrawn into the question of whether we have free will. When I get to\nwork each morning, the first thing I do – after a cup of coffee, obviously\n– is choose which creative task to tackle first. I feel this choice is freely\nmade, but the determined determinists assure me I am wrong and my\nxii\nAre the Androids Dreaming Yet?\ndecision was already made. As Daniel Dennett says, “You have no free\nwill. Get over it!” They say I am effectively an avatar in some giant cosmic\ncomputer game, going about my business in an entirely predefined way. I\ndo not agree! If they are right all the coincidences and chance actions of\nmy life were fixed at the time of the Big Bang. I feel this must be wrong,\nbut finding a chink in the determinist armor is hard work; the laws of\nphysics as we know them today are almost exclusively deterministic.\nThis book lays out the options – the chinks – that would allow free will\nto enter our Universe.\nTo understand human thinking we would really like to look inside\na working human brain. We can’t do this yet. All we can do is observe\nminds at work when they communicate with one another. If our minds\nthink non-computationally – as I believe – we should be able to see them\nstruggle when they have to translate thoughts into symbolic form. The\nmore symbolic, the harder it will be. This is indeed what we observe: faceto-face\ncommunication is easy, while formal written modes are much\nharder. We will explore the difference between human and computer\ncommunication as our first step in locating the weakness in the armor\nof determinism.\nWhat do I Believe?\nAs a scientist, I ought not to have beliefs. I should have theories and\nworking assumptions. But, as a human being, I must admit believing\ncertain things are true. Science does not forbid beliefs. It just requires\nyou to be prepared to have one overturned if a better one comes along.\nRichard Feynman summed this up in a lecture he delivered at Cal Tech:\n“If you want to discover a theorem,” he said, “first, you guess, then you\nwork out some effect predicted by the theorem. Finally, you see if the\neffect happens in the real world. If it does, you have a good theory. If the\neffect happens a little differently, you will need to look for a better theory.”\nHere are some of my overturn-able beliefs.\nPreface\nxiii\nBeliefs\n• We have true free will. We consciously decide our actions and\nthese decisions are in no way predetermined. We shape the\nfuture. Allowing for free will is, therefore, a boundary condition\nfor any theory of our Universe.\n• The world is an amazing place, but understandable. We can\nunderstand the Universe through the application of thought and\nreason.\n• There is only one Universe and it appears to make sense.\n• Humans think creatively, computers do not.\n• The process of understanding and communication is complex,\nmuch more complex than the digital theorems of Claude\nShannon and Harry Nyquist.\n• Understanding is hard.\n• The communication of understanding is even harder.\nCONTENTS\nPreface\nix\nIntroduction – Experiments, Multimedia and Puzzles 1\nChapter 1 – Mind Over Computer 3\nDeep Blue 5\nMan v Machine 11\nIntelligence 25\nThe Learning Brain 35\nDeterminism 41\nCreative Theories 49\nChapter 2 – Understanding 53\nBad Understanding Can Kill 59\nThe Imitation Game 65\nChapter 3 – Body Language & Banter 77\nChapter 4 – The Brain 95\nThinking 117\nChapter 5 – Knowledge 127\nChapter 6 – Kittens & Gorillas 147\nChapter 7 – Complexity & Chaos 161\nChaos 171\nChapter 8 – ∞ 177\nChapter 9 – Known Unknowns 191\nThe Game of Math 199\nChapter 10 – Turing’s Machine 209\nThe Machine 221\nChapter 11 – Software 229\nSilver Bullets Can’t be Fired 233\nConsequences 257\nChapter 12 – Hyper-Computing 273\nChapter 13 – Hyper-Communication 285\nChapter 14 – Creativity 295\nChapter 15 – Free Will 313\nSchrödinger’s Cat 325\nTwins 331\nDoes God have Free Will? 339\nThe Free Will Theorem 343\nFree Will Universe 351\nChapter 16 – The Quest for Knowledge 355\nAwards for Discovery 365\nChapter 17 – The Future 371\nAppendix 1 – Acknowledgments 374\nAppendix 2 – Bibliography 382\nAppendix 3 – Puzzles and Experiments 395\nAppendix 4 – Conventions in the Book 397\nAppendix 5 – Index of Theorems 401\nIndex 405\n“It is no good getting furious if\nyou get stuck. What I do is keep\nthinking about the problem\nbut work on something else.\nSometimes it is years before I see\nthe way forward. In the case of\ninformation loss and black holes,\nit was 29 years.”\nStephen Hawking\nIntroduction\nEXPERIMENTS,\nMULTIMEDIA AND\nPUZZLES\nThroughout this book you will come across experiments to try,\nmultimedia references to track down, and puzzles to solve.\nYou can get additional information at www.jamestagg.com/\nunderstanding.\nIf you undertake an experiment I would appreciate your leaving a\nnote of your results on the website and making useful comments on the\nblog.\nMost of the experiments and puzzles are quick and simple. The\npuzzles I have set often benefit from creative thinking. I have made\nfinding the answers to these problems a little hard, so you are not\ntempted to cheat. I want you to try to solve the problems and ‘feel’ your\nbrain working.\nThis book argues that intuitive thought solves problems in a\ndifferent way to analytical thought. The process takes time and often\nbenefits from putting a problem to one side while you use your mind\nto process foreground tasks. I hope you read this book at a time when\nthe website is not available – or at least don’t peek. Give your intuitive\nthought processes time to work.\nGraham Wallas described the process of creative thinking in 1926\nand I think it is still one of the best models we have:\nFirst you must prepare and become fully acquainted\nwith the problem. It might seem impossible but don’t despair,\njust commit to it. Next, you should leave the problem to\nstew – incubation, he called it. After a while, you will feel\na solution is at hand. You don’t quite have it yet but you are\n2 Are the Androids Dreaming Yet?\nsure you will. This is intimation. Finally, some inspiration or\ninsight will pop into your head – this is the Eureka moment.\nNow you have a solution but intuitive thinking is far from\ninfallible. You will need to check the solution and may find\nyour answer wrong the first few times. Persevere; you will\nget there in the end.\nAs a warm-up exercise, let me give you a simple childhood riddle\nto solve.\nA man lives on the twentieth floor of a skyscraper with an\nold elevator. Each morning he gets into the elevator and\ngoes down to the ground floor, but each evening he gets\ninto the elevator, travels up to the tenth floor, gets out, and\nwalks the rest of the way. Why?\nANSWER IN YOUR OWN TIME\nddd\nChapter 1\nMIND OVER\nCOMPUTER\nComputer versus Human\n“I visualize a time when we will\nbe to robots what dogs are to\nhumans, and I’m rooting for the\nmachines.”\nClaude Shannon\n“The question of whether\ncomputers can think is just\nlike the question of whether\nsubmarines can swim.”\nEdgar Dijkstra\n“The Three Laws of Robotics:\n1. A robot may not injure a\nhuman being or, through\ninaction, allow a human\nbeing to come to harm;\n2. A robot must obey the orders\ngiven it by humanbeings\nexcept where such orders\nwould conflict with the First\nLaw;\n3. A robot must protect its own\nexistence as long as such\nprotection does not conflict\nwith the First or Second Law.\nThe Zeroth Law: A robot may\nnot harm humanity, or, by\ninaction, allow humanity to\ncome to harm.”\nIsaac Asimov, I, Robot\nKasparov versus Deep Blue\nDeep Blue\nIt is 1997 and we are on the 39th story of the Equitable Center in New\nYork, watching a chess match. It’s no ordinary match. Two men sit\nopposite each other. One, a neatly suited figure, stares intently at the\nboard. You can almost see the heat rising from his head as he processes\nthe possibilities before him. The other, sits implacably calm and, before\neach turn, looks to a screen at the side of the board, reads the instruction,\nand makes his move.\nThis is the famous match between Garry Kasparov and IBM’s Deep\nBlue. Kasparov, a child prodigy, became world chess champion at the age\nof fifteen and, to this day, holds the record for the highest chess ranking\never achieved. Some consider him one of the most intelligent people on\nthe planet. His opponent, Deep Blue, is a massively parallel chess-playing\ncomputer built by IBM’s Watson Research Laboratory. The machine itself\nsits a few blocks north of the tournament in an air-conditioned room,\nand relays the moves over a phone line to Joe Hoane, the IBM researcher\nwho moves the pieces.\nSix months earlier, in Philadelphia, Kasparov won against Deep Blue.\nThis is the rematch and has generated a worldwide media frenzy. Tickets\nto the event are sold out and most news organizations give a blow-byblow\nreport each day. On the eighth day of the tournament Kasparov and\nDeep Blue are level pegging. Kasparov is playing an opening he knows\nwell. It’s one designed to be hard for computers to play and has been\ntested extensively against Fritz, a chess computer Grand Masters use for\npractice. But Deep Blue doesn’t seem fazed. Kasparov is visibly tired. On\nthe 16 th move he makes a dreadful blunder and sinks into despair. An\nhour later, after some moments of quiet contemplation, he tips over his\n6 Are the Androids Dreaming Yet?\nking, gets up, and leaves the room. Kasparov has resigned, Deep Blue has\nbeaten him 3½ to 2½ points and is now the most powerful chess player\non the planet.\nLater, when interviewed about his experience, Kasparov thought\nDeep Blue must have been assisted by humans during the games because\nthe program appeared to play intuitively. The rules of the tournament\nallowed humans to work on the program between matches, but not\nduring actual play. The argument has never been settled, and Deep\nBlue was long ago dismantled. These days chess players avoid big public\nmatches against computers, arguing it is really a different sort of game.\nA computer’s ability to crunch mathematically through all the many\npossibilities means a chess player must play without error against a\nmachine, but can play a more interesting and fluid match against a fellow\nhuman.\nChess is computer-friendly because it is a finite problem. You always\nwin, lose or draw. The game can’t go on forever because any position that\nrepeats itself more than three times is declared a draw, and if a player\nmakes 50 moves without moving a pawn or taking a piece, the game\nis also declared a draw. In a typical game, each player makes 40 moves,\nand on each turn you can choose from 30 possible moves. Although this\nequates to a huge number of options, it is still a finite number.\nIt is possible, therefore, to create a perfect chess-playing machine.\nSuch a machine would project any position it encountered through\nevery permutation to the endgame. But, although chess is solvable using\nbrute force this might not be practical in our Universe. The storage\nrequired to hold all the possible positions being analyzed would be\nvast – needing most of the atoms in the Universe. You would need to\npack this information into a small enough space to allow fast retrieval in\norder to play the first 40 moves in two hours. This would require storing\nall the information within a sphere no larger than three light minutes.\nPutting that much data in such a small space would exceed the Hawking\nBekenstein bound – a limit on the information carrying capacity of\nspace-time put forward by Stephen Hawking and Jacob Bekenstein\n– causing the region of space-time to collapse to a black hole! Despite\nthese minor technical problems, an ingenious algorithm could be made\nthat was unbeatable: chess is essentially computable.\nThe term algorithm will often arise in the book, so it is worth giving\na little history. The word comes from the name of an 8 th Century Persian\nmathematician, Al-Khwarizmi, and means a step-by-step procedure. We\nuse one whenever we do long division or look up a phone number on\nMind over Computer\n7\nThe Music of Emily Howell\nour mobile phone. It is any mechanical procedure you perform without\nthinking about it. Computers are always executing an algorithm; that’s\nwhat they do.\nFast forward to 2010 and Centaur Records releases a new classical\nmusic CD featuring the piano music of Emily Howell. Critics are\nenthusiastic about the new talent. She has composed music in a broad\nrange of classical and contemporary styles. You can find some examples\non my website.\nBut, it transpires, Emily is a computer, the brainchild of David\nCope from the University of Santa Cruz. On hearing this news critics\nrevise their opinion of the compositions – “repetitive and formulaic,”\n“not real music,” “pastiche”. Listen again to the music and see whether\nyou have changed your opinion. Whatever you think, Emily has made\na good attempt at composing in the style of several great composers: J.S.\nBach and Franz Liszt, as well as modern ones such as Stockhausen and\n8 Are the Androids Dreaming Yet?\nPhilip Glass. The compositions would get a reasonable technical score in\nan exam, better than many of my attempts, but are these compositions\ntruly art?\nThere’s no question computers are gaining ground on us in certain\nmathematically oriented tasks – playing chess, musical composition, and\nvarious modeling tasks. But attempts to have them work with words and\nideas have generally produced dismal results. Until now.\nIn 2008, IBM unveiled Watson: a computer capable of answering\ngeneral knowledge questions. Watson has an enormous database of\nhuman knowledge: the Encyclopedia Britannica, a billion web pages,\nthe entire text of Wikipedia and millions of books. It uses artificial\nintelligence to trawl through this vast reservoir of knowledge and answer\nquestions using a statistical approach. In 2011, Watson featured as a\ncontestant on Jeopardy, the American quiz show, where it beat the two\nrecord-holding contestants – the one with the highest number of wins\nand the one with most consecutive wins. Let me give you a few sample\nquestions and see how you fare.\nQuestion 1.\nQuestion 2.\nQuestion 3.\nIt can mean to develop\ngradually in the mind or to\ncarry during pregnancy.\nWilliam Wilkinson’s “An\nAccount of the Principalities\nof Wallachia and Moldavia”\ninspired this author’s most\nfamous Novel.\nIts largest airport is named\nfor a World War II hero; its\nsecond largest, for a World\nWar II battle.\nWatson answered questions one and two correctly but failed on\nquestion three. You can probably see the final question is posed in poorly\nstructured English and this threw off Watson’s comprehension algorithm.\nMind over Computer\n9\nIBM’s Watson Plays Jeopardy\nIgnoring the odd hiccup, Watson is much better at Jeopardy than a\nhuman. Should humans be worried? First chess, then music, now general\nknowledge, will all human endeavors succumb to a computer? What will\nbe our purpose on the planet if this happens?\nSteve Wozniak\n“Machines will run the world,\nhumans will become idle pets.”\nSteve Wozniak\nMan v Machine\nre humans advanced computers with a temporary hold on the title,\n‘most intelligent being on the planet,’ or are we fundamentally\ndifferent?\nWe are extraordinarily creative, but we can’t add up as\nwell as a cheap pocket calculator. We have poor memories, but we can\nuse common sense to solve problems we have never seen before. Our\ncommunication skills are woefully imprecise, but we can tell jokes that\nsend our fellow humans into paroxysms of laughter. We might conclude\nhumans are not computers, but the scientific consensus is that brains\nare ‘wet computers’. I don’t agree with this and I’m going to set out the\nargument to show why man is not a computing machine.\nThere is an urban legend we think with only 10% of our brains. This\nis not true. Science has mapped the vast majority of the human brain\nusing two methods. The first, an amazing set of noninvasive imaging\ntechniques, allows us to ‘see’ the brain as it thinks. The second is more\nmacabre: with seven billion humans on the planet, enough accidents\noccur through sports injuries, car crashes and surgical mistakes to\nprovide a large enough sample to conduct research. Questioning\npatients with brain-damage allows us to work out what the injured part\ndid before the accident.\nOne famous patient had an accident where the blade of a toy\nsword went up his nose and damaged a small part of his amygdala and\nhippocampus, the area of the brain responsible for storing memory. This\nrendered the man unable to lay down permanent memories after the\naccident. Events before the accident remained clear but he could not\nmemorize new information. You could tell a joke and he would find it\n12 Are the Androids Dreaming Yet?\nTurning Images to Music\nfunny and laugh uproariously. A few minutes later, you could tell the\nsame joke and he would find it just as funny as the first time. For him,\nevery time was the first time, because he had lost the ability to record\nlong-term memories. The syndrome is wonderfully depicted in the film\n50 First Dates starring Adam Sandler and Drew Barrymore. Another\npatient with specific stroke damage was unable to recall the names of\nfruits but, oddly, could still name vegetables. Interestingly tomatoes\npresented a particular problem. He had probably never known how to\ncatalogue them so they were partially remembered in both areas.\nThere are many such medical cases. In Oliver Sachs’ The Man who\nMistook his Wife for a Hat, the author relates the tale of a man with visual\nagnosia who could not reliably name familiar objects, including his own\nwife! He had a perfectly loving relationship with her but simply could\nnot name her from a picture. Sachs, Professor of Neurology at New York\nUniversity School of Medicine, provides many such fascinating stories,\nalong with their medical backgrounds.\nThe fruit and vegetable case suggests our brains are organized like a\nfiling cabinet. When we damage a part of the brain, it’s like losing a drawer:\nAll the information stored in that drawer is lost. Quite a few experiments\ncontradict this model and indicate many tasks are distributed around the\nbrain. The curious case of blindsight is one such example. People with\na damaged visual cortex can often recognize objects despite reporting\nthey have no sensation of vision. Show them a shape and they will report\nthey can see nothing. Ask them to name the shape and they might even\nget a little irritated by the question; they are blind after all. But, ask them\nto guess the shape and they will get it right every time. Seeing is more\nMind over Computer\n13\nBrain Image of Fish Hunting Prey\nwidely distributed in the brain than was first thought. Conscious seeing\nis based in the visual cortex, but there are older pathways still active in\nthe brain that facilitate this unconscious seeing.\nThe brain is very plastic. Lose your sight through damage to the eye\nor optic nerve, and the brain can repurpose the visual cortex to other\nuses such as processing sound or touch. Daniel Kish has developed this\nto such a high level that he can ride a bicycle despite being blind. He\nclicks his tongue against the roof of his mouth and uses echolocation\nto form an auditory model of the world around him. Using a similar\napproach, Amir Amedi from the Hebrew University of Jerusalem has\nbuilt an audio imager that turns pictures of the world into musical sound\npatterns. CAT scans of people using this system show they use the visual\ncortex to convert these sound images into models of the world in similar\nparts of the brain to a sighted person.\nWe now know roughly what each part of the brain does, but we\nhave no idea how it does it. The scale of an individual thought is too\nsmall to see in a brain scan. All we can do is observe large-scale electrical\nactivity associated with those thoughts. A video, from a group at Tokyo\nUniversity, shows an example of electrical activity filmed in real time\nas a fish hunts for its prey. Fish have transparent bodies and thin skulls\nfacilitating this sort of imaging. Humans are much harder subjects to\nwork with!\nThe most popular theory to explain how brains work is as some form\nof computer. Computers are easy to study because we manufacture them.\nThey tend to crash quite frequently – usually at the most inconvenient\n14 Are the Androids Dreaming Yet?\nmoments – so we have packed them with diagnostic monitoring systems.\nThese systems allow us to watch a computer think and, since they think\nsymbolically, we can easily read their minds.\nUnfortunately computers don’t display many human-like thoughts.\nThey don’t laugh and cry, they don’t report consciousness and they don’t\nappear to exercise free will or display creative impulses. This is frustrating\nbecause these are the thoughts we would most like to study. It might be\nthat computers are not yet powerful enough, and in another few years\nthey will be giving Mozart a run for his money. But there may also be\na fundamental difference which renders them incapable of this sort of\nthinking. This is the crux of the modern scientific debate: do humans\nthink differently?\nComputer Brains\nOn the face of it, humans and computers behave very differently. Our\nmemories are poor, but we understand things. We are creative, but bad\nat mathematics. We learn by example, computers are programmed.\nWe are emotional, impulsive and appear to have free will. Computers\nare ordered, predictable, but lack common sense. Both humans and\ncomputers appear to be physical, discrete systems. We both take inputs,\ngenerate outputs and are capable of solving similar problems. Indeed,\neach time we examine a problem solved by humans we usually find we\ncan automate it. This is known as ‘knowledge engineering’ and there are\nmany examples; from aerospace to finance, and architecture to medicine.\nAn example of where computers excel is in medical diagnosis.\nISABEL is a clinical diagnosis program designed to help ER doctors\nquickly diagnose critical patients. It was created by the parents of Isabel\nMaude, a little girl who presented with multiple symptoms to an ER unit.\nDoctors were initially confused by the symptoms and misdiagnosed\nher condition. She was later diagnosed with meningitis. Isabel suffered\nmultiple organ failure but survived. Her parents realized there was\nsomething wrong with the ER triage process. They got together with\nsome computer scientists and built the expert system ‘ISABEL’. When\nER doctors are presented with symptoms, they must mentally scan a vast\narray of literature to rule in and out possible diagnoses. The problemsolving\nprocess is not linear; if you’ve ever watched the TV series House\nit gives a great dramatization of the process. Certain symptoms might\nsuggest a diagnosis but are not conclusive, and there are many paths to\nexplore. Programmers have taken the heuristic rules from many doctors\nand codified them into software. ISABEL allows a doctor to input a set\nMind over Computer\n15\nof symptoms and it will spit out a range of possible alternative diagnoses\nwith probability weightings and suggested further tests. Similar systems\nare widely deployed in other fields, to build racing cars, design dams\nand fight crime. Even the game consoles in our living rooms implement\nartificial intelligence to make the aliens more believable and our hearts\npump faster.\nOrigin of Computers\nAlan Turing effectively invented the modern day computer in a paper\nhe submitted to the London Mathematical Society in the summer\nof 1936. He was not the first person to come up with the idea – that\nhonor probably goes to Charles Babbage – but he was the first to fully\nunderstand its power. When we talk about computers today we mean\nmachines, but it is worth noting computers in Turing’s time were more\noften humans using pencil and paper. The mechanical computers before\nTuring were elementary at best.\nRudimentary calculating machines were developed in Greece,\nPersia and China as far back as the Ming Dynasty. An astrolabe recovered\nfrom a ship wreck off the Greek Island of Antikythera had cogs and gears\nand could accurately predict the motions of the sun and planets. Many\nBabbage’s Difference Engine No. 2, Computer History Museum, CA\n16 Are the Androids Dreaming Yet?\nof these skills were lost in the Dark Ages but, once the Renaissance was\nunderway in the 16 th and 17 th centuries, complex mechanical clocks were\ndevised that were capable of predicting the motions of the planets to a\nhigh degree of precision. Mechanical, hand-cranked calculators appeared\nin the mid-18 th century, and in 1886 Charles Babbage conceived the\nfirst programmable computing machine, The Analytical Engine. It was\ndesigned to read programs from cards, and used cogs and wheels to\nperform the calculations. His first machine – The Difference Engine –\nwas designed to help the Admiralty calculate tide tables, but Babbage\nrealized he could generalize it to compute almost any function. He ran\nout of money to complete any of his machines, but in the 20th century a\ndedicated band of enthusiasts built a working model of Difference Engine\nNo.2. One copy sits in the London Science Museum and another in the\nComputer History Museum in California. These difference machines are\nnot Turing complete and his Analytical Engine has never been built.\n19 th Century Calculators\nMind over Computer\n17\nIn 1935, Turing was made a Fellow\nof King’s College, Cambridge, and became\ninterested in whether mathematical\nproofs could be found automatically.\nHe wanted to know whether solving a\nmathematical puzzle was simply a matter\nof working through all the possibilities in a\nmethodical manner, or whether something\nmore subtle was required. Although chess\nis a fantastically complex game, it is finite,\na big enough, fast enough computer can\nplay the perfect game. Is this the case\nwith discovering knowledge? Could a big\nenough, fast enough computer calculate all\nthe knowledge in the Universe? Is Douglas\nAdams’ fabled computer Deep Thought a\npossibility, able to calculate the answer to\nthe ultimate question of ‘life, the Universe\nand everything’, albeit with a more\nenlightening answer than 42?\nTuring boiled down the process\nof pencil and paper computation to a\nsystematic program – a computer program.\nModel of the Antikythera\nMechanism\nHe proposed a thought experiment where he would run every possible\nprogram and see if such a procedure would yield the solution to every\nimaginable mathematical problem. He was able to show this would lead\nto a paradox and concluded the universal problem solver could not exist.\nHis discovery is one of the most important of the 20 th century – in the\nsame league as relativity and quantum mechanics – and I will use it as\nmy main tool in trying to explain the difference between brains and\ncomputers.\nAlthough Turing’s original paper was not intended as a blueprint\nfor a practical device, he was one of those rare mathematicians who also\nliked to tinker with real world machines. The outbreak of the Second\nWorld War made the practical application of his work very important,\nand in Chapter 8 I will relate some of the code breaking stories that were\nto make him famous and caused Churchill to credit him with shortening\nthe war by two years.\nCalling Turing’s work an ‘invention’ is probably the wrong term;\n‘discovery’ might be more appropriate. Whatever you call it, people\nimmediately equated human brains with computers. This is not new.\n18 Are the Androids Dreaming Yet?\nEach time a new advance in technology is made, people use it to explain\nthe working of the brain. The ancient Greeks thought the brain was a\nfire consuming oxygen. When Alexander Graham Bell invented the\ntelephone, the nervous system resembled a maze of wires and the brain\nan exchange. Brains were obviously a sophisticated telephone system.\nThis idea has some potentially frightening consequences, particularly in\nlight of the speed at which computers are improving.\nThe most striking feature of computer technology is the rate of\ndevelopment. Cars travel faster than a person’s legs will carry them,\nmachines manufacture things faster than our hands are capable of\nworking. If brains are computers, surely it is just a matter of time before\nthey will think faster than humans. Turing predicted this would happen\nwhen computers reached the level of storing around 10 billion units of\ninformation. This happened some time in mid-2000. But today, in the\nyear 2014, I can report that although my computer can beat me at chess,\nit still cannot fill out my expense report for me. So I am still ahead!\nMaybe Turing just got the mathematics wrong. The human brain\nhas about 10,000 times more neurons than our most powerful computers\nhave logic gates. By this calculation, it’s not a billion units of storage we\nneed but, a trillion trillion units to put the computer on a par with a\nhuman brain. It’s just a matter of time!\nThe worrying thing – especially for fans of the ‘computers taking\nover the world’ science fiction genre – is that computers are improving\nexponentially fast in line with Moore’s Law, and the parity point is\ncoming soon. Gordon Moore founded Intel with Andy Grove, and ran\nthe engineering department there for more than 20 years. According\nto Moore’s Law, the power of a computer doubles approximately every\n18 months. The next significant event in the computer versus human\ncompetition is the gate count parity point – the moment when the\nnumber of logic gates and the number of neurons become equal. By my\nreckoning this will happen some time in 2053.\nDon’t despair. There may be a few dodges yet. The gate parity point\nassumes a logic gate and a neuron are equally powerful. However, some\nsingle cell organisms with only one neuron are capable of complex\nbehaviors, such as hunting prey and avoiding obstacles. To perform these\nsimple behaviors, a computer would need as many as 10,000 logic gates,\nabout the complexity of my TV remote control. This gives us a bit more\nbreathing space. The extra four orders of magnitude push the gate parity\npoint out to around 2080, too late for me to see, but certainly within the\nbounds of some readers of this book.\nMind over Computer\n19\nTo give you some idea of how Moore’s Law works, the graph shows\ngrowth in computing power over time; the y-axis is a logarithmic plot\nusing engineering notation. Because the growth is exponential we rapidly\nend up with very large numbers. Scientists use a special notation to cope\nwith these large and small numbers. In scientific notation a number\nis written out in a compact form. For example, three hundred can be\nwritten as 3.0 × 10 2 . To expand it back to a regular number you move the\ndecimal point in 3.0 two spots to the right, making the number 300.0. A\nsimilar technique is used for small numbers. To expand 3.0 × 10 -2 move\nthe decimal point 2 points to the left, giving 0.03. Why use scientific\nnotation? Well, once the numbers get large they would no longer fit on\na page! We can shorten the representation of numbers even further by\ndropping the ‘3.0 ×’ part and just looking at the order of magnitude.\nThe number 10 80 , one with eighty zeroes after it, is the number of atoms\nin the Earth, and 10 120 the number of particles in the known Universe.\n10 -43 meters is the ‘plank number’, believed to be the smallest dimension\nyou can have, and 10 100 is called a googol, named by Milton Sirotta, the\nMoore’s Law Extended by Ray Kurzweil\n20 Are the Androids Dreaming Yet?\nnephew of the famous American mathematician Edward Kasner, and\nsubsequently the inspiration for the name ‘Google’, the Internet search\nengine.\nRay Kurzweil, the prolific inventor and futurologist, is fascinated\nby this exponential growth. Exponential curves grow slowly to start with\nbut they pick up speed rapidly and, in the end, growth tends towards\ninfinity. We are all painfully acquainted with one example of exponential\ngrowth: The common cold. Each infected cell in our body releases\nvirus particles into the blood which infect further cells, leading to an\nexponential increase. This makes us feel rotten. Luckily our immune\nsystem can also respond exponentially, albeit somewhat delayed, so we\nsurvive. In the case of computer power there is no opposing immune\nsystem fighting back, so Kurzweil thinks computers will achieve almost\nlimitless processing power; perhaps even within our lifetime. He thinks\nthis will lead to some interesting consequences, for example, allowing\npeople to live forever! Far-fetched? Follow his argument.\nThe two most important elements in keeping us alive are medical\nimaging, to see what is wrong; and genetic engineering, to fix those\nthings. Both are improving in line with digital technology, doubling\nin power every 18 months. As computers get better at seeing into our\nbodies, and our ability to sequence and synthesize spare parts improves,\nwe will reach a point where we can fix almost any problem. Kurzweil\nfigures technology is improving and his body is decaying at just the right\nrate to mean by the time he needs heavy duty medical intervention it will\nbe available. Barring a traffic accident or mad-axe-murderer, he should\nlive forever. Even if his calculation is slightly off, the next generation will\ndefinitely have this option.\nYou might dismiss this as science fiction, but some amazing things\nare already happening. Recently a female patient in the USA suffering\nfrom bone cancer had her jaw replaced with a 3D printed component.\nDoctors were able to scan her head and take an image of the good side of\nher jaw, flip it right to left within the computer and repair any problems\nthey saw. Then they sent the image to a 3D printer. The printer made a\nnew jaw from tungsten powder, which was fused in a kiln. The final stage\nwas to cover the metal part with an inert bone-like substance to give\nthe human body a scaffolding on which to build real bone. They then\nperformed the operation to remove her old jaw and replace it with the\nnew one: result, brand new healthy jaw.\nThere are some practical limits to the power of computers on the\nhorizon. Currently, the wires in a silicon chip are about twenty-two\nnanometers wide. That’s around a thousandth of the width of a human\nMind over Computer\n21\nhair, or approximately two hundred atoms wide. To match the complexity\nof a brain we will need to pack an order of ten million more gates into\na silicon chip. One way to achieve this is to simply shrink the wires, but\nwhen we get down to around ten atoms wide, quantum effects begin to\ndominate. Signals in today’s chips involve tens of thousands of electrons.\nWe normally think of these electrons as a group, but in these tiny circuits\nwe need to consider the behavior of each individual electron. Problems\narise as this behavior is subject to quantum uncertainty. With only ten\nelectrons there is a finite probability that none of them will be where you\nwere expecting them to be. This causes problems for digital logic. You\ncan’t put a ‘1’ in a memory location and be sure when you come to read it\nyou will get a ‘1’ back. You have to factor in the possibility of error.\nQuantum effects can be annoying – requiring us to devise all\nmanner of error checking hardware – but they can also be helpful.\nRichard Feynman proposed using quantum bits, ‘qubits’, to perform\ncomputation. Quantum computers can calculate many times faster than\na classical computer because a single bit can represent more than one\npiece of information. Enterprising entrepreneurs are making use of this\neffect to build the next generation of devices, and you can already buy a\n512 qubit computer from a Canadian company called D-Wave.\nThe biggest problem with building more powerful conventional\nchips is their area is reaching the manufacturing limit for economic\nviability. Silicon wafers contain random spots of damage and, as a\nchip gets larger, the chance it will have one of these spots approaches\ncertainty. One solution is to use the third dimension and print the logic\n3D Chip, Intel\n22 Are the Androids Dreaming Yet?\ngates so that they communicate in the vertical direction as well. Intel\ndemonstrated the first three-dimensional chip in 2004, and these chips\nshould begin to appear in our laptops by around 2020.\nTaking a chip into the third dimension solves the economic\nproblem but adding logic gates to a 3D chip presents a new problem\n– heat. Heat is generated in proportion to the volume of the chip but\nit can only be lost through the surface area. Result: the chip overheats.\nLarge animals have the same problem which is why elephants have huge\nears, filled with blood vessels, they can flap to cool themselves and really\nbig mammals, such as whales, live in the ocean. The thermal problem\nis now the biggest problem in most computer designs. One data point\nsuggests we could solve this problem, the human brain. We pack huge\nprocessing power into our skulls without overheating by using a variety\nof techniques, including folding the surface of the brain, running each\nneuron very slowly and maybe even using quantum mechanics. A very\nrecent discovery is that brains could be using quantum effects to transmit\nsignals. If true – and the research has only been recently published –\nit means we may use a form of high-temperature superconductivity to\navoid overheating. More on this in Chapter 4.\nExcluding exotic quantum effects, the main difference between\ncomputer and human brains is their processing architecture. Brains\nuse slow, asynchronous logic to process information rather than the\nfast, synchronous type used in modern day computers. Logic gates in\ntoday’s computers work all the time, even when there is nothing to do.\nFor example, if I multiply 2 by 3 on my laptop the entire multiply circuit,\ndesigned to work on 20 digit numbers will still operate, and, even worse,\nit will operate on every tick of the master clock even if there is nothing\nto multiply. The brain, by contrast, works only as it needs; unused gates\ndon’t operate. This gives a massive reduction in unnecessary power\nconsumption. We’d like to use this technique in modern computers but\nit is very difficult to implement. Tiny changes in timing cause completely\ndifferent operation and this makes them hard to test. We accept this\nsort of problem in humans, calling it ‘human error’, but we count on\ncomputers to behave absolutely reliably, so full-blown asynchronous logic\nis not likely to appear anytime soon. Some of these ideas, however, have\nmade their way into today’s consumer devices. For example, the chips\nin the latest iPhone contain two CPUs: a small slow one operating when\nthe phone is dormant in your pocket, and a large fast one that switches\non when you need the power for a game or other high performance task.\nAll things considered there doesn’t appear to be a fundamental\nengineering problem that would prevent computer hardware reaching\nthe complexity of the human brain. But, even with all this hardware, it’s\nnot clear we would have something intelligent.\nRichard Branson\n“I was dyslexic, I had no\nunderstanding of schoolwork\nwhatsoever. I certainly would\nhave failed IQ tests. And it was\none of the reasons I left school\nwhen I was 15 years old. And\nif I – if I'm not interested in\nsomething, I don't grasp it.”\nRichard Branson\nIntelligence\nlthough my computer appears to have a mischievous sense of humor\n– deleting files and crashing just before important presentations\n– it does not appear to enjoy listening to Bach, nor does it ever\nask me to put it near the window to admire the view. I think this means\nit’s not intelligent, but what is ‘intelligence’?\nIntelligence is hard to define; I usually conclude someone is\nintelligent if I have an interesting conversation with them. In the\nworkplace we typically hire people based on interview, rather than\npractical tests. Could a computer hold a conversation with me and\npersuade me it is intelligent? Meet Eliza.\nInvented by Joseph Weizenbaum of the Massachusetts Institute\nof Technology, and named after George Bernard Shaw’s character in\nPygmalion, Eliza runs an algorithm pretending to be a psychiatrist\noffering a sympathetic ear to anyone who cares to talk. Try her out at my\nwebsite or read the sample dialogue below!\nUser: Men are all alike.\nEliza: In what way?\nUSER: Men are all alike.\nELIZA: In what way ?\nUSER: They’re always bugging us about something or other.\nELIZA: Can you think of a specific example ?\nUSER: Well, my boyfriend made me come here.\nELIZA: Your boyfriend made you come here ?\nUSER: He says I’m depressed much of the time.\nELIZA: I am sorry to hear that you are depressed.\nUSER: It’s true. I am unhappy.\n26 Are the Androids Dreaming Yet?\nELIZA: Do you think coming here will help you not to be unhappy ?\nUSER: I need some help, that much seems certain.\nELIZA: What would it mean to you if you got some help ?\nUSER: Perhaps I could learn to get along with my mother.\nELIZA: Tell me more about your family.\nUSER: My mother takes care of me.\nELIZA: Who else in your family takes care of you ?\nUSER: My father.\nELIZA: Your father ?\nUSER: You are like my father in some ways.\nELIZA: What resemblence do you see ?\nUSER: You are not very aggressive but I think you don’t want me to notice that.\nELIZA: What makes you think I am not very aggressive ?\nUSER: You don’t argue with me.\nELIZA: Why do you think I don’t argue with you ?\nUSER: You are afraid of me.\nELIZA: Does it please you to believe I am afraid of you ?\nUSER: My father is afraid of everybody.\nELIZA: What else comes to your mind when you think of your father ?\nUSER: Bullies.\nELIZA: Does that have anything to do with the fact that your boyfriend made\nyou come here ?\nIf you think Eliza a bit odd, you are right. Perhaps you won’t hire\nher just yet. The program looks for keywords in speech, and parrots them\nback at you interspersed with a few stock phrases. If you type a sentence\ncontaining the word “job”, the computer will say, “Tell me more about\nyour job.” It’s a simple program and runs to only three pages of text. It\nshows how good a job you can do with very few resources and how far we\nare away from a real human being. More complex programs with a larger\nrepertoire have been built and can hold a plausible conversation. People\nare occasionally taken in by them and are quite shocked when told they\nhave been conversing with a machine. If you’re on your guard, they are\neasy to spot. So far, no one has built a computer capable of holding an\nextended human conversation and fooling a human into thinking it’s a\nperson. Incidentally, having a sympathetic listener is so important to\nhuman beings these programs are used in psychotherapy and can be as\neffective as drugs.\nTuring proposed a test to tell whether a computer had truly achieved\nhuman intelligence called the imitation game. His argument is as follows:\nMind over Computer\n27\nIQ Test\nHumans are intelligent. (If you disagree with this premise then\nyou’re going to have a problem with this argument!) If you talk to a\ncomputer and cannot tell it from a human, it must also be intelligent:\nQED. The logic is sound but somehow feels wrong. It neatly, but\nirritatingly, sidesteps the whole problem of defining intelligence.\nIn 1912, William Stern devised a method for measuring intelligence\nin children. He named it ‘IQ’ from the German Intelligenz-Quotient.\nYou may have taken one of these tests at school. The tests consist of a\nseries of abstract reasoning problems that minimize cultural references.\nFor example, you might be asked to look at a set of blocks with dots on\nthem and identify which is the odd one out. Numerous versions of the\ntest have been developed over the years, but nowadays we mostly use one\nof three standard tests, Wechsler being the most common.\nMeasuring intelligence is complicated. Culture and language play a\nbig part. If we take a tribe of Amazonian Indians and ask them to list the\npresidents of the United States, they will fail. That does not mean they’re\nstupid. Drop me into the Amazon Rainforest and I will probably starve\nto death; they, on the other hand, can live off the land as hunter-gatherers\nwith only a few hours work per day. Who is more intelligent?\nOne problem with IQ is that individual candidate scores can differ\nwildly from test to test, sometimes by as much as 20 points. That’s huge. At\nthe high end of the scale it can be the difference between being classified\nas smart or as a genius; and, at the low end, between being average or\nmentally subnormal. These variations don’t usually matter and most\nuniversities and colleges take IQ with a pinch of salt, preferring more\nspecific tests such as SATs in America, the Baccalaureate in Europe or A\nlevels in the UK. IQ can be very important; and is sometimes a matter of\n28 Are the Androids Dreaming Yet?\nlife or death. In Atkins v. Virginia, the US Supreme Court found a person\nwith mental disability, defined as having an IQ of less than 80, cannot be\nexecuted.\nIQ is not really a measurement, in the normal sense. Most\nmeasurements in life are absolute, for example, distance, weight, and time.\nI can prove my house is bigger than yours using a tape measure. We each\nensure our measures are the same by calibrating them against a common\nreference. In the 1900s we could have walked down to the local town hall\nand checked our measurements against a ‘yardstick’. As measurements\nbecame standardized, these sticks were compared with a common central\nreference. For example, the metre was a platinum-iridium bar kept at the\nPavillon de Breteuil near Paris. In the 1960s, a laser superseded the metal\nreference, and today a metre is defined as 1,650,763.73 wavelengths of the\norange-red emission line in the electromagnetic spectrum of krypton-86\nin a vacuum. Measurement has become very precise!\nIntelligence is different. It has no yardstick. If I were to ask, “How\nmuch intelligence does it take to design a building?” there’s no simple\nanswer. IQ is not an absolute measurement – it’s a relative score. Test\n100 people and list their scores in order. The ones in the middle get a\nscore of 100; the top 5 a score of at least 130 and the top person a score\nof 140. Similarly at the lower end. A person with a high IQ is probably\nsmarter than one with a low IQ, but it doesn’t tell you if the building\nthey designed will stand up. It’s rather like quoting the odds of a horse\nwinning the Derby. Quoting the odds does not give the speed of the\nhorse, nor often the winner of the race!\nDespite attempts by test creators to remove cultural bias, it can\nnever be completely eliminated. Certain Amazonian tribes have no\nconcept of counting above five. For them, numbers are an alien idea and\nserve no useful purpose in their habitat. In the jungle there are always\nenough trees to make spears, and as a hunter-gatherer you simply need\nto know where to find your prey. There is no need to count animals into\nan enclosure at night. Another interesting environment is the Australian\nOutback. Aboriginal Australians appear to have a remarkable aptitude for\nvisio-spatial memory and can remember maps or collections of objects\nmuch better than you or I. Tests for this skill involve playing a variant\nof Pelmanism. A collection of objects is placed on a tray and covered\nwith a cloth. The cloth is lifted for 60 seconds to reveal the location and\ntype of objects and then replaced. Subjects are then given a bucket full of\nobjects and asked to recreate the tray. You and I do a modest job. Native\nAustralians do this almost perfectly. Why?\nMind over Computer\n29\nIn the vast, inhospitable Outback it is vitally important you\nremember that water can be found at the two rocks near the old gnarled\ntree. Forget this and you will die of thirst. It was once thought the skill\nevolved through natural selection, but this might not be the correct\nexplanation. Recent studies show many of us can use mnemonic tricks\nto significantly improve our memory. Aboriginal skills might actually be\nlearned and passed on from generation to generation.\nIQ gives us a way to sum up intelligence using a single number\nbut is this too simplistic? We all have friends who would be our first\ncall if we met that special someone or lost our jobs. They are often not\nthe smartest people we know, but they are highly empathetic. These\npeople have ‘social intelligence’. Other friends may fail academic tests\nyet demonstrate wonderful musical or artistic ability. They have creative\nintelligence. As we dig deeper, more talents emerge: sporting prowess,\norganizational brilliance, the ability to inspire loyalty. All these traits\nappear independently of academic brilliance.\nDuring the last century, scientists worked hard to understand these\ndifferent intelligence traits. The most influential theory came out of\nstudies done at the United States Army Educational testing service, by\nRaymond Cattell and John Horn, and later added to by John Carroll.\nTheir initials give the theory its name. CHC theory breaks down the\ngeneral idea of intelligence into many different subgroups: ‘G’ factors.\nIf you are good at recalling all the kings and queens of England\nin chronological order, or can name every member of the 1966 English\nWorld Cup team or, perhaps, all the members of the baseball Hall of Fame,\nyou would have high ‘crystalized intelligence’ – ‘Gc’. It measures the sum\ntotal of all the things you have learned and retained in your long-term\nmemory, your store of useful, and useless, facts. On the other hand there\nis innate intelligence, the sort that allows you to solve problems where\ntapping memory banks is not useful. My family often buy me puzzles for\nChristmas, the sort where you manipulate bits of bent metal that appear\nlinked, but can be separated\nwith a little ingenuity. These\npuzzles test our ability to work\nwith problems we have never\nseen before and is called ‘fluid\nintelligence’ – ‘Gf ’.\nWe can go further. A good\ntennis player will have high ‘Gt’\nand ‘Gv’ scores: ‘t’ for time and\n‘v’ for vision, a good pub quiz\nMetal Puzzle\n\n30 Are the Androids Dreaming Yet?\ncontestant a high ‘Glr’ score – ‘lr’ denoting for long-term retrieval. Carol\nVorderman, a UK game show presenter famous for mental arithmetic,\nwould have a good ‘Gq’ score, ‘q’ for quantitative numerical skills. With\nall these types of intelligence to choose from it begs the question, “Is there\na single master intelligence from which the rest follow?”\nPolitical correctness plays a part here. It feels rather elitist to say\nsmart people are good at everything. It is far nicer to think we each have\nour individual talents and some just have a few more than others. But\nthat’s not what the science tells us. ‘Group Intelligence’ – the overall G\nscore – does appear to be the underlying cause of the other types of\nintelligence, and smart people do tend to be good all-rounders. However,\nthere is one major flaw in the analysis; the studies only measure the\nsubjects’ ability to pass academic tests, they don’t look at our success in\nreal-life, nor our creativity.\nLewis Terman began the long est running study of intelligence\nand its relationship to life success back in the 1920s. It continues to this\nday. A group of 1500 children with high IQs were selected and tracked\nthroughout their lives. Terman assumed their high IQs would result in\nthem being very successful. They certainly did well, but studies show\nthey did no better than if they had been chosen randomly from the same\narea (all the children came from around Stanford University). Famously\ntwo children, William Shockley and Luis Alvarez, tested too low to be\nchosen for the study but went on to win Nobel Prizes for Physics in 1956\nand 1968, respectively.\nThere are many similar anecdotes: Apparently stupid people go on\nto great things. Einstein’s teacher famously stated he would never amount\nto anything and Sir John Gurdon’s school report said he was ‘too stupid’\nfor science. He went on to discover monoclonal antibodies for which he\nwas awarded a Nobel Prize! Scientists have now devised the alternative\ntheory of an intelligence tidemark. Once above this level – an IQ of\nabout 130 – you can pretty much do anything you want to. This might be\nbecause one very important type of intelligence – creative intelligence – is\nnot highly correlated with the rest. Creative people tend to be sufficiently\nintelligent for their field but once above that threshold the relationship\nbreaks down. Success in creative endeavors seems to reflect strength of\ncharacter and creative aptitude rather than raw brainpower.\nPhysical Basis of Intelligence\nThe high correlation between different sorts of academic intelligence\nsuggests we might find a physical process within the brain leading to\nMind over Computer\n31\nhigh IQ. Functional MRI scans show intelligent people use more neurons\nwhen tackling a given mental task, perhaps bringing to bear greater raw\nhorsepower, but this is not really an explanation. It is akin to saying Usain\nBolt runs faster because he gets more power to his legs. This is obvious.\nWhat we want to know is how.\nThe problem with looking at brains for a common cause is the\nvariation from brain to brain. We all have different genes and life\nexperiences. On top of this, we really only see brains post mortem and\nthis tends to confound comparisons of brain structure. One way to\nminimize the variation is to use separated identical twins. Twins have\nidentical genes so their fundamental hardware is the same. We should be\nable to see features of the brain that are common to smart sets of twins but\nabsent in less smart pairs. If a feature is not shared it can be discounted as\nsomething accidental, caused by disease, environment, or the like.\nWhen we examine smart twins, they appear to have greater\nmyelination of their neurons. Myelin is a flat protein that acts as an\ninsulating sheath, wrapping the nerves and the neurons in our brain.\nMyelination appears to be part of the mechanism involved in laying\ndown long-term memory – more myelin, more memories. It may also\nhelp sustain signals and allow them to move faster over a longer distance:\nthe increased insulation allowing the brain to include information from\nmore distant parts of the brain within a given thought. But increased\nmyelination may be an effect of higher intelligence rather than a cause.\nThe brain is responsible for a significant part of our overall energy\nconsumption so insulating the neurons might simply help with energy\nconservation. This is an active area of research.\nEvolution also gives a clue to the causes of intelligence. Humans,\nnonhuman primates, and dolphins all share spindle neurons. These\nspread across the brain and appear to help us coordinate complex\nactions between the different parts. The high function intelligence that\ncharacterizes these disparate species requires a great deal of cooperation\nbetween different areas of the brain. Take playing a musical instrument.\nThis uses physical coordination (motor cortex), sound processing\n(auditory cortex), rhythm (another part of the motor cortex), along\nwith emotional interpretation (amygdala). Humans have more spindle\ncells than other animals so this might explain our superior ability in\nperforming these complex tasks.\nHowever plausible these ideas, they are all hardware arguments. It\nis like me saying my word processor is better than yours because it has\ngold plated connectors. That might be true – it might allow the machine\nto run a little faster without electrical errors creeping in, but we all know\n32 Are the Androids Dreaming Yet?\nit’s software that matters. A great computer game is great because it is\ncleverly written and has beautiful graphics. The speed of the hardware\nmight help, but it does not define ‘great’.\nCan we see these software effects in the brain?\nNo, unfortunately, this is where our imaging technologies fail. They\nlack sufficient resolution. We would need 100,000 times more resolution\nto see our thoughts, even assuming we would recognize thought if we saw\nit. There is no reason to believe the brain lays out thinking in anything\nresembling the computer software we are accustomed to reading.\nThere is one exceptional group of people that does show a software\ndifference on a large-scale – chess players. It seems Chess Masters use\na different part of their brain to process information about chess than\nyou and I. This can be clearly seen on scans of the brain and is such a\ngross effect it even shows up in old-fashioned EEGs – where electrodes\nare taped to your head. Interestingly the effect can be used to predict\ngreatness. Players likely to become Grand Masters show they use a\ndifferent part of their brain from the rest of us at an early age. Chess\nplayers possess the only large scale wiring difference we know of, but\nthere is another group with a visible physical difference, London taxi\ndrivers. Their hippocampi are noticeably larger than the rest of ours. The\nhippocampus does many things, but one of its most significant jobs is to\nmemorize maps. The three years it takes to acquire ‘the knowledge’ and\nthe subsequent years of navigating London’s complex streets give cabbies\na 30% larger hippocampus than the average London resident.\nIs Intelligence Static?\nWe’ve all seen the headline. Every summer public examination results\ncome out and every year is pronounced a record breaker! Year after year,\nstudents get better and better grades. This creates a problem. There’s is no\nbetter grade than an A – and eventually all students get As. Welcome to\ngrade inflation – a problem affecting systems the world over, from British\n‘A’ levels to Harvard grade point averages. Newspapers are awash with\nstories bemoaning the dumbing down of today’s tests. “Examinations\naren’t what they used to be.”\nGrade inflation undoubtedly exists and studies of undergraduate\ngrades show progressive compression into the top grades, most competent\nstudents get ‘A’s, making it difficult to distinguish a good student from a\ngreat one.\nMind over Computer\n33\nAt first glance, the problem appears to be one of social engineering.\nTeachers don’t want to disappoint, and academic institutions want to\nimprove on last year’s results. The people awarding the grades often have\na vested interest in those grades improving. Even a tiny positive bias in\nthe most scrupulously honest teacher is enough for grades to creep up.\nHowever, grade inflation might not be purely a matter of over enthusiastic\nteachers. IQ scores are also rising. Welcome to the Flynn Effect.\nJames Flynn, Emeritus Professor of Political Studies at the\nUniversity of Otago in Dunedin, New Zealand, reported in 1987 that\nIQ scores rise over time throughout the world. All told the population\ngains about one IQ point every three years, and approximately every\nten years IQ tests have to be re-calibrated, so the average student once\nagain receives the average grade. This is a mystery. It is a large effect and\ncannot be explained by the rote learning of lots of sample questions. The\nhuman race is either rapidly getting smarter or the least smart members\nof society are coming up to the general average fast; either way it means\nthere are fewer dumb people around. The Flynn Effect has recently\nslowed in western countries, suggesting it might be that intelligence is\nconverging rather than increasing overall. Another interesting fact is\npeople become more intelligent as they age, gaining about one IQ point\nevery ten years. Against the stereotype, it’s not all downhill after forty.\nThere is hope for me yet!\nUntil recently we thought IQ was fixed, but new research contradicts\nthis. Muscles get stronger with exercise, physical skills, such as playing\ngolf and tennis, improve with practice; why not intelligence? Scientists\nused to believe brains couldn’t get smarter; you had the IQ you were\nborn with. You might learn more ‘stuff ’ during your life, but the G factor\nstayed the same. It looks like this is wrong and we were simply not using\nthe right exercises.\nIn 2008, Susanne Jaeggi and Martin Buschkuehl, of the University\nof Maryland, modified an intelligence test into a game and showed\nplaying the game improved ‘fluid’ intelligence and increases IQ. They\nbelieve playing their game helps improve working memory – the shortterm\nmemory we use for storing sums as we do mental arithmetic –\nor remembering telephone numbers. Previous attempts to improve\nIQ through practice had not shown much success as the skills did not\ntransfer between tests, but working memory is such a useful thing it\nappears to help across the board.\nThese factors argue against intelligence being a hardware feature of\nour brain. It does not remain static but instead improves with age, time,\nand education.\nAt the beginning of the chapter, I said Garry Kasparov was once\nthought to be one of the most intelligent people on the planet. When\nhis IQ was eventually tested – the German magazine Der Spiegel put up\nthe money – he scored 135. That means, in academic terms, he is smart\nbut no genius. Yet, he is undoubtedly a genius by any common sense\ndefinition: the best chess player to ever live. These days he involves himself\nin politics rather than chess and is still uniquely able to concentrate for\nlong periods of time. Concentration seems a very important factor.\nEinstein was once asked where his genius came from. He replied that\nhe did not consider himself a genius but instead put his success down to\nhis persistence and ability to concentrate on a problem for many years.\nIQ tests say nothing of our ability to concentrate over extended periods\nand nothing about our drive to change the world. The tests are, at best,\na useful but dangerous diagnostic tool for educators. One of the worst\nthings IQ can do is pigeonhole people. Would Kasparov have become\nworld champion if he had been given his IQ score of 135 as a teenager\nrather than late in his thirties after he had conquered the world?\n“Education is what is left after\nwhat has been learnt has been\nforgotten.”\nB.F. Skinner\nHole-in-the-Wall Experiment\nThe Learning Brain\nHuman beings are born with an extraordinary ability to learn\nthrough experiencing the world around them. Studies show\nbabies as young as three weeks understand musical ideas,\nsmiling as you play music to them in a major key and frowning at music\nin a minor key. By six months, babies have learned to distinguish the\nrelationship between objects, and by two, they have a command of\nlanguage and are beginning to develop a theory of self. They understand\nhow to lie and become adept at playing parents off against each other!\nSugata Mitra, of Newcastle University, has run an experiment in\nIndia to test minimally invasive education called the ‘Hole in the Wall\nProject’. As the name suggests, he cut a hole in the wall of a building in\nDelhi and put a computer in it. The hole opens out onto a slum district\nand local children rapidly discovered the computer. Without any formal\ntraining they picked up the necessary skills and very soon became adept\nat searching the Web. Remember, in order to ‘pick up’ this skill they often\nhad to learn the English language as well.\nAnother example showing children’s innate ability to learn is Nicolas\nNegroponte’s ‘One Laptop per Child’ program, which gives computers to\nchildren in remote villages around the world. The laptops are a triumph of\ncost engineering but are fully functional and can connect to the Internet.\nThe inspiration for the project came from an analysis of the economics\nof the computer industry. Huge capital investment in the western world\nis driving most costs down, but one cost that seems to have stuck fast is\nthe access device. Laptops tend to remain at a floor price of around $500,\nfar too high for much of the developing world. At $500, a computer store\nmakes $80 when they sell you a laptop. This is as low as is cost-effective\n36 Are the Androids Dreaming Yet?\nLaptops Galore\nfor them to stock the machine, employ someone to tell you about it, and\nfix it if it goes wrong in the first year. Value for money improvements\nhave all focused on faster processors, more memory, sharper displays\nand larger hard drives, not lower prices. These improvements are useful if\nyou want to shoot aliens, but overkill if you only want to surf the Internet\nand learn the ‘3 Rs’. So the ‘One Laptop per Child’ project has developed\na device for $100.\nNegroponte is often asked how he deals with the maintenance and\nrepair issues. His answer, “There aren’t any.” The computers are treasured\npossessions and rarely broken or lost. Children become empowered by\nthe machines and can access knowledge and information far beyond the\nwildest dreams of their parents’ generation. Stories abound of children\nchecking the spot prices for wheat or coffee on the Chicago Stock\nExchange, and advising their parents on the price to accept for their\ncrop. Negroponte estimates there are currently 500,000 children in South\nAmerica teaching their parents to read!\nIt’s interesting to speculate whether children learn spontaneously or\nare somehow ‘programmed’ by the adult members of society. In both the\n‘Hole in the Wall’ experiment and the ‘One Laptop per Child’ program\nthe children could simply be learning from adults and older children, but\nthere is a novel way to eliminate this influence. Negroponte and Mitra\nhave teamed up to run an experiment to see how children learn for\nthemselves. They are planning to air-drop laptops into remote villages\nin the Andes. In this scenario, the children can’t possibly learn from the\nMind over Computer\n37\nOne Laptop per Child\nadults – the adults have never even seen a computer before. Instead,\nthey must rely entirely on their innate learning ability. At this point, the\nexperiment has only just started; I will put details on my website as the\nexperiment progresses.\nThe 10,000 Hour Club\nLearning by experience takes\nhumans quite a bit of time. Anders\nEricsson, Professor of Psychology\nat Florida State University, studied\nmusicians in the early 1990s and\nfound they had accumulated a\nhuge number of practice hours\nby the time they became experts.\nHis research was popularized by\nMalcolm Gladwell, in the book\nOutliers, and by Daniel Coyle\nin The Talent Code. The idea is\nthat humans need around ten\nthousand hours of practice to\nbecome proficient at a skill. The\nmore skilled players seem to have\nsimply accumulated even more\nDan McLaughlin\n38 Are the Androids Dreaming Yet?\npractice. A number of people\nhave wondered whether you\ncan take this literally, and if you\ndevote 10,000 hours to practicing\nsomething you can become\nworld class. Dan McLaughlin\nfrom the USA used to be a\nprofessional photographer and\ndecided he might like to become\na professional golfer. He quit his\njob and is now 3,500 hours in. So\nfar, he has achieved a 4 handicap.\nI also personally got bitten by this\nbug and am learning the piano. I\nam about 3,000 hours in and am\nmaking good progress.\nGladwell’s interpretation of\nEricsson’s results is not without\ncontroversy. Ericsson stresses\n‘purposeful practice’ is the\nimportant element. Practicing\nPiano Practice\nthe wrong thing for ten thousand\nhours will just make you good at doing something wrong. Practicing\nwithout concentration and attention will equally have little effect. One\nillustrative example is the story of Edward Sanford, a supreme court\njudge, who read the morning prayer aloud every day over a 25 year\nperiod. After he retired he was asked if he could recite it from memory.\nDespite reading it as many as 5000 times during his working life, he was\nunable to remember it. It seems you must purposefully practice the exact\nthing you want to do if you wish to learn it, in this case recall.\nComputers don’t require practice to learn a skill. If their program\nis right they work correctly, and if it is wrong, they are always wrong.\nComputers can be programmed to learn but so far this learning has been\nlimited to specific problem domains, such as face recognition. They do\nnot have the general-purpose capability humans enjoy.\n\nAstrological Clock at Hampton Court Palace\n“The die is cast”\nShakespeare\n“How does the water of the\nbrain turn into the wine of\nconsciousness?”\nDavid Chalmers\n\nDeterminism\nI\nhave free will.\nLook…\nI can choose to type any word I like.\nGiotto...\nMany philosophers tell me I am deluded. I was always going to type\nthat word and I have no free will. Everything in my life is predetermined.\nI’m rather like a character in an enormous video game. The character\nmight think it was free to act, and its actions would appear random.\nYet from the moment the player clicked the button to start the game,\nevery action the character takes is determined by a preprogrammed set\nof rules. This is the free will debate. How can we tell we are free? Would\nthere be any observable effect?\nOne of the big problems is that philosophers codified much of our\nmodern theory of free will in the 19 th century, at a time when all the\nknown physical laws were deterministic and reversible. They could not\nsee a way for free will to emerge from such physical laws. There was even\na group called the Compatibilists lead by David Hume that thought free\nwill could coexist with determinism. Provided you felt free it did not\nmatter that your actions were inevitable.\nWe all want free will to mean actual freedom to make conscious\nchoices. We would like to affect the world in which we live; not the other\nway around. I dislike making definitions – I find they take away from the\ncore argument and only result in linguistic jousting, but it seems that two\ncenturies of philosophers have avoided a proper discussion of free will by\nloosely defining the term. Here is my definition:\n42 Are the Androids Dreaming Yet?\n‘We consciously, and through the exercise of will, make decisions\nbetween different choices without anyone or anything causing the\ndecision in advance. Others can influence decisions – by offering advice\nor even holding a gun to our head, but we choose.’\nIf you can devise a better, stronger definition please email me and\nI will revise my definition to your better one. I’m searching for the most\npowerful definition of free will – totally free and born out of the exercise\nof will.\nThe human mind appears to have free will. At least this is my\npersonal conscious experience. Computers, on the other hand, do not.\nThey run programs that dictate exactly how they will operate in every\nsituation. Could a computer be programmed to have free will? That’s\nhard to do. Let’s see why.\nThinking with Clockwork\nAstronomers have been predicting the motions of the heavens for\ncenturies and to do this they need accurate clocks. The very first clocks\nwere sundials. These suffered the obvious disadvantage of not working\nat night, but it was also unsatisfactory to use the motion of the sun to\npredict the motion of the sun. The earliest ‘heaven independent’ clocks\nused water flowing through small holes in pottery vessels. They were\neffective over short intervals but plagued by dust, dirt and evaporation.\nIt was the invention of the anchor escapement that enabled the first\naccurate mechanical clocks.\nBy the sixteenth century clockmakers had gone to town developing\nastrological clocks with more and more gears, to show all manner of\ninformation; the phases of the moon, the motions of planets, even the\nmotion of moons orbiting those planets. These clocks became hugely\nornate. The astrological clock at Hampton Court Palace was built for\nHenry VIII circa 1542 and, as well as showing phases of the moon\nand the signs of the zodiac, it accurately calculated the time of high\ntide at London Bridge, allowing Henry to travel quickly to the Tower\nof London. You might also notice it shows the sun orbiting the earth!\nCopernicus published his book, De revolutionibus orbium coelestium (On\nthe Revolutions of the Celestial Spheres) showing the earth orbited the sun\na year later in 1543, and it took centuries before it became accepted fact.\nClocks need gears. The humble gear is a simple machine. They\nwork because wheels of different size have different circumferences – the\ndistance around the edge – but one full turn is the same for all wheels.\nImagine you have a circular sweet such as a Life Saver – or Polo for\nMind over Computer\n43\nBritish readers – and you roll it once around the wheel of your car. The\nsmall sweet will turn many times. Now put a pencil through the hole\nin the sweet, jack up your car so the wheel is off the ground, hold the\nsweet next to the wheel of your car and press the accelerator. The sweet\nwill spin round very fast and probably disintegrate in a shower of minty\nsugar. This is the principle of gearing. A small circle has to do a lot of\nwork to keep up with a big circle. It’s very predictable. The sweet will turn\na set number of times for each rotation of the car wheel, equal to the ratio\nof the circumferences of the two circles.\nGears usually have teeth to lock the wheels together, but this is really\njust to make sure they can’t slip against one another when they transfer\nhuge forces, such as in racing cars. Some passenger cars have been built\nwith smooth gears; a friend of mine had one at university. If he put his\nfoot down too hard, the gears would slip, heat up and you would get a\nterrific smell of burning rubber. If you were lucky you could leave the car\nfor a few hours and all would be well. But, if not, you had to replace the\nrubber belt, which was very expensive. Toothed gears generally win out.\nToothed gears also have the enormous benefit of being digital. This\nis quite important if you want to keep things accurate. Gears can’t move\na fraction of a tooth so if a toothed gear has ‘slipped’ forward a small\namount, it will be kicked back into position when it meshes with another\ngear.\nIn a modern mechanical clock, a balance wheel swings back and\nforth on a spring and moves the main gear one notch forward each time\nit passes its central position. Gears divide this down to move the hour and\nminute hands. If I put the hands of a clock at midday and let the clock\ntick 86,400 times, the clock hands will come back to the same place. Once\nyou understand how a clock works you can play a trick. If you tell me the\nnumber of ticks the clock has tocked, I can tell you the exact position the\nhands will be in. To a small child this might be dressed up as a magicians\ntrick – but, of course, it is simply a matter of dividing the number of ticks\nby 60 and then 60 again to calculate the amount of time elapsed. This\ntype of precisely predictable behavior is called deterministic behavior.\nSomething is deterministic if you can set it up in a particular way and\nknow the exact state later or, conversely, examine something and trace it\nback into the past.\nModern computers scale up clockwork and make it much more\nefficient; gears are translated into electronic logic gates and a quartz\ncrystal vibrates at 1000 million ticks per second to give us the clock tick.\nOn each tick, the computer can do a mathematical operation, store and\nretrieve information, or branch down an avenue in its program. Using\n44 Are the Androids Dreaming Yet?\nthese simple building blocks the computer allows us to play computer\ngames or process the words of this book as I write. Importantly, all these\noperations are deterministic; given a set of inputs the computer will\nalways generate the same outputs and that means a computer has no free\nwill.\n“Ah,” I hear you say, “but my computer plays games with me and is\nnot predictable, otherwise I would always beat it.” You are right, but the\ncomputer has a clever trick to fake non-deterministic behavior: it uses\nyou!\nComputers on their own cannot generate random numbers. All\na computer can do is generate a pseudo-random number and it does\nthis by working its way through a very long calculation. It could, for\nexample, calculate the first thousand digits of π (pi), and then start using\nthe subsequent digits as random numbers. The digits look jumbled up\nbut we know they follow an entirely predictable pattern. The computer\nappears to behave randomly because when I press the button to kill\nan alien the computer picks the number it had counted up to at that\nmoment, say the 55,678 th digit of π, and uses that. It is I, the human, who\nunconsciously picks the precise moment in time and therefore provides\nthe random element. My choice is governed by all sorts of extraneous\nquantum influences: Did I have coffee this morning? Was it a big mug\nor a small cup? How hot was it? All these things will be important as\nthey determine the amount of caffeine absorbed across the brain blood\nbarrier and the exact timing of my actions.\nHumans are not good at consciously generating random numbers.\nWe tend to choose the same numbers too often. If I ask you to pick a\nnumber between one and ten, you are likely to choose three or seven.\nThis effect is called social stereotyping; magicians often use it when they\npretend to read your mind. The problem arises because we tend to over\nthink the problem. I asked you to pick a random number between one\nand ten. You won’t pick one or ten. Five is too obviously the mid-point.\nEven numbers don’t feel random. Nine is too large. That just leaves three\nand seven. So the mind reading magician has you! Humans can unlearn\nthis social programming and become quite good random number\ngenerators but normally we tend to conform.\nThere is a way two humans can generate a truly random number\nwithout training. Find a friend for this experiment. One of you should\npick any number between one and ten and start counting under your\nbreath, when you get to ten just go back to one and keep repeating. The\nother should wait a while and then shout stop. The number reached should\nbe genuinely random. Please post the results on my website and I’ll tell\nMind over Computer\n45\nyou if this crowd-sourced random\nnumber generator really works.\nThere should be no way to predict\nthe resulting number as both\nof you are affected by quantum\nrandomness and, provided you\nwait a little before shouting stop,\nany social stereotyping should\nbe overcome. If you want to be\nscientific, remember the random\nnumber you started with and the\nlength of time before your friend\nshouted stop. There should be an\nimprovement in randomness with\nthe amount of time they wait.\nIn the absence of human\ninteraction another way to give\na computer access to a random\nnumber is from a quantum\ndevice. A lava lamp works well!\nThe Lavarand, developed by\nSilicon Graphics, is a hardware\nrandom number generator which\nuses images of a lava lamp to seed\na random number generator. It is\ncovered by U.S. Patent 5,732,138,\nLava Lamp\ntitled “Method for seeding a pseudo-random number generator with a\ncryptographic hash of a digitization of a chaotic system.” Got that!\nA computer does not acquire free will just through the injection of\nrandomness. You could simply put an intercept on the link from the lava\nlamp to the computer and completely predict the computer’s behavior.\nThe system as a whole will certainly do unpredictable things, but the\ncomputer did not make a choice; behaving randomly is not exercising\nfree will. Where is the will?\nConsciousness\nI remember my first trip to Death Valley in the United States. We were\ndriving along the main east-west highway at the bottom of the valley\nand a sign said, “Turn off your air conditioning now.” I did as I was told\nand to cool down I opened the window. When I put my hand out I felt\n46 Are the Androids Dreaming Yet?\nnothing; no wind chill, nothing. The air was so hot the wind carried no\nheat from my hand. When I imagine hot weather it always brings back\nthis memory. It’s my conscious experience of the world.\nHumans experience the world through a vivid lens we call\nconsciousness. It allows us to think about the world as we watch it and\nplan actions. But, it also summons associated memories, something\nscientists call ‘qualia’. Most writers describe consciousness as an internal\ndialogue with themselves and see it as a consequence of human language.\nThat’s probably because most writers are linguists. Non-linguists, perhaps\neven dyslexic engineers like me, experience consciousness as more of a\nvisual dialogue.\nIt’s hard to pin down consciousness as the difference between\nhumans and computers. Computers do have something that resembles\nconsciousness; they have watchdog functions, they plan and anticipate\nactions and are aware of their own existence. But they don’t understand\nor make free choices based on this consciousness. It is an entirely\nmechanistic affair. A computer might know its CPU is overheating and\nsend a notification message to the administrator, but it does not really\nappreciate what this means. It does not have our sensation of a near death\nexperience. This self-awareness is the ‘hard question’ of consciousness.\nWhy, despite the computer knowing it is overheating, does this not\ntranslate into the intense experience we have? Philosophers, such as\nDaniel Dennett, think this lack of consciousness is only a matter of time;\nonce computers live long enough and have sufficient internal complexity\nthey will begin to experience the world the way we do. We are nothing\nspecial.\nThe problem with consciousness is it does not seem to have any\nexternally discernible effect. Anesthetics can take it away and brain\nscanners can see that it has been switched off, but what is it for? I think it\ncomes hand in hand with our faculty of creativity. Consciousness allows\nus to shape the world – not the other way round.\nSteve Jobs\n“We can't solve problems by using\nthe same kind of thinking we\nused when we created them.”\nAlbert Einstein\n\nCreative Theories\nOnce I have exercised my free will by getting out of bed in the\nmorning, I often decide to do something creative. Humans seem\ndriven to create. We compose music, draw, paint, and solve\nmathematical puzzles. Computers are not naturally creative; they spend\nmost of their time doing exactly the opposite – following preset rules. Is\nthis a fundamental limitation distinguishing the computational world\nfrom the real world?\nThe Conventional View\nMost scientists believe pattern-matching algorithms in the brain allow\nus to be creative. To see how this might work, imagine our brains are\nchaotic – not hard to do – and process many competing ideas at the same\ntime. The neurons in our brains build millions of useful, and useless,\nconnections based on the patterns in the data we see and hear. Then a\nselection process goes to work – something akin to natural selection – to\nsift and prune the connections until something bubbles to the surface\nand we get that, ‘aha’ feeling.\nDouglas Hofstadter, Professor of Cognitive Science at Indiana\nUniversity, famous for the book Gödel Escher Bach, has written a computer\nprogram using pattern matching to discover number theorems; things\nlike any number ending in a zero is divisible by 5. The program produces\ninteresting results, even perhaps generating some new theorems. He\nargues the human brain is essentially a scaled up version of his program.\nBy the way, if you like trivia, his book Fluid Concepts & Creative Analogies\nwas the first book ever sold on Amazon.com.\n50 Are the Androids Dreaming Yet?\nThe Unconventional View\nRoger Penrose, Professor of Mathematics at Oxford University, holds a\ncompletely different view. He thinks brains operate in a non-algorithmic\nmanner and provides a sketch of the possible mechanism in two books –\nThe Emperor’s New Mind and Shadows of the Mind. He suggests tubulin\nmolecules, which form the skeleton of our neurons, exploit quantumgravitational\neffects to calculate non-computable functions. The\nscientific community was initially highly skeptical that quantum effects\ncould survive the warm, wet environment of biological systems, but in\nJanuary of 2014, Edward O’Reilly and others at UCL discovered plants\nuse quantum effects to improve the efficiency of photosynthesis. No\nprize has yet been awarded for this discovery but it must be a contender\nfor a Nobel Prize at some point. Recently Travis Craddock, now of the\nNova Institute in Florida, has submitted a paper showing a very similar\ngeometry of proteins exists within tubulin microtubules in the brain. He\nbelieves this is evidence quantum effects may exist there as well.\nA simple quantum effect in the brain could merely reduce the\nresistance of the wiring in the brain to help conserve power and avoid\noverheating. We recognize this is a major problem in building small,\npowerful conventional computers. Roger Penrose suggests an altogether\nmore radical idea. He proposes our brains are quantum gravity computers\ncapable of calculating non-computable functions. We don’t yet have a\ntheory for quantum gravity so his idea is at the cutting edge of physics\n– read highly controversial. He raises a deep mathematical question. If\nthe Universe is deterministic and effectively equivalent to a computation,\nhow does ‘creative’ knowledge emerge within it? Lots of knowledge can\nbe manufactured by simply mechanically rearranging data. That’s what\nhappens when I watch a DVD or play a computer game, but, at some\npoint in the past, a director or a programmer had to put in the creative\neffort to make the movie or write the computer program. How did that\nhappen? Was it baked into the fabric of the Universe at the moment of\nthe Big Bang? Is what we take for a Universe really nothing more complex\nthan putting a DVD in the slot and hitting play?\nOne last piece of trivia links Hofstadter with Penrose: Roger\nPenrose and his father invented the Penrose Steps, inspiring the neverending\nstaircase in the Escher prints featured in Hofstadter’s book. For\nmovie buffs, the Penrose steps appear in the film Inception, starring\nLeonardo DiCaprio. The fact we get pleasure from these trivial links tells\nme something is going on in our brains that is not so mechanical.\nMind over Computer\n51\nM. C. Escher’s Ascending and Descending (Penrose Steps)\n\nChapter 2\nUNDERSTANDING\nAfghanistan COIN Dynamics\n“Power corrupts, PowerPoint\ncorrupts absolutely.”\nEd Tufte\n“No battle plan survives contact\nwith the enemy.”\nColin Powell\nOriginally, Helmuth von Moltke\n54 Are the Androids Dreaming Yet?\nJohn Masters stood up to address General Stanley A. McChrystal\nand his military staff in Kabul. The topic, of course, the war in\nAfghanistan. The main war lasted only eight weeks, but this did not\nend the conflict. A level of tribal violence and insurgent warfare rumbled\non for years, killing around 30 people a week. Masters’ job was to explain\nthe dynamics of Afghanistan and provide politicians and military\ncommanders a framework to understand what was going on.\nThink about your country for a moment. What maintains the fabric\nof society – police, family, the local charity club, church, newspapers, the\nbroadcast media? All these institutions work to keep us civilized, but what\nhappens if a country loses them? There are institutions in Afghanistan,\ngood and bad: tribes, gangs, corrupt officials, families. Masters had spent\na year investigating these interactions, and questioning the returning\ncommanders. He and his team believed that understanding the dynamics\nof the conflict was the key to bringing peace to Afghanistan.\nIf you live in an industrialized country, you rarely see society\nwithout its civilizing web in place. One interesting ‘experiment’ that\nshows what happens when it fails was the 1976 traffic police strike\nin Finland. Finland is a fantastically law abiding country where most\npeople obey both the written and unwritten laws. During the strike, this\nbehavior changed. Many people began parking illegally but refrained\nfrom blocking the roads. A few took advantage of the absence of police to\ndrive incredibly fast – twice the national limit. These would be labeled as\n‘defectors’ in game theory. Without traffic police, a different automotive\nGeneral Stanley A. McChrystal\nUnderstanding\n55\nmorality emerged, a different structure to society. Of course all the other\nparts of society remained the same. People paid their taxes and went\nabout their lives normally; only the traffic behavior was affected.\nAfghanistan has had most of its social structures removed over the\nlast forty or so years. First the Soviets, and then the Taliban, took apart\nmuch of the fabric until finally the Allied Forces swept the Taliban out,\nleaving very little behind. There were no police or courts, and few laws\n– or at least none enforced by the rule of law. The Allied Forces have\nspent a decade rebuilding these structures. Before we examine Masters’\npresentation, let’s look at the daily life of an Afghan farmer.\nIf you are an Afghan farmer you have a dilemma. Your most reliable\ncrop is opium. It grows well in the arid soil, does not require irrigation, and\nis resistant to most pests. For this crop there is a financial infrastructure\nto rival the Chicago Commodities Exchange. You get interest free loans\nsecured against the crop, and you can forward sell your product on a\nfutures market. Your investors can ‘add value’ by dealing with the major\npest – the US military. They do this through the simple expedience of\ntaking pot shots at them if they get too close to the crop. Since a field of\nopium is worth $30,000 and a militia wage for the year is $350, you can\neasily employ a few men to protect your investment. Of course, you are\nindebted to thugs and criminals, but they are at least reliable thugs and\ncriminals.\nOn the other hand, the traditional products of the Himalayas –\nwalnuts, pomegranates and vines – need years to cultivate. There is no\nforward market and the timescales over which you must take risks are\nfar greater. If you believe your American protectors will leave before the\ncrops mature, you will be loath to plant and care for them. But, if you\nmake the decision to take this risk, you have a strong incentive to foster\nstability and reap the rewards of your effort. There is a feedback effect:\nthe balance of power between all the different parties is important to the\ndecisions you make, and the decisions you make affect your desire to\ninvest in future stability.\nMasters’ team built a slide pack to demonstrate the complex\ninteractions between the groups: farmers, security, stability, markets,\nmilitary power, and emerging institutions. The COIN – COunter\nINsurgency – dynamics slide shows just how hard it is to communicate\ncomplex topics between human beings. The presentation is beautifully\ncrafted but it was a public relations disaster. At the end of the presentation\nGeneral McChrystal said jokingly, “When we understand that slide, we\nwill have won the war.” The slide was paraded in the press as, “the most\ncomplicated PowerPoint slide in history.”\n56 Are the Androids Dreaming Yet?\nIf you invest a little time on the slide you will understand it\nand may even see it as a thing of beauty. But Masters’ audience was\nobviously expecting something different and, presented with this level\nof complexity, went into shutdown. Perhaps they wanted a simpler\npresentation, a high-level summary, a few bullet points. Of course, there\nis no simple presentation on Afghanistan. The lesson is that context,\ntiming and expectation are often as important to good communication\nas the elegance of the content, and that information is a complex thing.\nIf you want a lighthearted poke at PowerPoint here is Peter Norvig’s\nPowerPoint version of the Gettysburg Address.\nUnderstanding\nNext time you are in a business meeting, count the number of times the\nword ‘understand’ is used. If you ask the people around you what it means\nyou’ll stump many of them. That’s because understanding has two very\ndifferent meanings. Most people don’t separate these meanings but the\ndistinction is important. Understanding means to decode information,\nto comprehend – but, more importantly, it also means to absorb and\ninternalize information. That feeling you have when you ‘get it’.\nIf I say, “I understand” I mean I have taken in the question you\nasked and decoded it into ideas so I can provide an answer. This can be\nquite a mechanical process and computers routinely understand natural\nlanguage and answer questions – Apple’s digital assistant Siri being a\ncase in point.\nWhen I say, “I understand a problem” or “understand a culture”\nI mean something far less tangible. Somehow the information I have\ngathered over my life is formed into a matrix within my brain that allows\nme to ponder and run scenarios. I can predict the effects of my actions\nbefore I do them, and often anticipate your responses. That’s clearly\na very useful evolutionary adaption, but is there more to it than that?\nRoger Penrose and David Deutsch think understanding allows us to\ntransfer non-symbolic information from one brain to another. We don’t\nrun programs in our brains, nor do we store precise information such as\nlists and tables. We have, therefore, had to evolve a creative approach to\ncommunicating skills and understanding each other. One of the most\nclosely studied areas in the field of communication is when it breaks\ndown in the lead up to a disaster.\nUnderstanding\n“The human mind tends to look\nfor clear linear relationships, we\nlike solutions that are close to the\nproblem in time and space and\nmake sense when we think about\nit quickly, unfortunately, those\nsimple solutions are usually\nwrong and come from acting on\na complex system as if it was a\nsimple one.”\nBrett Piersen\n57\nGettysburg Address, Peter Norvig\nSpace Shuttle Columbia Crew Photo\n“For a successful technology,\nreality must take precedence\nover public relations, for Nature\ncannot be fooled.”\nRichard Feynman\nBad Understanding\nCan Kill\nOn January 16, 2003, at 3:39pm, the Columbia space shuttle took\noff from Cape Canaveral. During the launch a small piece of\nfoam insulation broke off the fuel tank and hit the shuttlecraft.\nThe event was recorded on a few low-resolution video frames. They\nshow a tiny white object hitting the shuttle and a plume of dusty material\nsplattering outward. The shuttle made it safely into orbit and for two\nweeks engineers on the ground debated what to do. In the end, it was\ndecided the risk was minimal and the shuttle could safely return to Earth.\nOn reentry, the shuttle disintegrated, killing seven astronauts.\nNASA managers had decided the shuttle was undamaged based\non a series of presentations by the engineers. One image in particular\nanalyzed the potential\ndamage to the shuttle’s\ntiles from an impact.\nRead the slide, look\nat the key frames, and\ndecide for yourself what\naction you would have\ntaken.\nShuttle Tile\n60 Are the Androids Dreaming Yet?\nNASA Internal Slide\nWHAT DO YOU UNDERSTAND FROM THE SLIDE?\nSome images of the launch are shown on the right\nddd\nHere is what you should have understood from the slide: tiles are\nreally tough but if the foam dislodged from the fuel tank broke through\nthe outer coating it would cause significant damage. The estimated speed\nof the foam hitting the tile was 640 times greater than anything previously\ntested. Worried?\nIs this a proper understanding of the problem? You have the slide\nand the images. Take another look and think hard. If you want, you can\ncheck a video of a similar launch on YouTube to get a feel for the scale of\nthings, but the still frames shown all the information you need to make\nyour conclusion.\nUnderstanding\n61\nPhotographs of the Foam Impact from Video Footage\nFrame Showing Foam Dislodging\n62 Are the Androids Dreaming Yet?\nStill from Ground Camera\nLOOK AT THE IMAGES, WHAT HAPPENED?\nddd\nThe truth is you simply don’t know. If you are puzzling over the\nstrength of tiles, you have been misdirected. There is video footage of\nsome sort of impact on a wing mostly covered in white tiles, and a slide\ndescribing the effect of a benign sounding ‘foam’ hitting those tiles. But\nwhat is the evidence for an impact on a tile? The shuttle is certainly not\nmade entirely from tiles; I can see a window in the picture. You should\ninstead be asking more questions, “What happened?” “What hit what?”\nand “How bad is that?”\nIt was bad. The foam, a very tough material, had hit the leading edge\nof the wing, a weak point, punching a hole through it. The wing failed\non reentry and tore the shuttle apart. Clearly, a full discussion of the\npossibilities did not occur amongst the shuttle team, or perhaps it only\nhappened amongst the engineers in private. Once the analysis was tidied\nup and presented to ‘management’ it was a one-way communication of\nthe conclusions, not a discussion of the underlying ambiguous thought\nprocess. The result: people passively listened to the information rather\nUnderstanding\n63\nthan interactively understanding it and agreed on the recommendation\nthat it was safe to return. Clearly they did not understand the ambiguity\notherwise they would have realized they did not have enough information\nto form a conclusion. This is the tragedy of lack of understanding. If they\nhad known how little they knew, they could have deployed a spy satellite\nto take pictures of the damage – one was available nearby and would\nhave taken a few hours to re-task – but they did not.\nEd Tufte served on the second shuttle disaster commission and\nprovided an analysis of the disaster. He views slides as a poor medium for\ncommunicating complex problems and thinks documents are far better.\nThe danger with slides is they force you to simplify information in a way\nthat destroys the essence of the information. His analysis of the failure of\ncommunication at NASA formed a major part of the final report on the\ndisaster. Later he coined the paraphrase “All Power corrupts; PowerPoint\ncorrupts absolutely.” Good communication benefits from stories and\nnarrative, not bullet points and graphic fluff. Instead of using bullet\npoints, speak! After all, we have evolved for 250,000 years to understand\nlanguage, but only 25 to read PowerPoints. ’\nIf you write presentations, Ed Tufte’s book The Cognitive Style\nof PowerPoint is compulsory reading. He argues that much of the\ninformation you want to communicate is complex and interconnected.\nPowerPoint or any similar presentation software encourages you to\nsimplify it into hierarchical bullets. The format implies simple causal\nrelationships where none exists. This is dangerous. Communication\nshould convey understanding – which is very important – and not just\ninformation. What, you ask, is the difference?\nSearle’s Chinese Room\n“The hardest thing to understand\nis why we can understand\nanything at all.”\nAlbert Einstein\nThe Imitation Game\nAs an experiment, I am going to ask a student to spend a week in\na locked room. The room is perfectly nice; it has a bed, a light, a\ndesk, some reading matter, oh, and we’ll give him some washing\nfacilities too! Every now and then I post some food under the door to\nkeep him going, Pop-tarts and pizza (thin-crust) work well.\nOn the first evening a note is pushed under his door with a symbol\non it. The student puzzles for a while, then opens the book sitting on\nthe desk. The book says, “If you get a piece of paper with symbols on it\nlook them up and follow the instructions.” He looks up the symbols and\nthe entry in the book says, “Go to page 44, write down the third symbol\non a piece of paper then post it back under the door.” He follows the\ninstruction and is rewarded with another piece of paper, this time with a\nlarger set of symbols on it. Again he follows the instructions in the book\nand posts his answer back under the door. This goes on for several days.\nHe is somewhat bemused, but it passes the time, and he diligently looks\nup the symbols and performs all the complicated actions as instructed.\nMeanwhile, I meet our new Chinese graduate student and explain\nto her she needs to interview a potential translator for the department.\nHe has just come in from Hong Kong and there is a health scare, so we\nhave quarantined him in the lab room. He is bored and I have some\npaper for writing messages. She writes “hello” in Chinese on a piece of\npaper and posts it under the door.\n66 Are the Androids Dreaming Yet?\nThe exchange of notes goes on for a few days and the two seem to be\ngetting on well. There is even a little romance in the air. When the week is\nover I open the door and the two meet. The graduate student says, “Hello.\nIt’s nice to finally meet you in person.” The man is puzzled because, of\ncourse, she has spoken to him in Chinese. He knows no Chinese.\n“I’m terribly sorry, but I don’t speak Chinese,” he says.\nShe is puzzled, “But I spoke with you this last week!”\n“No, I really don’t speak it,” he says.\nAnd, of course, he is telling the truth. The book he has been using\ncontains the rules for answering questions in Chinese, but he has\nabsolutely no knowledge of the language. I’ll leave to your imagination\nwhether the two strike up a real relationship and live happily ever after.\nThis is the Story of the Chinese Room. The setup is able to fool\nsomeone into believing there is a Chinese speaking person in the room,\nyet there is not. Where does the understanding of Chinese lie? The man\ndefinitely does not understand Chinese. And the book clearly does not\nunderstand Chinese because it is an inanimate object. Yet the person\noutside the room is convinced she is communicating with a Chinese\nspeaker. The analogy to a computer is clear. The book is software and\nthe man blindly following instructions is the hardware. John Searle,\nwho devised the thought experiment uses it to show computers can\nnever understand because there is no place in a mechanistic system for\nunderstanding to exist.\nThe Chinese Room has sparked huge argument in philosophical\ncircles; let me boil it down to its simplest form. First, let’s refute Searle’s\nposition with the ‘System Argument’.\nThe man plus the book form a system. Systems understand; their\nindividual components do not. My blood does not understand. My brain\nwithout blood would not understand – it would be dead! Plug my brain\ninto a good supply of blood; add a dash of glucose, and it will understand\nthe most complex of things.\nThe systems argument is elegant and most scientists think this is the\ndefinitive argument against Searle, but Searle has a neat way to counter\nit. “Imagine”, he says, “that the man memorizes the book and leaves the\nroom. Now there is no system, there is just the man, but the man still does\nnot understand Chinese; he is just parroting rote-memorized words and\nrules.” Computers, Searle argues, process syntax – the rules of language;\nhumans understand semantics – the contextual meaning of language.\nArtificial Intelligence (AI) proponents hate the Searle argument.\nThey believe the memorization of a set of words and rules is exactly what\ngives us knowledge of Chinese. That is why we go to school!\nUnderstanding\n67\nA key problem posed by Searle’s Chinese Room is whether you can\nknow everything about a situation from just looking at the inputs and\noutputs. This is very similar to the restriction posed by the Turing Test.\nIn that case if we were to trace the wire from our computer terminal\nto the other room we would either find a human typing messages or a\nlarge box covered in flashing lights. This would definitively answer the\nquestion whether we were talking to a man or a machine. Similarly, if\nwe opened the door to the Chinese Room we would immediately know\nwhether there was a real Chinese speaker in there or not. But opening\nthe door on both tests misses the point. The question asks, “if the inputs\nand outputs are the same does it matter what is really going on inside a\nclosed system?”\nBlack Boxes\nExperiments involving closed systems are known as Black Box\nexperiments. They presume you can learn everything about the inner\nworkings of a box simply by probing it from the outside. Young electronic\nengineers are often given black boxes as a test. Electronic components\nhidden in the box are connected to three external terminals on the\noutside. The student is asked to deduce what is in the box using only\nan electric meter to probe those terminals. Here are a few examples of\nthe possible contents of a black box. They would all show up identically\non the student’s meter. Although internally different they are externally\nidentical. Even my ‘silly’ fourth choice with a cat in the box does not give\nBlack Box Equivalence\n68 Are the Androids Dreaming Yet?\nitself away if all you have to go on are electrical readings. (I dare say the\ncat would make its displeasure know if left in there for any time.) The\ncontents are, therefore, said to be black box equivalent.\nThe reason for teaching engineers about black boxes is to help them\nunderstand how to simplify things. We could construct option four, with\na cat and some food, but it would cost a great deal of money. Option 1 is\nfunctionally identical from an electrical point of view, but for a fraction\nof the cost. Steve Wozniak and Steve Jobs were so successful when they\nstarted Apple because Wozniak was brilliant at simplifying logic circuits.\nHe could take a design with thirty chips and come back with a black box\nequivalent solution using only five. It was a fraction of the cost and far\nmore reliable.\nScientists put great store in black box equivalence because of\na principle called Occam’s Razor. William of Occam was an English\nFranciscan friar living in the fourteenth century. He proposed the idea\nof minimal explanation. It states that, ‘among competing hypotheses,\nthe hypothesis with the fewest assumptions should be selected’. When\ntrying to explain the workings of a black box, the more complicated\ninner workings should be discarded, as they have no externally verifiable\neffect over the simpler mechanism. Our extraneous animal must be\neliminated! Sorry.\nIronically, given his calling, Occam’s Razor is sometimes wheeled\nout as a disproof of the existence of God. Surely God is a complication\nunnecessary to the explanation of our Universe. The argument is\nillustrated beautifully in Carl Sagan’s book Contact and the film of the\nsame name. God gets the last laugh in Sagan’s book when the difficulty\nwith Occam’s Razor is brought into sharp focus. Occam’s Razor contains\nan inherent paradox. At any moment in time we only have evidence to\nsupport the simplest of explanations, yet we know many of these simple\nexplanations are incomplete. We regularly discover new phenomenon –\ndark matter and dark energy being some recent examples. If we stopped\ndiscovering new things, Occam’s Razor would be a good way to simplify\nour thoughts. Occam’s Razor is a useful intellectual tool to prevent us\nover complicating explanations, but there will often be explanations that\nare correct, but for which there is not yet any observed effect.\nIf we go back to our black box example, we see the flaw in concluding\nthe boxes are identical from examining only their inputs and outputs.\nOpening them would clearly show they are not identical! But, how would\nthis fact reveal itself if they remain closed? The answer is: over time. If\nsomething in the box has memory or understanding, it could present\none set of results for a while and a completely different set of results later.\nUnderstanding\n69\nIn my trivial example, the cat could eat a wire and change the operation\nof the black box. Now there is an open circuit where none existed before.\nIf this happened, the output would change and we would need a new\ntheory to explain it. If the circuit was attached to a missile control system\nor a life support system, you would really want a full understanding\nwithout waiting. It’s humans nature to try to open black boxes. This is\nwhat MRI scans, X-rays, particle accelerators and all our other tools\nof scientific investigation are for. We want to open all the black boxes\nof nature and see what is going on inside: simply waiting to see what\nhappens is not acceptable.\nIn a sense, we live in a black box. We experience the world through\nour senses, seeing with our eyes and feeling with our hands. The brain\nnever directly experiences anything; it only infers the likelihood of\nScene from The Miracle Worker. Helen Keller\npictured at the moment she understood language.\n70 Are the Androids Dreaming Yet?\nsomething from the signals it receives. This is similar to our engineer\nprobing the terminals of the circuit of a black box. How can we know our\nexperience of the world is real?\nUnderstanding the World\nThe French philosopher Descartes gave us an explanation for this\nparadox. He spent a long time looking skeptically at everything we\nperceive. For example, when we poke a stick into a pond, the surface of\nthe water bends light and the stick appears to have a kink in it. Our eyes\ntell us the stick is bent, but our brain ‘knows’ the stick is straight: it’s an\nillusion. Descartes wondered if something so simple could be an illusion,\nperhaps the whole of our experience is too.\nHis eventual solution underpins much of modern philosophy – ‘I\nthink therefore I am’, cogito ergo sum. Even if we doubt everything else,\nwe cannot doubt we are thinking about this doubt. At least we can rely\nupon the existence of this ‘thought’ as some reality. Descartes built up\nfrom this bedrock the real world we live in. We can be sure we experience\nthings and can apply logic and use thought. We can use this intellectual\nfaculty to tell a great deal about our Universe.\nTrue Understanding\nIn the QED lecture series, The Strange Thing about Light and Matter,\nRichard Feynman relates the story of the ancient Mayan astronomers.\n3000 years ago they were able to predict the motion of Venus in the sky\nusing only pebbles. They had a simple system that could predict when\nthe planet would rise over the horizon. Put a stone in the jar every day,\ntake out a stone once a week, add a stone at every new moon. If the\nnumber of stones in the jar is divisible by 23, Venus will rise. I’m making\nup the details but you see the idea... It’s a very simple algorithm. What\nshould we conclude if the Mayans had perfected their calculations to\npredict the motion of Venus and it proved reliable over a whole century?\nWould this constitute understanding?\nFeynman would say no: the Mayan understanding was not\ncomplete. It was only black box equivalent to our modern understanding\nover a limited period. We known that once the Sun begins to run out\nof fuel it will swell to a red giant and explode, destroying Venus and\nthe Earth. Their model could not predict this catastrophic failure. Our\nmodern deeper understanding of the workings of the solar system allows\nUnderstanding\n71\nus to predict this future even though there is no clue from the motion of\nVenus today. Understanding allows us to predict discontinuous events: a\nsystem changing its state or a star running out of fuel.\nWe see the same predicament in stock markets. Stock markets\nnormally behave in a linear fashion but, when they go wrong; they go\nvery wrong. Recent recessions have been made much worse by the failure\nof hedging systems to handle market disruption. Some even think the\ncrises were caused by the automatic trading strategies of these hedging\nsystems.\nThe quants – as mathematicians in banks are called – spend\nconsiderable effort modeling financial instruments to show that if one\nstock goes down, another will go up at the same time. If the stocks\nare held together your investment is safe because, on average they will\nremain constant. The problem with these correlations, which often hold\nreliably for many years, is that when trouble hits they fall apart. Historical\ncorrelations don’t give us understanding of the future: something that\nwas only meant to happen once in a million years has happened within\nsix months. As they say on your investment papers, past performance is\nno predictor of future results.\nDo Computers Understand?\nToday’s computers don’t have our general-purpose ability to understand.\nWatson was thrown off by badly formatted English. The human\ncontestants, by contrast, had no problem with this. Just how good would\nWatson have to be, to call it – or should I say ‘him’ – intelligent? How\ncould I judge this had happened? Alan Turing proposed an ingenious\ntest in his 1950 paper Computing Machinery and Intelligence using ‘The\nImitation Game.’ We now call the Turing Test.\nIf we ask a series of questions to a computer and we cannot tell its\nresponses from those a human would give, then the computer is, for all\npractical purposes, the same as a human. Since we are intelligent – or at\nleast we hope we are – the computer must also be intelligent. QED.\nThat’s all there is to the Turing Test. Puzzled? Let’s pick his argument\napart.\nImagine you are chatting away on Facebook with someone you\ndon’t know. They may have posted a photograph so you can see what they\nlook like. The photo might be a fake; you have no real way to tell. What\nquestion would you ask the other ‘person’ to prove they were human and\nnot a computer? There are obviously some giveaway questions. Please\nmultiply the numbers 342,321 and 23,294 and give me the answer. This\n72 Are the Androids Dreaming Yet?\nwould be very hard for a human but easy for a computer. If you got a\nvery quick answer; the computer would have given itself away. But, the\ncomputer has been programmed not to give itself away, and it is free to\ngive the answer slowly or even reply that the calculation is too hard. Our\ncomputer can say anything it likes, including lying to pass the test! If the\ncomputer can fool a questioner into believing it is a human then Turing\nargued the computer has shown it is at least as intelligent as we are.\nIt used to be assumed that the field of broad general knowledge\nwould be hard for a computer, but Watson has shown this is not so. With\nenough storage and a reasonable algorithm, winning a pub quiz is well\nwithin the capability of a modern computer.\nThe really difficult questions for a computer are philosophical ones,\nnovel questions and things that don’t fall into a pattern. For example,\n“Are you happy?”\n“What do you think of Shakespeare’s Hamlet?”\n“Is there life after death?”\n“How went it?”\n“Think Differ…”\nIf a computer could plausibly answer this sort of questioning for an\nextended period, say fifteen minutes, should we conclude it is intelligent,\nor do we need more time to be certain?\nTuring’s approach to certainty was simple. Just ask lots of questions.\nAs you ask more and more questions, you will become increasingly\ncertain you are talking to an intelligent being. He characterized it\nas a linear process; after 15 minutes of questioning you might be\n99% certain and after a few hours 99.9% certain and after a few days\ncompletely certain. The problem with this approach is it does not flush\nout discontinuities. What if the questioning suddenly stopped without\nwarning or explanation? A human responder is likely to worry that the\nquestioner has had a heart attack and do something to find out what is\ngoing on including leaving the room. Humans can make creative leaps,\nsolve non-computable puzzles or come up with a clever new joke. A\nhumans could even announce the test is a waste of time and walk off.\nThey just exercised free will! A computer cannot do these things.\nEach year a group of scientists enters a competition run by\nCambridge University to win the Loebner prize, a competition to see\nhow close a machine can come to passing the Turing Test. If you can beat\nthe test you win $100,000. So far no one has come close and scientists are\nbeginning to realize just how hard it is.\nUnderstanding\n73\nNew Yorker Cartoon\nWith the anonymity the Internet provides we can imagine all sorts\nof strange scenarios if the Turing test could be passed. You would have\nno way of knowing what you were talking to. The New Yorker ran a\ncartoon back in 2000. “On the Internet no one knows you are a dog.” We\ncome across a similar problem the other way around when we encounter\nbad customer support. A few years ago, while trying to get an answer\nto a computer problem, I became convinced the thing responding to\nmy emails was a machine. The company did use machine responder\ntechnology so it could well have been. I asked it to prove it was human\nby putting the word marmalade into an English sentence and fixing my\n74 Are the Androids Dreaming Yet?\nproblem. The human pretending to be a machine saw the joke, fixed my\nproblem and replied “Marmalade is served with butter and toast.” The\ntest worked!\nUncannily not Human\nUnderstanding\n75\nThe sister test in robotics is equally hard. The goal is to simulate the\nphysical human form, its movements and mannerisms. It’s easy to get\nclose, but close is not good enough. The term ‘Uncanny Valley’ has been\ncoined to describe the discomfort humans have with something that tries\nto simulate a human being but does not quite get there. I think it is part\nof the reason Madam Tussaud’s waxworks are so fascinating. Humans\nhave a love-hate relationship with facsimiles of themselves. They love\nthe flattery but feel a sense of revulsion at anything that comes too close.\nSearle and Turing\nIn the Turing Test, we limited our senses to the purely symbolic: using\nonly typed words on a screen. I could break the lock on the door and go\ninto the room to see what was there.\n“Aha!” I would say.\n“I can see you’re a computer, I, therefore, know you’ll be good at\nsums and bad at creativity.”\nBut Turing wants us to see if the difference is given away purely\nthrough intellect. He argues there is no way to tell. But if you follow my\nargument from chapter 1, there is one way: ask the computer to find a\nnon-computable solution to a mathematical puzzle. This is, in practice,\na difficult test to pose because it might take a very long time. Twentyfive\nbillion people have lived on planet Earth during the last 350 years,\nand about 5 million of them were mathematicians. None of them was\nable to solve the problem posed by Pierre de Fermat until Andrew Wiles\nturned up but this is a clear difference between humans and computers.\nHowever long you give a computer it would never be able to solve the\nproblem.\nThis creativity test would take centuries to run if non-computable\nthought was rare, but I think we see it often – on display even when we\ntell jokes. In which case computers and humans should be easy to tell\napart: humans are the funny ones. I am not saying you can’t build a brain;\nour brains are physical devices, after all. I just believe a computer or a\nmechanistic machine, cannot think like a human being.\nI like the Searle argument but qualitative arguments are insufficient.\nWe need a quantitative argument. In the forthcoming chapters, I am\ngoing to look at the mathematical argument underlying the difference\nbetween human intelligence and computer processing. Before we do this\nlet’s take one last look at a qualitative difference; the way computers and\nhumans communicate.\n\nChapter 3\nBODY LANGUAGE\n& BANTER\nBody Language\n“England and America are\ntwo countries separated by a\ncommon language.”\nGeorge Bernard Shaw\n“I speak two languages, Body and\nEnglish.”\nMae West\n“The body never lies.”\nMartha Graham\nIn the summer of 1986 Ronald Reagan and Mikael Gorbachev met\nin person for their second negotiation session, this time at the\nHöfði House in Reykjavik. For five days, the leaders talked alone\nexcept for interpreters. Reagan badly wanted to develop the Strategic\nDefense Initiative; known by its nickname, ‘Star Wars’. The idea was to\nput smart weaponry in space that could destroy ballistic missiles before\nthey reentered the atmosphere. Reagan believed this would remove the\nthreat of imminent destruction that had hung over the world since 1945.\nGorbachev, on the other hand, felt this was just another escalation in\nthe Cold War, and the Soviet Union would be forced to build yet more\nweapons to overcome the American defenses. He wanted Reagan’s plans\nshelved, arguing that it broke the Anti-Ballistic Missile Treaty. He was\nprobably right. The leaders talked back and forth, unable to overcome\nthe impasse. At the end of the summit there was a mad scramble to\nannounce some sort of deal, but this proved difficult. In the last moments\nbefore they had to conclude a communiqué, Reagan suggested they\nabolish all nuclear weapons. Reagan’s negotiating team was horrified and\nshut the door.\nFor decades, the American strategy had been to use nuclear\nweapons as a deterrent against the apparent numerical advantage of the\nSoviets. In all the potential scenarios analyzed by the Pentagon, Russian\nforces ended up overrunning American forward positions – otherwise\nknown as Western Europe! The only way to stop them was through a\nrelease of nuclear weapons, which, inevitably escalated to all-out nuclear\nRonald Reagan and Mikael Gorbachev\n80 Are the Androids Dreaming Yet?\nwar. It was assumed this inevitable progression deterred the aggression\nin the first place, and the threat of mutually assured destruction kept the\nworld peaceful. Giving up this tenet of defense strategy was something\nthe American military just could not contemplate. Many people did not\nthink it a rational defense strategy; it seemed appropriate the acronym\nfor mutually assured destruction is MAD, but this was the status quo.\nWe now know our worry over Russian superiority was groundless.\nThe West’s technological advantage, founded on the invention of\ncomputing and sophisticated materials technology, gave us a huge\nadvantage. In the only battle to be fought in the 20 th century between\nRussian and Western tanks, during the first Iraq war, most of the Russian\ntanks were destroyed with no losses to American tanks. We know this\nnow, but we are talking of a time when paranoia over the Soviet advantage\nwas the common view.\nThere is speculation that Reagan had muddled intercontinental\nballistic missiles with all nuclear weapons. I do not think this is true.\nReagan was a man of vision, quite comfortable with using his folksy way\nto convey sincere belief, and I think abolishing all nuclear weapons was\nin his mind. It would have been a breathtaking moment.\nIn the end a rather feeble communiqué was put together and the\ntalks declared a technical failure. But, both leaders had seen eye-to-eye;\nboth were prepared to make major concessions and both wanted an end\nto the old strategy of mutually assured destruction. Wiping each other\nout was no longer considered a successful outcome! The meeting, and\nHöfði House in Reykjavik\nBody Language & Banter\n81\nthe fundamental thawing of relations between East and West, was to lead\nto the Intermediate-Range Nuclear Forces Treaty and the end of the Cold\nWar.\nFace-to-Face Communication\nWhat really happened between these two leaders when they met and\ntalked? Was it a mechanical process of offer and counter-offer, as easily\nexecuted by fax, or is human interaction more complex than this?\nReagan, as a young man, had been a liberal, sympathetic to socialist\nideals until a painful strike in California caused him to lose faith in the\npolitics of the left. Gorbachev, a lifelong Communist, was desperate to\nreform the Soviet economy and make it more competitive. He, also, had\ncome to see the hypocrisies that could emerge in far left-wing ideology.\nI don’t believe this common experience could have been communicated\nby fax or email. Indeed, I am sure these specific points were never made,\nbut the nonverbal communication must have conveyed something of\ntheir common background and purpose.\nWhen we phone someone or exchange emails, the interaction is\nfactual, there is no body language, and we rarely laugh. When we travel\nto meet someone, we spend a great deal of time with them. The average\nlength of a phone call is two and a half minutes, but meetings, especially\nwhen one party has travelled to see the other, can be hours long. When\nhumans meet they greet each other, shake hands, sit in the same room,\ntalk at length, and laugh. Body language is important; people mirror\neach other’s postures, adopt open and receptive stances, and make\neye contact. You can see this in the picture of Reagan and Gorbachev\nabove. Body language allows us to convey qualitatively different things,\nsuch as trust and happiness. It is very expressive; you can see the more\nguarded postures of Yasser Arafat and Shimon Pérez below, just after\nthey negotiated a landmark peace deal. Can you tell if the leaders smiles\nare false?\nCommunication\nCommunication is one of mankind’s greatest expenditures. The US\ntelephone system is arguably the largest machine on the planet, while\nthe world’s mobile phone networks have a capital value of $2.5 trillion,\ngreater by an order of magnitude than all the steel plants in the world put\n82 Are the Androids Dreaming Yet?\nYasser Arafat and Shimon Pérez\ntogether. This lifeblood of our existence – long-distance communication\nbetween human beings – turns out to be amazingly difficult, even with\nall our clever technology.\nIn recent years the Internet has, in theory, allowed each and every\nperson to communicate freely with any other person on the planet.\nIn some of the most distant parts of the world mobile phones, and\nprojects such as; ‘One Laptop per Child’ are rapidly bringing unlimited\ncommunication to all. This communication can be personal, one-to-one,\nor broadcast: I can talk to people interested in a particular topic directly.\nAs we watch the Arab world democratize, catalyzed by the Internet, there\nis no question that digital communication has now become a major force\nin the world. Yet, people don’t communicate over the Internet as much\nas you would expect; they often use the Internet to set up phone calls\nduring which they arrange meetings! This is odd. We have a fantastic\nphone system and sophisticated communication technologies; email,\nvideo and instant messaging. Yet, we still choose to travel when we want\nto communicate.\nOn the face of it, there should be no difference between a phone\ncall and a meeting. In principle the same information can be conveyed.\nYet when we want to really understand someone, we always go to meet\nBody Language & Banter\n83\nSmiles Fake or Real\nin person. No great treaty or big industrial contract has been negotiated\nwithout a face-to-face meeting. We see this daily: people talking on the\nphone get to a certain point, give up, and arrange to meet in person.\nThe consequence is that we spend $550 billion annually, flying\naround the globe to meet each other. Each day the world’s population\ntakes three million plane flights. Around 80% of these are business\nflights. Some are people emigrating or going to do specific manual tasks,\nbut most are to have meetings. We have always assumed that this is\nbecause the parties are unable to reach a sufficient level of trust over the\nphone and need face-to-face interaction to build that trust, but it may\nbe that the parties are not able to convey sufficient information to fully\nunderstand each other. Face-to-face meeting may convey much more\ninformation than we think.\n84 Are the Androids Dreaming Yet?\nSmiles\nWhen we smile naturally we use a full set of facial muscles, including the\nmuscles around our eyes. When the smile is forced those eye muscles\nremain passive and the smile, although superficially the same, is missing\nsomething. You can’t put your finger on it, but the look is insincere. A\nstudy of marriages in the USA analyzed smiles in wedding photographs.\nThe couples with false smiles divorced much earlier than the genuinely\nhappy couples. Similarly for high school photos; people with genuine\nsmiles at 18 years of age were happier later in life and in more stable\nrelationships. Smiling is really important. It is good to be around people\nwho smile, they are more successful – and nicer.\nThere is also a curious reverse effect. The link between our minds\nand bodies is much more fundamental than we thought. If you grasp a\npencil between your teeth, it forces you to smile. Try it. The mere act\nof smiling is found to make you happier, it causes the release of the\nchemicals called endorphins which improve your feeling of well-being.\nMicro-expression Analysis\nSince the involuntary movements of the muscles around our eyes give\naway genuine happiness, a whole science has evolved looking for other\nbiological cues to mood. The two most interested groups are the FBI,\ntrying to detect lies, and poker players, trying to make money! Much has\nbeen written on the topic, including a few best sellers, but the evidence\nfor micro expressions is mixed. Regardless of whether involuntary\nactions give away our emotions, humans voluntarily use a great deal of\nbody language when talking.\nBody Language\nA study by Albert Mehrabian is often cited to say 93% of the information\nin a conversation comes through nonverbal cues. This is misquoted.\nThe study really stated 93% of the emotional content is nonverbal.\nThat’s more believable. And further studies have shown when there is\ndoubt, nonverbal cues win over verbal information every time. The rule\nis sometimes laid out as the 7%-38%-55% rule – 7% words, 38% tone\nof voice and 55% body language. Remember this is emotional content,\nyour conviction and sincerity. You will still have to get over the factual\ninformation you want to convey.\nBody Language & Banter\n85\nLearning Swedish with The Two Ronnies\nTry this experiment on a friend. Tell them you like their shirt using\ndifferent tones of voice: sarcastic, sincere, amazed. Then see what they\nunderstood. You will find it difficult to appear sincere because I have\ntold you to say you like their shirt – unless of course you really do. When\nyou use sarcasm they will find it hard to process your statement. It is\nrevealing how we use the information.\nInterestingly, a piece of research described in Scientific American\nshows even insincere flattery is effective. If you want a pay rise from your\nboss, any form of flattery will do. Vanity appears to override skepticism!\nInteraction\nThe normal cadence of communication between people includes a great\ndeal of mutual interruption. When a meeting breaks down we often see\npeople begin to say things like, “Please don’t interrupt me,” “Do you\nmind, I was talking,” “Pleeeease, let me finish.” If the meeting is really\ngetting out of hand, third parties will often step in and tell one to wait for\nthe other. This is where the mechanics of face-to-face interaction fail, as\nwe need to interact in order to communicate effectively.\nBecause we have a lot more time in a face-to-face meeting people\ncan wander ‘off topic’. This is an important part of the process of\ncommunicating. After all since most phone calls are 2-3 minutes and\n86 Are the Androids Dreaming Yet?\nmost meetings an hour, there are another 57 minutes to fill! These off\ntopic items bring in social experience and help us form the background\ncontext we need to properly communicate.\nWhat is Background Context?\nAlex and Bella are both fans of the British comedy duo, the Two Ronnies,\nand enjoy their learning Swedish sketch. Bella asks Alex what kind of\nsandwich he wants for lunch. Alex replies ‘M’. Bella laughs. If you have\nseen the sketch you will understand the background context to the joke.\nIf not this paragraph might as well have been in Swedish. Take a look at\nthe sketch on YouTube and reread this paragraph... Now you understand.\nDo I think in English?\nMost scientists believe we think thoughts using language, but most\nscientists writing about thought are linguists or psychologists. If you are\na dyslexic engineer like me, language is a long way down the processing\nchain. I think abstractly and then translate those thoughts into words.\nSome ideas don’t map between languages and often, one language adopts\nthe words of another to fill in the gaps. Some interesting examples are:\nZeitgeist\nSchadenfreude\nChutzpah\nGerman, spirit of the times\nGerman, enjoying others misfortune\nHebrew, audacity\nAll of these are fully signed up, card carrying entries in the Oxford\nEnglish Dictionary.\nSome languages have fewer distinctions between ideas: truth and\nlaw are the same word, ‘torah’, in Hebrew. Languages have different\ntenses and structure. In Chinese all words are one syllable and the script\nis pictographic rather than phonetic. This is unusual, even Egyptian\nand linear-B, which look pictographic are mostly phonetic. With single\nsyllable words, Chinese uses voice inflection to change meaning; a rising\nor falling tone can change the meaning of a word from ‘grey’ to ‘girl’.\nIn many Western languages rising voice inflection is used to indicate a\nquestion, as in Australian English or irritation, as in English English. So\nhow do the Chinese show if they are annoyed or want to ask a question?\nThey elongate their words and accentuate the changes in intonation.\nAn argument in Chinese can sound quite alarming to the Western ear,\nwith its percussive monosyllables and extreme inflection changes. This\nBody Language & Banter\n87\ndegree of inflection is used in English, but only in extreme emotional\ncontexts: A Chinese argument over cold tea can sound like an accusation\nof murder to a Western ear.\nSymbolic Communication\nThe earliest recorded permanent human communication is cave\npainting, dating to 33,000BCE. Written communication emerged in\nSumer, the southern part of Mesopotamia (now Iraq), using a script\ncalled Cuneiform, written on clay tablets. It was used primarily for\naccounting. The Sumerians are responsible for our common use of base\ntwelve. Twelve hours in a day, inches in a foot, and notes in the scale; all\nstem from their civilization.\nAlthough not the first to write stories, the Greeks perfected the\ndramatic forms we use today: poetry, prose and plays. Watch an episode\nof ‘Law and Order’ and you are seeing a direct descendant of a Greek\ntragedy, complete with suffering and justice denied. All this permanent\nthought art is made possible by the translation of ideas into symbols.\nScripts and Symbols\nThe world supports a huge variety of scripts split roughly into phonetic,\nrepresenting the component sound of words, and pictographic, stylized\npictures of the ideas.\nChinese Traditional and Simplified\nSome scripts have interesting quirks. Ancient Hebrew, although\nphonetic, is a script where vowels are omitted. Modern Hebrew often\nleaves them out as well. This means words can be ambiguous and need\ncontext to decipher them. A common set of Chinese characters has long\nbeen used by Mandarin, Cantonese, and Japanese speakers even though\n88 Are the Androids Dreaming Yet?\ntheir spoken languages are entirely different. The script languages of\nthese people are gradually diverging and might in time become entirely\nseparate languages too.\nThe Chinese government in Beijing has moved to using simplified\nChinese for Mandarin speakers, while Hong Kong continues with the\ntraditional form. Japanese has developed many new characters for\nmodern ideas, such as computers, that differ from the Chinese, and mixes\nin a great deal of Katakana, a script allowing the phonetic representation\nof foreign words. If you walk around these countries their signage looks\nquite different, although I am told Cantonese speakers can still read\nBody Language & Banter\n89\nsimplified Chinese. Take a look and normally you will find them to be\nquite different. Each example in the figure is my best attempt to translate\nthe phrase “Hello Reader” into a script and the corresponding language.\nSymbols of the World\nEnglish is one of the most irritating script languages of all. It commonly\nuses etymological elements, showing the history or origin of the word\nthat has nothing to do with the sound of the word. A word like school\nhas the ‘k’ sound spelt ‘ch’, showing its historical derivation from the\nGreek, but confusing for pronunciation. English has 53 sounds derived\nfrom only 26 letters, so there are plenty of letter combinations, many of\nwhich are irregular. Because the language favors historical convention\nover simplicity, sugar is pronounced “shu-gar” whereas sand is strictly\nphonetic. As for Leicestershire I’ll leave that as a test for the American\nreaders amongst you. If you’re British, try Mattapoisett, a town in\nMassachusetts named in Native American.\nYet English is also a ‘lovely’ language. Because of its richness there\nare often twenty different ways to say something, and a dozen words\nto choose on any topic. One of my own favorite words is ‘jump’. It is\nphonetic, but also onomatopoeic and even pictographic. Jump both\nsounds like a jump and looks like a jump.\nTwo scripts that puzzled scholars for many years are Linear-b and\nHieroglyphics. Linear-b – found on clay tablets on the Island of Crete –\nturned out to be a coded form of ancient Greek with some slight quirks,\nsuch as dropping the letter ‘s’ from the ends of words. The ‘s’ is superfluous\nin most Greek words, and dropping it saved precious clay space!\nHieroglyphics was a real puzzle. It looks so like a pictographic\nlanguage that it fooled many people for centuries. The Rosetta Stone was\ndiscovered in 1799 and became the key to their deciphering. This stone\nhad the same edict written out in 3 languages – Greek, Egyptian and\nDemotic. The French adventurer Jean-François Champollion decoded\nhieroglyphics in 1822 and although it looks pictographic, it was found to\nbe predominantly phonetic. Linear-a, another script found on the Island\nof Crete has yet to be decoded and remains one of the world’s greatunsolved\nmysteries.\nAll these different ways to code ideas into symbols present the\nchildren of the world a great learning challenge. Because written language\nis so young, in evolutionary terms, our brains have not had enough time\nto evolve to master it. Instead words co-opt parts of our brains originally\n90 Are the Androids Dreaming Yet?\nevolved for different purposes. As languages differ in their construction\nthey co-opt different bits of the brain. It is possible to see this using brain\nimaging.\nDyslexics – and I am one – have difficulty in translating between\nthe realm of conceptual thought and written script. This translation is\nsubtly different for each language. Chinese speakers use their motor\ncortex to process characters. Young children write out the characters\nover and over, to memorize them, so the ‘muscle’ memory is highly\ninvolved. French and Spanish children use the audio pathways, as most\nof their language is phonetic, the motor part of writing is then an addon\nand does not process meaning. English children must use portions\nof their visual cortex to process the meaning of words, as many words\nhave spelling quirks that have nothing to do with the sound of the words.\nSome studies even suggest a child dyslexic in one language, because, for\nexample, their audio pathway is impaired, might not suffer the condition\nin another language that relied on a visual or motor skill.\nCan Objects Communicate?\nThe process of communication has many components, starting with\nsomething capable of communicating. Communication usually –\nperhaps always – is something that occurs between sentient beings. I\ndon’t think of my computer as communicating with me, but rather think\nof it as a medium for communication or a dumb machine. But colloquial\nlanguage around the subject is a little muddled. We all agree a lighthouse\ndoes not communicate, even though it can signal danger, but what do\nwe mean when we say, “That song really spoke to me.” No one believes\nthe song is actually communicating, but some kind of communication\nwas made nonetheless. When we talk of communication do we mean the\nagent or the message?\nStories\nHumans enjoy communicating; we create works of art, music and\nliterature that transcend simple analysis. The COIN dynamic slide,\nwhich we saw earlier detailing the strategic situation in Afghanistan,\nwould probably have been better communicated with a story. Humans,\nunlike computers, do not cope well with large quantities of unrelated\ninformation, and studies of memory and comprehension show we\nBody Language & Banter\n91\nbenefit from a narrative structure. Let me give you a basic example. One\nsimple trick the human brain uses is chunking. Give yourself a moment\nto try to learn this string of characters.\nHALTNTIBMGTATLAMATLOLPOMSGTG\nTRY TO MEMORIZE THE STRING WITHOUT READING ON\nNow, if I divide it into chunks, you will see it includes meaningful\ninformation.\nHAL TNT IBM GTA TLA MAT LOL POMS GTG\nYou probably won’t recognize all the acronyms unless you are\nunder 10. Even then, you will find memorizing it hard, but if you put the\nsequence into the context of a story then it is much easier to learn.\nHAL uses TNT to blow up the IBM building in Grand Theft Auto.\n“Three Letter Acronyms are annoying,” says MAT. I’m Laughing Out\nLoud; Parents Over My Shoulder. Got To Go.\nWe find it easier to fit new information into existing structures\nwithin our brains rather than memorizing by rote. I’ve used quite a\nbit of modern Internet slang here. You’ll find young people recall this\ninformation better than older people for whom GTG and POMS are\nnonsense.\nIf you want to memorize something, experts recommend you\nimagine bizarre images and relate them to a story pictured in the mind’s\neye. Try it and you may very well find you can still remember my sentence\nin ten years time!\nLet’s try something else. The following sentences are a little different,\nyet the recall scores for information in the two are dramatically different:\n1. I met an old tramp on 42 nd Street wearing a dirty grey rain coat.\n2. New York on a cold damp November day; as I cross the street\nI bump into an old man wearing a dirty grey Macintosh. His\nshuffling gait suggests some sordid intent. I think nothing of it,\nbut this brief meeting was to change my life.\n92 Are the Androids Dreaming Yet?\nThe addition of contextual cues allows you to form a mental picture.\nBy withholding some information at the end I have used a dramatic trick\nto cause your brain to free wheel and imagine what happens next. You\nare involved in the story. Notice the longer story, with more data in it, is\nparadoxically more comprehensible and memorable.\nEd Tufte makes the point about our ability to process information\nvery forcefully. He believes presentation experts are wrong when they\nrecommend you keep your slides to a few words! He points out the\ncommon advice to use only six bullets per slide and six words per bullet\ncomes from a misconception that has blighted a generation of presenters.\nStudies performed on memory in the 1960s measured unrelated word\nrecall. Six words are all you can remember if the words are meaningless.\nBut if the words have meaning we can comprehend and absorb many\npages of data. Hundreds of millions of people throughout the world read\na newspaper every morning and can recall the stories throughout the\nday; the poems, songs and plays we memorize when young are usually\nlong, comprising thousands of words, yet we are able to remember them\nverbatim for the rest of our lives.\nWhen we tell a story, we are trying to draw the reader in so they\ncan to experience our imaginary world and be ‘in’ the story. When I read\na story – perhaps Harry Potter – I don’t think about the grammar and\npunctuation, or even the accuracy of character portrayal. I’m transported\nto a different place. I experience a piece of the reality or ‘imaginality’\nthe storyteller has created. I can describe the characters, the scene, the\nsounds and the smells. A good author forms a complete world in our\nheads corresponding with the world they have in their heads. With more\nabstract information, comprehension and retention is harder. Often if\nthe information does not hang together in a linear narrative it can be\nimpossible to take in at a single sitting. However, if it forms a story and\nis well told so you ‘get it’, you do not need it repeated. We experience\nsomething of this effect when we watch a good movie. “I’ve already seen\nthat one,” means you have absorbed the whole story in a single sitting.\nYou don’t need to watch it over again to comprehend it.\nComedy\nFinally, when you mix all the elements up, emotional understanding,\nbody language, in-person communication and empathy; you get comedy.\nHumans ‘do’ comedy from a very young age and it’s vitally important to\nthe fabric of our lives. What purpose comedy serves in communication\nBody Language & Banter\n93\nMy XBox is Broken\nThe One Ronnie\nDead Parrot Sketch\nMonty Python\nGerald the Gorilla\nNot the 9 O’Clock News\nFork Handles\nThe Two Ronnies\nAndre Previn\nMorecambe and Wise\nSelf Defense Against Fruit\nMonty Python\nis not clear. In life, telling a joke will make another person smile. This\ncauses people to be happy and happy people release chemicals into their\nbloodstream which make them healthier. Happy people then tell jokes\nto others. This circular process improves the well-being of communities\nand helps bond people together. But why on Earth did comedy evolve to\nbe the mechanism that does this?\nComedy may be an important way to avoid an argument when\ncontext is unclear. Much of what we say can be taken the wrong way.\nSimple communication of fact can sound like criticism or challenge, and\n94 Are the Androids Dreaming Yet?\nhumans are naturally hierarchical – not unlike packs of dogs or beached\nwalruses. Humor allows us to test the response of others to statements,\nwhich might otherwise be taken the wrong way. Something said in a\n‘jokey’ tone of voice may not generate a negative response, even though\nthe raw content might be quite provocative. “Ah, late again I see…”\nIt is worth taking a look at some great comedy sketches because\nthey bring home the richness of human interaction. Here are some of my\nfavorite links as an antidote to the heavy-duty mathematics I am about\nto inflict on you.\nThe World’s Funniest Joke\nTwo hunters are out in the woods when one of them collapses. He\ndoesn’t seem to be breathing and his eyes are glazed. The other guy\nwhips out his phone and calls the emergency services. He gasps, “My\nfriend is dead! What can I do?” The operator says, “Calm down. I\ncan help. First, let’s make sure he’s dead.” There is a silence, then a\ngunshot is heard. Back on the phone, the guy says, “OK, now what?”\nSpike Milligan, from The Goon Show\nI think comedy is a fitness display. It demonstrates to those around\nus – particularly of the opposite sex – that we can be creative and use\nnon- computable thought processes, just as dancing is a fitness display of\nour agility and coordination. When we tell a joke we are showing others\nwe can ‘think outside the box’, a valuable survival skill.\nAt a simple level it has been proven that animals with the ability to\nbehave randomly escape being eaten more often than animals that follow\na pattern. Non-computability is the ultimate behavioral randomizer\nsince it is not an algorithm and cannot be copied. The ability to take\nnon-computable thinking to its logical conclusion to create and invent\nhas clearly taken off for humans.\nOf course, another explanation might be that making people happy\nis fun. People like to be around other fun people so humor encourages\ncrowds to form. If a saber-toothed tiger attacks you, and you are in a\ncrowd, you’re more likely to survive. You only have to outrun one\nmember of the crowd!\nChapter 4\nTHE BRAIN\nBaby EEG\n“The brain is a wonderful organ;\nit starts working the moment\nyou get up in the morning and\ndoes not stop until you get into\nthe office.”\nRobert Frost\n“The brain looks like nothing\nmore than a bowl of cold\nporridge.”\nAlan Turing\nPhysically the human brain is very boring. Alan Turing described it\nas looking like a bowl of cold porridge. To get to the porridge you\nmust first cut through the skull, a two-millimeter thick protective\nlayer of bone. The adult human skull has almost no gaps in it, and the\nonly ways into the brain without a bone saw are through the eye sockets\nor the soft area of bone at the back of the nose. Egyptian mummies had\ntheir brains removed through the nose and preserved in a jar for the\nafterlife!\nThinking with Porridge\nProtecting the brain is very important and the skull does a good job\nby being a tough, impenetrable barrier. But sometimes this toughness\nbackfires. In 2009, Richard Hammond, one of the presenters of the TV\nmotoring series Top Gear, suffered a crash while testing a land speed\nrecord-breaking car. Although he was in a multipoint harness, the\ncrash, at over 200 miles per hour, bounced his helmeted head around\nthe inside of the cockpit and his brain was badly bruised. As you know\nfrom experience, when you bruise you get swelling, and the brain is\nno exception. However, the brain is encased in bone, so this swelling\nhas nowhere to escape. The resulting buildup of pressure is dangerous,\ncausing an interruption of blood supply to the un-bruised parts. Brain\ndamage in such accidents is often fatal; Richard Hammond was very\nlucky to live through the experience.\nSurgeons often need to cut into the skull to relieve pressure on\nthe brain, or to gain access to remove tumors. Going through the scalp\ninvolves a great deal of blood, but once you have a clean hole in the skull\nyou can peel back the thin membranes, called the meninges, to reveal a\nwrinkly folded whitish thing that looks a bit like a cauliflower. This is the\nouter surface of the brain where much of our thinking is done. Unfolded,\nthis surface layer would cover the area of a football field and this intense\nfolding distinguishes the human brain from the brains of simpler animals.\nSome animals, such as elephants and dolphins, have larger brains than\nours, but the area of their folded surface is considerably smaller. It is\nthought that this efficient folding is key to giving us the ability to think\ncomplex thoughts.\nAnalysis of Einstein’s brain held at Princeton University shows it\nis not particularly massive, but it is strikingly more folded than average,\nand has a shorter lateral sulcus – the fissure between the front and back\n98 Are the Androids Dreaming Yet?\nEinstein’s Brain\nof the brain. Whether this is related to his highly creative thinking or just\nrandom chance is unknown, but it’s an interesting data point in our quest\nto understand creativity and intelligence.\nLooking through a microscope, the wrinkly grey matter is composed\nof 30 trillion neurons; small whitish cells sprouting filaments that wrap\naround each other like the tentacles of an octopus. The tentacles, and\nthere can be as many as 10,000 per cell, are known as dendrites and spread\nout to nearly touch other neurons. At the other end of the neuron is a\nsingle axon. The gaps between the end of an axon and the next neuron’s\ndendrites are called synapses, about one-tenth of the width of a human\nhair and varied in structure. When a nerve ‘fires’, an electrical pulse\nspreads out along the axon to the end and crosses the synapses to other\nbrain cells. This electrical pulse is not like the flow of current in a wire:\nneurons don’t conduct electricity. It is more akin to dominoes falling in\na line. Ion gates in the walls of the neuron open, letting potassium ions\nflow out. As the gates open in one section, the next section is triggered\nand so on. Thus, electrical signals ripple out along the axon. As the\nelectrical signals cross the synapses they either excite or inhibit the firing\nof adjacent neurons. There is a lot more structure to a neuron than was\nonce thought. The textbook model is of a sequence of ion sacks stacked\nend to end rather like plant cells, but neurons have a far more complex\nstructure. Bundles of actin and tubulin form a skeleton in the neuron and\nthe neuron metabolizes ATP to recharge its firing mechanism. Neurons\nbehave far more like small animals than inanimate plant cells.\nThe Brain\n99\nThe wiring of our brain looks a bit like the logic circuits of a\ncomputer, and our best guess is the cells in our brain form some kind of\ncomputer. The brain cells – a specialized form of nerve cell – connect to\nthe rest of the body via the nerve cells that largely run down our spine.\nThoughts trigger action and, in reverse, the nerves in our extremities\nsense things in the environment and relay information back to the\nbrain. If I think, ‘move my finger’ my finger will move, and if it touches\nsomething I will feel the sensation. Interestingly if my finger touches\nsomething hot a reflex will kick in. Reflexes work without involving the\nbrain. We don’t have to think, “that hurts.” Instead, our finger reflexively\npulls away. We may say ouch, but by the time we do, our fingers already\nmoved away from the heat.\nNerve cells are much slower than the electronic systems we build\nwith copper and silicon. This speed is quite noticeable and limits the\nrate we can do certain things. It takes around 0.08 seconds for a nerve\nimpulse to run down to the tips of our fingers, initiate an action and\nreturn to give us the sensation of the action. This may sound fast but if\nyou’re a tennis player in a rally or a pianist faced with a fast passage, the\nnerves don’t have time to make a full round trip signal before the next\naction must be initiated. In these instances we need to run on autopilot\nand there are parts of the body where the nervous system takes action\nwithout the brain getting involved. This is particularly the case with\nthings like walking and balance, which must respond fast to changes in\nground conditions. The signals just don’t have time – and don’t need – to\ngo all the way up to the top of the body for instructions. Rather like the\nheat reflex above, the peripheral nervous system can process information\nlocally. After all, brain cells and nerve cells are really all one type of cell.\nIf you have a group of people, you can conduct a fun experiment\nto show the speed of nerves. Hold hands in a big circle and squeeze the\nhand of the person next to you. When they feel you squeeze, they should\nsqueeze the next person’s hand and so on. The rate at which people\nsqueeze hands around the circle is limited by the speed at which nerves\nconduct the signals across our bodies.\nImaging the Brain\nThere are several ways to look inside the brain without recourse to a bone\nsaw. The methods are fascinating in their own right, even before we start\nlooking at the results. Each image is generated using a different physical\nprinciple.\n100 Are the Androids Dreaming Yet?\nX-rays\nThe first Nobel Prize in Physics was awarded to Wilhelm Röntgen in\n1901. He had discovered ‘X’ rays; so called because he had no better\nname for them. X-rays, as they became known, are just light of a very\nhigh frequency.\nLight comes in a variety of colors; at the low end of the frequency\nscale we see red, higher up blue and, at the top, violet. At this point\nhuman eyes give up and cannot see anything higher, so ultraviolet\nlight is invisible to us. Bees, on the other hand, can see a long way into\nthe ultraviolet spectrum and some flowers have beautiful ultraviolet\nmarkings that attract bees for pollination. Daylight contains a great\ndeal of ultraviolet light which is wasted on us – other than to tan our\nskin. But all is not lost. Clever manufacturers put fluorescent dyes\ninto their washing powders which stick to our clothes and convert\nultraviolet into visible light, making our T-shirts look brighter as they\nreflect more visible light than fell on them. You can see this effect most\neasily in a disco when ultraviolet lights are shone on the dance floor\nand anyone wearing a newly washed T-shirt will glow bright white. The\nother common substance that fluoresces strongly on a dance floor is\ntonic water. Quinine, the active ingredient in tonic water, is a strongly\nFlowers in Ultraviolet Light\nThe Brain\n101\nPit Viper\nfluorescent substance which converts ultraviolet light down into the\nvisible spectrum. Photoactive dyes have recently become controversial\nas suggestions have been made that they are unsafe and irritate the skin.\nGoing to discos might not be quite as fun in the future!\nThermal Imaging\n102 Are the Androids Dreaming Yet?\nAt the bottom end of the spectrum is infrared light. Pit vipers have\nevolved special organs on the sides of their heads to ‘see’ in this spectrum\nand they use this sense to hunt prey in the dark. I use the word see with\nsome caution. We have no idea what their sensation of ‘heat-sight’\ninvolves, but their organs are very precise, able to detect things only 0.2\ndegrees warmer than the background.\nInfrared cues help several species of snakes, bats and insects locate\nthings in the dark, but the animal that excels at the task, albeit using\ntechnology, is mankind. Special cameras allow us to use infrared to see\nin the dark or detect where our houses lose heat.\nX-rays are much higher in frequency – about one hundred times\nthat of the ultraviolet light that affects our T-shirts. The high frequency\ncorresponds to a small wavelength that allows the rays to pass through\nour bodies. Later on in the book we will understand that frequency is not\na proper explanation for light, as it is not a wave but rather a particle that\nobeys the laws of a wave. But for now we will ignore this detail.\nThe first use of X-ray images was to see broken bones. Bones block\nthe rays as they are dense, but the soft parts of our bodies are almost\ncompletely transparent to X-rays. We can see the soft tissues if we turn\nthe contrast up, but there are problems when using X-rays to view the\nbrain. Our skull completely encases the brain and however much we turn\nthe contrast up, all we see is bone. The solution to this problem is to\nperform sophisticated mathematical tricks using a computer to enhance\nthe contrast ratio and make image ‘slices’ through the living head.\nThe slicing technique was invented independently in the 1970s\nby Sir Godfrey Hounsfield, working for EMI in England, and Allan\nCormack, of Tufts University in America, and they shared the 1979\nNobel Prize for Medicine for their work. Legend has it that EMI was\nmaking so much money from The Beatles they could fund the enormous\ndevelopment cost of the CAT scanner from the profits; true or not, it’s a\ngreat invention.\nThe best way to understand the mathematics is to picture yourself\nin an episode of ‘CSI’, the American television crime drama. An intruder\nhas attacked someone with a knife and there are blood spatters all over\nthe walls of the room. Enter the brilliant pathologist who reconstructs\nthe scene of the crime from the pattern of blood on the wall. She can map\nthe trajectory of the blood spatters and back-calculate that the attacker\nmust have been 5’ 4”, left-handed and wielding a 6” blade. In a CAT scan,\nour head is hit with billions of rays that bounce and scatter over the walls\nof the machine. Sensors detect the rays and a mathematical algorithm\ncalculates an image of the body that would produce such a pattern. To\nThe Brain\n103\nX-ray of Roentgen’s Wife’s Hand\nsimplify things we shine the X-rays onto the head as a narrow slit of light\nso we only have to do the back calculation in two dimensions. Then we\nstitch successive slices together in the computer to form a 3D virtual\nimage. Thus, doctors can ‘fly’ through the brain looking at structures\nsuch as tumors from all angles.\n104 Are the Androids Dreaming Yet?\nThere are two problems with X-ray imaging. Even with clever\nmathematics, the dense bone in the skull blocks the rays so you don’t get\nmuch contrast, making it hard to distinguish normal brain matter from\nsomething like a tumor. But the bigger concern is X-rays are a form of\nionizing radiation, and ionizing radiation causes cancer.\nWe are told to wear sun block to protect our skin from ultraviolet\nlight; X-rays are 100 times more potent and can do a great deal of damage.\nFortunately, the body repairs itself quite well in the presence of low levels\nof radiation. The double part of the double helix in our DNA allows a\nset of proteins in our cells to go around correcting errors when they\ndetect a mismatch between the two strands. But, now and again an X-ray\nmight make an irreparable fault in both copies. If enough of these faults\naccumulate, they can lead to cancer or, if the errors are in reproductive\norgans, birth defects. Doctors try to minimize the radiation we receive\nand give us as few CAT scans as possible during our lifetime, especially\nwhen we are young and have not yet had children.\nMRI\nX-rays dominated our ability to see into the human body until the\nmid-1970s when Raymond Damadian came up with the idea of using\nmagnetism. Magnetic fields are not absorbed by bone and present\nno danger as they do not damage DNA. Ironically, the technique was\noriginally known as Nuclear Magnetic Resonance, ‘NMR’, which patients\nthought must be dangerous because of the word nuclear. The name was\nFunctional MRI: Working Memory\nThe Brain\n105\nDiffusion Tensor Image\nchanged to the one we use today: Magnetic Resonance Imaging, ‘MRI’.\nThe system works by applying a strong magnetic field to your body to\nexcite the hydrogen atoms. Since we are mostly H2O there are plenty of\nthese.\nThree magnetic fields are used. First, an extremely strong field is\napplied to the whole body. This causes all the hydrogen atoms in the\nwater and fat to spin in line with the field of the machine. Next a gradient\nfield is applied to the top of your head so it is slightly more magnetized\nthan the bottom of your feet and, finally, a pulse of magnetism is applied\nto the top of your head. The spinning hydrogen atoms line up a little\nmore when this pulse is applied and then randomize again when it is\nswitched off. As they randomize, they give off energy. The clever part is\nthe gradient field which causes the atoms to give off energy at slightly\ndifferent times – the top of your head first, your neck a fraction of a\n106 Are the Androids Dreaming Yet?\nfMRI\nsecond later, and so on down to your feet. What you see at any one time\nis a slice through a specific section of the body. You can then build up 3D\nimages from these slices and look at the soft watery tissue rather than the\nhard bone you can see with an X-ray.\nMRI scans give detailed images but today there are many more\nimaging tricks you can play. Give the patient gadolinium to eat – a type\nof paramagnetic material – and this contrast agent will highlight active\nparts of the brain. You can ‘see’ which parts are active: the location of\nemotions such as love, joy and even the effect of smells as the brain\nexperiences things. This is still coarse grained information; it shows only\nthe general area of excitation and it does not tell us what is going on at\nthe nerve level, but the images are fascinating.\nAnother recent development in imaging is the diffusion MRI. If you\nremember your school physics, molecules travel with a random walk:\nthey diffuse along pathways just as people wander along a corridor. If the\ncorridor is full of people, they are jostled around and make little progress.\nIf the corridor is empty, they move in straight lines. This difference in\njostling affects the reading in an MRI and allows you to color code the\nimage according to the rate of motion of water along the pathways. You\ncan therefore ‘see’ the rate at which signals flow in the brain and not only\nlocate thoughts, but also see the links between them.\nThe Brain\n107\nFunctional PET\nPET\nThe last scan we will look at is functional positron emission tomography,\nor f-PET. In this machine the scanner detects positrons given off by\nexcited oxygen atoms.\nAs you think, you burn glucose by combining it with oxygen.\nThe parts of the brain that are thinking hard use a great deal of oxygen\nand this shows up in scans. Again the consecutive slice trick is used to\ngenerate a 3D image that allows you to fly through the brain as it works\non a problem.\nThere is one problem common to all these methods. X-rays, MRI\nand PET scans only show us the location of thoughts with an accuracy\nof a few millimeters. Each pixel in the image contains around 10 million\nneurons, so we can’t see the details of thought. For a scale comparison it\n108 Are the Androids Dreaming Yet?\nis like looking at a car factory from space. You can see cars and people\ngoing into the factory but you can’t read the owner’s manual. We need\nto be able to see at least 10 million times more detail than our current\ntechnologies allow to see a thought.\nA Quick Tour\nNow that we understand how to look inside the brain, let’s take a tour\naround it. The brain is a highly distributed thinking machine. Some\nthings, such as hearing, are located in specific places while others, like\nthe enjoyment of music, are spread out.\nOur eyes work as an extension of the brain and use a specialized\ntype of nerve cell. Light falls on the retina and stimulates these cells,\ncausing nerve impulses to run along the optic nerve into the center of the\nThe Brain\nThe Brain\n109\nVisual Processing System\nbrain. The impulses split and form two distinct paths, one through the\ncerebral cortex, which gives us the sensation of conscious vision, and the\nother into the lower brain which provides us with instinctive reactions.\nThe right hand side of your body is connected to the left hemisphere\nof the brain and vice versa. This means each hand is controlled by the\nopposite side of the brain. But, your eyes see both your hands. To resolve\nthis conundrum a very complex thing has to happen to the optic nerve in\nthe center of the brain. The optic nerve from each eye splits and crosses\nover in the middle, so the left side of the left eye and the left side of the\nright eye goes to the right hand side of the brain and vice versa. This\nkeeps the brain focused on the correct hand.\n110 Are the Androids Dreaming Yet?\nFrogs Eyes are Very Sensitive\nThe processing power of the eye is staggering. The human retina has\nabout 120 million rods and 7 million cones, giving it an average resolution\nof 10,000 by 10,000 pixels. Each rod is sensitive to individual photons\nbut we register light consciously only if we see around 5-7 photons. It\nis thought frogs can react to single photons because of the chemistry of\ntheir eyes and the fact they are cold-blooded, but this is not proven.\nSome animals, including some frogs and my cat, have a tapetum\nlucidum. This is a reflective backing to the eye that allows each photon\ntwo chances to react with a rod, once on the way in and, if that fails,\nonce on the way out. This is why you can see the eyes of some animals if\nyou shine a light into the forest on a dark night. Cones are less sensitive\nthan rods but give us color perception. In the human eye, there are three\ntypes of cone: a red, a green and a blue, giving us trichromatic vision.\nWe see colors because light stimulates more than one types of cell and\nwe infer the color in between. A fourth type of cone is present in some\nspecies such as birds, reptiles, and fish. This gives them tetra-chromic\nvision, allowing them to see into the ultraviolet range. It is speculated\nsome humans might have this ability but so far none has come forward.\nSome animals lack the ability to see certain colors. Most dogs can’t see\nred. This gives cats a big advantage!\nMany people wonder if we all see the same color as each other. Is\nyour red the same as mine? The brain’s perception of color is complex.\nAlthough the color red is absolute and can be detected by a calibrated\nsensor, our perception of color is relative. We perceive them in the context\nThe Brain\n111\nColor is Relative\nof other colors – not in isolation. The two panels above contain identical\nblocks of color but they look very different against the background. Check\nout the website if you have a black and white book. It is an irrelevant\nquestion to ask if my red is the same as yours, since my red against one\nbackground is not even the same as my red against another.\nPeople generally agree on naming colors but not all languages have\nthe eleven specifically named colors of modern English: black, blue,\nbrown, gray, green, orange, pink, purple, red, white, yellow, if you are\ninterested. Ancient Celtic languages, so called ‘gru’ languages, recognized\nonly four colors and other languages don’t distinguish purple from blue.\nColor, or at least the naming of color, is a cultural thing.\nImpressionist Painting, Monet Haystack\n112 Are the Androids Dreaming Yet?\nThe resolution of the eye is not the same across the image. High\nresolution is concentrated in the center, while lower resolution black\nand white vision dominates the edge. This peripheral vision helps us\ndetect predators or play football but it is not the focus of our attention.\nWhen we focus our attention on something, we turn our eyes to look at\nit directly. The central part of our eye is called the fovea centralis and is\ncomposed of cones. About half our cones are concentrated in this very\nsmall section and this gives us immense visual acuity. For a computer\ndisplay to outperform this section of the eye it would need one billion by\nScintillating Dots Optical Illusion\none billion pixels. The fovea centralis is tiny, only two degrees across, so\nour eyes must dart around the image to take in all the detail. Once the\nbasic information is encoded in our retina and sent down the optic nerve,\nit goes into a production line process in the visual cortex where all the\nelements are analyzed. Our brains extract information from the image\nsuch as texture, edges and depth perception in specialized portions of\nthe brain. Because of this specialization it is possible to play tricks on the\nbrain with images that are not easy to process. Some we find pleasurable,\nwhile others can be a little disturbing.\nThe Brain\n113\nPenrose Steps\nOptical Illusions\nThis picture is an illusion that plays with your stereoscopic synthesis. The\ndots appears to flip between black and white. Other illusions play with\ndepth perception. The Penrose Steps are a type of illusion that tries to\nbuild an impossible physical model in our cerebral cortex. The brain sees\nperspective and depth perception cues, but the resulting shape could\nnever exist.\nHearing\nUnlike sight, hearing is an absolute sense. Our ears capture and focus\nsound down to the eardrum where a set of small hairs called cilia convert\nit into electrical impulses. The impulses stimulate cells corresponding to\nspecific pitches.\nWe are born with perfect pitch, yet most of us lose it early on. When\nI hear Maria Carey sing a top B flat a specific set of neurons located near\nthe ear fires, and if she sings a top ‘A’ then a different clump of neurons\nare stimulated. By the time most children come to learn music they have\nedited out this absolute pitch information. One group of children who\ndo not lose the ability are Chinese pianists. Because Chinese is a tonal\nlanguage – where the pitch of words affects their meaning – and because\n114 Are the Androids Dreaming Yet?\nMcGurk Effect; Go to the Website and Watch the Linked Video\nChinese children tend to learn the piano very young, they don’t lose the\nabsolute part of pitch. An astonishing 93% of these children develop and\nretain perfect pitch throughout their lives.\nThere are many cross connections between the audio and video\nprocessing systems. At parties you often can’t hear speakers clearly because\nof the background noise. Watching their lips will help comprehension,\nbut which sense wins if there is conflict between the two? The McGurk\neffect shows this.\nTo test the effect, go to the website, watch the video and see if you\ncan distinguish when a speaker talking normally and when he is making\nthe mouth movement of another sound. There is a winner. Try it for\nyourself; check out the link on my website.\nOnce upon a time people imagined the brain was like a camera\nforming an image of the world, but if this were the case there would be\na paradox. Who is looking at the image in our brain to make sense of it?\nModern research shows we don’t take a complete picture of the world\nlike a camera but rather parse the image into its constituent parts on the\nfly.\nIf someone asks, “Which side of the house is the tree on?” your\nbrain parses the question and compares it with the image map in your\nmind’s eye. What is the image composed of: trees, houses, sky, grass?\nYour brain manipulates the linguistic question about the relationship\nof elements and matches it with the visio-spatial understanding of the\nimage, allowing you to answer the question. You might not have to answer\nThe Brain\n115\nHumans’ Ability to Concentrate\nthe question verbally. If you hit a baseball, no language is involved; you\ndistinguish the ball from the background and perform quite a feat of\ntracking and calculation to connect it with your bat.\nBecause the brain is editing the scene on the fly to keep within\nits processing power, the eye only sees what it turns its attention to.\nMagicians take advantage of this to play amazing tricks on us. Watch the\nvideo on the web and then tell me what you see.\nVISIT THE WEB AND VIEW THE VIDEO TO SEE WHAT HAPPENS\nTiger Woods Swing\nYou can see just how intensively the brain works on a given problem,\nthrowing away all unnecessary information.\nThe brain contains mirror neurons, a type of brain cell that\nresponds when we see another human do something. These neurons\nfire as if we were performing the action ourselves even though we are\nmerely witnessing it. It is one of the ways we learn a skill. If I watch Tiger\nWoods’s golf swing, my mirror neurons will fire as if I were practicing\nhis swing. Later when I practice the swing for real, my neurons will have\nalready been partially programmed. This effect is presumably the reason\nwe enjoy watching sports; our mirror neurons allow us to begin acquiring\na skill while sitting in an armchair! This is clearly a useful evolutionary\ntrait but you do also need to practice for real!\nMirror neurons also fire in response to witnessing emotions. When\nwe see an actor laugh or cry, we experience their emotion as if for real.\nThis helps us empathize with the person we are watching and is part of\nthe reason we enjoy movies and plays.\nNeural Network\nThinking\n“We cannot solve our problems\nwith the same thinking we used\nwhen we created them.”\nAlbert Einstein\nIf you feel mentally exhausted reading this book, don’t worry. This\nis normal. Mental work takes energy. Scientists estimate the brain\nconsumes 20% of our resting energy; around 12 watts. Physical fitness\nis important for thinking. If you get out of breath running for a bus,\nthinking is going to be harder for you. Studies are mixed about whether\nthe additional work involved in solving a difficult problem causes you to\nuse more energy. We certainly see an increase in the flow of glucose to\nthe appropriate part of the brain, but the overall energy use in the brain\nis quite high in the first place, so it is hard to see the incremental effect.\nUnlike muscles, which store energy locally as glycogen, brain cells\n‘burn’ glucose and oxygen from the blood stream in real time. If scientists\ndetect glucose and oxygen flowing to a part of the brain they know it\nmust be working on a problem. As we know, there are several ways to\nmake glucose and oxygen show up in brain scanners. You can, therefore,\ninject someone with the right chemical markers, wheel them into a brain\nscanner, and watch them learn new skills. On a practical level, there\nis limited space within a scanner and you can’t wield a golf club, for\nexample. Julien Doyon, a researcher at the University of Montreal, was\nrecounting this problem to a friend and she suggested knitting. Knitting\nis a physical activity you learn just like a golf swing or a tennis stroke, with\nall the initial fumbles and jerky activity, settling down to a fluid learned\nskill. Most experienced knitters can engage in a full conversation while\nknitting complex patterns, only needing to break off and concentrate\nduring a pattern change. Luckily, there are ceramic and bamboo knitting\n118 Are the Androids Dreaming Yet?\nneedles which don’t interfere with MRI scanners, and they are small – no\ngolf swing problems here. Studies of knitters show that when they initially\nlearn a skill, several areas of their brain light up, but after a while, the\nbrain activity becomes concentrated in the sensorimotor striatal territory.\nGlucose, the brain’s power source, is a sugar we get directly from\neating sweets or indirectly by digesting starch. Some studies show\nchildren do slightly better at school if they eat starchy foods in the\nmorning for breakfast – a bowl of cereal or porridge. When you think\nand work your brain consumes the glucose in your blood, and blood\nglucose level drops. If there is a steady source of glucose from the starch\ndigesting in your gut, the glucose is constantly topped up and the level\nwill stay high. If there is no input of glucose from your gut, the body will\nfirst get glucose from glycogen in your liver or generate it by converting\nfat reserves. This takes more work so the body tends to avoid doing so\nuntil it absolutely has to. You can function with slightly lower glucose\nlevels but the body will shut down a little. One thing that suffers as a\nresult is the brain’s ability to perform cognitive tasks. A quick and easy\nway to fix this is to consume some raw glucose and most fridges have a\nready supply in the form of sugary drinks. Stories of kids running amok,\ndue to sugar highs brought on by too many sweets and sodas, appear to\nbe an urban legend. In tests, parents told their children have had a sugar\ndrink report them to be hyperactive even if they had been given a sugar\nfree drink. I’m not suggesting you drink lots of sugary drinks – it is bad\nfor your teeth and will make you fat – but the occasional soda is fine.\nMemory\nScientists are just beginning to explore the mechanisms that lay down\nmemory in the brain. There are two main classes of theory. The first\nbelieves memory is formed in the large scale wiring of the brain.\nNeurons connect with other neurons and the number and strength of\nthese connections cause memory. When we learn, new connections are\nformed. The electrical activity in a given part of the brain triggers the\nformation of new dendrites. They grow, piloted by tubulin micro-tubes,\nrather like vines growing in a slow motion nature clip. Once a microtube\nguided filament is close enough to other, a synapse forms. This\ngross-scale wiring growth is one method of memory formation. Another\ngross-scale effect is myelination. Myelin is the insulation the body uses\non nerves cells, including nerve cells in the brain. It looks a bit like the\ninsulation we used in the 1930s. Before the invention of plastic, strips of\nwaxed canvas were wrapped around wires to provide insulation. Myelin\nThe Brain\n119\nSynapse\nhas a similar structure. It is a flat protein laid down as a spiral on the\noutside of nerve cells. The theory is that cell firing causes myelination,\nwhich permanently imprints the memory.\nThe alternate class of theory proposes memory is encoded at a much\nsmaller scale. Neurons are quite complex structures in their own right.\nInside each neuron is a lattice of proteins, which forms a skeleton. Part\nof that skeleton provides structural integrity to the neuron, while other\nelements provide control and motility. It is this control part of the skeleton\nthat people believe might encode memory. A 2012 paper by Travis Craddock\nand Jack Tuszynski of the University of Alberta, and anesthesiologist Stuart\nHameroff of the University of Arizona proposes a protein called CaMKII\nbinds to the cytoskeleton in 32 different configurations, providing a binary\ndata encoding. It is an elegant idea but it also relies on your believing their\nmodel for quantum neuron processing which is still highly controversial.\nIf proven, they are my top Nobel Prize tip for this decade!\nPhotographic Memory\nUntil recently conventional wisdom held that true photographic memory\nwas a myth and the few people claiming to have it really used some sort\nof mnemonic memory technique to selectively memorize things. The\n120 Are the Androids Dreaming Yet?\nmost famous case was a Russian journalist known as ‘S’. He habitually\nmemorized things using association with places. In antiquity this was\ntaught as ‘the method of loci’. The unusual thing was his inability to turn\nthe effect off, and he found it as much a curse as a blessing. He was unable\nto forget useless information and found it hard to interpret complex\nimages, tending to see areas of color and shade rather than objects such as\ntrees, houses and fields.\nVery recently some people have come forward, six in America and\none in the UK, who appear to have genuine photographic memories It is\nwell worth watching the TV documentary The Boy Who Can’t Forget to\ngain a sense of what this is like. These people appear to lack the ability to\nforget, and this turns our understanding of memory on its head. It seems\nmemory might work the opposite way we thought. We had previously\nthought we only remember what we pay attention to, but perhaps we must\nactively forget, and this ability is missing in these subjects. Scientists are\nstudying these people to see if they can understand more about memory.\nThe Aging Brain\nWe can explode a myth and encourage older readers simultaneously.\nMemory does not deteriorate with age, or at least not until we are very\nold. Most studies looking at memory deterioration focus on the very\nold and compare them with the very young. Even then, the differences\nare small. When people are asked to attempt memory problems there\nis a mild drop off with age but the results are quite similar. The most\nlikely reason older people don’t remember so well is they don’t believe\nthey can. Perhaps they don’t have as much incentive to remember new\ninformation. Why learn someone’s name if you’re unlikely to meet them\nagain? Since IQ actually increases with age, don’t believe people when\nthey say you are going downhill from the age of 40. You are not!\nComputer Brains\nComputers are really quite simple compared with all the evolved\nbaggage we humans carry around. When a computer is presented with\ninstructions, for example, for a program like Excel and a file such as my\nexpenses, it will load everything into memory and ‘run’ it. The process of\nrunning a program is simple. Each instruction is a number. The computer\nreads the number, looks it up in a table, finds a corresponding number,\nand writes that down. Essentially that’s all there is to it. From a simple\nmechanism like this, we get the enormous complexity of a modern\nThe Brain\n121\ncomputer. The sophistication is achieved through reading and writing\nmany numbers in parallel, and chaining the steps together so that if you\nread a particular number it triggers another read/write process, and so\non. I’m glossing over some details such as logical functions but, if you\nknow how a modern computer chip is constructed, my description is\nnot far off. Almost all logic today is implemented in tables to achieve the\nspeeds we expect from modern chips.\nAll modern computers are clocked. A small piece of quartz rock\nhas been polished, coated with metal, and wired up to a control circuit in\nthe computer. When you apply voltage to the rock it bends and absorbs\nenergy. When the voltage is taken away it bends back and gives out the\nenergy. This is effectively a pendulum and it can be used to make an\naccurate clock. I used to design these for a living. Every logic gate in a\ncomputer is connected to this clock, and each time the clock ticks the\nlogic gates in a computer compute.\nMost modern computers are entirely synchronous. The clock rate\nis set so that the gates in the computer fully recover by the time of the\nnext tick, and every gate is therefore ready in its standard position when\nthe next instruction arrives. The human brain does not have a central\nclock. Each neuron acts independently – firing regardless of whether the\nneurons it is adjacent to are ready or not. It is wrong to think of the brain\nas digital. Each neuron does fire and recover, but it may be triggered again\nbefore it fully recovers. This makes for a chaotic and essentially analogue\noperation. If one neuron fires when a second has only half recovered, then\nit gets half an effect. If the neuron is 80% recovered, an 80% effect. Neuron\nrecovery time is quite long, perhaps as much as 1/1000 th of a second, and\nthey are wired in three dimensions to as many as 10,000 other neurons.\nIt is perfectly possible for a set of neurons to run one ‘program’ when\nthey are rested and a completely different ‘program’ when they are 50%\nrecovered and yet another programs if triggered from different starting\nlocations. I have said ‘program,’ but arguing a brain runs a ‘program’ is\nmisleading. It is not organized like this.\nNeural Networks\nA neural network is our best attempt at a computer model for the human\nbrain. Each neuron is represented by an entry in a table. The entry records\nall the connections to it, along with the strength of each connection –\nthese are called ‘weights’. In some models the connections can be both\n122 Are the Androids Dreaming Yet?\ninhibitors and activators like in real synapses. An individual neuron will\nfire if the sum of all the connections multiplied by the weights reaches a\ncertain pre-determined threshold.\nA neural network does not run a program in the conventional\nsense, and must be trained through experience rather like a human\nbrain. The training process allows the weights in the network table to\nbe adjusted to give the correct result. But, unlike the brain, you can read\nthe weights and even save them to a disk. The neural network tables\nstart with random settings. You show the network the letter ‘A’ and\nadjust the weights in the tables until it gives a positive answer: ‘It’s an\nA’. Repeat the process with the other letters until the network correctly\ndistinguishes them. As you do this a computer algorithm constantly\nadjusts the weighting tables using a method called ‘back propagation’.\nAt the end of the training process you can show the network some\nnew input and see how it does. For example, a letter ‘A’ that is in a slightly\ndifferent font to anything in the training set. Trained neural networks\ncan perform complex tasks such as recognizing faces or making clinical\ndiagnoses, and they can be allowed to modify their weighting tables as\nthey work so they learn from experience in a similar way to a human\nbrain. Strong AI proponents believe making a thinking machine is just\na matter of building a really large, fast neural network and working out\nhow to train it efficiently.\nQuantum Brains\nConventional wisdom says each brain cell is a single processing unit\nmaking an on-off decision – fire, or don’t fire – depending on the state\nof its neighbors. But, Stuart Hameroff, Professor of Anesthesiology\nat the University of Arizona, thinks neurons are not the fundamental\ninformation-processing unit in the brain. He suggests that this accolade\nshould go to tubulin. Tubulin is a small, versatile protein that selfassembles\ninto filaments rather like the way buckyballs – a magnetic\nchildren’s toy – can be arranged. There are two types of tubulin molecule:\nα and β. They slot together and wrap around to form a micro tube about\n25nm in diameter.\nTubulin micro tubes do several important things in the body.\nThey form the skeleton of neurons and give them structure. They are\ninvolved in guiding neurons as they grow towards each other to form\nnew connections, and they also operate in the nucleus of a cell to unzip\nThe Brain\n123\nParamecium\nDNA into its two complementary strands when a cell divides. In singlecelled\norganisms, including paramecium, the ends of the tubes stick out\nof the body and form the cilia that drive the organism along.\nThe presence of tubulin in complex, single-celled organisms\nprovides a clue that the smallest information processing unit might not\nbe the neuron. Some single cell organisms, such as paramecium, display\ncomplex behavior: hunting for prey and escaping danger. This suggests\nthey can process small amounts of information without the need for a\nmatrix of neurons. Since we evolved from these organisms, why wouldn’t\nour brain cells take advantage of this sub-cellular intelligence?\nThe structure of tubulin lends itself to digital processing as the\nmolecules forming the walls have two stable states and can flip between\nthem. We might recognize this as the basis of a binary computer, and\ncells might have little computers within them. They would not need to\nprocess many bits to be useful. Perhaps single-cell organisms developed\ninformation processing capabilities in their micro tube structures that\nallowed them to better survive and, as their nervous systems evolved, they\ncoupled these structures to form the brains we see today. This piece of\ntheory is not too controversial. After all, nerves have wiring within them\nto carry information to the synapses and it’s likely this wiring is involved\nin the thinking process. But Hameroff is not finished. He has teamed up\nwith Roger Penrose to bring quantum mechanics into the picture.\n124 Are the Androids Dreaming Yet?\nTheir reasoning is straightforward but has generated a great deal\nof controversy. Hameroff observes that anesthetics cause humans to\nlose consciousness by binding to tubulin, but they do not halt all brain\nfunction. He, therefore, concludes our conscious thinking is mediated\nby tubulin, not the larger scale firing of the neurons. Penrose had been\nlooking for a mechanism in the brain that would explain how brains\nsolve non-computational problems. Together Penrose and Hameroff\npropose tubulin micro tubes are quantum gravity computers that allow\nus to think non-computationally and are the seat of consciousness. The\nideas are still being worked.\nPenrose and Hameroff have a difficult task conveying their ideas\nto the rest of the scientific community. Scientists don’t recognize a\nneed for something that can think non-computably, so they are highly\nskeptical of a mechanism which performs that sort of thought. The\nlatest development on the Hameroff Penrose model comes in the work\nof Travis Craddock, now of Nova Southeastern University, Florida, and\nothers. They have written a paper arguing signals propagate according\nto quantum principles within microtubules through the excitation\nof thiamin molecules along the length of the tube. They believe these\nmolecules are quantum, entangled in a similar manner to the mechanism\nrecently discovered in photosynthesis. The geometry of these molecules\nis set out in a similar way to the active areas in chlorophyll and they\nhave a complementary problems to solve. Chlorophyll tries to maximize\nenergy conversion efficiency, while a microtubule tries to minimize the\nuse of energy while propagating signals along a nerve. You might wonder\nTubulin Protein\nThe Brain\n125\nTubulin\nwhere the light comes from since tubulin is housed deep within the\nneurons inside our brains and shielded from light by our skull. It turns\nout that the mitochondria which powers our bodies emit photons of UV\nlight as a waste product of their metabolism. The speculation is tubulin\nharvests this waste energy.\nBefore we argue for this mechanism any further we still need to\nestablish that a non-computational mechanism is needed to allow human\nthought. In the next chapters, we will look at the nature of knowledge\nand, in particular, mathematical creativity and the Wiles Paradox.\nQuantum Coupling of Tubulin in Microtubule\n\nChapter 5\nKNOWLEDGE\nChimpanzee and Typewriter\n“There’s an infinite number of\nmonkeys outside who want to\ntalk to us about this script for\nHamlet they’ve worked out.”\nDouglas Adams\n“I’m not young enough to know\neverything.”\nJ.M. Barrie\n“He has Van Gogh’s ear for music.”\nBilly Wilder\nCould an army of monkeys write Hamlet by bashing away randomly\non typewriters? Of course, we don’t mean this literally. We are\nasking whether knowledge can be created without understanding.\nCan a monkey, or perhaps some form of computerized random number\ngenerator, accidentally type out the script for Shakespeare’s Hamlet\nor write Tolstoy’s War and Peace? Is knowledge generation simply a\nnumbers game?\nLeo Tolstoy’s War and Peace is generally assumed to be the longest\nnovel ever written. This is not quite true. Wikipedia reckons the longest\nnovel is a French book, Artamène, with over 2.1 million words. Tolstoy\ncomes in sixteenth, with a mere half million!\nWritten in 1869, War and Peace tells the story of five Russian families\nduring the Napoleonic wars. Originally written in a mixture of Russian\nand French, and numbering over 500,000 words, it was quickly translated\nto other languages. The mistress of composer Franz Liszt translated it\nfully into French, where it expands to 550,000 words. Contrary to popular\nmyth the length of the book drops slightly in German. If you really want\nto save paper Chinese is best. Because\nit uses a single symbol per word, the\nChinese translation needs only 750,000\ncharacters compared with the 3 million\nfor English. It is wrong to assume this\nis necessarily more efficient than a\nphonetic language. Although it might\nsave on paper, it is considerably more\nlaborious to write. Three strokes are\nrequired to write ‘war’ in English\nwhereas the Chinese pictogram\nrequires ten.\nWar in Chinese\nComputers work with numbers. It is a simple process to translate\na book into numbers because books are composed of discrete symbols.\nAll we need do is give each symbol a unique number and record those\nnumbers in digital format. Artistic works involving pictures and sound\nare more difficult to represent because they are continuous in nature. We\nhave to digitize them first. With music or painting this inevitably means\nsome loss of information as we can’t cut a sound or image into an infinite\nnumber of pieces.\nThe modern standard for translating text to numbers is Unicode.\nEach character is represented by a five-digit number ranging from 1\nto 64,000 – two bytes for those of you who know computing. This is\n130 Are the Androids Dreaming Yet?\nsufficient to code almost all the world’s symbols, so we can avoid any\naccusation of being language-ist! Here are some examples of the\nAncient Greek, Japanese:\nKanji, Katakana, Chinese,\nand Russia-Cyrillic\nSymbols\ncharacters represented by Unicode.\nFor our discussion, it does not matter which language War and\nPeace is written in. We just treat the symbols as numbers. I am going\nassume the English translation which has around 500,000 words; a nice\nround number. Assuming a generous 10 characters per word, War and\nPeace is approximately 10-megabytes – that’s about the same size as a\nmusic track on iTunes. In practice, the book uses a bit more memory, as\nthere is some overhead for formatting information. My laptop has a 500\nGigabyte hard disk so I could fit half a million copies of War and Peace\non it!\nIf we take a look at the contents of the file on my computer the book\nstarts:\n8710110810844801141051109910144115111\nCan a computer calculate this number?\nThe obvious answer is YES. It is just an integer like 1, 3 or 42. Granted\nit’s a large number, but the length of the number is simply the length of\nall the symbols in the book coded into Unicode – about 10 million digits.\nWe have already determined this number can be stored on my hard disk\nhalf a million times, so it’s not an unimaginably large number. How long\nwould it take to calculate the number corresponding to War and Peace?\nThe simplest method is to count up starting at 1 then 2, 3, 4, 5, and\nso on until I try every number. Will this eventually get to the War and\nPeace number? The answer is yes. Eureka! All of human knowledge is\ncomputable. I have written this computation out as a simple computer\nprogram below. It says, in plain English, start at zero, go round a loop\ncounting up one at a time and print each number as you go along.\ni==0; Loop i++ Print i;\nKnowledge\n131\nEasy!\nNo, unfortunately. The problem is subtler than it first appears. First\nit will take a VEEEEERRRY long time. If I counted up from one, I would\nprint out War and Peace eventually but it would take 120 billion, billion,\nbillion, billion, billion… (I would need the entire length of this book\nto write out all the billions) years! For the physicists amongst you, I\nwould need 10 30,000 years, assuming I could use every atom in the known\nuniverse counting in parallel at the plank interval. ‘The plank interval’ is\nthe shortest time that can exist in the Universe as a discrete ‘tick’.\nEven going at this speed using with every atom in the known\nUniverse would take 10 5,000 longer than the age of the Universe. This is\nstupendously long. Remember scientific notation means I have a 1 with\n5000 zeroes after it. It is a deceptive notation as something as innocuous\nas 10 120 is equal to the number of atoms in the known universe. 10 5,000 is\nan absolutely enormous number. If you hear something is going to ‘take\nuntil the end of time’, we’re talking a lot longer than that!\nYou may have spotted that in the process of counting up to the War\nand Peace number we also count through EVERY book ever written\nshorter than 500,000 words in all the world’s languages. Interestingly we\ncounted through the Japanese and Chinese translations of War and Peace\nquite a bit before we reached the English and finally French translations.\nDuring the process, we also stepped through countless other wonderful\nworks: proofs of amazing theorems, the complete works of William\nShakespeare, and every composition ever written. Sadly, we never knew\nit. The problem is my program never stopped and told me it had found\nany of these wonderful things. I would have to sit staring at the screen to\nspot them. If I was off doing something else – making a cup of tea, taking\nthe kids to school – I would miss all these wonders; the program never\ntells me if it has succeeded, but quietly prints out War and Peace and\ncarries on. This is really annoying. It’s not a useful machine.\nWhat I need is a machine that rings a bell when it finds something\ninteresting so I can break away from what I am doing and take a look.\nReading every book it writes in every language and all the nonsense\nin between would take a ginormous amount of my time. (By-the-way,\ncontrary to statements by school teachers that ginormous is not a word\n– it is!) I want a computer to come up with War and Peace without me\nhaving to do all the work.\nIt’s no help if the machine writes everything down and lets me take\na look in my own good time. That only puts off the time when I have to\nbegin reading all the gibberish it produced. Another practical problem\nis the massive storage required. Just imagine the immense piles of printer\n132 Are the Androids Dreaming Yet?\npaper! Stephen Hawking and Jacob Bekenstein have shown space appears\nto have a limit to the quantity of information it can store. The quantity of\ninformation we are looking at here is greater than the storage capacity of\nthe Universe and would collapse space-time to a black hole before I got\neven a fraction of the way through. Let us try to be a bit cleverer about\nthe task of creating this information.\nThe simplest way to tie the computer down is to run a much\nstricter program. Ask it to count up from one until you get to a number\nrepresenting the novel War and Peace and then print it, stop and ring a\nbell.\nLoop i++ until i == “War and Peace…”; Print i; ring-bell;\nThis program succeeds!\nI am triumphant. I have calculated the War and Peace number, and\nthis time I did not miss the event. But, if you consider this a little more\ndeeply I gave the computer the answer! I told it the string “War and\nPeace…” and it was able to count up, stop, and tell me it reached it. In\nmathematical terminology, the program is said to have ‘halted’ when it\nreached the War and Peace number and in computer science speak it\nis a special purpose program designed to do only this one thing. This\nprogram is pointless. First, it would still take a ginormous amount of\ntime to get there and, second, it is trivially the same as running the\nprogram: Print War and Peace.\ni = “War and Peace…”; Print i;\nIt’s just the same as me taking my laptop, finding War and Peace and\npressing print. In no way is this equivalent to Leo Tolstoy’s creative effort\nof writing War and Peace in the first place.\nWhat went wrong?\nI wanted my computer to find an interesting string I did not already\nknow. War and Peace is trivially computable after Leo Tolstoy created it\nbut the question is whether my computer could come up with War and\nPeace or some similar creative work on its own. Can it create and, more\nimportantly, understand it has created something? We have linked the\nideas of creativity and understanding, and this will prove to be the key\nto the problem.\nKnowledge\n133\nThe Problem\nOne suggestion put forward by Daniel Dennett is the creative process\nis a two-part task – generate ideas, then critically assess them. I can, in\nprinciple, make a program write out every possible book less than 500,000\nwords long. Provided I don’t store the results this will not collapse the\nUniverse. This just leaves the problem of writing another program to\nread all the output and ring a bell each time it finds some interesting\ntruth. This second program might be called an appreciation program.\nLet’s examine this approach. I can write out a very simple program to do\nthis – provided I cheat and ignore the complexity of the term ‘something\ninteresting’. In plain English: Count up from one until I get an interesting\nfact, write it down and stop.\nLoop i++ until i == (Something Interesting), Print i\nThis generates two problems. We need to make a program that\ncan tell if something is interesting and it will need to be fast because it\nis going to be handed a huge amount of junk. Clearly I have a process\nrunning in my brain that can determine if something is interesting, but it\nis quite slow. It takes me an appreciable time to open a book, leaf through\nthe pages and declare it either junk or interesting. Leo Tolstoy had a\nprocess in his brain that allowed him to create something interesting but\nI want to prove he did not do this by generating random junk and sifting\nthrough it. Let’s look at the mathematics.\nWe know simply counting sequentially through every number\nwould take too much time, but why not generate random numbers and\nrun our critical eye over them? Surely this would give a faster result. Let\nus try with a short poem. How hard would it be to come across something\nas simple as a four-line poem using this technique?\nThis poem, by the late Spike Milligan, is only 23 words long,\nincluding the title, and I have a powerful computer. Wouldn’t it be\npossible to generate it using a computer? Unfortunately, no. We humans\ndon’t have a good head for large numbers and this problem is much\nharder than it appears. Let’s use playing cards to get a feeling for large\nnumbers.\n134 Are the Androids Dreaming Yet?\nA Simple Poem\nRain\nThere are holes in the sky\nWhere the rain gets in\nBut they’re ever so small\nThat’s why the rain is thin.\nSpike Milligan\nSpike Milligan\nComing upon a poem by chance can be likened to the probability\nof dealing a perfect bridge hand. Shuffle the deck thoroughly and then\ndeal four hands. What is the probability every player will have the ace\nthrough king in a single suit? It’s about 1 in 1,000,000,000,000,000 hands.\nBecause lots of people play a lot of bridge around the world, this outcome\nhas been reported quite a few times. The possibility appears within the\nbounds of human experience. Fifty-two playing cards seems close to the\n80 characters that make up this poem and 13 choices of cards is about the\nsame as the 26 letters of the Latin alphabet. Wouldn’t we expect poems of\nthis complexity to crop up almost as often?\nNO.\nKnowledge\n135\nThe 80 characters of this poem versus the 52 playing cards and the\ngreater choice offered by 26 letters increases the problem geometrically.\nTaken together the probability of accidentally getting this poem is vastly\nless than a perfect hand of bridge, 1 in 10 83 against the perfect bridge\nhand of 1 in 10 20 . That’s the difference between the number of atoms\nin the known universe and the number of atoms in a jug of water!\nNumbers get big very quickly when we are looking at the permutation\nof information. And there is another problem with our bridge analogy.\nAll the bridge players in the world are part of the machine finding the\nperfect hand. When a human sees a perfect bridge hand they are amazed.\nIt is an event that usually hits the local newspapers and a couple of years\nago one reached the national papers in Britain. Each bridge player looks\nat every hand, they play so there is a huge amount of processing going on\nduring every bridge game. To replicate this for our poem, we would need\nmillions of poetry classes spending hours each evening reading through\ncomputer printouts of gibberish.\nI should also add that sightings of perfect bridge hands are almost\ncertainly hoaxes. The probability of it happening even once would\nrequire everyone on Earth to play bridge continuously for a thousand\nyears. It is reported somewhere in the world about two or three times a\nyear. If we are charitable, we might assume people failed to shuffle the\ndeck properly but I suspect some mischief is going on! The numbers\ndon’t stack up…\nYou might think the problem is one of improving the efficiency of\nthe filter so humans would only have to examine a smaller number of\npossibilities. Surely I could improve things by writing a simple program\nto ban all non-English characters, words and poor grammar; things that\ndon’t pass the Microsoft Word grammar checker. This would generate a\nmore manageable number of potential poems.\nLewis Carroll shows this does not work; my idea to use a grammar\nand spelling checker to filter out gibberish just eliminated Jabberwocky,\none of the most famous verses in the English language. Take a look at\nwhat Microsoft Word thinks of it.\n136 Are the Androids Dreaming Yet?\nThe Jabberwocky\n’Twas brillig, and the slithy toves\nDid gyre and gimble in the wabe;\nAll mimsy were the borogoves,\nAnd the mome raths outgrabe.\n“Beware the Jabberwock, my son!\nThe jaws that bite, the claws that catch!\nBeware the Jubjub bird, and shun\nThe frumious Bandersnatch!”\nHe took his vorpal sword in hand:\nLong time the manxome foe he sought—\nSo rested he by the Tumtum tree,\nAnd stood awhile in thought.\nAnd as in uffish thought he stood,\nThe Jabberwock, with eyes of flame,\nCame whiffling through the tulgey wood,\nAnd burbled as it came!\nOne, two! One, two! and through and through\nThe vorpal blade went snicker-snack!\nHe left it dead, and with its head\nHe went galumphing back.\n“And hast thou slain the Jabberwock?\nCome to my arms, my beamish boy!\nO frabjous day! Callooh! Callay!”\nHe chortled in his joy.\nTwas brillig, and the slithy toves\nDid gyre and gimble in the wabe;\nAll mimsy were the borogoves,\nAnd the mome raths outgrabe.\nLewis Carroll\nLewis Carroll’s Jabberwocky\nKnowledge\n137\nThe Jabberwocky Spell Check\nMicrosoft Verdict on the Poem\n39 of the 166 words in the poem are unknown to Word’s spelling checker\nand this is an optimistic analysis of how the algorithm would fare. Many\nof the words are in the spelling checker because of the poem: galumphing,\nfor example. Lewis Carroll’s work was sufficiently influential that part of\n138 Are the Androids Dreaming Yet?\nthe English language was created in this poem. The same goes for much\nof Shakespeare. If we used a filter method, we would have just deleted\nmost of Shakespeare from the English language! Indeed half the poems\nin my anthology of English verse are destined for the waste paper basket\ndue to some minor infraction of ‘the rules’. If you want something that\ncompletely flummoxes my spelling checker here is the Loch Ness Monster\nSong by Scottish poet Edwin Morgan. I asked a Scottish friend whether\nScottish spelling checkers fared any better and he assures me, no.\nThe Loch Ness Monster’s Song\nSssnnnwhuffffll?\nHnwhuffl hhnnwfl hnfl hfl?\nGdroblboblhobngbl gbl gl g g g g glbgl.\nDrublhaflablhaflubhafgabhaflhafl fl fl -\ngm grawwwww grf grawf awfgm graw gm.\nHovoplodok - doplodovok - plovodokot\n- doplodokosh? Splgraw fok fok\nsplgrafhatchgabrlgabrl fok splfok!\nZgra kra gka fok!\nGrof grawff gahf?\nGombl mbl bl -\nblm plm,\nblm plm,\nblm plm,\nblp\nEdwin Morgan\nThe Loch Ness Monster\nKnowledge\n139\nThe foibles of spell checkers have long been a personal pain to me\nbecause of my dyslexia. Although I can see the red underlining Microsoft\nWord kindly inserts so liberally into my text, I can’t easily see the occasions\nwhen I use a homonym. A fine poem illustrating the problem was kindly\nwritten by Jerrold H. Zar and published in The Journal of Irreproducible\nResults. It hangs on the wall behind my computer to remind me to check\nfor these errors.\nCandidate for a Pullet Surprise\nBy Jerrold H. Zar\nI have a spelling checker,\nIt came with my PC.\nIt plane lee marks four my revue\nMiss steaks aye can knot sea.\nEye ran this poem threw it,\nYour sure reel glad two no.\nIts vary polished in it’s weigh.\nMy checker tolled me sew.\nA checker is a bless sing,\nIt freeze yew lodes of thyme.\nIt helps me right awl stiles two reed,\nAnd aides me when eye rime.\nEach frays come posed up on my screen\nEye trussed too bee a joule.\nThe checker pours or every word\nToo cheque sum spelling rule.\nBee fore a veiling checker’s\nHour spelling mite decline,\nAnd if we’re lacks oar have a laps,\nWe wood bee maid too wine.\nButt now bee cause my spelling\nIs checked with such grate flare,\nTheir are know fault’s with in my cite,\nOf nun eye am a wear.\n140 Are the Androids Dreaming Yet?\nNow spelling does knot phase me,\nIt does knot bring a tier.\nMy pay purrs awl due glad den\nWith wrapped word’s fare as hear.\nToo rite with care is quite a feet\nOf witch won should bee proud,\nAnd wee mussed dew the best wee can,\nSew flaw’s are knot aloud.\nSow ewe can sea why aye dew prays\nSuch soft wear four pea seas,\nAnd why eye brake in two averse\nBuy righting want too pleas.\nThe Search for Knowledge\nI hope this explanation shows you the simplest model for creativity –\nworking through every possibility, and examining them all – is doomed\nto failure. It would take longer than until the end of time to even list all\nthe options, let alone analyze them.\nYou might wonder just how long it is until the end of time? It’s\ngenerally assumed there are two possible ends to the Universe, a Big\nCrunch or heat death. Either way the approximate estimate is our\nUniverse will last somewhere between one and fifty times longer than\nit has lasted so far. That’s a long time, at least another 15 billion years,\nbut just generating War and Peace would take 5000 orders of magnitude\nlonger than this!\nMore complex models such as a three-step process have been\nsuggested. We could perhaps randomly create information and put\nit through a mechanical filter to bring it down to a manageable set of\noptions and then give it to an appreciation algorithm to finally decide\nwhether we have created something. The real problem with this model is\nthe filters. If we try to reduce the effort by assembling works only from\npre-existing words, we will have filtered away many works we know and\nlove. Gone are Shakespeare, Lewis Carroll, Dylan Thomas and Roald\nDahl, shall I go on? Indeed, once upon a time there were no words, every\nword was coined at some point. The process of creating art is continually\ncreative and mechanical filters can’t be applied to things they have not\nseen before.\nKnowledge\n141\nYou might argue we could devise a more sophisticated mechanical\nfilter, something that contains an algorithm with an understanding of the\nrules of language. The problem is both the size of the task and the nature\nof understanding. If I devised some really good appreciation algorithm\nwhich did not delete all the creative words of the English language, it\nwould still have to read and appreciate the huge quantities of input until\nit hit upon something good. There is no way for any machine to read\nall this information in the age of our Universe; the numbers are just too\nlarge. And there is no way for a machine to understand all the rules of\nlanguage, they are not written down and constantly evolve.\nThese descriptions should give you an intuitive feel for nature of the\ncreative problem. If you try to deconstruct it into mechanical steps you\nend up with either a mechanism that needs to be infinitely specified or\none that lets through an infinite quantity of nonsense. A human could\nnever sift through all that garbage to find the occasional pearl of wisdom.\nUntil the beginning of the 20 th century, most people thought\nknowledge and creativity must be just a matter of scale. A big enough,\nfast enough machine should be able to solve any problem. But early in\nthe 1930s two mathematicians – Kurt Gödel and Alan Turing – showed\nknowledge was not so simple. Let me give you a feel for why.\nKnowing When You Know\nThe essence of creating knowledge, is to know when you have done so.\nIn a sense, counting from one to infinity means I know everything, and\nmerely counting to 50 million creates every piece of significant symbolic\nknowledge that will ever be written – all the books, plays, mathematical\ntheorems you could possibly want. But, if I were to list all these numbers\nin an enormous imaginary book it would hardly constitute knowing\neverything: I would be awash with numbers but not with knowledge.\nThe essential feature of ‘knowing’ is to have a small number of steps\nthat will definitely answer a problem. For example, if I wish to phone\nsomeone I can look up their details on my phone. The process will tell\nme their number in two or three steps. If you tell me the number is\nsomewhere in the phone book this is not knowledge. It could mean I\nneed an infinite number of steps.\nIf I accidentally deleted all the names in my phone – a nightmare\nscenario – and just had a print out of numbers would I still ‘know’ them?\nObviously I would recognize my mother’s number, but most of them\nwould be useless. To know something, I need link the information to\nwhat it is for. A number with a name allows me to predict what will\n142 Are the Androids Dreaming Yet?\nhappen if I make a call. I will have an interesting conversation or pay\nmy gas bill. It’s the same with most numbers. If I have a number that\nrepresents the design for a building or a mathematical theorem, these\nnumbers have purpose. If I input these numbers to a computer along\nwith some building design software or a copy of Mathematica they\nwill do something interesting; allowing a construction firm to build a\ninnovative building or a mathematician to check a theorem is sound.\nIt’s a lot harder to prove numbers representing art are functionally\nuseful. A work of art is in some sense not complete – it still needs to go\nthrough the process of being appreciated by someone. We could show it\nto a friend or exhibit it in a gallery but this is un unpredictable process.\nVan Gogh’s paintings were so criticized in his lifetime, many people\nwould have denied them the label art, and Edwin Morgan’s Loch Ness\nArt or Information\nMonster poem is almost pure gibberish, but it’s undoubtedly art. Art is\na tricky problem but, in practice, most of us agree on what constitutes\ngood and bad art. We will look again at art, in Chapter 10.\nClassically we assume knowledge is discovered through random\nchance and iteration. To understand how this might work let’s lay out\nthe world’s information in a way we can visualize. Imagine every piece\nof discoverable knowledge could be found in an infinitely large library.\nKnowledge\n143\nThe infinity library would contain every possible symphony, theorem,\nnovel, poem, and play ever written, or to be written. Its sister library\nnext door, the continuum library, would contain all the analogue works\nof art; painting, sculpture, architecture, physical artifacts and the like.\nThe curators of the two libraries would constantly argue over whose\ncollection was the better. We’ll leave them to differ for the moment. The\ninfinity library is interesting enough so let’s explore it first. After all, its\nsister, the continuum library, takes an infinite amount of time just to look\nat the first room, and we are in a hurry!\nAlthough the infinity library is infinite, we are probably only\nconcerned with entries shorter than a million symbols. All the interesting\npapers, proofs and symphonies I know of are shorter than this. If I wanted\nto include all computer programs, I would still only need to increase it to\n100 million symbols. Looking for knowledge is not itself an infinite task.\nFor the sake of clarity, I will ask the infinity librarian to organize\nthe collection. Any book or paper will be sorted according to its title and\nthe contents of its pages, and similar books should be grouped together.\nI also only want to look at the English section of the library for the\nmoment. I will still have a huge section to look through but at least every\nwork is titled and readable by me. Much of the information will be junk\nbut amongst the sea of rubbish will be islands of useful knowledge. Now,\nis there a way to find knowledge in this library in an automated fashion?\nBattleship\n144 Are the Androids Dreaming Yet?\nThe best analogy I can find to illustrate iterative knowledge discovery\nis the 1970s family game ‘Battleship’. The game consists of two 10 by 10\ngrids that you plug your ships into. All the ships are linear shapes of a\nfew squares in length. The players cannot see each other’s ships and must\nguess where they are. A very simple way to do this would be to ask your\nopponent whether they have a ship on the top left square and continue\nsystematically across the board, square by square, until you reach the\nbottom right hand corner. This would eventually find every ship. If every\nship were a piece of knowledge we could discover all the knowledge in\nthe world by simply stepping through the board one cell at a time, but it\nwould take a long time.\nA better way to play Battleship is to pick a square at random. If you\nget a hit, explore linearly around the hit. This will efficiently find the\nrest of the ship. The same might be true for knowledge. We could take\nrandom shots, get lucky and move linearly to flesh out our knowledge.\nOnce we had exhausted an area we could take a step away at random and\nagain hope for another hit. This process is exactly the way some people\nimagine the frontier of knowledge expands.\nBut, it is wrong.\nThe monkey moon shot story explains…\n“I believe that this nation should commit itself to achieving the goal,\nbefore this decade is out, of landing a monkey on the moon and\nreturning him safely to Earth.”\nPresident Monkey\nThe monkey nation is asked to mount a moon shot. After a little\ntime a monkey is asked to report on progress.\n“I can report,” says the monkey, “I have climbed a particularly tall\ntree on the tallest hill on my island and have made over seven hundred\nmeters progress towards the moon, although this is only 0.0001% of the\nway there, this has been quick so I believe we are well on the way.”\nYou see of course the problem. Progress in many problems is\nnonlinear. Moving a bit of the way towards the goal does not provide any\nactual progress: That is the problem with knowledge. It is not linear in\nstructure. You need to take leaps to discover new knowledge. You can not\nsimply look around in the general area. Such leaps are mathematically\nhuge. The chance of making a successful one by pure chance is virtually\nzero.\nKnowledge\n145\nBut Cats Can!\nAs chance would have it, as I was writing this book about the impossibility\nof creating great literary works at random, our new kitten, Jessie, sat\non my keyboard – she likes the warmth. To my great embarrassment\nI have been proven wrong. Here is her first literary work. I managed to\ncapture her on camera a little later that evening, editing a spreadsheet.\nMy brain interprets this string as the cat thanking me for good food. I\nwonder if you see the same thing? This is just a demonstration of the\nstrength of human pattern detection algorithms and not, sadly, of feline\ncommunication.\nCats Creation\n…. Kkkklnk gfoooooooofd0------- iiiii;;;;;;;;;;;ii…..fffffffffffffffffffffffff……\n=================================================\n=================================================\n=================================================\n============================pppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\npppppppppppppppppppppppppppp..oppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppppppppppppppppppppppppppppppppppppppp\nppppppppppppppppppph\nJessie Cat\nJessie, Our Creative Kitten\n\nChapter 6\nKITTENS &\nGORILLAS\nOrangutan and Kitten\n“No kitten that loves fish is\nunteachable; No kitten without\na tail can play with a gorilla;\nKittens with whiskers will always\nlove fish; No teachable kitten\nhas green eyes; No kittens have\ntails unless they have whisters;\nhence...”\nLewis Carroll\n“Once you eliminate the\nimpossible, whatever remains,\nhowever improbably, must be the\ntruth.”\nSherlock Holmes,\nArthur Conan Doyle\ns well as giving us Alice, the Jabberwocky, and the Cheshire Cat,\nLewis Carroll lectured on mathematics at Oxford University.\nHe wrote several books on logic, illustrated with wonderful\nproblems involving fish, kittens, and gorillas – much less boring than the\nbrown, grass-eating cows of modern textbooks. Kittens and gorillas are\nnot usually in much contact, but I did find one hit on Google, pictured!\nThe words we organize into books, poems and plays are not just\na random jumble; they have structure and a logic to them. We group\nverbs, subjects and objects together to form sentences and, at a larger\nscale, characters have motivations and relationships: this character\nloves that character, the valet had the candlestick in the ballroom and\ncould not have stabbed the butler in the kitchen, and so on. We have\ndictionaries to define words, but to truly understand the information\nthey convey we need to understand the logical rules governing how they\ncan be combined.\nEveryday conversation is fragmented and repetitive. Fortunately,\nnow and again, we say something definitive. For example, “This gorilla is\nbrown.” The statement links a property, ‘brownness’, to a thing, ‘a gorilla’.\nLogical statements are precise but often need to be put in context. If I were\nstanding in a forest when I made my statement you must guess I mean the\nnearest gorilla. The word ‘This’ implies nearness, but nearness is not well\ndefined. Better to be precise. ‘The gorilla I am closest to, measured by line\nof sight distance is the Pantone shade dark brown.’ However, if I talked\nlike this all day I would not have many friends.\nLogical Beginnings\nThe formal study of logic began in 384BC with the publication of a treatise\ncalled the Organon by the Greek philosopher Aristotle. A student of\nPlato, Aristotle taught many of the famous leaders of his time, including\nAlexander The Great. Ancient Greece was not some idyllic think tank. If\nyou annoyed the political establishment you might find yourself having\nto leave town in a hurry. This happened to Aristotle after Plato’s death,\nand he spent nearly a decade touring Europe. Eventually, he returned to\nAthens where he published his study on logic.\nIn the Organon, Aristotle examined groups of up to four statements,\neach containing up to four relationships. For example: All kittens eat fish.\nSome kittens eat fish. No kittens love gorillas. No gorillas eat kittens –\nluckily. It is possible to put two statements back to back and infer things.\n150 Are the Androids Dreaming Yet?\nI could say, “All gorillas eat leaves.” “All leaves are green.” Therefore I can\ninfer all gorillas eat some green things. This is a valid inference. It is not\ncorrect to say, gorillas eat only green things.\nThere are 256 ways you can arrange four Aristotle statements with\nfour relationships but only 19 valid deductive conclusions can be drawn.\nThe kitten puzzle at the start of the chapter is an example of such a logical\npuzzle. Can you reach the right conclusion?\nddd\nTRY SOLVING THE KITTEN PUZZLE WITHOUT READING ON\nAristotle’s syllogisms are only a start. There are many other types of\nlogic. In antiquity, the Stoics developed a different brand of logic based\non the idea of larger and smaller. Stoic logic allows us to answer questions\nof relative size. If a Mini is smaller than an Audi, and an Audi is smaller\nthan a Rolls Royce, then a Mini is smaller than a Rolls Royce. The Stoics\npursued their branch of logic until around 180AD when study of this sort\ndied out. It’s not quite clear why. Perhaps the rise of religious power and\nthe onset of the Dark Ages curtailed intellectual inquiry. Even after the\nEnlightenment began around 1650 it took some time for the discipline of\nlogic to re-emerge. If you want to learn more about syllogistic logic and\nhow to solve Lewis Carroll’s puzzle you should read his book The Game\nof Logic. The definitive book on the logic of language, in my opinion, is\nLogic by Wilfrid Hodges.\nLogic for Computers\nWestern civilization mostly survived on syllogisms and stoic logic for\nnearly two thousand years before George Boole devised his theory of\nbinary logic in 1847. Boole developed an elegant mathematical system\nfor representing logical statements that allowed simple arithmetical\noperations to answer logical questions. We now call this system Boolean\nlogic and he gave us the modern convention of using one for true, and\nzero for false. Computers use his principles all the time. For example, if\nit is true my bank account shows less than zero, then make it true that\nsomeone will send me a letter warning me I am overdrawn. The best way\nto get your head around Boolean logic is to solve the ancient puzzle of\nthe Two Guards. The puzzle featured in the 1986 movie, The Labyrinth,\nKittens & Gorillas\n151\nstarring David Bowie and Jennifer Connelly. If you want to cheat watch\nthe film to see the answer. Here is the puzzle. I’ll put the answer on my\nwebsite.\nTwo guards stand barring your way and behind them are two\ndoors. One guard always speaks the truth, while the other always\nlies. You are only allowed to ask one question of one of the guards.\nYour life depends on picking the right question to ask as, based on\nthe answer, you must pick a door. One leads to life, the other to\ncertain death. Is there a question you can ask to ensure you pick\nthe door leading to life?\nTRY SOLVING THE GUARD PUZZLE\nddd\nTwin Guards - Left door or Right\nIf you are reading this, you picked the correct door and lived.\n152 Are the Androids Dreaming Yet?\nLogic for Humans\nSyllogisms can be used for practical purposes. Take, for example, the\nfollowing set of statements, “I want a hot drink.” “Coffee and tea are hot\ndrinks.” “I always drink milk with tea,” “We have no milk.” What drink\nshould I choose? I’m sure you can work it out. This logical problem\nfollows a simple chain and results in me getting the hot drink I like.\nWe use Boolean logic on a day-to-day basis. The simplest form\nis a checklist. Pilots use checklists all the time; do I have wings, fuel\nand a copilot? If they are all there, go ahead and fly. Otherwise do not.\nMathematically speaking, a checklist is simply the product of the options.\nIf they are all one, then the product is one – in this case we can fly. If any is\nfalse – represented by a zero – the product will be zero and we cannot fly.\nLife is often more complicated and we have many logical tools at our\ndisposal. Let’s take a look at a few, starting with a famous historical one.\nBenjamin Franklin invented the lightning rod and bifocal glasses,\nas well as charting the Gulf Stream and all manner of other scientific\ndiscoveries. He described his process for decision-making when there\nare many pros and cons to consider.\n“... my Way is, to divide half a Sheet of Paper by a Line into two\nColumns, writing over the one Pro, and over the other Con. Then\nduring three or four Days Consideration I put down under the\ndifferent Heads short Hints of the different Motives that at different\nTimes occur to me for or against the Measure. When I have thus\ngot them all together in one View, I endeavor to estimate their\nrespective Weights; and where I find two, one on each side, that\nseem equal, I strike them both out: If I find a Reason pro equal to\nsome two Reasons con, I strike out the three. If I judge some two\nReasons con equal to some three Reasons pro, I strike out the five;\nand thus proceeding I find at length where the Balance lies; and\nif after a Day or two of farther Consideration nothing new that is\nof Importance occurs on either side, I come to a Determination\naccordingly.”\nAnother important piece of logic is reductio ad absurdum. Reduction\nto the absurd allows us to disprove something because, if it were true, it\nwould lead to an absurd conclusion. An alibi is a familiar form. If I was\nseen in the pub when the murder occurred in the ballroom of the manor\nhouse and you claim I committed the murder, I must have been in two\nplaces at once. People can’t be in two places at once – that would be\nabsurd. Conclusion: I am innocent!\nKittens & Gorillas\n153\nNotice I not only prove I am not guilty I also prove the opposite:\nI am innocent. When a mathematician uses this trick, it is called an\nindirect proof and works the same way as the alibi. Assume the opposite\nis true of some theory you want to prove (I am guilty). If it generates a\ncontradiction or paradox (can’t be in two places at once) you can deduce\nthe opposite must be true (innocence). Mathematicians use this all the\ntime. It assumes, of course, mathematics is consistent and that true and\nfalse are opposites.\nSome mathematicians argue this is too strong an assumption. Why\nshould we assume consistency and recognize only two logical states, true\nand false? These mathematicians believe the only way to prove a theorem\nis with positive argument rather than using the opposite of a negative\nargument. They don’t allow indirect proofs in their mathematical\nmodels. This type of mathematics is unsurprisingly called positivism. It’s\na pure theory but, unfortunately, if you try to follow it you lose much of\nour current mathematical knowledge and understanding. Most modern\nmathematicians think it a historical curiosity, but it does pop up from\ntime to time. Modern mathematics is founded on the axioms that\ntrue and false are the opposite of each other and that inconsistency is\nforbidden within the system. Mathematical proofs submitted to journals\nare not permitted to contain inconsistencies or result in paradoxes.\nParadoxes – When Logic Fails\n“I would not be a member of\nany club that would admit\nme.”\nGroucho Marx\nParadoxes occur when a statement\nmakes no sense, or results\nin an internal contradiction as\nwith Groucho Marx’s famous\nquote. They are widely used in\nmathematics to implement indirect\nproofs. To do this, we suppose\nsomething is true, and if\nit results in a paradox then the\nGroucho Marx\n154 Are the Androids Dreaming Yet?\nthing we thought true must be false and the opposite is true. This is a\nsomewhat circuitous route to prove things, but it is often the only practical\nway.\nTwo paradoxes we are taught as children are the liar’s paradox and\nZeno’s paradox – also known as the story of the tortoise and hare. The\nfirst is a real paradox but the second is a false paradox. The liar’s paradox\nis just the simple statement:\n“This sentence is false.”\nIt is a paradox because of the internal inconsistency: We cannot\ndetermine if it is a true or false.\nFirst assume it is true, but it says it is false, so it is not true. Then\ntry it the other way around. Assume it is false but the sentence states\nit is false, so it must be true. If that were so it must be false by the first\nargument and so on ad infinitum.\nEither way around, the sentence contradicts itself. A paradox.\nZeno’s Paradox, on the other hand, is a false paradox. Here is the\nstory.\nOnce upon a time there was a hare. He was a very arrogant hare\nand believed he could outrun any animal. A tortoise was walking along\nthe way and the hare jumped out in front of him. “You are so slow,”\nsaid the hare. The tortoise replied, “You may be the fastest hare in the\nkingdom but I am the most persuasive tortoise. I bet I can persuade you\nof anything, including that I am faster than you.”\n“I don’t believe you,” said the hare.\n“OK,” said the tortoise, “let me show you. Give me 100 meters head\nstart since you are so fast. Then, we’ll both start to run. After 10 seconds\nyou will have run 100 meters and arrived where I used to be, but I will\nnow be ten meters ahead. After another second you will be where I am\nnow, but I will be 1 meter ahead again. So you can never catch me.”\nThe hare pondered for a while but, being a hare of little brain, could\nnot make out the true answer.\nIt is a false paradox. The time intervals are getting shorter. The\nquestion for a mathematician is, does the problem converge to a solution.\nThe answer is yes, and I can reframe the problem to see how it is solved.\nLet’s simply look at who would be ahead after 20 seconds: the hare!\nKittens & Gorillas\n155\nThe mathematical reason for it being a false paradox is that some\nseries converge and some do not. If I move progressively closer and\ncloser to something in smaller and smaller time intervals then I may\nindeed reach it. On the other hand, some series never converge. I will\nnever reach infinity how ever many steps I take.\nThe Barber Paradox\nNow, for a slightly harder paradox, let’s suppose there is a town with just\none barber.\nIn this town, every man keeps himself clean-shaven by either\nshaving himself or going to the barber; the barber shaves all the men in\ntown who do not shave themselves. All this seems perfectly logical, until\nwe pose the question: who shaves the barber?\nThis question results in a paradox because, according to the\nstatement above, he can either be shaven by himself or the barber, which\nis he. However, neither of these possibilities is valid! This is because if\nthe barber shaves himself, then the barber must not shave himself and if\nthe barber does not shave himself, then the barber must shave himself.\nYou might think this paradox an oddity but, using this simple idea,\nBertrand Russell changed the course of mathematical history and it is\nthe fundamental paradox used to show computers are Turing limited.\nThe Russell Paradox\nIn the late 19 th century, mathematicians began to think about the nature\nof numbers.\nWhat is a number?\nIt is certainly not an object we can hold.\nI can’t hold a two, unless it’s the brass number plate, for my front\ndoor. And, in that case I am holding one number plate, so I am not\nholding the idea of two, but rather the idea of one: one brass plate in the\nshape of a two.\nThe ‘idea’ of a number is to say something about the things I have in\nmy hand: two apples, two oranges and two brass number plates. These\nare all sets of two things and ‘two’ is the collection of all these sets.\nIn 1890, Gottlob Frege completed his theory of sets. The project had\ntaken him five years. Unfortunately, just before sending the book to the\npublisher, Bertrand Russell wrote to him and pointed out the following\nparadox. What about the set of sets that does not contain itself? Think\nabout it...\n156 Are the Androids Dreaming Yet?\nIt is the barber paradox with the word ‘set’ substituted for ‘barber’\nand ‘contains’ rather than ‘shave’. But it’s essentially the same logical\nproblem. You might find this rather contrived but mathematicians must\nhave a system totally free from paradox, otherwise there is no certainty.\nFrege’s system was holed below the water line.\nEventually, after much further work, a theory of sets was worked out\nthat does not contain the Russell Paradox. It’s called Zermelo-Fraenkel\nset theory, or ZF for short. It solves the Frege problem by forbidding sets\nto refer to themselves. It’s a bit like Microsoft Excel’s solution to dividing\nsomething by zero. It is simply forbidden and generates an error message.\nSet theory was fixed and is now the basis of most mathematical thinking.\nWhat is Logic for?\nLogic is the foundation of mathematics. Applying it enables us to make\nirrefutable statements about things: numbers, lines, planes, equations\nand the so on – the things you learned at school – and to prove statements\nabout these things beyond any doubt. This is not the ‘reasonable doubt’\nhurdle of our law courts, but an absolute measure: No possible doubt\nwhatever.\nLet’s look at one of the earliest mathematical proofs: Euclid’s proof\nthere are an infinite number of prime numbers. Euclid created this proof\nin ancient Greece around 300BC – so far back that logic was in its infancy\nEuclid’s Elements 100AD\nKittens & Gorillas\n157\nand numbers had not yet been properly invented. Euclid used distances\nrather than numbers for all his proofs but I will use the word ‘number’ in\nthis explanation.\nFirst a little revision. A prime number is a number that can only\nbe divided by itself and one, for example three, five, seven, and eleven.\nAll numbers can be split into primes using a couple of tricks. First, all\nnumbers are divisible by a set of primes. Ten is five times two – two\nprimes. We are also fairly sure we can form any number by adding two\nprimes together. This is Goldbach’s Conjecture, set as a question in a\nletter written to Euler in 1742. It is still unproven!\nEuclid proved there are an infinite number of primes by using\nreductio ad absurdum. Imagine we have a complete list of prime numbers\n– James’ list of primes. It contains every prime number. (This is the setup.\nWe are proposing something we suspect is incorrect and will lead to a\nparadox or contradiction. When it does, we will have proven the opposite\nfact. The proof relies on the fact that a number can either be prime or not\nprime. There is no middle ground.)\nLet’s make a new number by multiplying all the numbers on my list\ntogether and adding one. There are two possibilities: this new number is\neither prime or not prime.\nIf the number is prime, it is a new prime number that was not on\nmy list and I have disproved the theory.\nIf it is not prime then it must be divisible by two prime numbers\nalready on my list. However, neither of these numbers could have been\non my list, because dividing by one of them would give me a remainder\nof one. Remember I multiplied all prime numbers together and added\none. It must, therefore, be a new prime number, which had previously\nnot been on my list. Once again, I disprove the theory.\nSince both routes fail, James’ list of prime numbers is not complete\nand, therefore, prime numbers are infinite.\nFeynman’s Proof\nMy favorite piece of logic is Richard Feynman’s disproof of the existence\nof polywater. It’s a strange logical proof bordering on philosophy, but it\nshows just how far you can take logic.\nIn 1969, an urban legend spread around the world that there was a\nsubstance called polywater. It even made it into an episode of Star Trek.\nPolywater was believed to be a lower energy state of water, more viscous\nthan ordinary water. If this substance did exist, it would be possible\nto mine the oceans of the world converting water to polywater and\n158 Are the Androids Dreaming Yet?\ntherefore generate energy. There was a concern that if the right catalyst\nwas accidentally introduced into the oceans they would solidify into\npolywater thus dooming the human race, or at the very least making\nwater sports impossible!\nFeynman was consulted and stated, “If there were such a substance\nas polywater then there would have evolved an animal that eats water\nand excretes polywater, using the liberated energy as its power source.\nSince there is no such animal, polywater does not exist.”\nFeynman’s proof is an elegant indirect proof coupled with a\nsyllogism. Polywater exists. Polywater is a lower energy form of the highenergy\nsubstance called water. Food is a high-energy substance that can\nbe converted to a low energy substance by a process we shall call ‘being\ngood to eat.’ All things on earth that are good to eat have something that\neats them. Polywater is a food and therefore good to eat. Therefore an\nanimal must exist that eats polywater. No such animal exists, so either\nsomething in our chain of logic is wrong, or the premise is unsound.\nSince the chain is sound, the original premise must be wrong: Polywater\ncannot exist.\nIn short, Feynman’s proof says: if a thing is so, then the inevitable\nconsequence is the evolution of something else, and since that something\nelse does not exist, the original thing cannot be so. QED: disproof by\nnonexistent consequence.\nThe polywater disproof neatly demonstrates the important elements\nof Feynman’s Evolutionary proof. First, life must be continuously exposed\nto the thing in question, in this case water. This is clearly so as most life\non planet Earth lives in the oceans or is intimately entwined with water.\nEvolution takes time, so enough time must be allowed for life to evolve.\nIt must be a nearly linear problem so that a solution proceeds in steps\nwhere each step is an improvement and no step requires too high a level\nof mutation or adaption. We can illustrate the boundary between a linear\nproblem and one requiring a step change by describing how triple drug\ntherapy works in the treatment of AIDS.\nUntil triple drug therapy entered the picture progress against AIDS\nhad been a depressing story of drug discovery followed by the almost\nimmediate evolution of the virus to evade the drug. The AIDS virus\nis a retrovirus with a shell composed of sugar molecules. It is almost\ntrivial for an AIDS virus to mutate these outer markings to look different,\neven from one day to the next. This is the way the virus continually\nand nimbly evades our immune system. However, the AIDS virus does\nhave some components that it can’t easily mutate because they are not\nmerely aesthetic, they have a functional purpose. Why not target them?\nKittens & Gorillas\n159\nUnfortunately, it turns out the AIDS virus can even mutate its functional\nparts, but this is harder. The probability of a successful functional\nmutation is 1000 times less likely than a simple aesthetic mutation to the\nsugar coat.\nTriple drug therapy works by attacking three different functional\nelements of the virus simultaneously. It is possible for the virus to modify\nall these functional elements but the likelihood of it doing so is tiny.\nOne mutation alone does not help because the drug cocktail will still\ntarget the other two elements and kill the virus. The AIDS virus does not\nunderstand that it is facing a triple drug cocktail. It cannot reason like a\nsentient being and random chance is not sufficient to make the big leap\nnecessary to overcome the cocktail of drugs. Unless you can mutate all\nthree elements at once your time as a virus particle on this planet is over.\nMost problems we have to solve in this world require more than one\nsimultaneous logical step and these don’t happen by chance.\n\nChapter 7\nCOMPLEXITY &\nCHAOS\nMandelbrot Set\n“Life is really simple, but we insist\non making it complicated.”\nConfucius\n“Any darn fool can make\nsomething complex; it takes\na genius to make something\nsimple.”\nPete Seeger\nThere was once a great King who lived in a marvelous palace. To\nfend off boredom he collected all manner of interesting games\nand puzzles. One day an inventor came to his palace and told the\nKing he had a game of such subtle complexity, yet apparent simplicity, the\nKing would play no other. The King learned the game and soon agreed it\nwas, without doubt, the best of all games. The game was, of course, ‘chess’.\nThe King asked the price of this game and the inventor told him it was a\nmere trifle. The King should give him one grain of rice on the first square\nof the board, two on the second, four on the third, and so on, doubling\neach square until he filled the board.\nThe King called his treasurer to honor the bargain and the first bags\nwere brought from the storehouse. The grains were placed on the board\nin each square but soon there was not enough space and the grains had\nto be piled on the table next to the board. Soon this, too, was not enough\nand every table and chair in the hall had to be covered. Even this was not\nenough and they began to stack whole bags up in the courtyard.\nWhen they reached the thirtieth square, the treasurer turned white.\nHe sat and calculated for a while before saying with a trembling voice,\n“My great ruler, there is not enough rice in all the world to cover this\nboard.” The ruler called the inventor and told him he could not honor\nthe debt and the inventor should name another price. The King had\ntwo beautiful daughters, the first knew she was beautiful and deported\nherself accordingly, and the second, was bookish and shy, but perhaps\nmore beautiful for this. The inventor asked for the hand of the second\ndaughter and lived happily ever after. In the less favorable version of this\nstory, the King becomes very angry and has the inventor beheaded. I\nprefer the romantic version.\nPlacing rice on a chessboard and doubling it successively\nleads to wildly large numbers. Covering it completely requires\n18,446,744,073,709,551,615 grains, about four hundred trillion tons and\nequivalent to one thousand years of worldwide rice production. Like\nthe king, humans do not intuitively grasp the enormity of this problem\nbecause we’re not good with large numbers.\nAlthough the number of grains needed to cover a chess board\nis very large, it is not hard to calculate. The treasurer is the one who\nshould have lost his head for not being able to do the calculation. The\nequation is simply two, doubled sixty-four times, less one, 2 64 -1. A pocket\ncalculator can produce this number in a thousandth of a second: it’s just\nlong multiplication. Although calculating this number is quick, it is not\nalways the case. Answers to some problems have short cuts, while others\ndo not.\n164 Are the Androids Dreaming Yet?\nMathematicians have catalogued the universe of problems into\nclasses rather as biologists have catalogued animals into species. Each\nproblem is examined and put into a genus with a name. Sadly the names\nare not as readable as the Latin names for animals. For example, ‘nlogn’\nis the complexity class of most sorting programs, while traversing a maze\ntypically sits in the class NP or P/POLY. Although the classifications look\ncomplex the basis of cataloging is simple, a class name signifies the time\nneeded to solve a problem using the best possible algorithm, and the\nscale this is measured in is ‘Big O’.\nBig O\nEvery problem has a complexity. In mathematics this is expressed using\n‘Big O’ notation, where ‘O’ stands for order-of-magnitude. The simplest\nproblems have order 1.\nIf I am working at my computer on a Word document and I press\nprint, the printer will spring to action and print the document. This\nproblem is of flat complexity, notated O(1). It does not matter how large\nthe file is; one click is all I need. I am, of course, assuming sufficient\npaper in the printer and ink in the cartridges.\nThe next complexity class is a linear problem, O(n). For example,\nwalking to the store to buy a pint of milk. The farther the store, the longer\nthe walk. The time needed to get to the store is directly proportional to\nthe distance: if I am walking, a single step multiplied by the number of\nsteps required to cover the distance.\nYou might think adding two numbers together is a linear problem\n– the bigger the number, the harder the problem – but there’s a clever\ntrick to speed it up. You can get 10 people to add each column in parallel.\nThey’ll need to coordinate when someone ends up with a number larger\nthan ten and has to carry the extra digit but this can be easily solved. A\nproblem gets its classification only once we’ve used the cleverest possible\ntrick to solve it.\nMost problems we meet in mathematics are somewhere in between\nflat and linear but there are some that are much harder. The most common\nhard problem we come across in our daily lives is sorting. Rather than\ngo through a tedious written description, check out the video link on my\nwebsite. Sorting without using any spare space requires a bubble sort.\nThis is an example of something that needs n squared operations and,\nsince n squared is the simplest example of a polynomial, it is said to be in\nthe polynomial time, or ‘P’ time classification.\nComplexity & Chaos\n165\nBubble Sort Ballet\nThe Hardest Problems\nYou probably hope cracking the encryption used to secure the Internet\nis one of the hardest problems known to man but I’m sorry to tell you\nit is not. When you use your credit card to buy something from an\nonline shop, your web browser changes from http to https, the ‘s’ stands\nfor secure. The data you send to the Internet is coded using a system\ndeveloped in 1977 by Ron Rivest, Adi Shamir and Leonard Adleman\nof MIT, which is why it is called RSA encryption. Any information you\nsend is raised to the power of a very large number – usually around\none hundred digits long. Raising something to the power simply means\nmultiplying it by itself that many times.\nWhat makes decrypting a message hard is that division is a slow\nprocess; it is called ‘long division’ for a reason. It turns out there is no\nway to speed it up on a conventional computer so, unless you know the\nright number to divide by you will have to try every number. It is this that\nmakes decrypting RSA messages hard.\nAlthough RSA messages are difficult to decipher, they are nowhere\nnear the hardest problems. That accolade is commonly believed to go\nto non-deterministic polynomial problems known as ‘NP’ problems.\nNP problems are easy to describe but fiendishly difficult to solve.\nNondeterministic means each time you come to a branch in the problem\nthere is no way to tell which branch is the best to pursue without exploring\nit all the way to the end. It’s the same as a maze; at each junction in the\nmaze you can decide which path to take, but the junction gives you no\n166 Are the Androids Dreaming Yet?\nMaze\nclue which one will be better. Beware the confusing naming system, ‘N’\nstands for nondeterministic in this case, whereas in normal complexity\nclasses ‘n’ stands for number. Sorry. That’s just the way it is. Let me give\nyou an example of one of these NP problems.\nLet us assume we have one of those complicated recipes from the\nlatest celebrity chef cookbook. If all the ingredients can be bought from\none store, making the dish is straightforward, but if they come from\ndifferent stores, you will have your work cut out. What is the best order\nto visit them? With 2 shops, it’s trivial. Either order will do. With 3 it is a\nlittle harder and with 4 there is quite a bit of choice. This is known as the\n‘traveling salesman’ problem because the original formulation described\na salesman wishing to find the shortest route between all the cities in\nwhich he had customers. The complexity of this problem rises much\nfaster than the Rice and Chess Board problem. Try it for yourself. It\ndoesn’t matter if you imagine you are visiting customers or shops. I have\ngiven you a grid to count off distances. Try to solve a problem for 3 cities,\n5 and 10. What is the shortest path allowing you to visit each place?\nComplexity & Chaos\n167\nTRY THE PUZZLE ON THE WEB\nWarning: Don’t spend too long on these problems.\nddd\nThe reason I warned you not to spend too long is that solving the\n50-city problem would take longer than the age of the known universe.\nNP problems get harder very fast as the number of elements goes up. A\n50-city problem is hugely larger than a five-city problem, not just ten\ntimes harder.\nThe Clay Mathematics Institute has offered a $1 million prize for\nanyone who can say whether NP problems are really as hard as they\nappear. It may be there is a general trick or a series of tricks that allow\nyou to solve any NP problem in a shorter time. If you could do this, the\nproblem would be demoted to P, allowing fast computers to tackle it. No\none has yet found a proof of the P=NP problem. At the time of writing\nseveral proofs are sitting with the Clay Prize judges but don’t hold your\nbreath. Most people assume there is no solution. If you want to have a\ncrack at the problem let me state it in simple terms.\nTraveling Salesman\n168 Are the Androids Dreaming Yet?\nImagine you wanted to find the center of a maze. Is there a way to\nspeed searching the maze, so you do not have to test every branch? If\nyou can provide a mathematical proof that there is or is not, you win the\nprize.\nPlaces Game\nWhile it is commonly assumed NP problems are the hardest, this is not\nthe case. There are quite a few that are harder still. One such is called a\nPSPACE problem. It’s quite difficult to explain but luckily many of you\nwill have played a form of it on long car trips when you were a child: My\nfamily calls it The Places Game.\nI will pick a place – ‘London,’ and you must then pick another place,\nsay, ‘New York’, that starts with the letter my place ends with. I’ll then\npick ‘Canterbury’ and my kids will laugh at my dyslexia and I’ll have to\nswitch to ‘Kansas’ and so on. Once you use a place you can’t use it again.\nThe mathematical question is to predict who will win given each\nplayer has a finite list of places they know? It turns out this type of\nproblem is even harder to solve than an NP problem. This is because\non each turn a player gets to pick any name from their list. With the\ntraveling salesman problem, there is only one ‘player’ – the salesman –\nso we can write out a route and check it. In the Places Game there is\nno single route through the game because, after I pick my favorite town\n‘London,’ you can pick any place beginning with ‘N’. I have to anticipate\nan enormous table of possible paths through the game. The table takes\nhuge physical space – which is where PSPACE gets its name.\nRemember I’m just playing the simplest mathematical games with\nbits of paper and discrete ideas. I haven’t strayed into the quantum\nworld yet. That brings with it a whole new level of complexity to explore.\nComplexity is such a diverse subject that Scott Aaronson of MIT has\ncreated a web site called the complexity zoo to catalogue all the different\n‘species’. It is much to complex to reproduce here but let me provide a\nsketch.\nThe Complexity Hierarchy\nMy table below represents the hierarchical complexity of knowledge.\nWe start off with the problems both humans and computers find easy,\nthen rapidly move onto problems that even the fastest machines find\ndifficult: a perfect game of chess or predicting the weather. Above these\ncomputable problems are the non-computable ones which no computer\nComplexity & Chaos\n169\nrunning any algorithm can solve, and then\nthere are the free will problems: how do\nwe pick a problem in the first place? How\ndo inventors come up with problems no\none had ever thought to solve in the first\nplace, such as the invention of the Rubik’s\nCube?\nErnő Rubik’s Cube\nProblem\nExample\nFlat\nPrint File (for Human)\nnlogn\nSearching a list\nLinear\nFinding the lowest number in a list\nLogarithmic\nLong Multiplication\nExponential\nLong Division\nP\nMost Algorithms\nNear NP\nFactor Prime Number\nNP-non-complete Perfect Game of Chess\nNP-Complete, tractable Travelling Salesman, SAT\nChaotic\nWeather\nNP-Complete, Quantum Modeling a Quantum Process\nNP-Complete, intractable Busy Beaver, Towers of Hanoi\nPSPACE\nGraph Problems, Places Game\nCreativity, Finding Fermat Theorem for a\nNon-computable\nTuring machine, Tiling the plane with Penrose\nTriangles\nNon-deterministic,\nNon- time divisible, Non- Free will\ncomputable\nHalting problem for a Turing Machine, some\nmathematical theorems such as the Continuum\nImpossible\nHypothesis in ZF+AC (Hilberts 1st). Travelling\nfaster than the speed of light. Understanding\nthe American tax code.\nKnown Unknowns I know that I don’t know either way.\nUnknown Unknowns\nI have not thought to ask that question yet.\nInventing the Rubik’s Cube\nButterfly\n“Does the flap of a butterfly’s\nwings in Brazil set off a tornado\nin Texas?”\nPhilip Merilees, improving on\nEdward Lorenz\nChaos\nChaos is the twin of complexity. It burst into the public psyche\nin 1987 with the publication of James Gleick’s book Chaos. It’s\nnot a difficult concept to grasp. Complex systems can be formed\nusing simple rules, and very small changes in starting conditions can\nprofoundly affect future events. I experience this if I miss my train to\nwork in the morning: 30 seconds either way will change the whole\npattern of my day, the people I meet and the level of stress I experience.\nI’m sure you can think of similar experiences.\nHenri Poincaré, a French\nmathematician, first studied the\neffect back in 1880. Poincaré was\ntrying to solve an old mathematical\nproblem called the Three Body\nProblem originally set by Isaac\nNewton. Take the Earth, Mars and\nthe Sun. These three bodies orbit\neach other, or strictly speaking a\npoint in space somewhere between\nthem. Is there an equation that\nwill tell you where the bodies will\nbe in, say, 100 years’ time?\nThe answer is surprising,\nno. The three bodies will orbit in\na non-repeating way. There is no\nanalytical short cut, no equation\nthat will predict where they will be\nPoincaré\n\n172 Are the Androids Dreaming Yet?\nat some point in the future. The only way to know is to build a perfect\nmodel of the system and see what happens. Poincaré won a valuable\nprize for his proof from the King of Bavaria. You can see some amazingly\ncomplex orbits plotted below. Remember these are still deterministic and\npredictable – after all, they were calculated with a computer – they are\njust chaotic.\nFour Body Problem\nButterflies and Sliding Doors\nAfter Poincaré, the field of chaos remained fairly quiet until Edward\nLorenz began studying weather patterns using computers in the 1960s.\nThe story goes, one day his computer was misbehaving and he had to rekey\nsome data into the machine. Rather than using eight decimal places\nhe used only six to save time, and was amazed when the results of his\nprogram came out completely different. Dropping the seventh and eighth\ndecimal place represents a change of only one part in a million, yet the\npatterns of weather predicted by the computer were completely altered.\nComplexity & Chaos\n173\nLorenz went on to study the effect and created a new branch of\nmathematics. His quote about the beat of a butterfly wing creating\ntornados has entered the public psyche and is central to the plot of\nnumerous Hollywood movies. One of his functions – known as the Lorenz\nAttractor – nicely illustrates the nature of chaos. A very simple equation\nplots the beautiful, apparently three-dimensional, non-repeating shape.\nChaosville\nChaos, taken to its logical conclusion could explain our Universe. Stephen\nWolfram in A New Kind of Science, makes the argument that simple rules\ncould explain the extraordinary complexity we see in our Universe. He\napplies rules to elements in a two-dimensional grid programmed on\nthe computer which form ‘cellular automaton’ that function a little like\nsimple animals, generating all manner of complex shapes and behaviors.\nThe inspiration for this approach is almost certainly Conway’s Game of\nLife developed by John Conway in the 1960’s. In his computer game,\nanimals and machines seem to appear on the screen but in truth they\nderive from the most simple set of rules. You can check out the website\nto see a live version of Conway’s Game of Life. It’s a lot of fun. Wolfram’s\nStrange Attractor\n174 Are the Androids Dreaming Yet?\nthesis is that we could all be living in one of these games. Perhaps our\nUniverse is a form of Mandelbrot diagram – albeit a 3D version with\nstars and planets. If you look at the picture of a nebula and compare it to\nthe Mandelbrot set, you can see how this is a tempting conclusion.\nIn the Game of Life the rules are simple yet the behavior simulates\nlittle animals being created and destroyed. Of course, there are no\nactual animals. The things you see on the screen, ‘gliders’, ‘walkers’, and\n‘cannons’, just hang together accidentally. But, Wolfram considers these\nlittle digital creatures are animals. He argues our Universe is just like the\nGame of Life: A set of simple rules leading to complex behavior. If we are\nNebula\nComplexity & Chaos\n175\nCellular Automaton\nprepared to call ourselves animals, so should the little creatures which\nemerge within the game. We simply emerged in a similar but slightly\nmore complex game.\nThis proposal would mean our Universe is entirely deterministic,\nour lives the result of a gigantic computer program that we live within\nand form part of. Chaos might make it impossible to predict the future\nwithout running the program and watching what happened, but the\nresults would be inevitable, set in motion at the dawn of time. There is\nno place for free will in such a Universe, no place for reason. The world\nwould simply be.\nBut a strange idea will come to our aid to show us the limits of\ncomputation and allow us to question whether we live in a predetermined\nworld. This idea is Aleph 1 – something larger than infinity. And it is\ninfinity we will explore next.\nConway’s Game of Life\n\nChapter 8\n∞\nHilbert’s Hotel\n“All infinities are equal, but some\nare more equal than others.”\nGeorge Orwell, paraphrase\n“Only two things are infinite, the\nuniverse and human stupidity,\nand I’m not sure about the\nformer.”\nAlbert Einstein\n“God gave us the integers, all else\nis the work of man.”\nKronecker\nHealth warning! The man who discovered infinity had a mental\nbreakdown. This subject may tax your brain.\nGeorg Cantor didn’t really ‘discover’ infinity but he was the first\nmathematician to put it on a firm theoretical footing. In the late 19 th\ncentury, most mathematicians thought infinity was a curious idea with\nno proper place in mathematics. They treated Cantor’s attempts to make\nit into a real mathematical object with contempt. This affected Cantor’s\nmorale and caused him to suffer several bouts of deep depression,\nretreating to a sanatorium from time to time.\nInfinity is a difficult idea to grasp but it is vital to our study of\ninformation. It behaves counter-intuitively but is not impossible to grasp.\nThe reason it is important is that information can always be translated\ninto numbers and numbers go on to infinity. If you want to know all\nabout information, you must understand infinite numbers.\nHistory\nIndian scholars began studying infinity in the 4 th Century BC. It turns\nup naturally in all manner of places. In geometry, parallel lines extend\nforever in either direction without ever meeting. To define a parallel line\nyou must contemplate infinity. In arithmetic, even if you pick the largest\nnumber you can imagine, there is always a larger one; just add one. In the\nphysical world if you look up at the night sky it appears to go on forever.\nAgain you have infinity.\nHistorically there were two interpretations of infinity. The first,\nfavored by Plato, was a journey. When you embark upon a journey, you\ncan always take another step. Infinity is the idea of ‘one more’ or neverending.\nIt can never be reached. The second definition is more radical.\nInfinity is a thing, a number so big you could not imagine anything bigger,\nbut it is one number. Plato thought this second definition tantamount to\nmadness. Today we embrace this madness and go a whole lot further. Let\nme show you how.\nIf infinity were a number, you should be able to perform mathematics\nwith it; add it, multiply it, and even raise it to a power. This is not as\nradical as it might first seem. Until comparatively recently, zero was not\naccepted as a number – if you consider recent to be one thousand years!\nNowadays it is.\nAt the end of the first millennium Indian scholars found, against\ntheir intuition, that you can use zero as a number without generating\ncontradictions. Take addition. I can have zero cakes, add one, and I\nhave one cake, add another, and have two cakes and so on. In this way,\n180 Are the Androids Dreaming Yet?\nthe number zero behaves just like any other counting number. It also\nworks with multiplication. If I have zero lots of 4 cakes, I have no cakes.\nZero times four is zero, so multiplication with zero works. There is one\nembarrassing exception, if I divide by zero I seem to get infinity. When I\nwas a child this was a definition for infinity, but nowadays mathematicians\nsimply forbid the operation. Division by zero is not allowed and if you\ntry it on your computer, you will get the not terribly useful, #DIV/0!\nError. That’s progress I guess!\nZero had been tamed. What about infinity?\nCantor showed that while you could think of infinity as a number,\nit might not be just one number. He proposed there are many infinities.\nIn fact, there are a greater than infinite number of them! He did this\nthrough a rigorous analysis of a new branch of mathematics called set\ntheory.\nSet theory is now the cornerstone of modern mathematics, but it\nwas treated with suspicion in Cantor’s time. Rather than embrace the new\nthinking, many mathematicians ridiculed it; Poincaré wrote that Cantor’s\nideas were a grave disease infecting the discipline of mathematics! This\nseems odd given our modern propensity to embrace innovation, but the\ntone of science back then was different: innovation was not necessarily\nconsidered a good thing.\nAt the turn of the 20 th century, scientists were on a mission to tidy\nthings up. Lord Kelvin announced in 1890 that mankind had discovered\neverything there was to know and the role of future scientists was simply\nto catalogue and observe the consequences of these laws, and to improve\nthe accuracy of measurement. The last thing scientists wanted was a\ncompletely new set of numbers that behaved in strange ways. Cantor was\nupsetting the apple cart, but he was in good company. Just a few miles\naway in Berlin, a young Albert Einstein was beginning to study physics\nin his spare time. Those studies would culminate in his four papers of\n1905, two on Quantum Mechanics and two on Relativity, ushering in the\nmodern age of physics.\nHow to Count\nTo understand infinity you need to count in a particular way. You’re\nprobably used to counting with numbers. You count apples: one, two,\nthree, and say, “I have three apples.” You can do the same with oranges.\nIf you have three apples and three oranges, the totals are the same and\nyou can declare you have the same number of fruits. This is the first way\nto count.\n∞\n181\nBut there is a second way of counting. Take your apples and put each\nnext to an orange. If they match up, you can easily see they are equal in\nnumber. “Look,” I say, “I have the same number of apples as oranges.” This\nmethod is more primitive and does not require the concept of numbers,\nbut it is very useful. If I’m a shepherd I can hold a set of counters in a bag,\none for each sheep. To ensure all my flock are gathered in for the night I\ndrop one counter into the bag as each sheep enters the enclosure. I don’t\nneed to give the counters number names.\nThe Munduruku tribe, from the Amazon rainforest, have no concept\nof number names beyond five. Their counting system simply goes one,\ntwo, three, four, five, many. Yet this second way of counting allows them\nto function successfully, deciding whether two groups of things have\nthe same number of elements, even if there are more than five of them.\nFor example, if they need to determine if they have enough spears for a\nhunt, each person simply stands next to their spear. If everyone has one,\nthey’re ready. If not, then the empty handed Munduruku simply make\none. No need for pesky numbers or mathematics lessons.\nThis second way of counting is particularly useful when tackling\ninfinity because we are not sure what infinity is. Treating it the same way\nthe Munduruku treat the number ‘many’ is the safest thing to do. The\nfirst question we would like to answer is whether all infinite things are\nthe same.\nSpears and Hunters\n182 Are the Androids Dreaming Yet?\nWe know from our childhood that infinity plus one is still infinity.\nIs there anything we can do to make infinity bigger? Perhaps multiplying\ninfinity by infinity will do the trick.\nInfinity times infinity can be visualized as a square with edges of\ninfinite length. We can show that this square is the same size as a onedimensional\ninfinity through a clever trick – the zigzag method. Mark\nthe infinity square into a grid. Start in the corner square, go across,\ndiagonally down, then across, diagonally up, and so on. I’ll draw you\na picture. We visit every square in our grid using a single line. We can\nthen lay down our infinite zigzag line next to the infinite line of one\nof the edges. The lines are the same length as they are both infinitely\nlong! So infinity, times infinity, can be matched to infinity, they are the\nsame. Cantor thought this a very strange result and wrote to a fellow\nmathematician, Dedekind, “Je le vois, mais je ne le crois pas!”, “I see it,\nbut I don’t believe it!”\nIf you are struggling with this, don’t worry. We just jumped forward\nto quite a complex concept. Let’s take it more slowly. One way to get a\nbetter grip on infinity is through the stories of David Hilbert and the\nInfinity Hotel.\nInfinity for Dummies\nHilbert’s Hotel is a mythical building with an infinite number of rooms.\nOther than this strange feature it is a regular hotel complete with\nminibar, dodgy TV, and slightly mad manager. The rooms are numbered\nsequential starting at one, then two, three, four, and so on. The hotel\nallows you to play a series of mathematical games to see how infinity\nbehaves.\nAre there the same number of minibars as there are rooms? That’s\neasy. I said every room has a minibar. We can use the matching technique\nto match minibars with rooms. Go to the first room. There is a number\non the door and a minibar inside. The same goes for room 2 and 3 and\nthis goes on forever. I’ve just proven two infinite things are the same –\nrooms and bars, but I still have not shown you why the zigzag line is the\nsame length as the edge line.\nWhen you first explain infinity to a child they immediately ask\n“What’s infinity plus one.” A particularly smart kid I met, Dermot, asked,\n“What’s infinity plus three?” Hilbert’s Hotel allows us to answer this\nproblem in a way we can visualize.\n∞\n183\nTraversing an Infinite Plane with a Line\nThe infinite hotel is full. A man comes to the front desk and asks for\na room. The hotel manager says, “I’m terribly sorry, but we are full… But\nI may be able to help you. Let me think.” He ponders for a moment and\nthen says, “OK – I’ve found you a room.” He calls the people in room 1\nand asks them to move into room 2. He calls the people in room 2 and\nexplains that due to a double booking they must move out of their room\nto let the people from room 1 in. But it’s OK; they can move into room\n3. Everyone moves up a room and the new guest gets the checks into the\nnow vacant room 1.\nThis is a little harder to understand. We did not have a perfect oneto-one\nmatch as with the rooms and mini-bars. We had a mismatch of\nguests to rooms. But, we were able to show it is possible to re-establish\na one-to-one match by doing something to every guest, having them\nmove up a room. There is no problem with the last guest because it is an\ninfinite hotel, there is no last guest! Another way to visualize the problem\nis to ask ever hunter to pass their spear to the right in the picture below.\n184 Are the Androids Dreaming Yet?\nHunter with Spears\nProvided there are an infinite number of hunters there is always someone\nto hand the spear to and the person at the front of the line now has space\nfor another spear.\nYou can probably see how to answer Dermot’s question. The hotel\nmanager calls the guest in the first room and asks him to move 3 rooms\nup rather than one. He then calls the remaining guests and tells them\nthe same thing. Thus, he has managed to fit three more people into\nthe infinite hotel. Infinity plus 3 is infinity. You may worry that it takes\nthe manager an infinite time to call all the rooms, but it’s OK; he lives\ninfinitely long so it all works out.\nWhat about fitting an infinite number of new guests into the already\nfull hotel? Surely then we will get stuck.\nNo, Hilbert’s Hotel can fit an infinite number of extra guests. Here’s\nthe trick: ask all the people currently in the hotel to move to the room\nwith double the number they are currently in – 1 goes to 2, 2 goes to 4,\n3 goes to 6, and so on. Now all the odd numbers are empty and you can\nfit an infinite number of people into the empty odd rooms. Infinity plus\ninfinity is infinity. Voila.\n∞\n185\nNow, a very clever or annoying student asks, “What happens if an\ninfinite number of infinitely large buses arrive at the hotel. Can they all\nfit in?” The mathematical question is “does infinity times infinity, equal\ninfinity?” Let us ask all the guests to get out of the bus and line up in the\nparking lot in neat rows. Passengers from bus one in line 1, those from\nbus 2 in line 2, and so on. All the guests now form a two-dimensional\ngrid. We already know how to map a two-dimensional grid to onedimension\nusing the zigzag method. We can fit them all in the hotel and\nwe are done!\nIs Anything Larger than Infinity?\nIs there any bus or combination of buses that would cause the manager\nof Hilbert’s Hotel a problem.\nThe answer is yes and it involves a subtle change to the contents of\nthe bus.\nAn infinite number of buses turn up but this time the buses are\nfilled with men and women. The hotel manager is asked to put everyone\nin a room and once again he obliges using the zigzag method.\nAt the end of the process the tour guide comes to him. “I think you\nhave missed some people,” he says. “Since I am just one person, I know\nyou can fit me in. But, I have a whole bus in the car park you completely\nmissed.”\n“No,” says the manager. “I did every bus.”\nInfinity Plus Infinity Equals Infinity\n186 Are the Androids Dreaming Yet?\n“Ah, no,” says the tour guide. “The first bus you accommodated\nhad a man in the first seat but this has a woman. The second bus had\na woman in the second seat but this one has a man and so on. This\nbus has a different gender in at least one seat to every bus you so far\naccommodated. It is a new bus.”\nThe manager finds room for the passengers from the new bus but\nthe tour guide comes back a moment later.\n“You have missed another bus. This one has a different gender\nin at least one seat to every previous bus, including the one you just\naccommodated. It looks like there are an infinite number of buses you\nmissed, all lined up to get into the infinite hotel.”\nWhat is it about these buses that make them so difficult to\naccommodate? They are all just filled with people after all.\nThe manager is defeated by the more complex information held in\nthe contents of the buses. An infinitely large bus full of binary information\nhas more information in it than an infinitely large bus specified only by its\nsize. This is a larger infinity than the counting infinity. The permutation\nof all the possible options for the occupants of the bus is larger than\ninfinity.\nReal Numbers\nWhat about the real world we live in? Is the larger infinity we failed to\nfit into Hilbert’s Hotel present, or was it just a mathematical fiction?\nHold up your thumb and index finger for a moment. The gap between\nthem is a distance. Most likely this is a whole number with an infinite\ndecimal digits after it – say 2.2320394386…. centimeters. The infinite set\nof decimal digits in this measurement is the larger type of infinity: called\nthe continuum. Distances in space form a continuous unbroken line of\npoints, with no gaps in between. The counting numbers, on the other\nhand, form a broken line. We take discrete steps from one number to the\nnext. This is a hard distinction to grasp but it is the same distinction we\nused in Hilbert’s Hotel. Imagine you believe you have a list of all the real\nnumbers in the world. You can take the first decimal digit from the first\nnumber and add one, the second digit from the second number add one\nand so on generating new numbers not on the original list. Therefore,\nyou cannot have a list all the real numbers; they are not countable. Let’s\ntake a closer look at these real numbers.\nHere’s a quick test. Which is the larger number, the first or the second?\n∞\n187\nHolding a Real Number in your Hand\nddd\nFirst: 3.1233249837583462136421472374\nSecond: 3.1233249837583462134421472374\nYou have 2 seconds to answer!\nTRY ANSWERING WITHOUT READING ON\nThe first is larger. I changed one digit. Can you see?\nNotice, you need time to read each digit and process the information.\nIf you were an obedient reader and attempted it in two seconds you either\nguessed or gave up. Two seconds is too short to take in all the digits.\nLet me give you another test. Again, I’ll ask you the question, “Is the\nfirst number larger than the second?”\nddd\nFirst\n3.12332498375834621364214723751646464646464636…\nSecond\n3.12332498375834621364214723751646464646464636…\n188 Are the Androids Dreaming Yet?\nI know you’re looking for the difference but you won’t find one, as\nI did not have time to write the numbers out in full. The 10 20000th digit is\ndifferent, but even if I took the whole age of the universe and counted\nas fast as possible I would not reach this digit. Any number greater\nthan, 10 120 /10 -43 digits cannot be distinguished from another in the age\nof the observable universe. Real numbers are in practice subject to an\nuncertainty principle. Some mathematicians even wonder whether they\nreally exist. But, they do exist in our minds and our thought experiments.\nIn my view, any model of the Universe that ignores them is likely to be\nwrong.\nRandom Numbers\nWhich of the following numbers is random?\nddd\n11111111111111111\n34289460370124001\n49293741762343083\nTHINK ABOUT YOUR ANSWER THEN READ ON\nEach of the numbers could be random. There is no reason any set\nof 10 digits is more likely than another, but it feels very unlikely that if\nI tried to generate a random number I would get 15 consecutive digits.\nWhat a human means by random is a jumbled up number: one with\nvarying digits that have no real pattern. An American mathematician,\nGeorge Chaitin has been able to explain this by saying that a random\nnumber is uncompressible. This means there is no way to describe the\nnumber more efficiently than writing it out in full. A string of ones\ncan be compressed. “Write a million 1s” takes only 18 characters, yet\naccurately describes a number that is a million digits long. By contrast\n8988376132 can’t be compressed very much at all, its information\nis just a jumble. There are many interesting numbers around. Some\nnumbers are Hamlet; some numbers are pi. One interesting number is\nthe following: 17733173332032037377. It is the genetic sequence for the\nvirus smallpox, or at least the first 20 digits. Copies of the full sequence\nsit under lock and key in the Pasteur Institute in France and the CDC in\nAtlanta. This number is a candidate for an ‘evil’ number. You might think\nthere are many numbers that could represent smallpox because there are\n∞\n189\nSmallpox Virus\nmany languages in the world and many ways you could code the genetic\nsequence of GATC. But, there will be one most efficient binary coding\nfor smallpox and that number is the nearest we have to an evil number.\nThe other important element of random numbers is the process\nby which they are created. Computers can’t genuinely generate random\nnumbers. The numbers they generate are predictable and eventually\nChild Survivor of Small Pox\n190 Are the Androids Dreaming Yet?\nrepeat. To create the random number in my example above I went to www.\nrandom.org, a website that uses fluctuations in atmospheric quantum\nnoise to generate random numbers. As far as we know quantum effects\nare truly random and have neither rhyme nor reason.\nNumbers are more complex than they first appear. They are infinite,\nyet there are different infinities, and they have meaning. The smallpox\nexample above and the Turing numbers we will discover shortly suggest\nnumbers do have meaning independent of culture and language. The\nnext two chapters will show us what happens when we think about the\nmeaning of numbers. We will also explain one more ‘super infinity’ and\nthis will be the key to understanding creativity.\n“There are known knowns; there\nare things we know we know.\nWe also know there are known\nunknowns; that is to say we\nknow there are some things we\ndo not know. But there are also\nunknown unknowns - the ones\nwe don’t know we don’t know.”\nDonald Rumsfeld\nUnited States Secretary of Defense\n(2001-2006, 1975-1977)\nChapter 9\nKNOWN\nUNKNOWNS\nDonald Rumsfeld\nIn the spring of 1981, London staged its first marathon. The field of\nrunners included 1200 international athletes and 20,000 amateurs.\nAn estimated 20 million viewers watched from around the world.\nThe top international runners stayed together for the first twenty miles\nand then two runners, American Dick Beardsley and Norwegian Inge\nSimonsen, made a push for the finish. They were long-standing rivals\nand, as they ran the final mile each man challenged the other to see if\nthey could get ahead and gain the advantage. Because of the fine balance\nhuman muscles maintain between anaerobic and aerobic metabolism,\nthe small set advantage could prove insurmountable. The other runner\nwould need to sprint to catch up and the resultant lactic acid generated\nwould turn their legs to jelly. As the two runners neared the finish line\nthey glanced at each other, smiled, reached out and held hands as they\ncrossed the line. Who won?\nWe all instinctively know the answer. The race was a draw, but the\nrules of the International Athletics Federation are clear. Read rule 164.\nRULE 164\nThe Finish\n1. The finish of a race shall be denoted by a white line 5 cm wide.\n2. The athletes shall be placed in the order in which any part of\ntheir bodies (i.e. torso, as distinguished from the head, neck,\narms, legs, hands or feet) reaches the vertical plane of the finish\nline.\nThe organizing committee held a brief conference and the result\ndeclared a draw. They had interpreted the rules in the same way 20\nmillion TV viewers already ‘knew’ to be true.\nThis story should set your minds thinking about the nature of rules\nand truth and how the two are often different. According to the rules,\none person crossed the line a little ahead of the other. The truth, as we\nall instinctively know, is that the race was a draw. Maybe the rulebook\nis missing a rule – ‘The contact draw rule’. Clearly you could amend the\nrulebook to add this one rule. I checked the current athletics rules and\nthey don’t contain this amendment. If the rules were amended the mischievous\namongst you will realize an unsporting athlete could grab the\nhand of their opponent as they crossed the line to force a draw. The rules\nwould have to stipulate that holding hands must be voluntary for both\nparties, and refinements could go on for some time. What if I held your\nhand but you tripped and let go? What if my attempt to hold your hand\nKnown Unknowns\n193\ncaused you to trip? You could go on\nforever, generating rules to cover every\neventuality.\nClearly, in the fuzzy world of\nhuman endeavor, truth and rules often\npart company. Yet, we all assume mathematics\nis free of such uncertainty. Let\nme tell you this is not so. The brilliant\nmathematician Kurt Gödel proved\nthis when he was just 22, and his proof\nsays something fundamental about the\nnature of knowledge.\nThe story of his discovery involves\nKurt Gödel\nsome of the greatest mathematical\nthinkers in history. My introduction to it came about from a chance\naccident. I became ill in my first year at University (mononucleosis,\notherwise know as glandular fever, if you’re curious) and was eventually\nsent home to recover. Lying in bed for two months is boring. So\nto pass the time my mother suggested I read Bertrand Russell’s, The\nHistory of Western Philosophy. I think she figured I had plenty of time, so\npicked a thick book. This nearly 800-page tome charts the entire history\nof philosophy from the time of the ancient Greeks. I presumed Russell\nwas a philosophy professor, but he was originally a mathematician. He\nwas a mathematician. And because he lived and worked productively for\nalmost all of his 97 years, spanning much of the 19 th and 20 th centuries,\nhe crops up repeatedly as a central figure in many areas of intellectual life.\nRussell the politician, Russell the philosopher, Russell the mathematician\nand Russell the peace campaigner are all the same man – not, as I had\nincorrectly first guessed, a prolific family. In his early career, Bertrand\nRussell was a Fellow of Trinity College, Cambridge, working on a broad\nrange of mathematical problems. Meanwhile, in Germany, his contemporary\nDavid Hilbert, also a polymath, held the chair of mathematics at\nGöttingen University. Both men shared a common objective: to tidy up\nthe loose ends in mathematics and set down the rules once and for all.\nThis movement was called Formalism.\nFormalism\nDavid Hilbert and Bertrand Russell believed you should be able to set\nout all the rules of mathematics even though it might be a complicated\naffair. Without contradiction or inconsistency you should be able to\n194 Are the Androids Dreaming Yet?\nwrite down the rules and then play the ‘game of mathematics’ to derive\nevery possible truth. Hilbert despised the idea that there could be\nunknowable things and was a forthright speaker. His battle cry was: Wir\nmüssen wissen — wir werden wissen! “We must know — we will know!”\nHe believed there were no fundamental unknowns in the world.\nDonald Rumsfeld famously summed up the problem of unknowns\nin an attempt to clarify a question from a journalist at a Whitehouse\npress conference:\n“There are known knowns; there are things we know we know. We\nalso know there are known unknowns; that is to say we know\nthere are some things we do not know. But there are also unknown\nunknowns – the ones we don’t know we don’t know.”\nInterestingly Donald Rumsfeld, like Bertrand Russell, is another\nperson to span a huge swath of time in the public eye. He was both\nthe youngest and the oldest serving U.S. Secretary of Defense, serving\nunder both Richard Nixon and George W. Bush. We will shortly discover\nRumsfeld’s convoluted view of the world turns out to be closer to the\ntruth than Hilbert’s tidy mathematical aspiration.\nAs well as believing there were no unknowable unknowns Hilbert\nthought mathematics was completely abstract. You did not need to know\nwhat you were talking about. Whether the symbols meant dogs, cats or\nnumbers all you needed to do was apply the rules and all would be well.\nHis belief is captured in his quote below.\n“It must be\npossible to\nreplace in all\ngeometric\nstatements the\nwords point,\nline, plane by\ntable, chair,\nbeer mug.”\nDavid Hilbert\nGeometry with Beer and Furniture\nKnown Unknowns\n195\nNewton’s Principia\nPM\nIn 1890, the Cambridge mathematicians Alfred North Whitehead and\nBertrand Russell embarked on the mammoth task of writing out all the\nrules of mathematics and publishing them in a set of books called Principia\nMathematica. Every rule is written down in meticulous detail. The books\nare heavy going and look like more like computer programs than text.\nThey set out precisely what you can, and cannot, do with numbers, and\nare the most impenetrable textbook you will ever read. Just to give you a\nflavor here is one line where Russell proves 1+1=2. It has taken about 100\npages of densely packed equations to get to this point!\nOne Plus One Equals Two, PM\nPM is a 3-volume set of books. Volume One costs £480 on\nAmazon. This is a significant work and a collector’s item. The last time\na first edition volume came up at auction in 2007 it went for over £800.\nCambridge University Press printed only 750 copies and I suspect they\n196 Are the Androids Dreaming Yet?\nAmazon Listing for Principia Mathematica\nare undervalued. When mathematicians use the letters ‘PM’, they are\nusually referring to Russell and Whitehead’s Principia Mathematica\nrather than the afternoon.\nHilbert’s Problems\nIn 1900, while Russell and Whitehead were in full flow writing out\ntheir rules, David Hilbert was invited to deliver the annual lecture at\nthe International Congress of Mathematicians in Paris. He asked a\nmathematician friend what subject he should pick for the talk and, in\na moment of inspiration, the friend suggested laying out a vision for\nthe future of mathematics. Rather than tell people how wonderful\nmathematicians were, and why their discipline was the pinnacle of\nhuman scientific endeavor, why not try modesty and list all the problems\non which they were stumped? Hilbert liked the idea and devoted his\ntalk to all the problems he thought mathematicians would solve in the\n20 th century. Hilbert’s Problems were simply an intellectual challenge.\nHe offered no prizes. At the turn of the 21 st century, the Clay Institute\ncreated the Millennium Prizes for solving the most important modern\nmathematical problems. Each solution wins a prize of a million dollars!\nThere are 23 numbered Hilbert Problems in all: ten in the original\nlecture and a further 13 in the written transcript. In 1928, he clarified\nthe 2 nd and 10 th problems, refining them into three distinct questions: Is\nmathematics consistent, complete and decidable? Ironically this means\nthat Hilbert’s 23 problems actually number 24! The most important\nHilbert questions where these last three. They ask whether Russell\nand Whitehead would be successful – can you write out all the rules\nof mathematics and then simply calculate the answer to any problem\nor derive any proof. This is known as the Decision Problem. Can you\nmechanically decide any mathematical question without doubt? To\nexplain Hilbert’s Problems, I need to define mathematics properly.\nGiuseppe Peano, Mathematician\n“A mathematician is a blind\nman in a dark room looking for\na black cat which isn’t there.”\nCharles Darwin\nThe Game of Math\nOne of my most vivid childhood memories is driving my mother\ndistraction by asking the ‘why’ question. Most children go\nthrough this phase:\nMe: “Why is a sponge wet?”\nMy mother: “Because it has soaked up water.”\nMe: “Why has it soaked up water?”\nMy mother: “Because it has small holes in it.”\nMe: “But what makes water wet?”\nMy mother: “Because it is made of wet stuff.” a bit weak now.\nMe: “What is wet stuff?”\n…\nYou can ramble on indefinitely unpeeling a never-ending onion.\nSometimes, if you are unlucky, you may get stuck in a loop. For example,\n“where did the chicken come from?” “An egg,” “and where did the egg\ncome from?”...\nMathematics breaks this cycle!\nIn mathematics, there is no danger of an infinite number of ‘why’\nquestions because at its core are a clearly defined set of absolute rules\ncalled axioms. You cannot ask the ‘why’ question of an axiom. It is a\nRULE!\nStarting from an absolute minimum of fundamental rules\neverything else is built up so that no step requires any leap of faith nor\ngenerates any contradiction. Let me give you a concrete example and, in\nthe process, show you how numbers are defined.\nKnown Unknowns\n199\nNumbers\nIt was not until the late 18 th century that numbers were properly codified.\nThe mathematician Giuseppe Peano gave us the rules, so they are called\nPeano axioms. Here are his ‘axioms’ in natural language.\nPeano Axioms\n1. The first number is named zero.\n2. Every number has a next number (called its successor). Example:\nthe next number after one is two.\n3. Numbers are singular. Every number with the same name is the\nsame thing.\n4. If something is true of a number, it should be true of the next\nnumber (the successor number).\nFrom this we can prove some very simple things.\n1+1=2. Because the next number after 1 is 2 and ‘+1’ means take\nthe successor. (You can see I cheated here a little and did not take 100\npages for the proof.)\nBack to my poor mother: “Why is the lowest number zero,\nMummy?” “Because I say so!” Or, at least “…because Mr. Peano said\nso.” That’s what an axiom is.\n“OK, but why is 3 greater than 2.”\n“Because I said that each number has a thing that comes after it.\n“But, why can’t 3 come after zero!”\n“It can!”\n“But then, if 3 is the thing after zero, I could count 0, 3, 2, 4…”\n“Yes, if you want to…”\n“I’m sort of lost. Now, you are saying that 3 doesn’t really ‘mean’\nanything. It just comes after 0.”\n“Yes. You can make up any symbols you like. You just have to\nremember what you said and be consistent.”\nThe dialogue shows the importance of definition in mathematics.\nI could define my counting numbers as 0, 1, 2, 3, 4 or as ο, π, ρ, σ, ς, or\n享 , 仇 , 仕 , 仝 or to be really annoying and confusing 0, 3, 1, 2, 4; they\nare only arbitrary symbols. It helps us to learn the numbers because 1\nis a single line, 2 is two lines joined, three is basically three lines looped\ntogether, and four is four lines, but we could have used any symbols\nwe cared for. It is the rules for manipulating these symbols that are the\nimportant part and give mathematics its meaning.\n200 Are the Androids Dreaming Yet?\nThe Game of Mathematics\nWhen I was a child, our living room carpet had a square pattern. You\ncould use boiled sweets to play checkers on it. Even though there was\nno board and no pieces, it was clearly a game of checkers because we\nfollowed the right rules (with the one exception that if you jumped over\na sweet you got to eat it). Mathematics is like a game with a set of rules.\nIf you follow the rules, you are doing mathematics.\nConsider the simple mathematical theory that if A equals B, then B\nequals A. This seems clear-cut, but you can get into trouble if you’re not\ncareful when defining the word ‘equals’. ‘My dog equals naughty’ does\nnot imply ‘naughty equals my dog. Here I have used ‘equals’ to mean\n‘has the property of.’ My dog has the property of being naughty. This is\nan attribute, not equivalence. You must be careful with mathematics. A\nequals B implying B equals A is a property of numbers when the equals\nsign is used to mean equivalence.\nHere are the rules of the game that provide a proof for this theory.\nLet us start with the position in which we don’t know whether A\nequals B implies B equals A. We have these three axioms, call them rules\nfor now since we are using the game analogy.\nRule 1: If I have no minus sign in front of a letter I can assume there\nis an invisible + sign there.\nRule 2: If I have a positive letter (or a letter with no symbol in front\nof it) I can put a minus in front of it and put it on the other\nside of the equals sign.\nRule 3: I can swap the plus and minus signs of all the letters in my\nequation if I do it to all of them.\nNow I am ready to prove my theorem.\nA = B is the same as +A = + B. (rule 1)\n+A = + B is the same as -B = - A (rule 2 done twice)\n-B = -A is the same as B = A (rule 3)\nSuccess.\nSo A = B is the same as B = A.\nI have my proof. It might be glaringly obvious, but that’s not the\npoint. The point is you can apply rules to symbols and derive new rules.\nIt does not matter what the symbols are or how obvious it is. Here’s the\nsame proof with dingbats.\nKnown Unknowns\n201\nRule 1: If I have no glyph in front of a symbol I can assume there is\nan invisible Ψ there.\nRule 2: If I have a positive letter (or a letter with no symbol in front\nof it) I can put a � in front of it and put it on the other side\nof the →\nRule 3: I can swap the Ψ and �symbols of all the symbols in my\nequation if I do it to all of them.\nThe proof in symbols\n� → ß is the same as Ψ � → Ψ ß. (rule 1)\nΨ � → Ψ ß is the same as �ß → �� (rule 2 twice)\n�ß → �� is the same as ß → � (rule 3)\nAny collection of symbols will do. The symbols have no meaning\nin themselves other than the meaning we have given them. A tribe in\nthe Amazon jungle could demonstrate a proof without knowing any\nmathematics. All I need say is, “Hey, I want to play a game with you. Can\nanyone make this into that, in the fewest possible steps, while obeying\nthese rules?”\nBut, is it true we can ignore the meaning behind the symbols. Does\nit matter that we were talking of numbers rather than spears, counters, or\ncrocodiles? If we look at the marathon winning analogy again, we know\nthe nature of a game is important. In a running race we can interpret\nholding hands to mean the two athletes are treated as one, the existing\nrules can then be applied as normal and the pair become a single winner.\nBut, in tennis, there would be a problem. I wouldn’t want to come on court\nand find I’m playing against two opponents! On consideration though\nI’d be happy if they had to hold hands while they played so that they\nconstituted a single player. When we examine the actual circumstances,\nwe can add a rule and show the rule works, but we have to see something\nabout the specific sport that makes the rule fair and workable.\nHilbert was convinced mathematical truth is not like this and\nthat proofs follow from the rulebook without any knowledge of the\ncircumstances, i.e., the sport being played or any other analogous thing.\nHe was to be proven wrong by Kurt Gödel.\n202 Are the Androids Dreaming Yet?\nKönigsberg Bridges\nGödel\nGödel studied mathematics at Königsberg University, Hilbert’s\nhometown. Königsberg is famous for having a mathematical problem\nrelated to the seven bridges that link the city together. It’s quite fun to try\nto solve. Find a route across the city that crosses each bridge once and\nonce only. You can start anywhere, but no walking halfway over a bridge\nand no swimming!\nEuler discovered a rigorous mathematical proof that there can\nbe no solution in 1735 after five hundred years of failure by other\nmathematicians. The answer is you cannot.\nIn 1931 Kurt Gödel, then working at the University of Vienna, proved\nmathematics is like our sporting analogy. There are true statements in\nmathematics that cannot be proven by the rules of the system. Someone\noutside the system, with common sense, can see a statement is true, but\nit’s impossible to prove this if you constrain yourself inside the system. It\nis the equivalent of all the members of the London Marathon Committee\nwondering what to do about the race while all of us watching the TV are\nshouting, “It’s a draw!” Looking at the rulebook ‘really hard’ doesn’t help.\nKnown Unknowns\n203\nYou have to step back and think about the problem in the round and then\ndevise some additional rules to handle the circumstances. Mathematics\nis like this also.\nHere is how Gödel proved his result.\nIt is easy to turn logic or any text into numbers. That’s how this\nbook is stored on my laptop. All we need do is translate sentences into\nASCII or Unicode. In this way, any theory can be reduced to a string of\nnumbers.\nSince Gödel’s proof predates the invention of the computer, he had\nto come up with a novel way to store information. He deployed an old\nRoman invention; a substitution code. The number one was represented\nby 1, two by 2 and the symbols by larger numbers, for example, ‘=’ was\ncoded as 15 and so on. He then raised a sequence of prime numbers to\nthe power of each of these codes and multiplied all the results together.\nThis generated a single enormous but unique number that he could later\nfactor back into its constituent parts to recover the information. This is\na truly complicated solution to a very simple problem. Today we would\nsolve it by storing each number in the memory of a computer as an array.\nLet’s use the easier table method to store things and code as follows:\n000 will stand for ‘start of proof ’. Each step in the proof will start with 00\nand each symbol in the proof starts and ends with a zero. This way we\ncan code one plus one equals two as follows.\n0000001110454011101210222000000\nI think this is simple enough for you to guess the coding scheme.\nHint: 111 stands for 1. The scheme is on my website if you can’t work\nit out. Using this technique, any series of mathematical statements can\nbe turned into a number. As a series of mathematical statements is a\nproof, we can generate proof numbers. They are just the sequential list of\nall the instructions. These numbers are sometimes referred to as Gödel\nnumbers.\nGödel’s next step was to say one number demonstrates the proof of\nanother number. For example, the number 000820962 might demonstrate\nthe proof of another number 000398... This is the mathematical equivalent\nof my saying a Word file demonstrates the truth of your mathematical\ntheorem. Any statement can be represented by numbers, provided\nyou have a consistent coding scheme that allows you to get back to the\nmeaning.\nNow Gödel set up his paradox:\n204 Are the Androids Dreaming Yet?\nEvery correctly formed theorem number has another number,\nwhich demonstrates the proof of that number.\nIf this is universally true there should be no contradiction.\nUnfortunately if you apply the theorem to itself you get something\nsimilar to the liar’s paradox.\n“This proof number is not a proof of the truth of this theorem\nnumber.”\nThe proof number proves the theorem number is true, but the truth\nof the statement is that it can’t be a proof of the statement… Paradox.\nThe only way to resolve the paradox is to go back one step and\nrealize that not every correctly formed theorem number has a proof\nnumber using only the rules of that system.\nConcisely, Gödel’s theorem says, “Within any formal system of\nmathematics there can be statements that are true but are not provable\nusing only the rules of that system.”\nWhen Hilbert heard of Gödel’s proof, his first reaction was anger.\nAfter all, he had spent 30 years of his life trying to prove mathematics was\ntidy and complete. Gödel had just shown it was not. Hilbert never worked\non formalism again, but the rest of the mathematical establishment\nlargely ignored the result. Gödel’s proof did not stop mathematicians\nproving new theorems nor doing useful mathematics. They went on\nmuch as before, using a mixture of intuition and analysis. The only\ndifference was someone had told them analysis alone would not succeed.\nThe repercussions of Gödel’s theory have more to do with understanding\nour place in the Universe and the nature of knowledge discovery. These\nare ‘big’ philosophical questions, which don’t greatly affect the day-today\nability of a mathematician to do their job. However, it is important\nto understand that knowledge discovery is not simply analysis. Knowing\nthis helps us understand human creativity.\nInconsistency\nIn the proof above, I said the only way to resolve the paradox is by saying\nthere cannot be a proof number for every mathematical statement and\ntherefore mathematics is incomplete. There is one other way to solve the\nparadox, and that is by allowing inconsistency into the system. Gödel’s\nproof assumes you can prove something true or false, but what if you\ncould prove it true and false? In this case, the system is complete but you\ncan prove truths and untruths within it! This may seem an acceptable\nsolution, but inconsistency in a mathematical model is a cancer that will\nKnown Unknowns\n205\nspread through the entire body. Think about it. If I am allowed to prove\nanything either way, of course, my system is complete. It can say anything\nit wants, but the proofs I make are worthless.\nLet us imagine, for a moment, we created a new system of\nmathematics where all the numbers in our new theory behave as we\nexpect, except for the numbers 5 and 6. You may use them to count, but\nthey are also equal to each other! This feels bad and it certainly breaks the\nPeano axioms. In my new system 1 plus 5 and 0 plus 5 are the same, so I\ncan equate 0 to 1. Because 0 and 1 are the basis of binary arithmetic, all\nnumbers can be equated. Numbers now have no guaranteed meaning in\nmy system and, what is worse, since logic uses 1 and 0 to represents true\nand false, all of logic falls apart as well. Whenever we allow inconsistency\ninto mathematics it rapidly brings the whole pack of cards down.\nThe example I gave was glaring; an inconsistency right in the\nmiddle of the counting numbers! Maybe I was too aggressive and a\nsubtle and less damaging inconsistency might be tolerable. However,\nany inconsistency allows me to make zero equal one somewhere in my\nsystem and, therefore, any theorem based on proof by counterexample\nwill be suspect.\nThere might be systems where inconsistency could be a legitimate\npart of a mathematical system, but I would always need positive\ncorroboration for each proof. If I tried hard enough, I could always prove\nsomething either way. I would need to formulate a new mathematical\nrule – something like “I will believe short, sensible-looking proofs to be\nright and circuitous proofs to be wrong.” Mathematics would be a bit like\na court of law. You would have to weigh up the evidence from a variety\nof sources and the verdict would be a matter of subjective opinion rather\nthan objective fact. Inconsistency is very bad in mathematics.\nThe Lucas Argument\nJ.R. Lucas of Oxford University believes Gödel’s theorem says something\nfundamental about the nature of the human mind. In 1959, he wrote a\npaper, Minds, Machines and Gödel, where he argued humans must be able\nto think outside a fixed set of formal rules. The paper has been causing\narguments ever since. Strong AI proponents have a visceral reaction to\nit. Forty years later, in 1989 Roger Penrose picked up the baton and put\nthe Lucas argument on a stronger theoretical footing. The Lucas-Penrose\nargument is this:\n206 Are the Androids Dreaming Yet?\nIf humans used a formal system to think, they would be limited by\nthe incompleteness theorem and unable to discover new theorems that\nrequired them to extend the formal rules. Humans do not appear to have\nsuch a limitation and regularly extend their appreciation of mathematics\nby expanding the rules, and seeing through to the truth.\nMany scientists dislike this argument and think it farfetched, saying\nthere is no evidence to show people see past the limitation. Our brains\ncould be following a formal system capable of discovering everything we\nhave discovered to date or, indeed, might encounter in the future. Why\nshould we assume human minds are constrained in the same way as the\nmathematical systems they discover? There is no evidence to suggest a\nhuman thinking about Peano arithmetic is running a Peano based model\nin their head. When Peano discovered his theorem he was certainly\nextending our mathematical knowledge, but this does not imply he was\nextending the capability of his brain.\nThe critics of Lucas and Penrose have one big problem to deal with.\nThe formal system in our head would need to be able to see the truth in\neverything we could ever encounter. But, our formal system appears to\nbe small. As infants, it is almost nonexistent. Where does this enormous\nsystem come from? It can’t come from our parents because they have\nthe same problem; they were once children. You might argue that the\ncapability of the human brain is huge and we can learn from all the other\nhumans on earth, but let me remind you what Gödel said. However large\nTwo Giants\nKnown Unknowns\n207\na system you have and however much you extend it, the system will\nalways be incomplete. And we really do mean; however large. Even an\ninfinitely large formal system would be incomplete.\nThe only way to avoid this problem is with some sort of conspiracy\ntheory where we only come across problems our formal system can\nalready solve. Such a theory is a determined Universe. In a determined\nUniverse, all the mathematical problems we ever solve must be expressed\nby the formal systems existing in the Universe. We must never encounter\na problem where we need to extend the system and break the Gödel limit\nbecause we are pre-determined not to do so.\nThe Inconsistency Defense\nAn argument put forward by opponents of the Lucas-Penrose position\nis that humans are inconsistent formal systems. Inconsistent formal\nsystems are not subject to the incompleteness limit. Humans certainly\nbehave inconsistently with remarkable regularity but simply making\ninconsistent statements is not sufficient to show the underlying formal\nsystem is, itself, inconsistent. Inconsistent beliefs can come simply from\nmaking mistakes or reading the same story in two different newspapers!\nWe need a fundamentally inconsistent thinking mechanism inside our\nbrains to break the constraint. The very machinery itself would have\nto be inconsistent. But this is exactly Penrose’s point. Constructing a\nmachine capable of reasoning in an inconsistent but useful manner would\nneed exotic technology, some sort of non-deterministic, rationalizing\ncomputer. The components to make it could not be computer logic as we\nknow it today. All such logic is entirely computationally deterministic.\nLet me see if I can reframe the Lucas argument. Imagine IBM’s\nWatson computer was let loose on mathematical reasoning. Watson could\nscan every mathematical theorem ever written down. It would know\nevery programming language created. It would have its enormous bank\nof general knowledge to call upon and it could answer many questions.\nIt would sometimes appear inconsistent because the information it had\ntrawled from the Internet would be wrong. But Watson would still be a\nconsistent formal system and Gödel’s theorem says there would be truths\nWatson could never see. Lucas argues humans can see such truths where\na machine cannot, and these truths would allow a human to discover a\nproof to a mathematical problem that would forever elude Watson.\nThe Lucas argument runs into a brick wall because it asserts we see\ntruths a machine cannot. For each alleged creative step, his opponents\nsimply assert your brain was already sufficiently powerful to perform\n208 Are the Androids Dreaming Yet?\nthat creative step. Lucas’s argument is largely a philosophical one. Surely\nall this creativity can’t all be pre-coded within the brain. Surely we must\nbe extending our model in order to extend mankind’s mathematical\nmodel. “Prove it,” say the detractor, and he cannot. We need something\nmore practical if we’re going to show a difference between humans and\nmachines - something an engineer, or even a physicist, could grasp! That\nthing is a Turing Machine. We will examine this next.\nChapter 10\nTURING’S\nMACHINE\nAlan Turing\n“A computer would deserve to\nbe called intelligent if it could\ndeceive a human into believing\nthat it was human.”\nAlan Turing\n“The only real valuable thing is\nintuition.”\nAlbert Einstein\n“Mathematical reasoning may be\nregarded rather schematically as\nthe exercise of a combination of\ntwo facilities, which we may call\nintuition and ingenuity.”\nAlan Turing\nIt is 1943 and a small group of Polish mathematicians sit, ears glued\nto their wireless set, waiting to hear whether the German army will\nadvance on Warsaw. The Polish Intelligence Bureau badly needed\nto know what the German army was planning and had recruited this\ngroup of young mathematicians as code breakers. Up to this point, codebreaking\nhad been the domain of linguists able to see word patterns\nin apparently random sets of letters. The arrival of electro-mechanical\nmachines made this method redundant, and code-breaking had become\nthe domain of mathematical minds. The British, French, and American\nintelligence agencies were all hard at work deciphering the German\ncodes, but only the Polish group, motivated by the imminent threat of\ninvasion, had made real progress. The code they were breaking: ‘Enigma’.\nAs with many inventions, Enigma got off to a difficult start. The\ninventor, Arthur Scherbius, tried to sell it to the army but they rejected it\nsaying it did not provide any real military benefit. Instead, the machine\nwent into service transmitting commercial shipping manifests. However,\nsome senior figures in the German military had not forgotten the lesson\nof the First World War. During that war, the German army suffered\nmajor setbacks because the British broke all their codes early on. With\nthe onset of World War II, Rommel ordered the German Army and Navy\nto deploy modern coding machines. The previously rejected Enigma was\nrapidly pressed into service and, all of a sudden, Europe went dark to\nAllied Intelligence. The man to lead the task of breaking Enigma for the\nEnglish was Alan Turing.\nAlan Turing\nAlan Turing was conceived in India but born in London in early 1912.\nHe was precocious from an early age and an extraordinarily determined\ncharacter. His first day at Public School, Sherborne in Dorset, coincided\nwith the British General Strike of 1926. With no public transport available,\nthe thirteen-year-old Turing cycled the 60 miles to school, staying in a\nguesthouse on the way and earning a write-up in his local newspaper.\nTuring went on to study Mathematics at King’s College, Cambridge and\nwas made a Fellow at only 22. In 1936 Turing, aged 24, published On\nComputable Numbers and their Application to the Entscheidungsproblem,\nnot a snappy title, but one of the most influential mathematical works of\nthe 20 th century. The paper described the new the science of computing\nand solved Hilbert’s ‘Entscheidungsproblem’, a mathematical puzzle\n212 Are the Androids Dreaming Yet?\nsimply translated as ‘the Decision Problem’ – could you decide the truth\nof a mathematical statement using some sort of automatic computation\n– an ‘algorithm’ as we now call it?\nIt is difficult to imagine, but Turing worked on ‘computing’ before\nthe invention of the computer. When he talked of computing, he\nmeant the abstract idea of doing something mechanically. The nearest\nthing he had to a ‘computer’ at the time was a human mindlessly but\nmethodically calculating something with pencil and paper! The scientific\npaper he submitted to the London Mathematical Society described both\nthe theoretical basis of computing, and the design of a general-purpose\ncomputing machine: the forerunner of all modern computers.\nAt the time, only a handful people in the world could assess\nTuring’s paper. One of them, Alonzo Church, was based at the Institute\nof Advanced Mathematics in the USA on the Princeton University\ncampus, next door to the Institute for Advanced Study that housed\nEinstein. Turing travelled to America in 1937 and completed his doctoral\nthesis at Princeton. He might have stayed, but Europe was heating up\nand war seemed inevitable, so Turing returned to England to take up\na part-time job in the government code-breaking branch. Here he was\nable to indulge his passion for hands-on engineering, experimenting\nwith the newly invented valve technologies. When war finally broke out\nTuring was ordered to report to Bletchley Park, just north of London.\nThis was to be the home of the top-secret British code-breaking group\ntasked with cracking Enigma. Turing’s first task was to debrief the\nPolish mathematicians and see what they had discovered. The Polish\nmathematicians had seen there were flaws in Enigma that made it repeat\nitself. They had made a copy of the machine to test different coding\nconfigurations and had been routinely cracking Enigma for 6 years,\nbut the Germans had been getting smarter and it was taking longer and\nlonger to crack the codes. Turing realized he could apply the Polish ideas\nin a more general way and break the codes on an industrial scale. He was\ninstalled at Bletchley Park to lead the project.\nInitially he was successful but as the war continued, Enigma\ndeveloped subtleties making it harder to break. At one point, it was\ntaking a whole month to break a single day’s messages. Turing realized\nthe only solution was to use computer technology to fully automate the\ndecryption. He built a computing machine that could simulate thousands\nof Enigma machines and try out all the possible settings in a short space\nof time. The machine acquired the nickname ‘a bombe’, perhaps because\nof the ominous ticking sound it made as it calculated (or maybe as a\nreference to the smaller Polish machines).\nTuring’s Machine\n213\nThanks to Turing’s insight into coding schemes and the machines\nhe designed, the British were soon able to read almost every coded\nmessage the Germans sent during the war, giving the Allies an enormous\nadvantage. The D-Day invasion involved convincing Hitler that the Allies\nhad a huge army of nearly 400,000 men, massed around Dover preparing\nan attack on Calais head on, with a second army in Scotland poised to\nattack Norway. In truth, they had only 150,000 men planning an assault\non the Normandy Beaches in the South. Just before the landings messages\nwere decoded showing Hitler had fallen for the Allied subterfuge. Even\nas the Normandy landings began, Hitler still thought this a bluff and\nkept his 28 divisions at Calais waiting for the imagined attack. Without\nthis intelligence advantage, the Allies would have needed a much larger\ninvasion force, and Churchill believed Turing’s work shortened the war\nby as much as two years.\nThe cracking of Enigma remained a secret after the war and\nTuring’s story remained untold for many years. When Churchill wrote\nhis history, The Second World War, a massive work in six volumes, all\nsorts of sensitive information featured, but Turing’s work was omitted.\nOne sentence hints that Churchill might write something about it in the\nfuture, but he never did. Churchill considered the work at Bletchley Park\nso sensitive he had it put in the highest classification – extending the\n30-year secrecy rule. We must presume the decoding schemes were still\nbeing deployed during the Cold War. The papers were finally released in\n2010.\nIn one of those sad turns in history Turing was found guilty of gross\nindecency for homosexuality in 1954, a criminal act at the time, and was\nprescribed hormone treatment. This affected his mental state and he took\nhis life by eating an apple laced with cyanide. He was eventually honored\nposthumously as a war hero and one of the most significant thinkers of\nthe 20 th Century. A Turing Award is the equivalent of the Nobel Prize for\nComputing. He was given a royal pardon in 2013.\nTo see how Turing came up with the idea for the Turing machine\nand solved the decision problem, we need to get a feel for theoretical\nmathematics. That might sound a little heavy going but don’t worry, I will\nuse a simple piece of mathematics to explain, one we have all played with\nas children, secret codes.\n214 Are the Androids Dreaming Yet?\nCodes\nEveryone has played with some sort of\nsecret code as a child – the Aggy Waggy\ngame, passing notes written in invisible\nink made from lemon juice, or perhaps\na simple cypher. If I want to send you a\nsecret message, I can use a substitution\ncode. Let’s see how good a code breaker\nyou are. Can you decode this?\nGdkkn Qdzcdq\nIt’s really easy. You might guess the\nEnigma Machine\nmessage from the pattern of letters and\nyour knowledge of my writing style. There are a couple of interesting\npatterns to note: the 3 rd and 4 th letter of the first word are the same and\nthe first and last letter of the second word are the same. As a test I gave\nthis code to my wife and my eight-year-old daughter to see how long it\ntook them to decode… Less than a minute for my wife – a linguist. We\nwill come back to my daughter shortly!\nRoman Emperors used this sort of simple code to secure their\nmessages, but modern codes have to be a great deal more sophisticated.\nLet us use a progressive cipher where we vary the substitution using a\nsecret word. Take the name of my dog and write it down repeatedly next\nto the letters of the message you want to keep secret. Now translate all\nthe letters in the message and the code into numbers ‘a’ = 1, ‘b’ = 2 and\nso on. Then add the letters of my dog’s name to the letters of the message\none at a time. If I get to 26 (‘z’) just wrap around to ‘a’ and carry on. This\nis called modulo arithmetic. This coding scheme will translate ‘l’ to ‘a’ the\nfirst time but ‘l’ to ‘c’ the second making it much harder for a linguist to\nsee any pattern.\nhello reader can you read this code\ngeorgegeorgegeorgegeorgegeorgegeorge\nGives\nojacveyjpvlwghpegcvzoilfkehzpxghcvle\n\nTuring’s Machine\n215\nThe advantage of this cipher is that I can easily remember the name\nGeorge. I don’t need to write it down. And the circular application makes\nthe message sufficiently obscure you can’t easily work it out…\nIs this, therefore, a good code?\nNo.\nThis cipher is easy to break. Once you have guessed that I have\napplied a repeated short code word, you can write out ALL the possibilities\nand decrypt my message! This may be tedious, but if you are fighting a\nwar and your life depends on it, you can employ a thousand people to\nwrite them all out. The British government employed 10,000 people at\nBletchley Park, many of them doing exactly this. You might think that\napplying ALL the possibilities is too time consuming in practice but\nthere are many shortcuts. If I suspect the message contains the name\nof a German town all I need do is try keys until I find a German town\nsomewhere in the message then work my way outwards from there. Or\nperhaps I suspect the key is something easy to remember like the name\nof the Commandant’s dog. I can try ALL German dog names until I get\nlucky. If I’ve 10,000 people working for me this is easy.\nThe Enigma machine and the coding process set up to operate it\nwas designed to remove these loopholes. For a start, the keys were all\nrandom numbers taken from a code book – no dog names allowed – and\nthe machine took the idea of a simple progressive cipher and made it\nmuch more complex.\nImagine I took my GeorgeGeorgeGeorge pattern but then every\n3 rd character added one, every 14 th character subtracted 15 and every\n40 th character added the 3 rd letter of the First Mate’s mother’s maiden\nname. Now this would be a VERY hard code to break. I would need a\nmachine to code messages because if I tried to do it by hand I would\nmake so many mistakes that the messages I send would be unintelligible.\nThe Enigma machine made these coding schemes a practical possibility.\nBut, although Enigma is hard to break it is not impossible with enough\ncomputing power. Is there any code that is impossible to break?\nAn Unbreakable code\nIs there a way of coding a message so you can never break it?\nThe answer is there are two ways to code a message so it is\nPERFECTLY safe. The first is to use a one-time pad and the second is\nquantum cryptography.\n216 Are the Androids Dreaming Yet?\nOne perfect way to encode a message is to use a one-time pad. On\na sheet of paper I write a completely random set of numbers or letters\n– since we are going to translate numbers to letters it does not matter\nwhich. I make a copy and give it to a person I later want to send a coded\nmessage. Because I will only use these two paired sheets once it helps to\nmake a few of them – a pad in fact. By convention, we refer to a single\nsheet or a whole book as a one-time pad code. Here is the one-time pad I\ncreated earlier. It is just a random sequence of letters and spaces.\nkaleygnqaloiuebldlan dlkawoqyevbax gmlsosuebal\nTo code a message, I substitute numbers for letters as with the\nprogressive cypher earlier again using modulo arithmetic to wrap around\nif I reach the letter ‘z’. I have applied my one-time pad to the hello reader\nmessage below to get ‘sfacngfvbpta’.\nhello reader\nsfacngfvbpta\nThis code is unbreakable – almost! Notice there are very few clues\nfor anyone wanting to decode it without holding a copy of the pad. Spaces\ndo not necessarily indicate breaks between words, and letter patterns are\nabsent. It has only one flaw. The total number of characters and spaces\ncould have some meaning. This is a problem because if I routinely\ncommunicated bombing targets and my message was “Bomb Bath”. You\ncould figure out the sender was not going to bomb Bristol if the message\nwere shorter than 11 letters and spaces. To avoid this problem, messages\nare extended with nonsense at beginning and end to make sure no\ninformation can be gleaned from the length. The convention is to code\nmessages to the full length of the pad. You must never reuse a pad. Each\ntime you code a message, rip off that page rather like a calendar. Destroy\nit and use the next page for the next message. At the other end, the\nrecipient uses his copy of the pad to run the process in reverse. Decode\nthe message by swapping each letter according to the modulo method,\nrip the page from the pad, and burn it. Because each key is only used\nonce you can’t use any sort of statistical method to work out the message,\nmaking the one-time pad perfectly secure. Claude Shannon proved this\nin 1945 while working for Bell Corporation but, due to wartime secrecy,\nhis proof was not published until 1948.\nTuring’s Machine\n217\nThe Perfect Code\nThe proof that a one-time pad is perfectly secret is straightforward.\nImagine I take a coin and flip it 1000 times. I’ll write down some of the\nresults as follows:\nHHTHHHTTHTTTHTTTTTHTH…\nI give you a copy of my results and keep one for myself. Now we\neach have the same random set of Heads and Tails recorded on a piece\nof paper. I can convert any message from letters to binary numbers: ‘a’\n= 00000001, ‘b’ = 00000010, ‘c’ = 00000011 and so on. If you are not\nfamiliar with binary just assume I have a code where we only ever use\ncombinations of 0s or 1s. To encrypt the message we flip each bit – 0 goes\nto 1 or 1 goes to 0 – using my random list of heads and tails according\nto the following rule: If I have a head flip the bit, otherwise leave it the\nsame. I now have a randomized message, and it really is truly random. To\nconvince yourself, imagine answering the question, do you like coffee or\ntea? Think of your answer and flip a coin. If the coin lands heads change\nyour answer otherwise leave it the same. Now write your answer down.\nTry it out a few times. Do you see you end up with a totally random set\nof decisions – tea, coffee, coffee, tea, tea, tea. If you don’t record the coin\ntoss there is no way to determine your true answer.\nSimilarly, the message I encoded above now looks like a completely\nrandom stream of 1s and 0s and the only person who can decode it is the\nparty with the other record of the coin tosses. Apply this to the message\nand, as if by magic, the message reappears. Any other random sequence\nwill yield gibberish. It has to be the SAME random sequence I used in\nthe first place.\nMathematically, the proof involves working out that the probability\nof getting the right answer by applying a random sequence is 1 in 2 n and\nthe probability I could guess the answer is also 1 in 2 n ? The same! So the\nchance of decrypting the message knowing the encryption method is the\nsame as simply guessing the message and getting lucky. Therefore, the\nmessage is perfectly encrypted.\nQuantum Cryptography\nIt turns out there is one other perfect encryption method that involves\nthinking about the nature of secrets. Normally we consider the primary\nproblem with sending a secret message is coding it so that it can’t be read\n218 Are the Androids Dreaming Yet?\nby anyone but the intended recipient. However, wouldn’t it be equally\nvaluable to know if someone other than the recipient had intercepted\nand read the message? This is the trick quantum cryptography gives us.\nTaking a measurement with a quantum device disturbs the system\nso measurements can be taken only once with the same results. By the\nsame logic, I could send you a message and if someone else has read it in\nthe meantime, you will know. I could arrange to meet with you in Berlin\nand if you detect the message has been intercepted, you could simply not\nshow up.\nI could use this same technique to send you a one-time pad. If you\nreceive it without it being overheard, I could then safely send you an\nencrypted message. In 2007, this technique was used to transmit the\nresults of a Swiss election from the polling booths to the central counting\ncenter.\nEnigma\nWorld War II accelerated the evolution of encryption from simple\nsubstitutions a human could perform to complex ciphers only a machine\ncould calculate. You might wonder why everyone does not use a onetime-pad\nsince it is a perfect code. The problem is distributing and\nmaintaining the pads while keeping them secret. My daughter cracked\nmy earlier code because she knows my laptop password, broke in, and\nread the answer. That’s the problem with codes – security. The pads\ncould be sent out in sealed envelopes but it would be easy to intercept an\nenvelope, copy the pad and reseal it. You would then have a perfect and\nundetectable way to break the code. Also, if I were an Admiral wanting\nto communicate with my fleet of submarines I would need a huge pad\n– one page for every message I want to send – and either a pad for each\nsubmarine or one pad for all submarines. If I use only one pad, then I\ncannot talk to a submarine privately, and if any pad were lost all security\nwould be breached. One-time-pads were used by both sides during\nWorld War Two, and often printed on nitrocellulose – a chemical similar\nto the explosive nitroglycerine. This allowed users to burn the codebooks\nquickly if an enemy threatened to capture them.\nBoth the Americans and British captured Enigma machines and\ncodebooks during the war. A Navy Enigma machine was a sought-after\nprize, as it was more complex than the Army version, with extra dials\nand plug settings. To crack the more sophisticated codes Bletchley Park\nTuring’s Machine\n219\nneeded to get hold of Enigma machines, ideally without the Germans’\nknowledge. The film U-571 merges two such capture stories into one,\ntaking a few dramatic liberties along the way, but it’s well worth watching.\nEven with a captured machine, the codes were hard to break. You\nneeded a starting point – a crib to give you a clue what the machine\nsettings were. Helpfully, the German Army often began their messages\nwith a weather report. Everyone knows the German word for weather –\n‘Wetter’. Decode the first 20 letters of a message until you found ‘Wetter’\nand the message is unlocked. The German Navy, however, was less chatty\nand avoided obvious words in their messages. One way the Allies could\nfind a crib was to blow something up. They would sail to some point in\nthe Atlantic, fill an old boat with oil drums, and set it alight. The German\nNavy would get wind of this and go to investigate. The first thing they\nwould do is to radio a message back to base with the coordinates of\nthe wreckage, which, of course, the British already knew. This gave the\nBritish a crib, and once they were in, they could decode messages for\nseveral days in a row because the Enigma machines often cycled through\na repeating pattern.\nThroughout the War, the German military never suspected the\nBritish had cracked their codes and thought they must have traitors giving\naway their secrets. The Enigma machine was an elegant compromise\nbetween a truly unbreakable code and a simple cipher. Unfortunately for\nthe Germans, Turing was on the side of the Allies.\nIn the 1930s almost all mathematics, accounting, and code-breaking\nwere performed by humans using pencil and paper. It was the science\nbehind this process Turing sought to understand. We’ll take a step back\nin time again to 1935 and Turing’s discovery of a solution to the Decision\nProblem – the Entscheidungsproblem.\nLego Turing Machine\n“Machines take me by surprise\nwith great frequency.”\nAlan Turing\nThe Machine\nTuring probably learned of the Entscheidungsproblem in a lecture\ngiven at Cambridge University by Max Newman. Newman\ndescribed a new proof by Gödel showing mathematics was\nincomplete. The proof solved the completeness and consistency problems\nby turning mathematical statements into numbers and showing you\ncould generate a logical paradox if you tried to argue for completeness\nand consistency at the same time. Thus, of the three original Hilbert\nproblems, completeness, consistency and decidability, only decidability\nremained unanswered.\nTuring spent all of 1935 and much of 1936 thinking about\nthis question: Is mathematics intuitive, or could a machine decide\nmathematical questions automatically? Eventually, cycling through\nthe Cambridge countryside one day, he stopped to rest in a field near\nGrantchester and in a flash of inspiration envisioned his mathematical\nmachine. The machine was entirely imaginary but made as if from\nmechanical parts common in the 1930s.\nThe idea was to reduce the process of computing with pen and paper\nto its most basic level. Turing hit upon the idea of using a long ribbon of\npaper tape similar to the ones used in telegraph machines. A paper tape\nis simpler than rectangular paper as it can be handled mathematically as\na single sequence of numbers – we don’t have to worry about turning the\npage or working in two dimensions. If you are worried that a tape is less\npowerful than a sheet of paper remember Cantor’s theorem: an infinite\nplane is the same as an infinite line. The use of a tape massively simplified\nthe mathematics, and subsequently many early computers used tapes, as\nthey were easy to handle in practice as well as in theory.\n222 Are the Androids Dreaming Yet?\nThe eye, hand and pencil of a human mathematician was modeled\nas the read-write head of a teletype. It allowed the machine to read\ninput from the tape and write information back so as to keeping track of\nintermediate calculations or provide the final output. The operation of\nthe machine was straightforward. At each moment in time the machine\ncould read a symbol on the tape, move the tape forward or backwards,\nand write or erase a symbol. That’s all he needed to model a human doing\nsomething like long multiplication. Turing argued his model was exactly\nanalogous to a human performing a computation.\nTuring’s imaginary machine was now able to perform computations\njust like a human. You could write down the rules for a given procedure\nand the machine could, for example, do long multiplication. At each step\nof the calculation, the computer would examine the state machine, look\nup the state in the instruction book and put the machine into its new\nstate. If you recall Searle’s Chinese Room, this is the same process the\nman in the room followed: get a symbol, look it up in a book, and reply\nwith the corresponding symbol.\nUniversal Turing Machine\nWe have missed one important step from our explanation of the modern\ncomputer: the ability to run programs. Nowadays, we take for granted\nyou can download a program from the Internet or buy one from a shop.\nIn the 1930s adapting a single machine to multiple purposes was a radical\nidea. Machines were built to do one thing, and one thing only, and there\nwas no concept of a general-purpose machine. Nowadays this is hard to\ncomprehend, but there is a similar revolution going on in manufacturing\ntoday with the widespread adoption of 3D printing. Today most factories\nuse tools – lathes, drills and saws – to fashion objects. Each machine does\na specific job and is not ‘general purpose’. But innovative new machines\ncan now be purchased relatively inexpensively called 3D fabricators,\nwhich print entire objects. The same happened for electronic logic in\nTuring’s time.\nBefore computers, logical tasks were performed by banks of relays.\nHow these banks work can be illustrated by the workings of an oldfashioned\nelevator. If you pressed a button to call an elevator, you closed\na switch coupled to a relay in the basement sending power to the car.\nAnother switch was tripped automatically when the elevator reached the\ndesired floor. All the functioning of the elevator system was fixed. Once\nyou pressed a button to go up you could not change your mind and press\nTuring’s Machine\n223\nOld Fashioned Relay Mechanism\nthe button to go down. That logic did not exist in the relay banks. If you\nwanted to improve the logic of the elevator you would need to rip out all\nthe relays and rewire everything from scratch.\nTuring’s first imaginary machine was set up in the same way. It\nhad a fixed set of hard-wired logic, a rule book. In order to perform\ndifferent tasks – say addition or multiplication you had to use a different\nrule book. His revolutionary idea was to write a rule book that told\nthe machine to read a soft-wired set of instructions from the tape and\nexecute those instead. He called this a Universal machine since it could\nperform any procedure written on the tape. Today we call this software.\nIt is fair to say Turing was not the first to use this idea. Charles Babbage’s\nanalytical engine could read instructions from cards and execute\ndifferent procedures, but Turing thought through all the ramifications\nof the idea and made it general purpose, giving us the modern science\nof computing. It is easy to build a real Turing machine, but by today’s\nstandards it is a little clumsy; a team in Denmark has built one using\nLego. You can see a link on my website.\nVery soon after Turing’s paper was published, a number of people\nproposed better practical implementations. In 1943, John von Neumann\nof Princeton University created the architecture for ENIAC, the first\nstored program computer, developed for the United States Army’s Ballistic\n224 Are the Androids Dreaming Yet?\n3D Printing Machine\nResearch Laboratory. The laptop I am writing on uses the von Neumann\narchitecture, and most modern computers evolved from it. By contrast,\nmobile phones are descended from the Harvard architecture developed\nby IBM and first supplied to Harvard University in 1944, hence its name.\nThe distinction in architectures has blurred over the years. The world\nsupports two main computer chip technologies, one built for desktop\nand laptop computers, designed by Intel in Santa Clara, California, and\nthe other, designed for mobile devices by ARM, in Cambridge, England.\nAll these computers can, in principle, run any piece of software.\nPrograms\nSoftware is just a series of numbers. When you click an icon on your\ndesktop, the computer reads the number and interprets it as a series\nof instructions. There is a decoder inside the computer that knows the\nnumber ‘1’ means add the next two digits and the number 5493 means\ndisplay them on screen and so on. On my computer the operating system,\nApple’s OSX, takes the number, decodes it and passes it to the CPU for\nTuring’s Machine\n225\nexecution. You might ask what runs the operating system and that is a\nsmaller program called the BIOS. What runs BIOS? An even smaller\nprogram called the Bootstrap. Once all this is up and running you have a\nworking computer, which can run any program you throw at it.\nThe problem with programs is they tend to crash – usually at\nthe most inconvenient times. It is often not clear whether a program\nhas truly crashed. It might be stuck in an infinite loop, or it could be\ncalculating the answer to a complex question, such as the answer to life,\nthe Universe, and everything. How would we know? If only I had waited\na little longer before rebooting, the program would have run to its end\nand given me the answer to Douglas Adams’ question.\nIt would be very useful, and save a great deal of time, if I had a way\nof telling whether a program will ever stop. An elegant solution would be\nto have a second program called ‘Halt’, which would test the program and\noutput ‘will halt’ or ‘will crash’ as appropriate. It turns out this program\nwould be more than just useful. It could be used as an oracle, capable of\nanswering almost any question imaginable.\nI could, for example, write a program that says: for every index in\nFermat’s puzzle try every number and halt if you find a solution greater\nthan 2. Now if I run my halt program on this program and it states ‘will\ncrash’, I will have solved Fermat’s Last Theorem! Do you see why?\nIf we give ‘Halt’ an input: a program we are interested in, along with\nsome data, it will tell us if the program finds an answer. If I am trying to\nsolve Fermat’s Last Theorem, we will ask it to try every possible index for\nthe equation 3 x +4 x =5 x and halt when it finds a true result greater than 2.\nIf the halt program says yes and halts, you can trace through the program\nand work out how it did it. The theory would be proved. If the program\nsays no, the theory is disproved. This gives us a way to discover proofs of\nmany mathematical theorems.\nI could try almost any puzzle using a program with this form. All I\nneed do is put a problem in the following decision format: try all possible\noptions, and then stop and ring a bell if a solution is found. The Halt\nprogram would then give the result leading to untold riches, winning all\nthe remaining Clay Mathematics prizes at the very least and earning me\n$6m.\nDoes such a magical program exist? The answer, sadly, is no. There\nis no Halt program and the final part of Turing’s paper proved there can\nnever be.\n226 Are the Androids Dreaming Yet?\nThe Proof\nLet’s write a list of all the possible programs my laptop could ever run. A\ncomprehensive way to do this is to start at one and try every number.As\nI count up I am simply generating numbers, for example, 5,433,232, then\nturning each number into a program file and running it. For a bit of fun,\nI created a couple and tried them out on my laptop. They did nothing, so\nit was not very edifying. Most numbers are just junk because programs\nhave to be in the right format for the computer you are working on. It’s\njust like words. If you randomly take a handful of scrabble tiles out of a\nbag, most of the time you will have nonsense, but every now and they\nyou will have an actual word. Be careful with this; you could accidentally\nwrite, “delete every item on my hard disk.” Of course, the probability is\nastronomically low, but Murphy’s Law says it will happen, so back up\nyour data!\nAs you count up, you will generate every possible program along the\nway. A mathematician would say programs are recursively enumerable.\nThe word recursive means there is an algorithm and enumerable means\nto count. Therefore, there is a counting algorithm that would run every\nimaginable program. Here is a list of them, or at least a some of the\nhighlights:\n0 (probably doesn’t run)\n1 (ditto)\n00 (ditto)\n01 (ditto)\n011001001001000100 (makes the computer beep once)\n… (from here on I’ll give the program names since the numbers are\ntoo large to print)\nDoes Nothing (there are many of these)\nIs Gibberish (there are an infinite number of these)\nJunk (an infinite number of these)\nPrint Something (again an infinite number of these)\nMore Gibberish\nExcel\nWord\nPowerPoint\nMathematica...\nFermat’s Last Theorem enumerator (runs for ever)\nA nonworking version of the Halting Program\nA nonworking version of the Crashing Program\nReally big programs that don’t fit on my hard drive\nTuring’s Machine\n227\nand so on.\nYou can see that every program imaginable is generated in our\nlist. If you are wondering which version of Word or Excel, the answer\nis every version and every bug ridden unreleased version as well. We\nare enumerating every program that could ever be run in the known\nuniverse!\nPerhaps you can see a problem looming. I can pose any mathematical\npuzzle in a clever way so that a program only stops if there is a solution.\nI am about to list every possible program that could ever be created. If\nhalt exists this will automatically prove every mathematical theorem\nimaginable.\nLet us see if this is so.\nFor our thought experiment, we will assume every program takes\nan input. Historical convention in computing means this is generally the\ncase. If you type a program into the command line of a computer with\nsome words listed afterwards, the computer will usually run the program\nwith the words as input. For example, if you type, “Print ‘Hello World’”,\nmost computers will print ‘Hello World’.\nWe now imagine there is a Halt program that can run on an infinity\nof inputs. Will it work for every input? We are looking for a paradox\ncaused by the existence of the Halt program. If Halt causes a paradox\nthen Halt cannot exist.\nHere goes...\nIf there is a Halt program, we can write a Crash program. That’s a\nprogram that goes into an infinite loop if it detects a program will halt.\nNow what happens when we feed Crash into itself? Does Crash halt if it\nruns with the input Crash?\nThis creates a paradox; there is no solution which makes sense. It’s\nsimilar to the Barber Paradox of earlier. Since a paradox is created there\nmust be a fault in our original theory. The error is the existence of Crash.\nSince Crash cannot exist and it was created as the logical opposite of\nHalt, Halt cannot exist either. QED. There is no general program that will\ntell if another program will halt because such a program could not run\nwith the negative of itself as input.\nThis places a limit on the power of computers to automatically\nsolve problems. There is certainly no general purpose algorithm which\nwill solve every problem. Slightly more subtly there is no general\npurpose program that is guaranteed to solve one arbitrary problem.\n228 Are the Androids Dreaming Yet?\nIf there were, you could just write a program to sequentially present\nevery problem to the arbitrary problem solver and you would have\nsolved everything.\nThis presents us with a puzzle. A huge software industry has\ngrown up based on Turing’s ideas, employing tens of millions of people\nworldwide. This industry regularly solves all manner of problems.\nThe proof from Turing’s original 1936 paper suggests there should be\nquite strict limits on the power of computers. In the next chapter, we\nwill examine this industry and take a look at Turing’s theorem from a\nmodern view point. The chapter can be read as a stand alone article but\nwas originally written as an integral part of this book.\nChapter 11\nSOFTWARE\nFred Brooks\nMedieval Block Print from ‘No Silver Bullet’\n“The bearing of a child takes nine\nmonths, no matter how many\nwomen are assigned.”\nFred Brooks\n“Adding manpower to a late\nsoftware project makes it later.”\nBrooks’ Law\nIn No Silver Bullet – Essence and Accidents of Software Engineering,\nFred Brooks explains why writing software is hard, and why machines\nare not going to do it for us anytime soon. The original article\nappeared in the proceedings of the Tenth World Software Conference.\nIt was subsequently expanded into the, now famous, book, The Mythical\nMan Month.\nBrooks believed solving real world problems involves understanding\nthe essential complexity of life. ‘Accidental Complexity’ – the simple type\n– is the time-consuming part of writing software, for example, listing all\n220 countries of the world in a website, or making sure all the buttons in\nan interface line up correctly. These tasks are tedious – you have to look\nup all the countries in Wikipedia and make decisions, such as whether\nthe United Kingdom will be denoted ‘UK’ or ‘GB’. They don’t need any\nreal ingenuity. ‘Essential Complexity’ is altogether different. It involves\nunderstanding the world and setting out the rules in meticulous detail.\nBrooks argued essential complexity is not susceptible to being sped up\nby machine processes. Navigating these architectural decisions cannot\nbe automated. He gives us an analogy by comparing writing software to\nbuilding a house.\nWhen you build a house, an architect designs it, an engineer makes\nthe calculations to ensure it is safe, and a construction firm builds it. The\nconstruction process dominates the cost and time. In software projects,\nan engineer writes a program that precisely defines the design and the\nconstruction and calculation is done by a compiler – software that\ntakes the design and makes it machine-readable. Compilers operate in\na fraction of a second. Making software is, therefore, dominated by the\ndesign time, and design is all about capturing the essential complexity\nof a task.\nThis chapter will try to show where essential complexity comes\nfrom, why computers can’t tackle this sort of complexity and, therefore,\nwhy they can’t write software. Good news for programmers as this means\njob security!\nFor a more thorough treatment of the mathematics read my paper\nThe Free Will Universe at www.jamestagg.com/freewillpaper.\nJames Tagg’s Home Page\n“Computers are stupid. They can\nonly give you answers.”\nPablo Picasso\n“Software is like sex: it’s better\nwhen it’s free.”\nLinus Torvalds\nSilver Bullets\nCan’t be Fired\nHuman brains are wonderfully creative things. We can compose\nmusic, play golf, write novels, and turn our hands to all manner\nof problems. Many people use their brains to write software. In\nour modern-day lives we use software all the time: when we access the\nweb, type on a word processor or play a computer game. Software also\ninhabits many apparently dumb devices. Modern cars contain dozens\nof computers quietly working away; providing entertainment and\nnavigation, controlling the engine, and helping the car brake safely. In\nmy living room I count over a hundred computers. Many are tiny, like\nthe one in my TV remote control, while others are hidden as parts of\nlarger machines. The laptop on which I write has over twenty computers\ninside it, besides the main Intel processor.\nOne thing all these computers have in common is that a human\nbeing sat for many hours writing their software. Software is formal logic\nwritten in something resembling English.\nIf I go to my ATM and try to withdraw cash, a programmer will\nhave written out the logic for the transaction as a set of rules.\nWhen I put my bankcard in the slot, and type in my PIN, a line of\nsoftware will ask: If the bank balance of ‘James Tagg’ is less than twenty\ndollars and I have pressed ‘withdraw’ for an amount in excess of twenty\ndollars, then display, “We are sorry we cannot process the transaction at\nthis time.” and return the card. There seems to be an unwritten rule that\nthe things a computer says should be accurate but unhelpful!\n234 Are the Androids Dreaming Yet?\nAlice, Ted and Software Specification\nIt would have been much more helpful if the computer had said,\n“You do not have enough balance in your account.” And, it would have\nbeen more helpful still if it had asked whether I needed a temporary\noverdraft. However, such a feature needs many more lines of software\nand this is time-consuming to write.\nSoftware takes time and is expensive, because it has to be written\nin a general-purpose way. Any name could substitute for James Tagg,\nand any amount could be used. After all, it would be useless if an ATM\nmachine could only give out $20 to one person. The generalization of\nsoftware makes use of variables instead of fixed values and this renders\nit hard to understand. Wherever we meet an idea that needs to be\ngeneralized, a letter must be used instead of a fixed value. Computer\nprograms tend to look like this: if ‘a’ wants to do ‘b’ with ‘c’ then allow\nit only if ‘d’ is greater than ‘c’. The software programmer has to keep\ntrack of all the possible values that could be inserted into each of the\nvariables and make sure each and every combination would make sense.\nMy ATM scenario gets complex quickly. It needs to be able to answer a\nrange of questions for all the bank’s customers, deal with any amount of\nSoftware\n235\nmoney and handle security when communicating with foreign banks is\nnecessary. A human being must write lines of code for all the rules and\nevery exception, making provision for any gibberish that might be typed\nin by the customer.\nMany people ask, “Wouldn’t it be great if my computer could write\nsoftware for me? Humans could sit back and put their feet up.” While\nmost people don’t actually believe this could happen, they will often ask\nwhy we can’t specify software exactly and use unskilled people to write\nit. Both proposals fundamentally misunderstand the nature of writing\nsoftware.\nWhat do Programmers Do?\nA human software programmer can write up to 1000 lines of code per\nday. At the beginning of a project, when the work is unconstrained,\nprogrammers write fast. Things slow down once programmers encounter\nthe enemy: the real world. By the time the code is complete and selling\nin shops, the productivity of a programmer can be as low as one line\nof code per day. This is staggeringly low and luckily only applies to big\n236 Are the Androids Dreaming Yet?\ncommercial software, equating to about 10 words per day. A good typist\ntypes at 80 words per minute and most programmers are reasonable\ntypists. So software writers in a big project spend only a minute or so\nper day in the act of writing. The rest is taken up by meetings, process\ndiscussions, email, reporting and so on. In projects that avoid much\nof this administrative overhead, good software programmers reach a\nlong-run average of about 225 lines per day. This has been the level of\nproductivity on the products I have developed in the past. These projects\nwere lucky. They had a single team on the task from beginning to end and,\nin general, the projects took few wrong turns. Still these programmers\nwere spending only 10-20 minutes of each day on actual programming.\nWhat were they doing the rest of the time?\nIn the early days of programming you might have a great idea,\nbut the process of turning this idea into software was immensely longwinded.\nI learned to program at Manchester University in the 1980s. The\nenormous machines in the basement of the computer building provided\nheat for both our building and the mathematics tower next door. We were\nnot permitted to play with these basement monsters but were ‘privileged’\nto submit instructions to a mini computer in the undergraduate section\n– a PDP11-34.\nFor those of you not acquainted with computers I can tell you the\nprocess of writing software in the 1980s was immensely tedious. To\nadd two numbers and display them on a screen took a month of lab\ntime, using detailed instructions written in machine code. Everything\nwas manual, including writing your code out in pencil on special paper\nwith little numbered squares and then giving it to someone to type in\novernight! You would return the next day to discover whether you had a\nusable program or a something riddled with errors. If you found an error,\nit would require editing. This was nothing like using a modern word\nprocessor. The online editors of the day were the ultimate in annoying\nsoftware. If you misspelled a word, you would need to count up the letters\nand spaces manually on a printout and enter a command – replace letter\n27 of line 40 with the character ‘r’. Each and every typo would take five\nminutes to correct. I managed to finish the simple program required for\ncourse credit – I think it displayed an eight-digit decimal number – and\nran for the hills. In my second year I bought a PC and decamped to\nthe physics department next door where I remained for the rest of my\nundergraduate life.\nThe PC revolution provided programmers with a new and intuitive\nsoftware creation environment where almost all the tedium was removed.\nA wealth of tools for creating software was pioneered by Bill Gates of\nSoftware\n237\nMicrosoft and Philip Kahn of Borland, along with intuitive applications\nsuch as the spreadsheet invented by Dan Bricklin and Bob Frankston and\nmade popular by Lotus Corporation. Today all computers have elegant\nWYSIWYG, ‘What You See Is What You Get’ interfaces, where you drag\nand drop elements into place on the screen. Over the last 25 years writing\nsoftware has sped up and stopped being tedious – becoming almost a joy!\nIn No Silver Bullet, Brooks explains that writing software can’t be\naccelerated any further because all the tedious mechanical tasks have\nalready been removed. Remember his analogy: Writing software is like\nbuilding a house, but with some important differences. With a house,\nan architect handles the design and then turns over construction to\na building company. Construction takes an appreciable time, more\ntime than the design and quite a bit more effort. But in software the\nconstruction is totally automated. When we complete the design for a\npiece of software we press compile on the computer and the software\nis built and tested automatically in a matter of seconds. Speeding this\nprocess up any further would make only a tiny improvement in the\noverall software creation time, since the process is already 99% design\nand 1% building. For the most part, the creative process of writing\nsoftware cannot be improved through mechanical means.\nThis is not always the case. I recently upgraded the machines for\nsome developers I work with. We added solid state hard drives. Compiling\na program now takes only 10 seconds, compared with 6 minutes before.\nBecause programmers nowadays tend to compile their programs very\nregularly we estimate this saves them as much as an hour a day. This is\nthe only real innovation I have seen in the build phase of software in the\nlast 5 years, and it’s arguably not an innovation at all. We just forgot to\nkeep on top of the build time and allowed it to get out of hand.\nYou might argue some counter examples. Modern software design\nsuites let you drag and drop things on the screen to make applications\nor build a website. Two hundred million people have managed to put\ntogether WordPress websites using this technique. These are mechanical\nprocedures for solving a programming task and seem to contradict my\nargument. They allow us to lay out graphics, press a button and turn the\ndesign into software. But they perform very simple tasks. The computer\nsimply notes the coordinates of each box on the screen and places those\nnumbers into a file. The process is entirely mechanical and could be\nperformed by a clerk with no programming knowledge following a set\nof rules. The computer just does it faster. I did the clever work; I had the\n238 Are the Androids Dreaming Yet?\nidea for the software, I came up with the idea for the interface, I decided\nwhere to place the boxes, and I chose all the colors, fonts and graphics. I\ndid all the creative bits!\nSo, now we know what programmers do all day. They create!\nOrigins of Software\nAlan Turing first described the modern day computer in a paper presented\nto the London Mathematical Society in 1936. He was not trying to invent\nthe computer. That was a by-product. He was trying to solve a puzzle that\nhad been troubling mathematicians for 30 years: The Decision Problem.\nDavid Hilbert set out the challenge during a public lecture to the\nFrench Academy of Science in 1901, marking the turn of the century.\nRather than give a boring lecture extolling the virtues of scientists, he\ndecided to give his audience a list of all the puzzles mathematicians were\nstumped on.\nRather like the XPRIZE of today, he presented the problems as\na series of challenges. Sadly for the mathematicians of his time, there\nwere no million dollar prizes on offer, just a moment of fame and the\nadulation of their colleagues. Each challenge was given a number. The\nlist included many famous puzzles; the Riemann Hypothesis, the puzzle\nof Diophantine Equations and the Navier Stokes Hypothesis, to name\nonly three. A group of these questions were to coalesce into what we now\nknow as the Decision Problem.\nThe Decision Problem is very important to computer science\nbecause it asks whether an algorithm can be written to automatically\ndiscover other algorithms. Since all software is itself algorithmic you\ncould rephrase the question: Can software write software? This might\nseem esoteric. But, if you are a computer scientist, it is an important\nquestion. If we could solve all mathematical problems automatically\nwe would not need mathematicians anymore. And, since programs are\napplied mathematics, the same goes for computer programmers.\nBefore you breathe a sigh of relief because you are neither a\nmathematician nor a computer scientist, you should remember it is\npossible to describe all knowledge using numbers. That’s what your\niPhone does when it stores music. If everything can be represented by\nnumbers, then a fast-enough computer could use an algorithm to create\neverything! You really could set Douglas Adams’ Ultimate Question of\nLife the Universe and Everything before a computer and it would come\nup with the answer – presumably extrapolating the existence of rice\npudding and income tax along the way.\nSoftware\n239\nAlgorithms\nBack in the 1930s no mechanical system could perform a calculation\nwith any speed. People still used pencil and paper for most things; the\nnewly-invented mechanical cash registers were slow and could perform\nonly one calculation for each crank of the handle. If you wanted to\ncalculate something complex, you had to employ a computer: a person\nwho could do mental arithmetic enormously fast. Richard Feynman’s\nfirst job was computing for the Manhattan Project. The question was:\nCould a computer, either mechanical or human, blindly follow known\nrules to decide all mathematical questions? Hilbert’s 10 th Problem asked\nthis question of a particular type of mathematical expression – called a\nDiophantine equation.\nHilbert’s 10 th Problem\n“Given a Diophantine equation with any number of unknown\nquantities, devise a finite process to determine whether the\nequation is solvable in rational integers.”\nDavid Hilbert\nDiophantus lived in ancient Persia – now Iran. His son died young\nand Diophantus was so consumed by grief he retreated into mathematics.\nHe left us seven books of mathematical puzzles – some he devised himself\nand some of them taken from antiquity. The puzzles look deceptively\nsimple and are all based on equations using whole numbers. His most\nfamous puzzle is set in a poem which tells how old Diophantus was when\nhe died. Can you solve it?\n“Here lies Diophantus,’ the wonder behold. Through art algebraic,\nthe stone tells how old: ‘God gave him his boyhood one-sixth of\nhis life, One twelfth more as youth while whiskers grew rife; And\nthen yet one-seventh ere marriage begun; In five years there came\na bouncing new son. Alas, the dear child of master and sage, after\nattaining half the measure of his father’s age, life chill fate took him.\nAfter consoling his fate by the science of numbers for four years, he\nended his life.”\nDiophantine puzzles look straightforward. Hilbert asked if these\nproblems could be solved by a mechanical procedure, in modern terms,\nby an algorithm. To show you what is meant by this, allow me to take you\n240 Are the Androids Dreaming Yet?\nLong Multiplication\nback to your childhood. Do you recall being taught long multiplication\nat school? Take a look at the next illustration and it will all come flooding\nback. Once you learn the process of long multiplication you can follow\nthe rules and get the right answer for any similar problem every time. To\ndo this, you lay out the calculation in a particular format and apply the\nlogic. Multiply each number by a single digit of the other number and\nthen add the results together.\nDiophantine problems are a little more complex than long\nmultiplication and some of them are a bit abstruse. But there is one\nvery famous Diophantine problem we can all recite. “The square on the\nhypotenuse is equal to the sum of the squares of the other two sides.” The\nequation for a Pythagorean triangle.\nThe theorem applies to right-angled triangles and there are sixteen\nwhole number solutions, known as Pythagorean triples; three, four, five;\nis one example.\nSoftware\n241\nPurists may protest that Fermat’s Last Theorem isn’t strictly\nDiophantine because it refers to a variable exponent – the x to the n\npart. This is hair splitting. But, of course, the splitting of hairs is bread\nand butter to a mathematician. We will see later that Fermat’s Theorem\ncan be made Diophantine, but we are jumping ahead of ourselves a little.\nA question that taxed mathematicians for many centuries was\nwhether there are triples for higher powers, such as cubes. In other words,\nwould the cube of the hypotenuse be equal to the sum of the cubes of the\nother two sides for some set of numbers? After much work, it was proven\nno triple exists which can solve the cubic equation. But what happens if\nwe substitute higher indices?\nThe next shape to consider is the hypercube – a four-dimensional\ncube. That may stretch your visual imagination but the equation is simple,\n3 4 +4 4 ≠5 4 . Again the challenge is to find a whole number solution for:\nHypercube\n242 Are the Androids Dreaming Yet?\n“The hypercube of the hypotenuse is equal to the sum of the hypercubes\nof the other two sides.” A picture of the hypercube might help you\nvisualize things.\nIt’s quite difficult to get your head around this shape because it is\nhard to think in four dimensions. This seems strange because we have no\nproblem seeing in three dimensions on flat, two-dimensional paper – it’s\ncalled a picture, but four dimensions on flat paper appears to stump us.\nAgain there is no solution for a hypercube: no Pythagorean triple exists.\nFermat’s Last Theorem asked whether this inequality for the cube\nand the hypercube is true for all higher dimensions – for the hyperhypercube,\nthe hyper-hyper-hypercube and so on. Tantalizingly, he\nclaimed to have found a proof but wrote that it was too large to fit in\nthe margin of his book. It’s partly due to this arrogant annotation\nthat it became the most famous puzzle in mathematics, frustrating\nmathematicians for nearly 400 years.\nHilbert’s question back at the turn of the 20 th century was whether a\nmachine could find a proof of this conjecture by following a mechanical\nprocedure, similar to our long multiplication example above.\nThe puzzle was eventually solved in 1995 by Andrew Wiles, a mere\n358 years after Fermat claimed to have solved it. Wiles’ proof runs to\neighty pages of densely typed mathematical notation – considerably\nlarger than the margin in which Fermat claimed his proof did not quite\nfit! There is an excellent book by Simon Singh – Fermat’s Last Theorem –\nthat tells the whole story.\nWe now know for certain, thanks to Wiles, that the answer is ‘no’.\nThere are sixteen answers to the two-dimensional triangle puzzle but\nthere is none for any higher dimension all the way up to infinity. How\nmight a computer tackle this problem and find a proof?\nA computer could apply brute force and try many solutions; every\ncombination up to 100 million has already been tried and no exception\nfound. But, mathematicians are haunted by big mistakes of the past.\nThere were theories they imagined to be true until someone discovered\na counterexample. This sort of thing dogged prime number theorems.\nMathematicians don’t like to look foolish and are suspicious of\npractical answers, “Well, I’ve tried it and I can’t seem to find an exception.”\nThis sort of argument does not wash with them. That’s what engineers\nand physicists do. Mathematicians are better than that!\nMathematicians want definitive answers; “It is certain no solution\ncan exist”, and these sorts of answers require an understanding of the\nproblem to see why no solution could exist. That’s a very high bar. What\nwe need is a program that, rather than mechanically trying every possible\nSoftware\n243\ncombination, takes our problem and definitively says, “Yes, there is a\nsolution,” or, “No, there is not.” There are plenty of man-made proofs of\nthis nature. Pythagoras’s proof there are an infinite number of primes\nis an example. Pythagoras did not have to try every prime number. He\nsimply understood the nature of prime numbers and gave us a logical\nreason why it is so.\nMathematicians love a general solution. One way to solve Hilbert’s\n10 th Problem would be to find a single mechanical way to solve every\nproblem. If you could solve every possible problem, you could certainly\nsolve Hilbert’s 10 th Problem. It turns out there is a way to test whether\nevery problem has a mechanical solution – pose the Halting Question.\nThe Halting Question\nI should say for a little historical color that the Halting Problem was not\ncalled that by Turing. The name was coined much later, in the sixties, by\nMartin Davis. Turing knew the problem by the less catchy name of the\n“not crashing” problem, or as he preferred, “Being circle free”, meaning\nthe program did not get caught in an infinite loop.\nTo understand halting we should imagine a brute force program\nstepping through all the possible solutions to Fermat’s problem. If there\nis a solution this stepping program will eventually halt and answer ‘true’.\nIf there is not, the program will run forever. Can we predict a program\nwill not run forever? At first pass this is hard. We can’t watch it forever\nand say, “It never halted.” So is there a clever way to do this? An algorithm\nperhaps?\nThe Answer to the Ultimate Question\nThe answer is ‘No!’ In 1936, Alan Turing proved there is no generalpurpose\nmechanical way to tell whether a program is going to find an\nanswer at all, much less what the answer is. This means Hilbert’s Decision\nProblem has no solution; there is no general purpose algorithm which\nwill discover all mathematical theorems.\nTuring succeeded in proving this by turning the problem on its\nhead. He proved that a crash detection program is unable to see whether\nit will crash itself. Since you cannot tell whether a program will crash\n– and by this I mean go into an infinite loop – you cannot tell if it will\nhalt. He used the simple argument that since you can’t tell if the crashing\nprogram will halt, you have already proved you can’t predict if every\nprogram will halt.\n244 Are the Androids Dreaming Yet?\nImpossible Shape\nThat is Turing’s argument in a nutshell. But if that was too large a\nstep, let’s take the argument a little more slowly and prove it a couple of\ndifferent ways. First, we will use a proof by counterexample, known by\nmathematicians as an ‘indirect proof ’. These may tax your brain. If you\nwant a visual image to help with the idea of an indirect proof, take a look\nat the impossible shape. It is paradoxical, which means it does not exist.\nQED.\nThe Proofs\nThere are several ways to prove the non-existence of the Halting Program.\nI am going to present a few in the hope one of them will hit the mark and\nallow you to see why. The first proof uses a software flowchart. I have\nlaid this out on the assumption the program exists and then attempted\nto apply it to itself. Unfortunately, the flowchart contains a paradox\nand thus there can be no Halting Program. The paradox is at once\nstraightforward and confusing. It is a more elaborate version of the liar’s\nparadox: “This sentence is a lie.” If the sentence is true it must be false,\nand if the sentence is false then it must be true.\nThe Halting Program\nLet us suppose there is a Halting Program. Remember that a Halting\nProgram simply takes another program as input and predicts if it will\nhalt or not. It follows there must also be a program called Haltcrash.\nHaltcrash goes into an infinite loop if it examines a program with input\nthat halts, otherwise it halts itself.\nSoftware\n245\nHalting Flowchart\nNow we create a third program called RunMe. RunMe runs\nHaltcrash on itself. Still following this? Now execute RunMe with RunMe\nas its own input. What happens? The analysis is as follows:\n1. RUNME started on input RUNME halts. If RUNME started on\nRUNME halts, then Haltcrash started on RUNME with input\nRUNME halts. If Haltcrash started on RUNME with input\nRUNME halts, then HALT decided that RUNME started on\nRUNME does not halt!\nTherefore,\nRUNME started on input RUNME halts implies that RUNME\nstarted on input RUNME does not halt. (contradiction)\n2. RUNME started on input RUNME does not halt. If RUNME\nstarted on RUNME does not halt, then Haltcrash started on\nRUNME with input RUNME does not halt. If Haltcrash started\non RUNME with input RUNME does not halt, then Halt decided\nthat RUNME started on RUNME halts!\nTherefore,\nRUNME started on input RUNME does not halt implies that\nRUNME started on input RUNME halts. (contradiction)\n246 Are the Androids Dreaming Yet?\nBoth analyses lead to a paradox! There is only one way out. There\ncan be no halting procedure. I’m sorry if this is quite convoluted.\nPhilosophical Proof\nIf you find these technical proofs difficult to follow, it may be easier to\nexamine the problem philosophically. Consider the consequence of\nthe existence of a Halting procedure. A Universal Turing Machine is a\nrelatively small program. Roger Penrose gives a three-page example in\nThe Emperor’s New Mind, and Stephen Wolfram has implemented one\nusing a cellular automaton with as few as five component parts.\nA Halting Program running on such a machine should be able\nto compute all the knowledge in the Universe. Every structure, every\nwork of literature, every galaxy could be the output of this single, simple\nprogram. My pocket calculator could, theoretically, paint like Picasso\nand compose like Mozart. All art, knowledge and science would be\nentirely determined in our Universe and we would have no free will. If\nyou philosophically rebel against this then the Halting Problem must\nhave no solution.\nGödel’s Insight\nAnother way to understand this conundrum is through the earlier work\nof Gödel. Solutions to mathematical puzzles are neat, orderly sequences\nof statements where the problem is solved step by step. Computers are\ngood at step by step processes. Surely a computer could simply proceed\nin a painstaking fashion to check all the possible combinations of words\nand symbols to discover a proof.\nAn analogy might be trying to find your hotel room if you have\nforgotten the number. You could simply find it by trying every room.\nAs you progressed through each floor, you would try every corridor\nand retrace your steps to the main hallway before attempting the next.\nEventually you would succeed.\nFinding proofs of theorems is often understood to be the same sort\nof task: search systematically through all the numbers and you will find\nthe solution. But this is not so: There is a hidden problem.\nAlthough it is true to say problems and proofs can be described by\nnumbers, they are not simply related like a lock and key. We need the\nfirst number to translate into a set of symbols meaning something about\nmathematics: for example, that x squared plus y squared equals z squared\nbut for higher powers there is no equality, and the second number to\nSoftware\n247\ndenotes a set of sequential steps we can apply to demonstrate this fact.\nThese steps must have meaning and obey the rules of mathematics, but\nwhat are these rules? Are they written down in a text book?\nIt turns out there is no way to find this set of rules; it is a superinfinite\ntask. We would need to reach into our infinite bag of numbers\nand pull out rule after rule, turning each into a mathematical model\nthat explains numbers and logic and what can be done with them to\nform mathematical statements. The number of ways to do this is not just\ninfinity, but two to the power of infinity. This is the number of ways to\npermute all possible mathematical rules.\nYour mind may be rebelling at this. Surely, if I have an infinite\nset of numbers I can just pluck all the numbers from my bag and then\nI am certain to have the solution. Unfortunately, it turns out there is\nno complete, consistent set of rules; no valid dictionary that maps all\nnumbers to all of mathematics. That is Gödel incompleteness theorem.\nDespite a fundamental limit on mapping all numbers to all of\nmathematics, there might still have been an algorithm which could\npractically find solutions for a given arbitrary problem. Turing proved\nthis is not the case.\nThe Wiles Paradox\nTuring showed us there can be no general purpose, mechanical procedure\ncapable of finding solutions to arbitrary problems. A computer program\ncannot discover mathematical theorems nor write programs to do so. Yet\ncomputers regularly solve problems and generate programs. That’s what\nsoftware compilers do. This seems to be contradiction.\nThe solution to this apparent contradiction is to propose a boundary:\na ‘logic limit’ above which computers may not solve problems. With a\nhigh boundary a general-purpose machine could solve most problems\nin the real world, though some esoteric mathematical puzzles would be\nbeyond it. But if the boundary were low, many activities in our daily life\nwould need some sort of alternative, creative thinking. It is crucial to\nknow where the logic limit lies.\nThe Logic Limit\nAmazingly, in many branches of science it is possible to pinpoint the exact\nlocation of the logic limit, but finding that boundary in mathematics has\ntaken forty years work from some of the greatest mathematicians of the\n20 th century.\n248 Are the Androids Dreaming Yet?\nThe story starts back in the 1940s at Berkeley University with a\nyoung Julia Robinson, one of the first women to succeed in the previously\nmale-dominated profession of mathematics. By all accounts, she had a\nwry sense of humor. When asked by her personnel department for a job\ndescription she replied: “Monday—tried to prove theorem, Tuesday—\ntried to prove theorem, Wednesday—tried to prove theorem, Thursday—\ntried to prove theorem, Friday—theorem false.” Like Andrew Wiles, she\nfell in love with one of the great mathematical puzzles, and although she\nmade great strides, the problem passed from her to Martin Davis for the\nnext steps.\nThe final elements were put in place in the 1970s with the work of\nanother young mathematician, this time a Russian – Yuri Matiyasevich.\nRobinson wrote to him when she heard of his proof, “To think all I had\nto do was to wait for you to be born and grow up so I could fill in the\nmissing piece.” The complete result is the Robinson Davis Matiyasevich\ntheory which sets out the limits of logic and algebra. What, you may ask,\ndo we mean by logic and algebra?\nMathematicians like to turn everything into logical statements, even\nordering a round of drinks! The discipline of logic emerged from ancient\nGreece as the study of language. The starting point was the syllogism:\nStatements such as, “All cows eat grass.” or Lewis Carroll’s assertion,\n“There are no teachable gorillas.” Over time the study of logic became\never more precise with, for example, the introduction of variables and\nequations; a=all cows, b=some grass. The formula “a eats b” translates by\nsubstitution into, “The cows eat the grass.” This doesn’t look much like a\nstep forward but, trust me, it is.\nThe modern way to represent logic is using prenex normal form.\nThis mouthful simply means separating relationships between things\nfrom the things themselves. The following four statements say the same\nthing, each in a more formalized way.\nSpeech: Harry loves Sally\nLogical: x loves y (substitute Harry for x and Sally for y)\nFormal: There exists an x, there exists a y (x loves y)\nPrenex:\n∃x∃y (x R y), Where R, the relationship, is ‘loves’\nSoftware\n249\nThe final example is in prenex normal form. The symbol ‘∃’ means\n‘there exists’ and R stands for relationship in this equation. All logical\nstatements can be translated into this form using a purely mechanical\nprocess. There is even a website that will do this for you. It’s useful but I\ndon’t recommend it as entertainment!\nIn the example above, something exists in relation to the existence\nof something else: one person who loves another. Give me a name and I\ncan look up the person they love. This is simple. A computer can easily\nsolve such problems. Indeed there are hundreds of websites doing this\nevery day. Once you’ve solved one problem of this type, you have solved\nthem all.\nWe can rearrange Diophantine equations into many different\nprenex forms. The simplest form might be, ‘there exists an x which solves\nthe following equation, x equals three.’ This would be written out as ∃x,\nx=3 and is of the ∃ class – ‘there exists’. There are slightly more complex\nclasses than our simple ∃ relationship: ∀∃∀ ‘for all, there exists for all’ or\nthe class ∀ 2 ∃∀ ‘for all, for all, there exists, for all’. Each of these groups of\nequation is called a ‘reduction class’.\nOne way to think about a reduction class is as a problem in topology,\n‘knots’, to non-mathematicians. Imagine someone handed you a bunch\nof tangled cables – the sort of mess you get when they are thrown\nhaphazardly into a drawer. You can tease them apart and rearrange\nthem but you must not cut them or break any connection. Once you\nhave done this you will be left with a series of cables on the desk. They\nare all separate, looped or in someway knotted together. Each cable has\na fundamental topological arrangement: straight cables, granny knots,\nfigure eight, and so on. You have reduced them to their simplest form,\ntheir logical classes. The same goes for logical statements. Once you\nhave rearranged logical statements into their simplest form you can lay\nthem out and group them together according to their complexity. Each\ngroup makes up a reduction class and you can ask whether that class as a\nwhole is automatically decidable. It is a huge task to untangle and classify\nmathematical problems, and it took Robinson and her colleagues nearly\nforty years to succeed.\nIt turns out problems with a form as simple as ∀∃∀ (for all,\nthere exists, for all) have no general purpose algorithm. Each must be\nexamined individually and solved by something that is not a computer.\nThis is a remarkable result as the logic boundary is set quite low. An ∃∃,\n(exists, exists), class of problem is automatically solvable by a general\n250 Are the Androids Dreaming Yet?\nalgorithm, but a ∀∃∀, (for all, there exists, for all), is not. Each individual\ntype of problem within the class must be examined with insight and\nunderstanding.\nOur lives are full of problems – playing chess, finding a mate,\ndesigning space ships and simply getting to work in the morning.\nImagine we expressed everyday problems as logical problems. Where is\nthe logic limit for life? We have no answer for this yet, but we do know\nthe logic limit for computing; it is given by Rice’s Theorem.\nNamed after Henry Rice, and proven in 1951 as part of his doctoral\nthesis at Syracuse University, Rice’s Theorem states: “No nontrivial feature\nof a computer program can be automatically derived.” You cannot tell if\na program will halt with a given input. You cannot tell if one program\nwill generate the same output as another. You cannot tell if a simpler\nprogram could be written to do the same task as a more complex one.\nIn fact, no nontrivial thing can be proven. This means the logic limit in\ncomputers is low, and computer programmers have job security.\nFor Programmers\nFor the programmers amongst you, here are some of the things that\ncannot be done automatically even given infinite time:\n• Self-halting Problem. Given a program that takes one input,\ndoes it terminate when given itself as input?\n• Totality Problem. Given a program that takes one input, does it\nhalt on all inputs?\n• Program Equivalence Problem. Given two programs that take\none input each, do they produce the same result on every input?\n• Dead Code Elimination. Will a particular piece of code ever be\nexecuted?\n• Variable Initialization. Is a variable initialized before it is first\nreferenced?\n• Memory Management. Will a variable ever be referenced again?\nSoftware\n251\nCan humans solve ‘unsolvable’ problems?\nThe question of whether Fermat’s Last Theorem could be solved\nmechanically remained unanswered until 1970 when Yuri Matiyasevich\nfilled in the missing piece in Julia Robinson’s proof. Matiyasevich used\nan ingenious reduction method to match up sequences in Robinson’s\ntheorem with a set of Turing machines. This showed that if Robinson’s\ntheorem was false you could solve the halting problem and since you\ncan’t solve the halting problem, then Robinson’s theorem must be true.\nAll this effort proved Diophantine equations have no general algorithmic\nsolution. This was a hugely important result but, as we noted earlier,\nFermat’s Last Theorem is not, strictly speaking, a Diophantine. It is an\nexponential Diophantine equation. We still had no definitive answer to\nFermat.\nIn 1972 Keijo Ruohonen and again in 1993, Christoph Baxa\ndemonstrated that Diophantine equations with exponential terms could\nbe rewritten as regular Diophantine equations with one additional\ncomplication – the necessity of adding an infinite set of terms to the end\nof the equation. In 1993, J.P. Jones of the University of Calgary showed the\nlogic limit for regular Diophantine equations lies at thirteen unknowns.\nMatiyasevich had already pointed this out but never completed his proof.\nSince infinity is greater than thirteen, all exponential Diophantine\nequations are above the logic limit and, therefore, undecidable. Finally,\nwe have a proof that Fermat’s Last Theorem is unsolvable by a computer\n– or at least by a general purpose algorithm running on a computer.\nMatiyasevich went on to show many mathematical problems can be\nrewritten as exponential Diophantine equations and that much of\nmathematics is undecidable. For example, the Four Color Conjecture:\n“Given an arbitrary map on a Euclidean plane, show the map can\nbe colored in a maximum of four colors such that no adjacent area\nshares the same color.”\nMeanwhile, Andrew Wiles, an English mathematics Professor at\nPrinceton had been secretly working on Fermat’s Last Theorem. When\nI say secretly, he had not told anyone in his department, and only told\nhis wife late in 1993 when he suspected he might have a solution. He\nhad been working on the problem a long time, having fallen in love with\nit at the age of 8! In 1995, after nearly 30 years work, he announced he\n252 Are the Androids Dreaming Yet?\nFour Colors is All You Need\nhad found a proof. He had solved an unsolvable problem, a problem that\ncould not be answered by using a computer. Therefore, Andrew Wiles\ncannot be a computer!\nAs with all real-life stories, it was not quite as neat as this. It turned\nout Wiles’ initial proof had an error in it, identified by one of his referees.\nWiles had made an assumption about a particular number theory that\nhad not been proven: it was still a conjecture. Working with another\nSoftware\n253\nmathematician, he managed to prove this conjecture and so, two years\nafter first announcing that he had solved Fermat’s Last Theorem he could\nfinally lay it to rest.\nThe Special Purpose Objection\nBefore I declare mankind’s outright victory over computers, the Special\nPurpose Objection must be overcome. The objectors would argue that\nWiles is a Special Purpose computer. Special Purpose computers are at\nno risk of breaking the Turing limit when they solve problems they have\nTheorem (Undecidability of Hilbert’s tenth problem)\nThere is no algorithm which, for a given arbitrary Diophantine\nequation, would tell whether the equation has a solution or not.\nbeen programmed to answer. The objection misses the key point. I am\nnot arguing having a solution to a given mathematical puzzle presents a\ndifficulty to a computer; I am arguing a computer cannot discover one.\nTake, for example, the search engine Google. If I type “where can\nI find the proof of Fermat’s Last Theorem?” into the search box, it will\nretrieve a PDF of the proof as the third result. It appears this special\npurpose computer solved the problem. But you immediately see the\ndifficulty. Google search already knew the answer, or more precisely had\nindexed the answer. The computer was not tackling a random problem\nfrom scratch. It was tackling a problem for which it knew the answer, or\nat least where an answer could be found. There is no sense in which the\nsearch engine discovered the proof.\nTo really understand this objection we need to examine exactly\nwhat Turing and Matiyasevich proved.\nAn arbitrary problem is one you do not already know the solution\nto when you write the algorithm. You can think of it as a variable. Is\nthere an algorithm that can solve problem ‘X’? The alternative is a special\nprogram. It can solve problem Y. Y is a problem it knows. It must have\nthe solution coded somewhere within it in a computably expandable way.\nYou might think of this as a table of constants; problem Y has solution\n1, problem Z has solution 2, and so on. But it could be more subtle than\nthat. Problem Y might have a solution which is encrypted so you cannot\nrecognize it within the program, or it might even be the result of some\n254 Are the Androids Dreaming Yet?\nchaotic equation so complex that the only way to see it is to run the\nprogram and watch the output: no form of program analysis will give\nyou any clue as to what it produces. There is only one stipulation. The\nanswer to problem Y MUST be held within the program as a computable\nalgorithm. Put another way, the computer must already be ‘programmed’\nto answer the question.\nCould a human mathematician be pre-programmed from birth?\nYes, there is no fundamental objection to this. Mathematicians could be\nborn to solve the problems they solve. But this would present a couple of\nissues. Where is this program stored? And who, or what, programmed\nthe mathematician? Could we perhaps find an experiment to determine\nwhether mathematicians are pre-programmed?\nOne view held by philosophers is that the Universe programmed\nthe mathematician. They believe we live in an entirely determined\nUniverse with no free will. There is then no mystery as to how Andrew\nWiles came up with his proof. He was destined to do it from the dawn of\ntime. The ink that fell from his pen to the paper was always going to fall\nin just that way. We live in a clockwork Universe and although we might\nfeel we have free will, this is an illusion. I simply don’t believe this. If I\nam right and humans do exercise free will, Andrew Wiles cannot be a\ncomputer. And because Andrew is not alone in discovering proofs, those\nmathematicians cannot be computers either. Humans are, therefore, not\ncomputers.\nThe Chance Objection\nI said there was no automatic way to solve any problem above the\nlogic limit, but this is not quite true. There is one automatic method\nyou could deploy to generate a non-computable proof, the infamous\n‘monkeys and typewriters’ idea where we use random chance to generate\ninformation. Many people have suggested it is possible to write a play\nsuch as Shakespeare’s Hamlet by simply typing random characters until\nwe happened upon the play. The argument is flawed.\nThe first flaw is the process would take a super-astronomically\nlong time. Even if every atom in the Universe were a monkey with a\ntypewriter, it would take orders of magnitude longer than the age of the\nknown Universe to come up with the script to a play or a mathematical\nproof.\nThe probability of finding a solution to Fermat’s Last Theorem\nby chance is about 1 in 10 50,000 . That’s 1 with 50,000 zeros after it. For a\ncomparison, there are only 10 120 atoms in the known Universe. To be, or\nnot to be, certain of finding the proof, you would need to run a computer\nlong enough to calculate all the possible proofs up to the length of Wiles’\nsolution. Currently, a computer using every particle in the Universe\nclocked at the Plank interval – the fastest conceivable computer running\nat 10 34 operations per second – would take 10 500 times the age of the\nknown Universe to do this. If someone tells you this is astronomically\nunlikely they are making a huge understatement. A computer running\nuntil the end-of-time would only scratch the surface.\nThe second flaw is even more damning. Even if the monkeys\nsucceeded in generating something interesting, something else needs to\nspot this. If an algorithm stumbled upon a proof of Fermat’s Last Theorem,\nwhat would recognize it as such? There are no ways to systematically\nanalyze proofs. There are no mechanical methods that understand these.\nDalek Trouble\n“All non-trivial abstractions, to\nsome degree, are leaky.”\nSpolsky’s Law\nof Leaky Abstractions\nConsequences\nMachines cannot discover theorems using algorithms, yet\nmathematicians do it all the time. Do the rest of us break the\nlogic limit? It seems we do. People appear creative – painting,\ncomposing, sculpting and so forth. But, are these endeavors creative\nin the mathematical sense. To prove this, ironically we need to find\nsomething outside mathematics that is definitely non-computable. This\nis tricky. Most artistic things are fuzzily defined and there are no written\nrules we can apply. How can we prove a work of art could not have been\ngenerated by a computer?\nTrivial proofs exist but they are rather contrived. For example, it\nwould not be possible to make a film with a solution to the still unproven\nRiemann Hypothesis on the blackboard in the background of a movie\nscene. All the mathematics Good Will Hunting had been already\ndiscovered before the movie was made. New mathematics cannot be\naccidentally generated by a set designer – unless, of course, they also\nhappened to be a world class mathematician.\nThese trivial proofs might lead a mathematician to argue the theory\nis proven. There are some artworks which cannot be computed. QED. But\nthese are not very satisfactory proofs. I could create almost any movie I\nwanted without tripping over this rule. What I really wanted to know is\nwhether Good Will Hunting as a whole could have been generated by a\ncomputer. Not that some weird version with a particular mathematical\nproof on the blackboard is forbidden. Movies are a difficult subject for\n258 Are the Androids Dreaming Yet?\nthis argument, but music is much easier to analyze. It is linear, highly\nmathematical and largely uniform by culture and language. Yet it is\nuniversally appreciated. Is music a computational or a creative endeavor?\nIs Music Computable\nTo prove a piece of music is non-computable requires two tests. First to\nshow we can ‘reduce’ it to a problem that is already non-computable and,\nsecond, to demonstrate it ‘looks like’ or ‘sounds like’ a piece of music. An\naccountant would say it needs to pass ‘the smell test’.\nThe first non-computable problem to be studied in depth was\nEmil Post’s Word Problem. Post was a contemporary of Alan Turing\nand studied at the Institute of Advanced Mathematics in Princeton. He\nsolved the Halting Problem six months before Turing, but his proof used\na complex recursive method called the lambda calculus. Turing’s method\nwas far more practical, which is why we now refer to Turing machines\nrather than Post machines. Later in his career, Post came up with a\nbranch of non-computable mathematics called ‘Post Problems’. They\nlook like a puzzle you might find in a newspaper. Imagine starting with\nthe word ‘camel’ and being asked to turn it into ‘aardvark’, using only a\nfew simple rules. We’ll make the problem very easy to start with: cam\n↔ aard and el ↔vark. This solution is obvious; just do the substitutions\nand you are there. But what if the rules were a little more complex?\nGennadií Makanin, a Russian mathematician based at the University of\nMoscow, found a set of extremely simple puzzles that are nevertheless\nnon-computable. Here is one:\n{“CCBB” ↔ “BBCC”, “BCCCBB” ↔\n“CBBBCC”, “ACCBB” ↔ “BBA”, “ABCCCBB”\n↔ “CBBA”, “BBCCBBBBCC” ↔\n“BBCCBBBBCCA”}\nWord Problem\nCan a computer tell us which word problems have a solution and\nwhich do not? The answer is ‘no’. Word substitution puzzles are a class\nof non-computable problem. Martin Davis proved this in 1948. Using\na reduction argument we can use these word problems to prove some\nmusic is also non-computable.\nSoftware\n259\nLet us start by substituting the notes of the musical scale for the\nletters of the alphabet to create a piece of ‘music’. Since it is a direct\nanalogue of the word problem, we have created a non-computable piece\nof music. It is definitely non-computable, but is it music? If it just looked\nlike a random jumble of notes it would be unconvincing, but luckily there\nare many forms of music that look exactly like a word substitution puzzle.\nBach’s Art of Fugue, the canons of Tudor composers such as William Byrd\nand Thomas Tallis, and the works of Grieg all use sequences of chords\nthat move from one to the next using substitution rules. If you were to\nlisten to the steps in our word substitution music, they would definitely\nsound musical. I think they should pass the main artistic criticism – that\nthey should not sound formulaic.\nBut is any actual human composition non-computable?\nUnfortunately, we cannot prove whether a particular piece of Bach, Tallis\nor Grieg is non-computable because we don’t know the specific rules\nused to compose it. All we know are the general musical principles of\nharmony and counterpoint that applied at the time. We don’t have these\ncomposers personal rule sets because they were held in their brain and\nthey are, of course, long since dead. It is statistically likely that most pieces\nare non-computable because there are an uncountably infinite number\nof them, whereas computable pieces are merely countably infinite. But\nthat’s just probability; it is no proof.\nI puzzled for some time whether there is a way to prove it but had to\nconclude it is impossible. However, and this is how creativity works, once\nI had given up on the problem, my brain continued to work on it. I was\nnot conscious of this, I was only aware that failing to solve the problem\nannoyed me. I then had a Eureka moment. Although I couldn’t prove\na piece of music was non-computational, I could make one! – a piece\nthat could not have been created\nusing computation alone. This\nrequires me to inoculate your\nbrain.\nTake either Andrew\nWiles proof of Fermat’s Last\nTheorem or Alan Turing’s proof\nof the Halting Problem; both\nproofs are non-computable.\nEach document is made up of\nsymbols, the Roman alphabet\nand some special Greek symbols\nsuch as α, β, ζ, and so on. Let us\nCreative Inoculation\n\n260 Are the Androids Dreaming Yet?\nwrite out the symbols in a table and assign a musical note to each. It is\nstraightforward to put these notes into a synthesizer and play the piece\nof music. I have provided a link to such a piece. Warning: once you listen\nto this you will have been ‘creatively inoculated’.\nThis resulting piece of music, based on the transliteration of a proof,\nis non-computable. You might immediately argue with this, “The piece\nof music was translated from proof text to music file using a computer. It\nis clearly computed.”, but this is not my point. The music could not have\ncome into existence in our Universe as a result of a computation. It is a\ncomputable translation of a non-computable string. It could not have\nbeen generated solely by a computer: It was done in two steps, the first of\nwhich could not have been computed.\nIf, up to this time, our Universe has never contained a piece of\nmusic that was generated non-computationally, it does now. If you listen\nto this piece, you will find it impossible not to be somewhat inspired by\nit. You cannot erase the experience from your memory. And once you\nhave heard it you will have been creatively inoculated. I have defeated\nDaniel Dennett and his like, and given you creative freedom!\nwww.jamestagg.com/noncompmusic\nHaving made at least some music above the Turing limit I could\ndeclare victory but I want to go further. Using the same reduction method,\nI believe we can show all art is above the limit. First let’s attempt novels\nand plays. Do you enjoy those crime novels by Agatha Christie and Colin\nDexter? It must be possible to construct a plot sufficiently complex, and\na murder sufficiently baffling that it exceeds the logic limit. I could keep\nextending this idea to provide any number of examples and, therefore,\nprove all art and creative output is above the logic limit.\nThere are many other arts we could apply this argument too. In\nthe visual domain there are non-computable images. In principle, it is\npossible, to draw or paint things beyond the capability of a computer.\nRoger Penrose has created non-computable visual puzzles such as tiling\nan infinite plain with special jigsaw pieces. Creating an image containing\na solution to his visual puzzle is non-computable.\nThis extension argument also applies to me. There is an argument\nthat I am a finite being and therefore can be simulated by a computer.\nSince I can be simulated by a computer, I am the same as a computer\nand therefore incapable of non-computable thought. The argument is as\nfollows: James Tagg will have during his life a finite number of inputs and,\nequally, a finite set of outputs. This means you could model me using a\nSoftware\n261\nJackson Pollock\ncomputer. You could simply create a table of all the possible inputs and all\nthe possible outputs I would make and this would be a perfect facsimile\nof me. A number of people have posed this as an argument to refute\nRoger Penrose’s assertion that humans are capable of non-computable\nthought.\nBut this analysis misses a key point. There is no way to calculate all\nthe contents of this table. My past could be tabulated. It is the history of\nall the things I ever did, but my future cannot. I might yet discover some\ngreat theorem that could not be computably generated. This would be\na part of my output which could not be generated by an algorithm or\nany mechanical process. This forms a non-computational arrow of time;\nwe can write down the past, we cannot write out the future. If a creative\nperson such as Andrew Wiles could be simulated in advance, we would\nhave an automatic way to find a solution to Fermat’s Last Theorem. Since\nthis is not possible, it follows that creative people cannot be simulated.\nThis also means the Turing test is not passable by a machine. Humans\ncan create; machines cannot. That is the difference.\nWill Computers Take over the World?\nRay Kurzweil, the American inventor and futurologist, has suggested\ncomputers are getting exponentially faster and will soon reach such\nimmense power they became effectively infinitely powerful. They could\ninstantly answer any question posed and solve all our engineering\nproblems. He dubs this point ‘the singularity’: a point of near infinite\n262 Are the Androids Dreaming Yet?\nWatson and Our Future?\ncomputing power and therefore universal knowledge. This could herald\na Utopian future; global warming, cancer, all things of the past. But\ncomputers might just as easily become bored and determine we humans\nare the real problem. If we are lucky, they may treat us as amusing pets.\nIf we are unlucky...\nThese consequences might have come to pass if the answer to the\nHalting Problem were ‘yes’, but as the answer is ‘no’! This is not the future\nwe face.\nMummy, where do Bugs Come From?\nOne consequence of the logic limit provides a theoretical basis for the\norigin of computer bugs. The mention of ‘bug’ conjures up stories of\ndead creepy crawlies stuck in early computer circuits, but the term had\nbeen in use for over 150 years before the computer was even invented.\nBugs are not simply annoying mistakes.If you misspell my name as Stagg\ninstead of Tagg that’s just carelessness. Real flaws creep into a computer\nprogram when you fail to understand Brooks’ essential complexity, or by\nmy terminology, you stray above the logic limit without realizing it.\nImagine we have created a piece of software. The software goes\ninto test and is subjected to a range of use cases. Some of these will fail\nbecause we did not take into account all the real world possibilities.\nThen a strange thing happens. We get trapped in a loop of patching the\nerrors in the program in a rather mechanical way. Find an error, patch\nSoftware\n263\nit. Find another, create a work-around, and so on. By doing this, we are\neffectively mechanically generalizing our solution. This is forbidden as\nit breaks the Turing limit, so we can’t mechanically solve a general logic\nproblem above the logic limit. We need instead to use intuitive or creative\nthought. In our panic we did not stop, take a step back and engage our\nbrain. Instead, we attempted, unsuccessfully, to blindly hack our way\nthrough the problem.\nIf we eventually succeeded in perfecting the code this way, we\nwould have broken a fundamental law of the Universe. Something nasty\nwould have to happen to prevent it, such as rupturing the space-time\ncontinuum or an event equally horrible! Luckily something prevents this\nand keeps our Universe intact – BUGS! Bugs stop us breaking Turing’s\nlimit.\nThe next time you curse a bug, remember if they didn’t exist you’d be\nin danger of causing a logical paradox. There is no problem in redefining\nthe domain and then creatively producing an all-encompassing design,\nbut, you can’t patch and hack your way there. This theory of bugs leads to\nan explanation for some modern programming rules of thumb.\nWritten specifications are valuable because they force you to lay out\nthe whole problem. You don’t need to be detailed regarding the depth,\nbut should be expansive about the breadth, covering all the logical\ncomplexity. This might result in many details as a by-product, but a\nspecification needs to delineate the edges of the problem space and not\nsimply focus on a few key points.\nWriting the tests for the software in advance is helpful as it is likely\nto tell you early whether your design encompasses the whole problem\nspace.\nAlso, building a prototype, throwing it away, and then building the\nreal thing can help greatly. It may be the only way to examine the edges\nof the problem space in detail. Armed with a full understanding, you\ncan then imagine solutions to the complete problem in a single creative\nsitting. Whatever techniques you use to improve the quality of your\nsoftware, remember you are engaged in a creative process that is not,\nitself, open to automation.\nThe Art of Programming\nProgramming is an art: a creative endeavor. It is also, of course, highly\nscientific. When you work with a good programmer – and I have been\nfortunate to work with some of the best in the world – they all follow\na similar process. First they talk with you at length about your needs\n264 Are the Androids Dreaming Yet?\nGeek Humor\nand examine the full scope of the problem space. Even if you say, “Oh\ndon’t worry about that bit,” they always will. They want to know about\neverything. Then, they write a high-level list of features, some simple\nblock diagrams, and occasionally a flow chart, only then do they begin to\ncode, ticking off the list as they go. Sometimes, they will check to see if\ntheir list is the same as your list but more often they will come back and\njust check the high-level purpose. “If I give you something that achieves\nthis, will that do it for you?” They test as they code so you end up with is\nsomething that meets your high-level purpose, and can prove it does so\nin its own right. At the end of the coding they write out the specification\nfor the project so that they can remember what they did, or a colleague\ncan pick it up in the future.\nThis is not how students are taught. Students are told to write a\ndetailed specification at the start and then simply implement it. If you’ve\nbeen following my argument, they are being taught to do something\nimpossible! There is no ‘just’ to programming. Sometimes teams are\neven split up so that one person writes the specification and another the\ncode – again an impossible task. If the specification was the answer to\nthe problem, it must have required creative thought to develop and so\nwould be as complex as the program itself. Since it is not yet a program\nyou cannot test it, so it becomes an untestable solution to a creative\nproblem. Since the specification is not the answer but rather a general\nlist of tasks, the great danger is to give it to a separate programmer and\nSoftware\n265\nthey implement it mechanically. You see, of course, the problem. It\nwill be riddled with bugs because they have missed the creative step of\nimagining the whole problem and solving it in the round.\nThis fundamental misconception of software is common in many\norganizations. “Ah,” says the finance director, “I’ll write a very detailed\nspec and then we can get someone cheap to just program it.” This does\nnot work. If the finance director has done the creative work of taking a\nproblem and turning it into a detailed specification for the programmer\nto ‘just program’ – removing any ambiguity and therefore the creative\noverhead – he will have all but written software himself, albeit in\na computer language of his own making. On the other hand, if the\nspecification is a linear list of issues with no creative thought, he will not\nhave reduced the time needed to program. He may have improved the\nquality by effectively getting a second pair of eyes onto the requirements\ngathering stage, but this does not help the programming effort itself.\nIdeally, you should never split up specification and coding. It is a\ncreative process best handled by very small numbers of people working\nintensively on it. Of course, there is one big problem with this: some\nsoftware tasks are huge. Before we look at the science of splitting up a\nsoftware project, it is worth pointing out that many of the most famous\nprojects were written by one man. I have met many of these people and\nthey are all exceptional – Linus Torvalds, Linux; Anthony Minessale,\nFreeSWITCH; Daniel-Constantin Mierla, Kamailio; Eric Allman,\n,SendMail. Before splitting a project between many people, it is worth\nconsidering whether you can give it to just one individual. To do this you\n266 Are the Androids Dreaming Yet?\nwill need to unload this person of ALL interruptions and administrative\nburdens. This is the most effective way to solve a creative programming\ntask. Practically, once your task is over the limit for a single human, a\nsoftware project must be split up. This requires great care. Dividing a\nproblem efficiently means specifying the interfaces between them and\ndecoupling the components. This is the art of an architect or a producer\nin the creative arts. The creative process operates similarly in other walks\nof life. There are many examples of successful creative duos – Rogers\nand Hammerstein (The Sound of Music), Ben Elton and Richard Curtis\n(Blackadder).\nGood managers, therefore, find ways to break projects into\nmanageable sub-projects that can be worked by pairs or rely on single\nsuper-programmers with support around them. If you are lucky enough\nto gather together a group of super-programmers and can divide a\nproblem efficiently amongst them, you can achieve great things. You\nsee this pipeline in movie production. A script writer generates a script\ncreatively. The casting director finds the actors, a director is in charge of\nfilming, and an editor puts it together. In very great movies you will often\nfind a great director or producer who had a hand in almost everything\nholding it all together. They are often accused of micro-managing but\nyou can see that’s what they must do. They are the super-programmer\nwith the whole creative work in their head, and an eye on the audience\nand financial backers.\nIf you talk with great programmers you will be amazed by their\nbreadth of technical, commercial and product knowledge. Why do they\nneed all this commercial information to do their job in the round?\nRules and Tips\nI began writing some rules on how to split up a project, and almost\nimmediately ran into exceptions and special cases. The job of dividing\nthings into sub-tasks is, itself, a creative problem and must not be done\nmechanically. Any ‘one size fits all’ rule will fail and you must apply\ndomain knowledge and careful thought to the process.\nIt is the job of architects or a senior engineer to split projects into\nsmaller chunks. To do this they must accurately ‘guess’ boundaries\nbetween subtasks to create self-contained, creatively solvable problems.\nThis can be done by either vertical or horizontal abstraction. Both have\ntheir problems.\nSoftware\n267\nHorizontal abstraction is the simpler of the two to understand,\nand the more common. Computer systems are built ‘on the shoulders of\ngiants’. That is to say we no longer need to place individual pixels onto\nthe computer screen. We can assume a computer will draw a square if we\nspecify the dimension and coordinates of the center. That’s abstraction.\nToday’s computers are even more helpful. We can ask them to draw a\nrotating cube lit from a certain angle and the computer will do the whole\njob for us. But, there are always practical limitations to this.\nI want my cubes to move around the screen naturally but I am not\nsure what physics model has been implemented. What will happen when\nthey bump into each other? If the abstraction is not thoroughly thought\nthrough they pass through each other in a very odd way, breaking up\nand showing me they are really made of triangles, the illusion of three\ndimensions is lost. Whenever we work at an abstract level, we risk being\nexposed to its inner guts at some point. Joel Spolsky, a computer scientist\nwho worked on Microsoft Excel, proposed the Law of Leaky Abstractions\nto explain this. An example of his law in action is the TCP/IP protocol\nstack that transports data over the Internet. The stack is hugely reliable,\nyet I have to debug one of these stacks at least four times a year!\nThe problem is that the TCP (Transmission Control Protocol) is\ndesigned to provide reliable delivery of information: internet pages,\nmy bank account and the like. But, the internet protocol ‘IP’ on which\nit relies is only designed for best-efforts. When a link loses a packet of\ninformation, the TCP has to retransmit it. This takes additional time. TCP\nprovides an abstraction of a reliable connection, but the implementation\nis not as robust as it may seem, and the details leak through as variable\nlatency and throughput. This explains why your web pages sometimes\ndo not completely render. You are told it is reliable, but often it is not!\nExperience is so valuable to a programmer because they know which of\nthese specifications to take with a pinch of salt and when they are likely\nto leak. They are battle scarred by previous naivety.\nI think Spolsky’s Law follows from Rice’s Theorem and ultimately\nfrom Turing’s no halting proof. If leak-less abstraction was possible you\ncould, in principle, write a recursive partial halting solution. By layering\nabstraction on top of abstraction you would be able to solve some very\ncomplex problems, eventually including the Halting Problem. We know\nthis is impossible, so non-leaky abstraction cannot exist.\nThe other method of splitting software is vertically. This is often\ndone following the natural boundaries of an organization: functional or\ngeographic. Again there will be leakage between the systems; the data\nyou get from the finance department might not be detailed enough for\n268 Are the Androids Dreaming Yet?\nSpecification Cartoon\nthe engineers or vice versa, and so groups have to interact. The main\nproblem with vertically divided software is each group tends to reinvent\nthe wheel, so you end up with multiple similar implementations of the\nsame thing.\nAll said, the architectural job in software is a dynamic one. You can\nsplit up software into separate elements but you must take into account\nthe leakage between them. When you detect a leak you must bring people\ntogether to collaboratively solve the problem, rather than insisting on\nthe original partitioning. While doing all this you must keep track of\nthe overall aim and all the irritating small details contained in the many\nSoftware\n269\nlists that form the project specification. I should confess that I am no\ngreat fan of specifications, because they can mislead you into thinking\nyou’ve solved the problem, but I concede a good specification is helpful.\nSpolsky’s Second Law is ‘Always write a specification.’ Engineers should\ncollaboratively write the specification as a response to the desires of the\nproject creators. But they must not blindly implement the specification\nthey’ve been handed. They must not forget the creative element.\n270 Are the Androids Dreaming Yet?\nThe Role of ‘Process’ in Creativity\nWe hear a lot about ‘process’ when developing software and other\ncreative tasks. The first thing to realize is process does not write software\nand every moment spent on process is a moment not writing software.\nExcessive process can bring the productivity of the average programmer\ndown from a thousand lines per day to one. On the other hand, we all\nknow that using no process to write software results in useless software.\nGood solo programmers, playwrights or composers are surrounded by\nlists and post-it notes full of process. Where is the balance to be struck?\nIn my view ‘process’ is there to help humans with the tasks we find\nnaturally difficult. Humans, as we know, are dreadful at remembering\nlists of symbolic information. Give a human ten numbers to memorize\nand they will quickly forget them. Give Microsoft Excel ten numbers and\nit will remember them forever, or, at least, until your next upgrade! So\nthe first job of process is to collect lists of things and sometimes even lists\nof those lists.\nAnother significant affliction affecting humans is procrastination.\nWe tend to put off decisions. Process can set waypoints; when will the\njob of splitting a project occur, when will we begin the test, and so on.\nThe third job of process is to keep track of the division of labor – if\nthe project has to be divided. Who will do what? Essentially we are back\nto lists again.\nThe most important job of process, in my view, is to keep track\nof scope. ‘Logical scope creep’ when unrecognized destroys software\nprojects. Scope creep is fine if it just adds more linear work. “Could we\nadd three more product types?” “Could you do another language?” “Can\nyou make this interface prettier, less cluttered?” It may cause a busy team\nto groan, but it does not damage the integrity of the design. To put it back\nin Brooks’ language, accidental creep is fine – provided you add some\nresource. Essential creep is not. Adding the french language prompts to\na project in English might be fine, putting language translation into a\nproject may be a step too far. The project may have strayed into a different\nlogical class. Increases in logical scope often require redesign, you must\nstop and re-architect if you are to avoid bugs in plague like quantities.\nIf programming software is a creative task, how can we help improve\nproductivity? The most important factor is to provide uninterrupted\npeace and quiet. Programming is a task where people need to hold many\nideas in their head at the same time, and this requires deep concentration.\nTo get some idea of the creative process at work, listen to the excellent\nTED lecture by John Cleese.\nSoftware\n271\nA common and costly mistake is to put off thinking about a class of\nthings you are going to need in the next release because of time pressure.\n‘Time out, that’s for the next release’ and similar statements spell disaster\nfor the future of a project as when you come to the next release, you may\nhave to rewrite much of it from scratch. This is why good architects are\nso valuable. They anticipate the future even when they are told to ignore\nit and ship now!\nJust as there are artistic geniuses, there are programming geniuses.\nHold onto them if you get one. They are rare. We don’t know if they\ncan be made or they are lucky accidents, but statistics shows that some\npeople are 1000 times more productive at writing code than the average.\nIf you can find lots of them and make them work together you will build\nthe next Google or Facebook. If you have a tight deadline, a superprogrammer\nmay get you out of a hole, producing in a week what might\notherwise take a year. Remember your great programmers will most\nprolific if you can get process and distraction out of their way. Just make\nsure they have a clear idea of purpose.\nLaws\nA programmer interrupted eight times a day does no work.\nA creative person interrupted eight times a day does no work.\nProgramming is a creative endeavor.\nThere are creative geniuses. Hold onto them.\nBugs save us from collapsing space-time when we are lazy and try\nto use mechanical means rather than creative thought to write software.\n\nChapter 12\nHYPER-COMPUTING\nWhat’s in a Brain\nPerpetual Motion from the 1600s\n“If you are in a spaceship that is\ntravelling at the speed of light,\nand you turn on the headlights,\ndoes anything happen?”\nStephen Wright\nIf you believe humans outthink computers, be warned; you are in\ncontroversial territory. This would need a hyper-computer and many\nscientists speak of these in the same breath as perpetual motion\nmachines.\nI’m not sure it’s an entirely fair analogy. We understand machines,\nand the physical laws of our Universe forbid perpetual motion. We\ndon’t understand brains, so we can’t reasonably dismiss human hypercomputing.\nHumans commonly demonstrate one clear example of\nthinking which appears to break the Turing limit, namely finding\nsolutions to mathematical puzzles. We need an explanation for this.\nLet me take you on a whistle-stop tour of all the schemes people have\nimagined that might lead to a hyper-computer.\nA hyper-computer is a machine that can calculate a function which\na Turing machine can not. For example, when given a number denoting\na problem such as Fermat’s Last Theorem, it can give me in return a\nnumber representing a valid proof. We are not concerned here with\nspeed. We are talking about fundamental ‘do-ability’. Such machines are\noften dubbed ‘super-Turing’.\nEpic Fails\nLet us first look at some proposals that blatantly fail. My children call\nthese ‘epic fails’, and they are the perpetual motion machines of the\nhyper-computing world.\nCould we run many Turing machines at the same time, perhaps\neven an infinite number? Then we would have a much more powerful\nmachine that must beat the Turing limit.\nThe answer is no.\nTuring machines are already infinitely powerful and we know from\nour chapter on infinity that all countable infinities are the same. Infinity\nplus infinity, infinity times infinity, infinity to any power; all are equal.\nOne single, fast, one-dimensional machine can simulate them all. We get\nno greater power with an infinite number of similar machines.\nThe next technique which might realize a hyper-computer is to\nhave a machine which simultaneously runs every possible branch in a\nprogram. Each time the machine gets to a point where there is a binary\ndecision, it can take the ‘yes’ branch, spawn a copy of itself, and run the\n‘no’ branch as well. Logically this machine should be able to calculate\nanything since it tries every conceivable option. The process is called\nnon-determinism. This doesn’t mean the computer has free will. It just\nmeans the computer never chooses one option over another. It just\n276 Are the Androids Dreaming Yet?\nassumes each could be correct and travels down both. Solving a problem\nusing a machine like this can be fast. The problem is this machine has\nno greater power than a regular Turing machine. Let me show you why.\nA non-deterministic machine is essentially the same as a single\nTuring machine; each time there is a branch in the program you would\nstart running two processes. The first process works on every even tick\nof the computer clock and the other on every odd tick. Now we have a\nsingle machine running two branches at the same time. Using this trick\nover and over again, a single machine can run a program exploring every\npossible branch. Although it generates an enormous number of branches\nand takes a huge time to run, it is still a single machine and we have an\ninfinity of time on our hands. Therefore, the machine is limited as before.\nWe are not doing well so far and we have already exhausted an\ninfinite number of options! Let’s try a different tack. We know true\nrandomness is non-computable, the sort of randomness generated by\nthe Lavarand we examined earlier in the book. Might this help? Truly\nrandom processes can’t be simulated by a computer. If we throw this into\nthe pot might it let us compute something a Turing machine cannot?\nAgain, no.\nThis idea still only generates a machine as powerful as the nondeterministic\nmachine above. A non-deterministic Turing machine runs\nevery possible program. All a random one does is choose some of the\nsame paths at random. It, therefore, can’t be any more powerful. The one\ndifference is that it can generate non-computable numbers. However, the\nonly interesting characteristic of these numbers is they are truly random\nand this randomness was an input. Their presence does not make the\nmachine any more powerful.\nThere are quite a few proposals for hyper-computers that are just\ncleverly dressed up versions of the machines we have already met and\ndismissed. For example, it has been proposed the Internet could form\na super-Turing machine. This is known as a site machine because the\nprocessing is distributed across many sites linked together through the\nInternet. It is proposed each site could act as an oracle to the others. This\nis quite an elegant idea, and some proofs have been offered that show\nsuch a machine is capable of generating non-computable functions. The\nproblem with this idea is that you can simply draw an imaginary line\naround the whole site machine and it looks exactly like a big Turing\nmachine. There is no conceptual difference between such a machine\nand a regular computer with subroutines. After all, that’s in Turing’s\nHyper-Computing\n277\noriginal proof. Again we have reached a dead end. We need something\nqualitatively different to a traditional computer in order to break the\nTuring limit. The obvious place to turn is the quantum world.\nQuantum Computers\nQuantum computers have had an extraordinary run in the press recently.\nIt has been variously claimed they offer limitless computing power and\ncan break all known security schemes; cracking, for example, the prime\nfactors that form the basis of public key cryptography. This is big news.\nThese codes are used to protect all the financial transactions we make on\nthe web.\nIn a regular computer, bits of information are processed by switches\nthat make simple ‘yes’ or ‘no’ decisions. In a quantum computer each\nswitch can take both the yes and no branches, at least for a short time called\nthe decoherence interval. The calculations are said to be superposed.\nThis allows a quantum computer to calculate exponentially, rather than\nlinearly, as the number of logic gates increases. Grover’s algorithm and\nShor’s algorithm use this superposition to speed up factoring numbers\nand looking things up in databases, respectively.\nGrover’s algorithm gives us the ability to find something stored in a\nrandom place without having to look in every box. If you think about a\nstandard search, say for your lost car keys, you must look everywhere to\nguarantee finding them. It does not much matter in what order you do it.\nWhen you are halfway through the search, you will be 50% likely to have\nfound your keys. But, with a quantum computer, you can be fuzzy and\nlook in many places at once. A quarter of the way through a quantum\nsearch, you are 50% likely to have found your keys. That might sound\nlike a small improvement, but when working with very big numbers, it\nmakes an enormous difference.\nShor’s algorithm works a little differently and, yes, it does allow\na quantum computer to break Internet encryption, so the newspaper\nheadlines are true up to a point. Some time in the future we will need to\nmove to a more secure type of encryption.\nThe largest quantum computers today can process 300 qubits at\na time or remain ‘coherent’ for about two seconds. These results are\npitifully low. The largest prime number factored so far is 143, a mere 7\nbits long! By way of comparison, internet security routinely uses 1024\nbits. But, quantum computers are improving exponentially faster than\nclassical computers: They really do change the rules of the game. If you\nremember our discussion of chess, the quantity of space needed for a\n278 Are the Androids Dreaming Yet?\ncalculation can be the limiting factor. A quantum computer is very space\nefficient. When the computer branches and makes a copy of itself, it does\nso without needing more space. There are two theories for how it does\nthis, (well, three, but the third is highly controversial). The first theory is\nthe computer doesn’t need the space because it hasn’t made its mind up\nyet; somehow the calculation floats in an undecided state. The second is\nthat the computer puts a copy of itself in a parallel Universe each time it\nbranches. When the calculation is over, either all the Universes collapse\nto a decision, or every possibility is chosen in some Universe or other and\nthey all go on their merry way! This is the ‘many-worlds’ interpretation\nof quantum mechanics and we will return to it later in the book.\nWe have now explored all the straightforward ways to make a hypercomputer,\nand all have failed. We need something still more exotic.\nMore Horse Power Needed\nIs there anything more powerful than a Turing machine?\nYes, in theory, there is.\nThe first person to explore ways of breaking the Turing limit was\nTuring himself. He cut right through the problem by proposing the\nexistence of an oracle function. At any point in a computation, you could\nask this function a question and it would give you the right answer.\nWe must leave completely aside the question of how this wonderful\noracle function is constructed. All we know is it can’t be a machine. If it\nreally existed, a Turing machine that was able to consult it would be able\nto answering any question you put to it. That is a hyper-computer.\nUnfortunately having access to such an oracle does not get us far.\nWe can use it to compute numbers we could not otherwise have obtained\n– or answer a single question – but it does not give us a general-purpose\nway to solve further problems outside of the logical area we asked it to\nanswer.\nEach time the oracle answers a question we break the limit a tiny\nbit. Each question and each answer moves us forward, but does not give\nus something universally applicable. If I ask the oracle to prove Fermat’s\nLast Theorem it will give me that answer, but this does not turn me into\na creative mathematician, able to prove any other theory. You can test\nthis by typing a mathematical question into the Google search box. Does\nobtaining an answer make you better at mathematics?\nIn any case, an oracle is not and cannot be a machine, so it does not\nlead us any further in our quest to build something super-Turing.\nHyper-Computing\n279\nThe Weird and Wonderful\nThere are some really weird and wonderful proposals for machines\ncapable of super-Turing thought. Let’s take a bit of a flight of fantasy.\nIf we could make a spaceship survive the inhospitable environment\nnear a spinning black hole, it might be possible to send information\nbackward in time. We could see the answer to a calculation before we\nhad to go to the trouble of calculating it in the first place.\nBlack Hole Malament-Holgarth Space\n280 Are the Androids Dreaming Yet?\nDavid Malament and Mark Hogarth of the University of California,\nIrvine have proposed a form of space-time called the Kerr Metric. This\nallows a machine to break the Turing limit, but has the drawback that as\nit does so it falls through the event horizon and is sucked into the black\nhole. We might discover new information but are now trapped inside the\nevent horizon unable to communicate it – a form of cosmic censorship.\nCandidates for a hyper-computer that could fit inside a human\nbrain include mathematical curiosities which stretch the concept\nof infinity. The easiest to understand is the Zeno machine. In a Zeno\nmachine a computer runs each successive step of a calculation in half the\ntime of the previous step. The computer can pack an infinite quantity of\ncomputation into each finite time interval and can therefore outperform\na Turing machine. This theory fails at a practical level because we simply\ncan’t build such a machine.\nThere are numerous weird suggestions for mathematical super-\nTuring machines, and many are described on the Internet. They all fit\nbroadly within the two models above: modifications to space-time or\npeculiar mathematical paradoxes. The inspiration for the true solution\nto super-Turing thought may lay in there somewhere, but there are some\nmore plausible proposals to look at next.\nPlausible Ideas\nI have characterized the next set of ideas as plausible, but they may still\nbe highly controversial. My only criteria for plausibility are that the\nmechanism must outperform a machine limited to counting numbers,\nand it might fit inside our skulls. No black holes allowed.\nOne interesting proposal for a super-Turing machine that could\nfit inside our skulls is the Adaptive Recurrent Neural Network, ‘ARNN’\nproposed by Hava Siegelmann of the University of Massachusetts,\nAmherst. An ARNN is a neural network with real number weights. As\nyou recall, real numbers are equivalent to the continuum infinity, a larger\ninfinity than that of counting numbers.\nThis is the infinity that defeats a Turing machine, and Siegelmann\nharnesses it as the basis of her computing machine. She argues that,\nalthough the machine cannot be programmed as it is impossible to write\nreal numbers down, once it is running, the weights diverge and real\nnumbers will be used within the network. These real numbers allow the\nmachine to compute using numbers that are not, themselves, computable\nHyper-Computing\n281\nand this is where the machine’s greater power comes from. Of course\nsuch a thing might easily fit inside our skulls, and the physics within our\nbrains are certainly capable of using real analogue values.\nThe biggest stumbling block for Siegelmann’s idea is the information\nthat gives her machines their power is fine-grained and easily destroyed by\nnoise in the environment. This is not just from the sort of electrical noise\nwe hear when our cell phones interfere with the radio, but the precision\nrequired by her machines is so exacting that anything might interfere\nwith them. For example, gravitational waves caused by the motions of\nnearby stars would disturb calculations at only the fiftieth decimal place.\nSince it is these digits that constitute the difference between an ARNN\nand a regular Turing machine, most people conclude ARNNs can’t work.\nThere is one effect stemming from the quantum world which might\ncome to the rescue. The potential to do something in the quantum world\nis sufficient to modify the behavior of a system even if the system does\nnot actually do that specific thing. This is called a counterfactual process.\nThe possibility an ARNN might perform infinite precision calculations\nmay be enough to give the machine the edge, even though in practice it is\ndisturbed by noise. This is speculation upon speculation, but interesting\nnevertheless.\nNeurons and Microtubules\n282 Are the Androids Dreaming Yet?\nRoger Penrose is fascinated by such counterfactual experiments\nand is inspired to think such effects might have a role in non-computable\nthought. It is his ‘machines’ we will look at next.\nPenrose-Hameroff Machines, aka Brains\nRoger Penrose of Oxford University and Stuart Hameroff of the\nUniversity of Arizona have proposed a very different way to understand\nthe workings of the brain. They focus on the much smaller scale structures\nwithin neurons called tubulin microtubules. If you watch a brain form,\nthe dendrites grow towards each other, twisting and turning rather like\nthe growth of a plant as viewed in a slow motion nature film. This motion\nis controlled by micro-tubular structures formed of a protein called\ntubulin. Tubulin is made from peanut-shaped polar molecules that selfassemble\ninto helical tubes with a radius of just seven molecules. The\ntubes bundle together to form the backbone of neurons. The peanutshaped\nmolecules are bipolar switches and can flip between two states.\nThis allows them to bend into different shapes and, in the most extreme\nexample, to flap fast enough to propel small organisms such as paramecia.\nIt is also, interestingly, the protein that unzips the double helix when a\ncell divides, and so plays a fundamental role in our evolution.\nPenrose and Hameroff suggest these tubes form the true processing\nelement in our brains. The walls of the tubes are formed of successive\nalpha and beta tubulin molecules. Each of the tubulin molecules can\nflip between two states, propagating a ripple along the tube wall. The\nscale is small enough for quantum effects to matter, and Hameroff\nsuggests quantum error correction keeps the ripples from decohering\ntoo fast. Because the processing is happening at a molecular level\nrather than at the scale of a neuron, the brain would be considerably\nmore powerful than a count of its neurons would suggest. They propose\nincreased computing power would stem from three sources: There are\nmany more tubulin molecules than neurons; the micro-tubes could\nperform quantum computation, and the micro-tubes are capable of noncomputable,\nconscious, thought.\nMeasurement of a quantum process is the only candidate we\nhave for a non-deterministic physical process today; all other physical\nprocesses are deterministic. Penrose argues that quantum processing\nin the brain spontaneously collapses in decision making because of\nthe interaction between quantum superposition and gravity. The\narguments are put forward in two books: The Emperor’s New Mind and\nShadows of the Mind. This theory remains controversial for two main\nHyper-Computing\n283\nreasons. First, most people see no need for super-Turing thought. They\nbelieve computers are sufficient. Second, they believe the brain is not a\nhospitable place for quantum effects: it is too hot and too chaotic. Indeed,\nuntil recently people assumed quantum effects would have no place in\nbiological entities, but this orthodoxy has recently been overthrown by\nthe discovery of quantum processes in photosynthesis. The paper by\nTravis Craddock of Nova and others suggests there may also be quantum\nstructures in the neurons of our brains and we might possess quantum\ncomputers after all. But, remember, Penrose and Hameroff don’t only\nneed quantum coherence within our brain to explain consciousness.\nThey also need gravitational effects.\n\nChapter 13\nHYPER-\nCOMMUNICATION\nWorld Wide Communication\n“The single biggest problem in\ncommunication is the illusion\nthat it has taken place.”\nGeorge Bernard Shaw\nEach Christmas I buy the Private Eye annual (an English satirical\nmagazine) only to be slightly disappointed when much of the\nhumor falls flat, yet I can watch the TV current affairs quiz ‘Have I\nGot News for You’ featuring its editor and be reduced to tears of laughter.\nBeing at a live recording of the show is even more powerful. Why is\nthis? Why is the experience and effect so different? Is it just the sense of\noccasion when I go to a live show or is there something more to shared\nexperience?\nWe appear to learn more from lectures delivered in person than\nreading the lecturer’s book, or even watching the same lecture recorded\non video. Studies show children who are read to by their parents do better\nthan if they are left to follow along with a CD. Two groups of children\nwere tested on two made-up words used in a story. The children read to\nby their parents had an 80% recall rate, while children who followed the\nCD only 17%. This is a big disparity. The simplest explanation is that the\nchildren who were read to pay more attention. Are there other effects?\nIMAX\n288 Are the Androids Dreaming Yet?\nMost scientists believe communication between humans is classical:\nwords spoken in proximity have no more power than had we carefully\nwritten out what we wanted to say. Body language and tone of voice are\nsimply useful tools to aid the transmission of this information. I’m going\nto explore the ways in which human face-to-face communication might\nexceed this traditional classical model. Let us look first at the bandwidth\nof communication between people.\nBandwidth\nLet me give you a mental picture for what I mean by bandwidth. Imagine\nI am sitting in a darkened theatre enjoying one of my favorite comedians\nat the Edinburgh Festival – the biggest arts festival in the world. I phone\na friend who is also a fan and let them listen in. Perhaps I even use the\ncamera and surreptitiously point the phone at the comedian. My live\nexperience is digitized, compressed and transmitted over the mobile\nnetwork to my friend. He gets the same experience but at much-reduced\nbandwidth.\nMy friend has a similar but qualitatively different experience to\nmine. He cannot hear the degrees of loud and soft I hear, nor the full\nrange of high and low frequencies forming the timbre of the comedian’s\nvoice; no sense of the smell of old armchairs or the heat of the audience\naround me. He is spared the strange stickiness my shoes meet on the\nfloor of the auditorium and the occasional slosh of beer that hits me\nfrom a slightly inebriated neighbor. For the person at the other end of the\nphone, their view is of a tiny two-dimensional screen about 4 by 3 inches\nsquare. Of course, they can enlarge the picture, but then the pixilation\ndominates and it looks like an impressionist picture viewed close up. He\nhas nothing like the same intensity of experience. Loss of bandwidth is\nsomething we can study mathematically and the reduction is enormous.\nVideo and Audio\nThe image of the comedy show is digitized by the camera and\nmicrophone; the video at 384,000 bits per second and the audio at 64,000\nbps. Mathematical compression will be applied and the video will shrink\nto 30,000 while the audio drops down to 4,700. After compression, the\nwhole experience amounts to around 40,000 bits per second. To put it in\nsome perspective, a DVD would be 11.5 million bits per second, nearly\n300 times the bandwidth.\nHyper-Communication\n289\nMy in-person experience has much higher bandwidth than even\na DVD. It may even have infinite bandwidth. Physicists argue whether\nspace-time is quantized but, for now, we will look at what would be\nneeded to reproduce the experience faithfully on modern digital\nrecording equipment.\nDigitization\nWhen something is converted to digital form, it goes through a number\nof steps. First, some way must be found to chop the thing into small parts\nin space and time. Then each of these parts is sampled with a sensor to\ngive an electrical signal and, finally, this signal is measured and turned\ninto a number.\nOld microphones used carbon granules. As the sound waves passed\nthrough them, the granules were shaken and made better contact with\neach other. Connecting a battery across the granules gave a varying\nvoltage. Modern microphones use a variety of technologies. The\npreference of most recording artists today is the electret microphone.\nA coil moves inside a magnet generating a varying voltage which is\ntranslated into a voltage as before.\nNext we use a fast running clock and measure the voltage on each\ntick giving us a sequence of numbers. We have created a near perfect\nrecord of the sound, and we can prove this by recreating the sound\nthrough a loudspeaker. This is what happens every time you listen to\nyour iPod.\nTo digitize film, each frame must be split in space as well as time.\nOn each tick of the clock, a process scans left to right and top to bottom\nto form a one-dimensional stream of numbers that records the image.\nThe system cuts the picture up into little elements called pixels, standing\nfor picture elements. Each small square has its average color measured\nfor red, green, and blue content coded as a number.\nDigitization techniques have become the dominant way electronics\nwork in the home, and digitization circuits are now ubiquitous.\nReality\nHow big is reality? Setting aside for a moment the problem that it might\nbe infinite, we need to reproduce all the elements that go to make it up.\nA normal DVD has an image of 720 by 576 pixels with 16 bits of\ncolor depth and a frame rate of 25 frames per second. The eye, however,\nis considerably better than this and a DVD does not fool it. HD video\n290 Are the Androids Dreaming Yet?\nis 1900 by 1000 pixels with 32 bits of color depth and 100 frames per\nsecond. This is a great deal better – if you enjoy watching sport or nature\ndocumentaries, the additional resolution is amazing. This still falls far\nshort of reality. An IMAX theatre gives a wrap-around image of about\n10,000 by 7,000 pixels and comes closer to the average resolution of the\nhuman eye, estimated at about 30,000 by 20,000 pixels. But the eye cheats.\nIt concentrates the rods and cones in the central portion of the retina.\nAlthough IMAX achieves the average pixel density of your eye, it comes\nnowhere near the peak density which is nearly 10,000 times greater.\nFor a truly equivalent experience, we would need about 320 million\npixels per eye at a frame rate of 120 frames per second, allowing us full\nstereo synthesis. At this speed and resolution, we are matching the visual\nacuity of the eye and should be able to fool it completely. But there is\none more problem to overcome: The image is not interactive. Move your\nhead in the real world and the image will change. The objects in the\nforeground will vary their position in relation to the background, socalled\nmotion parallax. Try it now, move your head and you will see that\nthe book, or screen you are reading moves in relation to the background.\nIn a simple digitized 3D image this will not happen. You will have a 3D\nimage but you will not have a real image, a light field.\nTo create a real image you need to view a hologram or use headtracking\ntechnology. A hologram records the light waves given off by\nan object in multiple directions rather than just the intensity of the light\nstriking the camera through a single focal point. When you shine a laser\nback through the hologram, it regenerates the light waves as they would\nhave originally come from the object. That light can be viewed from\ndifferent directions, giving the impression of three dimensions rather\nthan a mere two-dimensional photograph. There is often a limitation in\nviewing angle because the original photographic plate must wrap all the\nway around an object to capture the full 3D light field, but the illusion is\nvery convincing.\nA more effective way to create a real experience – and one with no\nrestriction on viewing angle – is to construct the image in a computer\nand track the movement of your head. The computer can create the\ntwo-dimensional images each eye would see if the scene were truly\nthree-dimensional. Computer software resolves motion parallax and a\nhost of other elements, but to do so the computer must understand a\nmodel of the world so it can calculate how the scene would look from a\nparticular angle and in the appropriate lighting. Some recent games such\nas Activision’s ‘Call of Duty’ do this, and the experience is compelling.\nHyper-Communication\n291\nHologram\nThere are still problems. The image is stereo but planar. All the\nlight coming into your eye comes from the screen a meter or so away.\nIn the real world objects need you to change the focal length of your\neye to bring them into sharp focus depending on their proximity. Try\nlooking at your hand as you move it towards and away from your face,\ntoo close and your eye can’t pull focus any further and it will blur. This\nmismatch between focal depth and the apparent distance implied by\nmotion parallax is one of the reasons you can get headaches watching\n3D images. There is something not quite right about them and your eye\nhas to learn a new behavior.\nAudio Field\nOur poor friend at the end of the phone is listening to a mere 4700 bits\nper second rendition of the comedian. A compact disk is 64,000, 16-\nbit samples per second in stereo, over a million bits per second. So the\ninformation content of a mobile phone call is very low. It is a miracle\nyou can understand speech at all over such a narrow channel, but this is\nmade possible by two factors. First, human speech uses a limited range\nof frequencies. All the information in our voices lies within about two\noctaves centered on middle C. And, second, you can perform some\n292 Are the Androids Dreaming Yet?\nclever mathematics to generate speech from seed information. For a\ngiven speaker the vowel ‘a’ might be 20% middle C, 50% F and 25% A,\nwith a few other things thrown in for good measure. We can transmit\nthis information and ask the computer at the other end to re-synthesize\nit. This is what happens when you listen to someone on a modern phone.\nYou do not hear their actual speech, you listen to a computer synthesizer\nmake a near approximation.\nCD is no longer the gold standard for sound. Professional audio has\nstandardized on 24 bit recording which is probably far beyond the limit\nof the human ear. An audio soundtrack is doing a good job at 2 million\nbits per second.\nSitting perfectly still in the middle of a room, each ear will pick up\na different signal if the source is not directly in front of us. The two ears\non a human head face a little forward, and the hair on your head slightly\nabsorbs sound. We can calculate the source of the sound by the slight\ndifference in the times at which it strikes each ear, and the variation\nin frequency content. We can use these two pieces of information to\ndetermine the direction from which a sound is coming. It was useful for\nour ancestors to be able to tell where the saber-tooth tiger was hiding.\nWe can gain more accurate information by turning our heads from side\nto side. The differences in frequency and timing should vary as we do\nso and we gain a little more data to perform the calculation. If we walk\nthrough the room we sample yet more of the soundscape and this can be\nused to pinpoint the exact location of the source. As we move, we expect\nthe sounds we hear to change subtly according to the mental model we\nuse for locating objects in the soundscape.\nTo give the illusion of a soundscape modern systems use multiple\nmicrophones to capture the sound, so it can be reproduced on multiple\nspeakers. Ideally, we would record a hologram of the sound but it is\npossible to record on thirty or so microphones and mix the tracks down\nto 5 or more channels giving us the sound experience we now expect at\na modern cinema.\nWhat is the Bandwidth of Life?\nWe have not yet talked about the other senses; smell, vibration,\ntemperature, balance, wind chill, and touch. In all, there are over 25\nsenses that must be stimulated accurately to simulate reality. Just think\nfor a moment how much information must be replayed to reproduce the\nsensation of bungee jumping off a bridge in the jungle or taking off into\nHyper-Communication\n293\nspace, or giving birth. To digitize life completely, we need to stimulate\nevery relevant nerve ending in the human body in real-time – skin, ears,\neyes, balance, pain centers, and so on.\nAt the low end, a ‘perfect’ IMAX production would require 360\ndegree stereoscopic projection and the generation of a full sound field.\nThis would take 3 Gigabits per second for the audio field and 5,600 terabits\nper second for the video field. This could be substantially reduced if the\nperson wears virtual reality glasses to track their head and eye movements,\nbut then you are substituting resolution with computer power.\nAt the high end, a team at the US Department of Energy’s Fermilab\nestimate reality needs one hundred trillion samples per inch for a\n‘simple’ quantum representation. If we look at the many worlds view of\nquantum mechanics, each photon hitting our eye can’t be fully described\nby a single number. The photon may be entangled with other realities\nwe should keep track of. This causes our picture of reality to become\nwildly complex. Everything we might see and experience is in some way\na combination of possibilities, and these possibilities all interact. Real life\nis very complex.\nSymbolic Communication\nComputers have no concept of an in-person meeting. They communicate\nusing purely symbolic methods in binary numbers. These have the same\nmeaning whether communicated over a short piece of wire or using a\nfiber optic cable half way around the world. Computers never have to\ncommunicate understanding to each other because they use programs\nand a program can be perfectly transmitted. Body language is, of course,\ncompletely alien to them!\nWe know there are non-computable things; functions, numbers,\nmusical melodies, and mathematical puzzles. Why would there not also\nbe a place for non-computation in communication? David Deutsch has\nsuggested human creativity is used to guess the ‘program’ running in\nsomeone’s mind, and evolved so we can learn skills. Instead, might faceto-face\ncommunication be important because it lets us impart knowledge\nin a non-symbolic manner?\nHyper-communication\nAs with hyper-computing, hyper-communication is controversial. We\ninstinctively know human communication is very different to computer\ncommunication. Face-to-face communications have a qualitatively\n294 Are the Androids Dreaming Yet?\ndifferent feel to them. My question is this. Is there more to face-to-face\ncommunication between human beings than the simple exchange of\nsymbolic information?\nLet us propose an experiment. I erect a 3D screen with a hi-fi\nsurround sound system in a university lecture hall and deliver a lecture\nto a camera in the adjacent hall. Half the students see the lecture directly,\nand half remotely. With modern screens, it might be possible to set up\nthe experiment so well that is difficult to tell which hall I am actually in.\nIs the experience of the remote students the same as the ones sitting in\ndirect proximity with me? Do mirror neurons fire more strongly and\npick up more information when you see me in the flesh, or is the feeling\nthat a lecture is better when you are ‘physically there’ an illusion? You are\nperhaps less likely to fall asleep in my lecture if you are physically there\nbecause you are afraid I might walk over and hit you! What possible nonclassical\neffects could be in play when you see an event or communicate\nin person that might make the communication different? Here are two\npotential differences:\nInformation in a face-to-face encounter is continuous, not digitized.\nContinuous information is infinite in nature and does not have the finite\nlimitation of digitized data. Of course, if we have digitized the sound\nat 24 bits and replayed it with extreme fidelity, there should not be any\nloss in information, but the interactivity of the soundscape is hard to\nsimulate.\nLight entering your eye contains information that could be quantum\nentangled with the object you are viewing. You become part of the system\nrather than merely an independent observer. It is difficult to see why this\nwould produce a different quality of communication but it is testable.\nSet up the lecture experiment and measure the quality of understanding\ncommunicated between the parties.\nIf we believe our brains are super-Turing, then considering there\nmight be some similar effects involved in human communication is not\nunreasonable, perhaps quantum effects play a role in communication. If\nwe conclude our brains think classically, then we probably communicate\nclassically.\nChapter 14\nCREATIVITY\nThomas Edison, his wife and a Light Bulb\n“Creativity is allowing yourself to\nmake mistakes. Art is knowing\nwhich ones to keep.”\nScott Adams\n“Invention is 1% inspiration and\n99% perspiration.”\nThomas Edison\n“Creativity is just connecting\nthings. When you ask creative\npeople how they did something,\nthey feel a little guilty because\nthey didn’t really do it, they\njust saw something. It seemed\nobvious to them after a while.\nThat’s because they were able to\nconnect experiences they’ve had\nand synthesize new things.”\nSteve Jobs\nThe ancient Greeks believed there was no such thing as creativity.\nOur job, as humans, was to look at the earth and discover things\nabout it. When we looked at light passing through water or built\na boat to travel on it, we were discovering, not inventing. Shipwrights did\nnot invent boats they were simply building inevitable forms. Everything\nthere was to know already existed, we just hadn’t realized it yet. Of course,\nGreek playwrights were busy ‘creating’ the first plays; tragedies, comedies\nand the like, but serious thinkers thought of them as documenting the\nhuman condition. It wasn’t until the Renaissance, 1500 years later, that\nhumans began to appreciate that they create knowledge, and this started\nus on our quest to understand creativity.\nOne of my childhood memories is sitting on the kitchen floor with\na glass of water and surrounded by knives and milk bottles. I was trying\nto solve one of the problems from Edward de Bono’s book on lateral\nthinking, A Five-day Course in Thinking. De Bono, now in his 80s, is\na prolific writer with over 60 publications to his name – all aimed at\nmaking us more creative. His books pose a series of practical problems,\neach needing progressively greater creative intelligence. The particular\nproblem I was trying to solve was to balance a glass of water on knives\nsuspended from four milk bottles. It took me after 2 hours.\nSteve Jobs shows the iPhone\n298 Are the Androids Dreaming Yet?\nExcept for De Bono there is not much written about creativity\nin books or on the Internet, but if you dip into the video archive, the\ndiscussion really opens up. Perhaps this is a feature of creativity; it’s\neasier to explain in person. Of course, I have taken on the writing task\nwith this book but I have the benefit of modern day resources such as\nmultimedia, interactivity, and the web.\nSome people appear to have creativity in abundance and the things\nthey create are truly wonderful. I’m thinking here of Picasso, Einstein,\nMozart, Edison, or Maxwell, but a precise definition of creative thinking\nis hard to pin down. Here are some generally accepted categories:\nDivergent Thinking\nThe first sort of creative thinking we recognize is divergent thinking,\noften called brainstorming. This is the art of coming up with ideas – lots\nof them. A quick way to test your skill is to take a minute, and list all the\npossible uses for a paperclip. Try it!\nIn 60 seconds write down all the uses for a paper clip you can\nthink of. Time yourself.\nddd\nCreativity\n299\nANSWER WITHOUT READING ON\nThis is the classic test of creativity developed by J.P. Guilford in 1967.\nIt is called the Alternative Uses Task. You can try the task with many\nobjects: bricks, chairs, even water. How did you do on your first attempt?\n8 to 10 uses is about average, 20 is extremely good. It’s possible to teach\nmost people to get near twenty and I’ll show you how to do this in a\nmoment.\nAnother test of idea generation is to draw 30 things in 30 circles.\nThirty is such a large number it forces us to come up with some nutty\nideas and break our natural tendency to self-censor.\nFor example, I’d like you to create logos or logo ideas, for a new\ncoffee company in your circles. The test is best done without a time limit\nso now is the time to break off reading and make yourself a coffee. Then\ncome back and draw 30 circles on a piece of paper. Fill in the circles.\nMAKE A COFFEE, THEN START DRAWING.\nddd\nThe aim of brainstorming is to remove our inhibitions and get us\nto generate a mass of ideas. In normal life, we tend to suppress ideas\neven before we are consciously aware of them. Sir Ken Robinson has\nresearched creativity in children and found the ability to brainstorm\nreduces linearly with age. At five or six, children given one of these\ndivergent thinking tasks come up with many creative solutions: fold the\npaper clip into a dinosaur, and use it to attack your friends, get two and\nuse them as chop sticks. As adults, we tend to disqualify ideas. You could\nnever fold a paperclip that tightly or accurately, we said, “a” paper clip\nnot two. But, you can fold a paper clip tightly, and the room you are\ndoing the test in has thirty paper clips and thirty people in it so just team\nup with a friend. I never said this was a solo task!\nDo you see how you impose nonexistent rules on your thinking,\nparticularly the implied rule of not working with others? I did not say\nthis test was subject to examination conditions. The first twenty years of\nour lives teaches us to work alone on intellectual tasks, yet when we get\nto the workplace we can, and indeed must collaborate to succeed. Now\nyou have an idea how to ace the paper clip test: don’t censor yourself and\ndon’t imply rules I have not imposed!\n300 Are the Androids Dreaming Yet?\nTRY THE PAPER CLIP TEST AGAIN!\nddd\nDivergent thinking is rarely the final goal; it is rather a jumping off\npoint for the creation of something new, like a solution to a mathematical\npuzzle, a painting, or a novel invention. The exercises allow us to\nexplicitly see one of the early creative steps – idea generation before the\npruning step. But most creative people often just create, they don’t follow\na scripted process. The term ‘the creative process’ is a great misnomer.\nThere is no process that actually creates. Process merely puts us in the\nright frame of mind to do so. Processes are useful for framing a problem\nand ensuring we have all the right tools at our disposal: good crayons,\nsome nice art paper, a hot cup of coffee. But process must be put to one\nside at the moment of actual creation.\nConvergent Thinking\nConvergent thinking is the opposite of divergent thinking. It focuses\non discovering the final solution to a problem rather than generating\nprecursor ideas. Some creative people only use this method, avoiding\nlaborious processes such as brainstorming.\nTests of skill for convergent thinking generally pose puzzles where\nthere is only one correct answer, but one that requires a non-linear step.\nHere’s a really simple convergent thinking puzzle to try. It only requires\na piece of paper and pen. Draw a circle on a piece of paper with a dot in\nthe center. It should look like this. Do NOT take the tip of the pen off the\npaper until you are finished.\nCreativity\n301\nTRY ANSWERING IN YOUR OWN TIME\nddd\nAnother famous, but clichéd, problem is of you to draw four straight\nlines through these nine points without lifting the pen from the paper.\nCan you do it?\nTRY ANSWERING IN YOUR OWN TIME\nddd\nI won’t put the answers here, or even a hint. It’s quite famous and\nmany of you will be familiar with them. The answers are buried on the\nwebsite, and for those of you who already know the solution, there are\nsome alternative problems. If you can’t immediately solve a problem,\nthink about it overnight. It’s worth seeing what your brain will do while\nyou are asleep!\nThe Science of Creativity\nThe first person to theorize about the creative process was Graham Wallas,\nthe co-founder of the London School of Economics. In his book The Art\nof Thought, he proposed a five-step model for creative thinking. First\npreparation, when you become fully acquainted with the problem and\nits domain. Then incubation; walk the dog or make a cup of tea. After\nthe meditative incubation phase you may get a gut feeling that a solution\nis on its way. Wallas called this third step intimation. It’s left out of many\nmodern versions of his theory, but I think it’s an important step. Shortly\n302 Are the Androids Dreaming Yet?\nEureka\nafter this you get that Eureka moment – illumination or insight where\nthe creative idea bursts forth into your conscious awareness. The idea\nmust finally be verified. Many of our ideas will turn out to be mistakes,\nbut that’s part of creativity. In the nearly hundred years of investigation\nsince Wallas proposed this theorem, we have not moved much further\nforward in understanding creativity.\nAlan Turing described his thoughts on the science behind creativity\nin a short piece he wrote about decision making:\n“When making a decision of minor importance, I have always\nfound it advantageous to consider all the pros and cons. In vital\nmatters, however, such as the choice of a mate or a profession, the\ndecision should come from the unconscious, from somewhere\nwithin ourselves. In the important decisions of personal life, we\nshould be governed, I think, by the deep inner needs of our nature.”\nCreativity\n303\nLater in his career he came to believe machines would become\nintelligent and this sort of intuitive thinking could be effectively\nperformed by a computer. As you know, I don’t agree with his later\nviewpoint.\nAnother person who has thought long and hard about creativity is\nJohn Cleese, the comedian and actor. He describes the process wonderfully\nin a number of talks which you can find on YouTube. He finds a lot of his\ncreativity emanates from his unconscious rather than conscious thought\nprocesses. To optimize this he needs large uninterrupted blocks of quiet\nJohn Cleese on Creativity\n304 Are the Androids Dreaming Yet?\ntime. Often, if a problem seems impossible, he will sleep on it. When he\nwakes the next morning, he will frequently find the problem has solved\nitself and a solution is ready at hand.\nArt\nThe final class of creative thinking we generally recognize is artistic skill.\nThis is probably a form of convergent thinking, except both the problem\nand the solution are open. Good artists are considered highly creative\nand most people tend to agree on what constitutes good art. There are\nsome arguments but they are usually more about genres. I might not\nappreciate modern installation art, even to the point of declaring it, “not\nart.” But, when forced to ignore their prejudices most people tend to\nagree on the distinction between good and bad.\nPainting, sculpture, music, architecture and poetry are the\ntraditional fine arts. There is often some argument over architecture: is\nit not too ‘functional’ to be considered an artistic endeavor? After all,\nart is not supposed to have any purpose other than to be, well, art. This\ndefinition inevitably leads to arguments about whether bad art is still ‘art’.\nArt should be artful and how do you arrange a pile of used tires artfully?\nBut this is a very narrow definition. I prefer to define art as something that\nprovokes an emotional response in the beholder. Using this definition,\nthe fact that a pile of tires disgusts and annoys you is exactly the point.\nPerhaps a more ‘enlightened’ viewer than you is intrigued by the clever\nuse of materials.\nRegardless, we consider art to be a creative endeavor and we can\nmeasure it using the criteria of novelty and quality. Since most people\nagree on these measures for a given piece of art, we can use the wisdom\nof crowds to give us a scientific scale. That does not mean there won’t be\nart that you love but which leaves me cold. That is the joy of it. Novelty\nand quality are not the same as joy and pleasure, far less the tingle factor.\nddd\nA quick test for artistic skill is to take a pen and paper and turn to\nthe person sitting on your left and try to sketch them.\nTRY IT!\nCreativity\n305\nIf you tried, you and your neighbor would probably find the results\nrather humorous. But, most likely, you did not follow my instruction.\nThis is a form of social self-censorship. I asked you to do something rather\ndifficult and embarrassing, but very creative and likely to enlighten you.\nSadly most people – I am no exception – tend to censor their creativity\nfor fear of embarrassment. Children, of course, do not sensor themselves\nas much as adults.\nNow you know how to be more creative. Find your inner child and\ndon’t censor yourself too much!\nWhat Sparks Creativity\nAs an inventor, I’m often asked what makes me creative. How do I do it?\nThe answer is, I have no real process. After all, a process is mechanical\nand this entire book has been about exploring how creativity is a nonmechanical\ntask. However, there are many things you can do to unleash\nyour creative potential.\nNew ideas are often sparked through linking disparate ideas. Expose\nyourself to as many ideas as you can, read widely, attend conferences,\nvisit customers.\nCreativity requires peace and quiet. I personally get up early every\nmorning. This gives me a good two hours of uninterrupted time every\nday. It’s also the part of the day when my brain works best. Others prefer\nto work late into the night.\nPressure, for me and for many people, is a great incentive. Tales of\nthe Polish Enigma code breakers, Douglas Adams’ writing deadlines and\nthe fear of impending death in shark attack stories all force people to\nthink in an accelerated way. This appears to help many people defeat the\nhuman tendency to prevaricate.\nOn the other hand avoid panic. While a level of pressure can help,\npanic is unproductive. There is a sweet spot between having enough time\nto get properly acquainted with a problem and an impending deadline\nto force the crystallization of ideas. This balance varies from person to\nperson and is something you need to test for yourself.\nYou need time off. Once you have a well thought out idea, you\nmay need to leave it alone for a while to allow your subconscious to\nwork. Time off does not need to be two weeks at the beach. Charles\nDarwin and Benjamin Britten used to go for long walks. You can walk in\nDarwin’s footsteps at Down House in Kent. Others such as John Cleese\n306 Are the Androids Dreaming Yet?\nlike to ‘sleep on it’. Stephen Hawking distracts himself by working on a\ndifferent problem for a while. Anything that avoids focusing directly on\nthe problem itself seems to allow our creative freewheel run.\nEnvironment can be important. The campuses created by Steve Jobs\nfor both Apple and Pixar are designed to foster creativity. The physical\nenvironments build team behavior but also cause people to bump into\neach other. Cross-pollination drives creativity.\nThere are also some myths to dispel about creative people. Inventors\nare portrayed as eccentric and hopelessly disorganized, but Feynman\nkept notes of every idea he ever had. I have kept a series of notebooks,\nnow computer based, since I left university. I still have almost all of these\non a shelf at home. Creative people may be a little mad, but the successful\nones are rarely disorganized.\nYou must allow your brain to free wheel. J.K. Rowling has said the\ncharacters in the Harry Potter novels write themselves. I come to my\ncomputer each morning having not thought too much overnight and\njust write. Creation is just that; you must allow yourself to do it. It’s not\na process.\nThe Innovator’s Dilemma\nWhy don’t big companies create? In 1997, Clayton Christensen of\nHarvard Business School wrote The Innovator’s Dilemma, the seminal\nwork on creativity within organizations. In it, he shows us why established\ncompanies tend not to innovate and why startups exist. Christiansen’s\nacademic research examines how companies handle discontinuous\nchange in technology, focussing on the hard disk industry.\nYou might not think this a very sexy sector. Microprocessors and\ngame consoles would be more fun, but the great advantage with the hard\ndisk is there is a single industry journal that has tracked the progress of\nevery player over 30 years, collecting detailed annual data on every facet\nof their business. For an academic, this is gold dust.\nIBM invented the hard disk drive in their research center near\nWinchester, England. The first prototypes were, consequently, called\nWinchester Drives. When Christiansen examined the industry, he found\nsomething very strange. As the size of disks reduced first from 8” to\n5¼” and then from 5¼” to 3½”, the dominant players in the previous\nera went out of business and new startups colonized the market. This\nfallout was not confined to a few small companies. It affected large, wellestablished,\npublicly-listed organizations, too. They failed en masse at\neach discontinuity. At first this made no sense to him. Surely a skilled\nCreativity\n307\nHard Drives\nhard drive manufacturer would be the obvious group to construct the\nnext generation. But it seemed that not only did incumbent players not\nconstruct the next generation, they ran their businesses into the ground\nwhile ignoring the technology discontinuity. Despite their legions of Ivy\nLeague graduates and business school MBAs, they all went bankrupt.\nAs he looked around the economy, he found a similar pattern in\nother sectors. Minicomputer companies failed to make the jump to\npersonal computers. Further back in time, buggy whip companies –\nin the Fortune 100 at the turn of the 20 th century – failed to make the\ntransition to the motor vehicle economy. The only exception he could\nfind was IBM. IBM had successfully navigated some transitions but\nat that time was fighting for survival as companies transitioned from\nmainframes to Linux based servers and their survival was in question.\nWhy was this so?\nChristensen’s conclusion is that established companies tend to\nconcentrate too much on their existing revenue streams while ignoring\npotential new ones. This is no surprise. When the disc drive industry\nmade the move from 8” disks to 5¼”, the only customers for these\nnew new smaller models were unheard of manufacturers of personal\ncomputers. Some were based in the dorms of MIT and Harvard – Dell\nand Compaq – not in the existing powerhouses of computing – Digital\n308 Are the Androids Dreaming Yet?\nEquipment and Wang. New technology often underperforms the existing\nforms. 5¼” drives were slower, less reliable, and cost more per bit than\ntheir 8” predecessors but, of course, in one respect they were better. They\nwere smaller and lighter and could fit in portable computers. The new\ntechnologies did a different thing in a different way, and overcame their\ndisadvantages later. This chain of events is repeated many times over:\nYellow Pages overtaken by Google, Borders by Amazon, Blockbusters by\nNetflix. Disruptive innovation changes the rules of the game as well as\nthe pieces in the game.\nChristensen’s advice to companies is to separate your innovators\nfrom the existing business because their priorities will differ too greatly.\nModern companies build entirely new divisions to create new products,\nor set up innovation labs to incubate ideas that would otherwise never\nget enough resources.\nReward for Creativity\nThere’s no doubt society values creativity very highly. One of the first\ntasks Thomas Jefferson undertook when he became President of the\nUnited States was to set up a patent system. He remained head of the\npatent office for over ten years. These days, the protection of creative\nHarold Cohen, Computer Art\nCreativity\n309\nideas through patents, copyright, and trade secret is big business and\ncombines to form the practice of ‘intellectual property’. Societies with\nthe best protection of intellectual property are often the most successful.\nThe USA is the unassailed leader, with Asian countries rapidly catching\nup. Poor old Europeans have struggled with an almost unworkable\npatent system for nearly 30 years; a genuine Europe-wide patent only\ncame into effect in 2013.\nCreativity in the economy is now extremely important, and nothing\nemphasizes the point more than the job market. During the 60s finding a\njob was easy. There was an almost unlimited range of mechanical jobs on\noffer. In the post-industrial age, almost all the mechanical jobs have gone.\nToday we need to be experts in a field, able to solve problems creatively.\nYou can’t expect to walk into a job and be profitably productive on the\nfirst day. Finding a job is harder and the cost of employing someone is\ngreater.\nWhy did we Evolve Creativity?\nRoger Penrose wonders why mathematical creativity evolved in humans\nsince it only became useful in ancient Greece a few thousand years ago.\nHe believes it must have been useful for something before this. But what?\nDavid Deutsch thinks creativity developed to allow one human to\nunderstand the thoughts of a fellow human being. We can’t precisely\ncommunicate the ‘programs’ we run in our heads. We are unable to\ndownload a detailed thought and put it on a memory stick. He thinks\nour creative capacity developed to help us pass skills from one to another.\nThe ability to paint and sculpt is an accidental by-product of this adaption.\nIt’s my view we evolved creativity to deal with new situations\nand puzzles in our daily lives. We use creative thought processes and\ningenuity to come up with novel solutions for when we can’t rely on\nprogramming or a store of rules. Otherwise, the very first unforeseen\nsituation could kill us!\nComputer Creativity\nHumans find creativity difficult. It requires peace and quiet, detailed\nstudy and input of caffeine. How does a computer fare? I have argued\nthat computers cannot be creative above the logic limit, so this does not\npreclude them from creating within the narrow confines of a particular\nsolution space. But a human still needs to set the rules for this space. The\nlevel of creativity we should see from computers is convincing within\n310 Are the Androids Dreaming Yet?\na limited conceptual area. Computers are not going to wake up one\nmorning and decide to compose a breathtakingly beautiful symphony,\nbut if we give them rules they can make a convincing version.\nMany computer systems have been designed to tackle creativity. We\nhave already met the composer Emily Howell and Douglass Hofstadter’s\ncomputation program. Here are two more examples: Jape and AARON,\nwhich create jokes and art, respectively.\nJape – Joke Analysis and Production Engine – is a program created\nby Graeme Ritchie and Kim Binsted. It generates puns, the sort of things\nyou might find in an English Christmas cracker or children’s joke book.\nI’ll let the output speak for itself.\nQ: “What is the difference between leaves and a car?”\nA: “One you brush and rake, the other you rush and brake.”\nQ: “What do you call a spicy missile?”\nA: “A hot shot!”\nOne of the most enlightening examples of computer creativity is\nAARON – refreshingly not an acronym. His machine is depicted here\nand you should look up some works on the web, such as Adam and Eve,\nand Aaron’s Garden. The program encodes rules about figures, objects\nAARON – Harold Cohen, Automatic Painting Machine\nCreativity\n311\nand perspective. Once coded the program takes off and is remarkably\ncreative in its compositions, without any further human intervention.\nHowever, each new capability must be hand-coded by its creator, Harold\nCohen. These paintings give a good visual interpretation for the sort of\nlatitude imposed by the logic limit. AARON can do some very impressive\nthings, but always in a mechanical – albeit beautiful – way, within the\nrules set by Harold Cohen, the true artist. AARON will not suddenly\nawake one morning and independently decide to experiment with the\ncolor blue!\nTo give an idea of what I mean by ‘mechanical elaboration’ in a\nmusical context, imagine you were using a Casio synthesizer. These\nmachines have all sorts of fun settings. You can program them to play\ndrum tracks, fill in chords, and add a jazzy, syncopated harmonization\nto your melody. But none of this is truly innovative. It’s mechanical\nelaboration of your artistic material. Jape, AARON and Emily Howell\nall do the same thing within their domain. They mechanically elaborate\nthe artistic creation of their human masters. AARON does an extremely\ngood job of this.\nThe Myth of the Design Tradeoff\nAn important consequence of the non-linearity of creativity is we are not\nconstrained by tradeoff laws. Let me explain.\nVolkswagen Polo\n312 Are the Androids Dreaming Yet?\nHow often do you hear the phrase, “It’s down to tradeoffs,” or “It’s a\nmatter of priorities”, or even “You can’t have your cake and eat it.”\nThese stock statements misunderstand the infinitely complex nature\nof creativity and problem solving. Let us take a concrete example: the car.\nMy first car was a Volkswagen Polo. It was a great little car, quite\nnippy, cassette-radio, and four seats. The most recent Polo has antilock\nbrakes, airbags, NCAP 5-star crash resistance, smarter styling, and a low\nemission engine. Shall I go on…? The doctrine of tradeoffs says I would\nhave to give up something to gain these new features. But, I have not.\nThe newer Polo is cheaper in real terms than my original, as well as being\nbetter designed.\nProblems always have at least two dimensions of freedom. We can\ntrade one feature for another or we can innovate to both have our cake\nand eat it! We are never constrained to simple on-the-one-hand, on-theother-hand\ntype decisions. Creativity is unconstrained by linear rules\nand tradeoffs.\nProcess versus Creativity\nHow many times have you heard the words, “We must create a process\nfor this!”\nIn its place, process is good; It makes things consistent, repeatable\nand predictable. You can follow a process by rote without error. Processes\nare also easy to document and communicate because they are symbolic.\nBut process is limited. It is, after all, a set of prescribed rules for solving a\nparticular problem – and, because of this, it falls into the same trap.\nA process cannot solve a problem that requires creative thought or\nlogic more complex than the logic limit. Logical processes are useful for\ntracking lists. I am reassured when I get on an airplane and know the\npilot has been through a preflight checklist. I would not want to fly in an\nairplane where the pilot announced he was taking a creative approach to\nthe preflight check.\nProcess is a perfect tool for organizing the steps around being\ncreative, but it won’t do the creating for you.\nChapter 15\nFREE WILL\nDilbert Ponders Free Will\n“We have to believe in free will -\nwe have no choice.”\nIsaac Singer\n“Time really is an illusion -\nlunchtime doubly so.”\nDouglas Adams\nchild grows up in poverty, their father absent, mother a drug\naddict. Riots break out and the child defends the local convenience\nstore. Another child born on the same road, but from a better\nbackground, loots the store and is arrested. This scene played out on\nthe streets of London during the summer of 2011, but similar incidents\nhappen all across the world. People choose different moral paths; one\nperson makes a good decision; the other, a bad one. Did they make these\ndecisions freely or was their behavior inevitable, dictated at the dawn of\ntime?\nFree will is at the heart of our justice system. It requires a crime to\nbe intentionally committed by a person of sound mind. If I kill you in\nan accident or because I am mentally incapacitated, I am innocent. Of\ncourse, if I mentally incapacitate myself with alcohol I would be guilty of\nmanslaughter, perhaps even murder.\nOur justice system requires a crime to be intentionally committed\nby a person of sound mind. Whenever we see something bad in the world\nwe trace the events back to the thought processes which led up to it. It\nseems we punish the decisions in our brains leading to a crime, not the\ncrime itself. But, in a deterministic Universe my thoughts could never be\nat fault. They are inevitable. “The Universe made me do it!”\nYou need not worry about the fabric of society falling apart in a\ndeterministic Universe. The whole of existence will play out according to\na predetermined script, complete with lawyers, trials, drama and pathos.\nThe judge, jury and executioner would also have no free will. It would\nlook as if you paid the price for the choices you made, but this would\nbe an illusion. The whole thing would be like one enormous screenplay.\nThe concept of determinism goes against our conscious experience.\nWe all have a strong sense of free will. I certainly think I have it! And this\npresents a problem, because the classical laws of physics say our Universe\nis entirely deterministic, and that free will is an illusion.\nI should briefly mention ‘compatibilism’, a branch of philosophy\nthat claims determinism is not at odds with free will. It argues that if\nI feel free and my actions do not appear constrained, then I am free\neven though my future might be inevitable: a sensation of freedom is\nsufficient. This seems rather feeble. I am seeking an explanation for\nhow we might be truly free to choose our actions, not some linguistic\ntrick to argue freedom is subjective. I believe true free will is a physical\nprinciple with observable effects on the Universe that would not be seen\nin a determined one.\n316 Are the Androids Dreaming Yet?\nDomino Toppling\nDeterminism\nTo firmly grasp the idea of determinism let’s look at a fun example,\ndomino toppling. If I arrange a set of dominoes on their edge in a\nlong line and push over the first it will fall, knock over the next, then\nthe next, and so on until all the dominoes have fallen. It is inevitable,\nand fun to watch. The same is thought to happen with particles in our\nUniverse, albeit at a much smaller scale. The laws of physics governing\nthese particles describe precisely what will happen as they interact. Our\nUniverse could be thought of as a mechanical clock, wound and set at the\nBig Bang, or a fractal equation generating the wonders we see around us.\nWhen I push over the first domino it should be possible to capture\nall the information about the particles in the dominoes, my hand, the\ntable, and the surrounding environment to precisely determine what will\nhappen next. Will all the dominoes fall perfectly, or is there a break in the\npattern – one domino just a tiny bit out of alignment – which will spoil\nthe fun? All the information is there in front of me and I should be able\nto predict it perfectly.\nThe laws of physics, as we understand them, are not only\ndeterministic, they are reversible. This means if we know the position\nand momentum of every particle in the dominoes and the surrounding\nenvironment, we can extrapolate their motion back into the past. It\nshould be possible to trace back the path of each particle to reconstruct\nthe past history of the dominoes.\nIf we were to cast a wide enough net, and collect all the available\ninformation, we could go back and see the events in the factory where\nthe dominoes were made, or even see the trees that was felled to make\nthem. We would need a lot of information and huge computing power,\nbut we could do it! With a sufficiently powerful computer we could travel\nFree Will\n317\nback in time, albeit as a simulation, and relive past events. This would\nhave no effect on the events themselves as it would be like watching a\nmovie, but we could see every aspect of the past from any viewpoint.\nTo perform this time travel trick for real, we would have to gather\ninformation from an enormously wide area. Information spreads\nout at the speed of light. One minute after the dominoes topple, the\ninformation about the event will have spread one light minute – that\nis over a sphere forty-million kilometers across – half way to Venus.\nAn hour later and it would be outside the solar system. If you were to\ncast your net that wide, and gathered up all the information within the\nsphere, you could still perfectly model the moment when the dominoes\nwere toppled. The wider you cast the net, the more information you have\nand the further backward in time you can travel. If you take the idea of\ncollecting information to its logical conclusion you could gather all the\ninformation in the Universe at a moment in time.\nIn 1814, Laplace put this idea in an essay. He proposed an immensely\npowerful being observes the position and momentum of every particle\nin the Universe. Armed with any snapshot of the Universe and the laws\nof physics, the entire future and the past of the Universe. The being was\nnicknamed Laplace’s Daemon and the idea has influenced philosophy\never since.\nIf the Universe is predictable, our concept of time needs to be\nrethought. A common sense notion is that things in the future are unknown\nand things in the past are known. But, in a deterministic Universe a\ndaemon or a supercomputer could keep track of all the information and\ntell you what is inevitably going to happen. The conscious feeling we have\nof moving through time would be just an illusion. Past and future have\nno meaning and there would just be a solid, permanent block of spacetime.\nIf you stood outside the Universe and looked at this block of spacetime,\neverything that is going to happen and has already happened is set.\nThis is sometimes called the Block Universe Hypothesis and is the logical\nconclusion of any theory that imagines an entirely determined Universe.\nOne thing that seems to throw doubt on this Block Universe\nHypothesis is our personal conscious experience of the world. We\nexperience the Universe unfolding over time. (Of course, we could have\nthis conscious experience in a determined Universe if someone had\nprogrammed it that way. All we can say is that it seems unlikely someone\nwould go to the trouble of giving us a completely fictitious experience.\nThere are an infinite number of possible Universes, why pick one where\nwe think time flows, but it does not.)\n318 Are the Androids Dreaming Yet?\nUncertainty\nIf you know a little of quantum mechanics you might imagine Heisenberg’s\nUncertainty Principle comes to our rescue.\nHeisenberg’s principle is often misunderstood. People sometimes\ntry to explain it as an experimental problem. If I want to measure the\nposition of a particle I am going to need to shine a light on it. The photons\nI use to illuminate the particle will knock it out of position so the act of\nmeasurement disturbs the system. This is not the Uncertainty Principle.\nIt is a different but related effect, called the measurement problem. The\nmuddle is really Heisenberg’s own fault. When he tried to produce a\nlayman’s explanation he used the analogy of disturbing the particle with\nthe photon. This is wrong. A photon would not disturb a particle enough\nto explain the uncertainty we find; particles are fundamentally uncertain\neven before we measure them. Heisenberg’s Uncertainty Principle is\na quantum property, which means it makes no sense and there is no\nanalogy I can give you to properly explain it! Here is the closest thing I\ncan find.\nImagine I am playing a musical note on a guitar. You might want\nto know two things about it; where exactly is the string and what pitch,\nor note, am I playing? The problem with these two measurements is they\ncan’t be stated at the same time. Pitch is dictated by the rate of oscillation\nover time: the number of times a string vibrates back and forth per\nsecond. Position is the exact location of the string at a given moment in\ntime. If I state the position precisely this has no pitch because pitch needs\na time interval. If I allow a time interval the string will move during that\ntime and it won’t be precisely in one place. The best I can say is the string\nis about two millimeters above the fret board and two-thirds of the way\nacross it.\nSo, I hear you cry, this Uncertainty Principle means our Universe is\nnot deterministic because it is uncertain.\nUnfortunately, the principle only prevents us from measuring the\nposition and momentum of a particle at the same time, it does not prevent\nthe Universe knowing the information it needs to allow the particle to go\nabout its business in an entirely deterministic fashion. There is a perfectly\nreliable and predictable wave function that governs the motion of every\nparticle, just as there is an entirely predictable equation for the motion of\na string on a musical instrument.\nIf both the classical and quantum laws of physics are deterministic\nwhere does the freedom come from to make our Universe nondeterministic?\nThere is just one place to look: you and me.\nFree Will\n319\nThe Observer\nI am looking out of my office window. It is a sunny autumn day and I\nhave a beautiful view over London, but if I squint a little I can also see\nmy reflection. The window in front of me is not perfect. Although it is\nmostly transparent, the glass also reflects some of the light. If you think\nof light as particles, the majority of the photons go through. But some\nbounce back. I’m going to show you that the behavior of these photons is\ngoverned by the observer – me!\nThe laws governing light, and most of the strange and wonderful\neffects it has, were first stated by Isaac Newton. Newton was an\nextraordinary man. He discovered many of the physical principles we use\ntoday, and his view of the Universe reigned unchallenged until Einstein’s\ndiscovery of relativity. He was also, by many accounts, a nasty piece of\nwork. Not only was he a famous academic, he also head of the Royal\nMint. He is said to have taken great pleasure in having forgers hanged\non Tower Hill. He claimed the invention of differential calculus despite it\nbeing invented independently by Gottfried Leibniz. Newton managed to\nhave himself appointed to chair the committee reviewing Leibniz’s work\nand determine who had come up with the idea first. Unsurprisingly, the\ncommittee found for Newton!\nWe see Newton’s laws of reflection and transmission in all manner\nof everyday products, for example, the antireflective coatings of camera\nlenses or the screen of your smartphone. Manufacturers cover the glass\nin these products with coatings just a few molecules thick. Interference\nbetween the layers kills the reflections. On a very expensive lens several\ndifferent layers are used; some kill red light and others kill blue light.\nTogether they suppress most of the reflection. If it were not for these\ncoatings you would be unable to go to the park on a summer’s day and\nread your iPad. We need to think about reflection and transmission to\ndemonstrate our role as observers.\nA windowpane has two surfaces. Both surfaces reflect light, and if\nyou look closely you will see your face is really reflected twice. You might\nthink this is simply a double reflection but this is not so. Light behaves\nlike waves. As with water waves, they interfere with one another. If two\nlight waves are at the top of a crest as they meet, the result is a crest of\ndouble height. If both are at the bottom, you have a double trough, and if\none is a crest and the other a trough you get nothing as they cancel each\nother out. You can see this effect in waves on the surface of a pond.\nWhen light strikes a window pane, the light has two chances to\nreflect: one from the front surface and the second from the back surface.\nThese two reflections interfere with each other. And, again, when you\n320 Are the Androids Dreaming Yet?\nWave Interference\nhave interference you sometimes get constructive interference – the\ndouble crest or trough – and sometimes destructive interference – the\ncrest and trough canceling each other.\nThe reason we don’t see this effect in every reflection is because of\nimperfection. Windows are not perfectly flat and light is multicolored, so\nthe effect is hard to see. But it is definitely there, and if you look really hard\nat a reflection in a window, you can sometimes see it at the boundary of\nsharp objects. The effect is very clear in the next picture which has been\nset up with two flat pieces of glass resting against each other. There is a\ntiny air gap between them. It is also commonly seen on puddles in cities.\nIn this case the puddle usually has a slight film of oil on it. Unlike glass,\npuddles are perfectly flat thanks to gravity, but the oil film is thick in the\ncenter and thin at the edges. The light reflecting off a puddle will show a\nrainbow of colors. This is because each color is giving us a pattern of light\nand dark. If you look at the same puddle at night in a yellow streetlight,\nyou will just see a monochrome pattern of light and dark. Look at the\npicture of waves on a pond.\nThe patterns of light and dark are usually explained by imagining\nthe photons interfere with each other. This explanation is insufficient.\nImagine for a moment you can see as well as a frog, and perceive one\nphoton at a time. One moonless night just one photon comes to the two\nglass surfaces and reflects. What happens?\nFree Will\n321\nNewton’s Rings\nIt turns out a single photon can interfere with itself! How can this\nbe? It must somehow split up and consider both the available paths\nreflecting off the glass surfaces.\nNow that we have these two concepts in our head, that a photon\nsometimes reflects and sometimes does not, and a single photon must\nconsider both paths, we can ask: what tells the photon what to do?\nThere are only three possible answers: the light source that emitted\nthe photon, the pane of glass that reflected the photon or the observer\nthat saw the photon – me.\nThe first obvious place that might control the photon is the original\nsource of the photon; the light bulb. The photon might leave the bulb\nalready knowing what path to follow, whether it will be reflected and\nwhether that reflection will be affected by the gap between the two\nsurfaces in a positive or negative way. This is sometimes called a pilot\nwave theory. The problem with this theory is I could insert a piece of\nglass into the experiment after the photon has left the light source. This\nwill affect the photon but the light source could not have known my\nintention in advance and told the photon what to do. Therefore, the path\nof the photon is not pre-programmed by the light source.\nNow our photon has left the bulb and is traveling toward the glass.\nThe glass has two surfaces. The photon reaches the first surface and has\nto decide if it will reflect. But there is a problem. The second surface\n322 Are the Androids Dreaming Yet?\nwill have an effect on this decision – constructively or destructively. The\nphoton can’t make up its mind at the first surface. It has not yet seen the\nsecond surface.\nThe photon travels on and reaches the second surface. It needs to\nmake a decision: Shall I reflect or not? It cannot decide that it should\nhave been reflected from the first surface because it is already at the\nsecond surface; it’s too late.\nThe photon is stuck. It cannot make the decision at the first surface\nbecause that is too early, nor at the second surface because that is too late.\nThe glass surfaces cannot be the source of the decision.\nThis leaves only one remaining option: I, the observer, tell the\nphoton what to do. The word ‘tell’ is probably a little strong. Sadly, I am\nnot that powerful. All I can do is tell the photon to make up its mind.\nWhen the photon reaches my eye, it must decide what happened to it\nalong the journey, but this decision appears purely random and I have\nno effect upon it. The best way physicists have found to describe what is\ngoing on is to say particles, such as a photons, behave according to a wave\nfunction. Particles oscillate between all the possible options available to\nthem and when we take a measurement this freezes the oscillations and\ngives a single result.\nWhere exactly is the measurement made? At my eye when the\nphoton is refracted by the lens, when the photon enters the aqueous\nhumor, or perhaps as it interacts with the rods and cones in the retina.\nMaybe we must wait until the detection of the photon is converted into\nan electrical impulse in the optic nerve or even the point at which my\nhuman consciousness perceives it.\nThis prompted the physicist John Bell to ask a slightly tonguein-cheek\nquestion, “Was the world wave function waiting to jump for\nthousands of millions of years until single-celled creatures appeared? Or,\ndid it have to wait a little longer for some more highly qualified measurer\n– with a Ph.D.?” You see his point. Where is the bar set that defines a\nmeasurement?\nOne of the most extreme answers to Bell’s question is the strong\nanthropic principle. It argues humans – or at least sentient beings,\nperhaps even cats – cause the Universe to exist. The Universe bubbles\nalong in a state of superposition with every possible event occurring and\nbifurcating until an observer emerges in one of the branches and the\nwhole edifice collapses to that state. It is not clear if this produces many\nconcurrent universes or if the first universe with a sentient being wins!\nFree Will\n323\nSolvay Conference\n“There is no way to understand\nthe mechanism that turns the\nwater of the brain to the wine of\nconsciousness.”\nColin McGinn\n“If you think this Universe is\nbad, you should see some of the\nothers.”\nPhilip K. Dick\nSchrödinger’s Cat\nMeasurement is a big puzzle. What causes the collapse of the\nwave function so that the photon stops considering many\noptional paths and makes a hard and fast decision. When light\npasses through a series of glass surfaces, it is reflected or transmitted by\neach. We can stack up as many pieces of glass as we want, but none of the\nsurfaces will cause a measurement – a collapse of the wave function. It is\nnot until the photon reaches a detector that a measurement is made and\nall the potential reflections and transmissions that might have happened\n‘collapse’ into the one choice that actually happened.\nYou might doubt this but there are ingenious experiments that can\nbe performed to prove it. One is quite simple to do and can be set up\non your kitchen table with a handheld laser and $100 worth of optical\ncomponents. You need three ordinary mirrors and a beam splitter. Beam\nsplitters are often made from half-silvered mirrors. They are similar to\nyour bedroom mirror except the silver coating is more thinly applied,\nallowing only half the light to reflect while the rest passes straight\nthrough. Arrange the mirrors and beam splitter on a table at the four\ncorners of an imaginary box, as in the diagram. If you point your laser at\nthe half-silvered mirror, half the light will go straight through and half\nwill be reflected upwards towards the first mirror. It is sent on around the\nsquare until it meets the half-silvered mirror again, and the beams meet\nup. You might expect that half the light reaches the detector but this is\nnot what happens. Depending on the way the mirrors are positioned,\neither all the light reaches the detector, or none does. (The light does not\ndisappear it just gets sent back to the light source, energy is conserved.)\nIf you turn down the brightness of your laser, this does not change. Even\n326 Are the Androids Dreaming Yet?\nInterferometer\nif only one photon is traveling at a time, still no light comes out in one\ndirection and all the photons come out the other. The wave functions\nof each photon interfere with each other constructively or destructively.\nThe only conclusion available is the photon must be traveling along both\npaths! They are said to be in ‘superposition’. If you introduce a measuring\ndevice half way around the experiment, it will destroy the superposition\nand the photons behave in the common sense way. Remove the measuring\ndevice and, once again, the photons seem to take both paths. Richard\nFeynman pointed out that you really have to imagine that the photons\ntake every possible path, not only the straight line paths. He received his\nNobel Prize for demonstrating how to add up these infinite paths to get\na finite answer with his ‘sum over histories method’. Superposition is a\nstrange idea when limited to the realm of small particles but what about\nlarger things? – cats for example.\nErwin Schrödinger’s unfortunate cat is trotted out to demonstrate\nthe paradox so often that Stephen Hawking is on record for wanting to\nreach for a gun every time he hears mention of it.\nThe thought experiment works like this. A cat is put in a box with\na radioactive substance, a Geiger counter and a vial of poison. If the\ncounter detects a radioactive decay it breaks the bottle and the cat dies, if\nno decay is detected the cat lives.\nFree Will\n327\nSchrödinger’s Cat – both Alive and Dead\nSince radioactive decay is a quantum event, we have to assume\nit might or might not have happened right up until the point of\nmeasurement. It is the same with any quantum event: photons reflecting\nfrom a piece of glass, measuring the spin of an electron or measuring the\npolarization of a photon. All these quantum effects exist in superposition\nuntil measured. But in the real world, we don’t experience superposition.\nIf I miss the train, I miss it. I don’t partially catch it and partially miss\nit, and I don’t experience any such quantum ambiguity. The only place\nI ever see such effects is watching science fiction movies. In real life the\nlarge scale world is certain. At what point does this quantum uncertainty\ntransition to our classical certainty? What is the state of the cat before I –\na sentient observer – open the box? Was the result of the decay measured\nby the Geiger counter, the cat, or are we waiting for someone to open the\nbox and observe the result?\nThe Copenhagen interpretation of quantum mechanics – named\nafter the main center of early quantum theory at the Niels Bohr Institute\n– says the cat is both alive and dead until I make a measurement. The cat\nis said to be in superposition, meaning a live cat and a dead cat inhabit\nthe same volume of space-time ‘experiencing’ both alternatives and\nwaiting for my measurement. This seems nonsensical, but Copenhagen\nquantum folk simply say, “That’s the way it is; the mathematics works, if\nyou don’t like it, tough. Nature does not have to explain herself.”\nEinstein strongly disagreed with this position. He believed the\nworld is certain and laws must govern radioactive decay and, therefore,\nthe breaking of the vial and the life and death of the cat. There must be\nsome, as yet, undiscovered theory. He reasoned as follows: A particle\n328 Are the Androids Dreaming Yet?\nhas position, velocity and spin. Why can it not have more hidden\ninformation that tells it when to decay? Perhaps particles are composed\nof sub-particles that cause the weird quantum effects we see.\nWe have discovered sub-particles – quarks and the like – but more\nthan a hundred years of experimentation have gradually ruled out any\nform of theory explaining how these random events can be governed\nby the properties of the particle. The collapse of the wave function just\nseems to happen randomly.\nThere is one explanation for quantum mechanics that avoids\nthe measurement problem altogether but it is even stranger than the\nCopenhagen interpretation: ‘the many worlds’ view’. The idea was first\nput forward by Hugh Everett in 1957, and it claims measurements are\nnever made, there is never a collapse of the wave function, and every\nwave continues to exist. We just can’t see them all. There is a version of\nme that has seen a live cat and another in a parallel universe that saw a\ndead one. The two versions of me are also in superposition, just like the\ncat, so there are an infinity of parallel universes tracking every possible\noption.\nThe only measurable consequence of this ‘many worlds’ idea is the\nexistence of enormously enjoyable science fiction plots and much poking\nof fun between the many worlds camp, and the no-many-worlds camp.\nThe single-worlds proponents point out the whole idea is untestable and\njust plain odd. For example, each choice we make, every reflection and\nany quantum process generates a new branch in the Universe. This is a\nvast amount of information to track and puts us back in a position where\nmoral choices have no consequence. Every decision I make spawns a\nUniverse where I made a different choice.\nFor a humorous take on this, you can visit a website and buy your\nown Universe for $2.99. You pose a question based on the throw of a die,\nlet’s say, one to three I go to work today and, four to six, I take a sick day.\nThe website generates a quantum random number using an experimental\nsetup at a laboratory in California. You can make your choice based on\nthis quantum random number in the certain knowledge that another\nUniverse springs into existence where you made the alternate choice, so\nsomewhere you are not taking a sick day after all, and can be found hard\nat work at your desk.\nThere is one more explanation for quantum measurement, proposed\nby Roger Penrose. He proposes gravity comes to the rescue. Once enough\nparticles are involved in the superposition of states, the curvature in\nspace time becomes great enough to force a measurement event. In\nhis view, a measuring instrument is simply an amplifier which brings a\nFree Will\n329\nquantum event to the point where gravity begins to matter. His solution\nremoves the requirement for many worlds and, indeed, our curious\nposition as the conscious beings that bring the world into existence. Of\ncourse, Penrose does not stop there. He proposes the quantum gravity\ninteraction gives rise to conscious thought and this process is the root of\nmathematical intuition.\nThe aim of our discussion is to show where determinism might break\ndown in the physical laws of the Universe. If our Universe is determined,\nthere will need to be a huge quantity of information stored somewhere\nto tell it what to do at each step. Storing a script for the Universe is not\nthe conventional way people imagine determinism works. Rather they\nexplain the apparent complexity we see through the application of a\nsimple set of rules called ‘the laws of physics’. We imagine using these\nlaws to expand up a small set of starting conditions into the complexity\nof the Universe we experience. This is similar to the way fractals produce\nbeautifully complex images from a tiny quantity of information. For\nexample, the Mandelbrot set is created from a single, simple mathematical\nstatement just twelve characters long, with one or two starting numbers.\nIf this is how our Universe works then our thoughts and actions are just\nlike the fronds of a fractal. It would mean the particles in the Universe\n‘know’ what they will do next and carry enough information with them\nto determine their next action. This is a testable hypothesis and the test\nwe have devised to measure this is the twin particle experiment.\nRight and Left Socks\n“Was the world wave-function\nwaiting to jump for thousands\nof millions of years until singlecelled\ncreatures appeared? Or\ndid it have to wait a little longer\nfor some more highly qualified\nmeasurer - with a Ph.D.?”\nJohn Bell\nTwins\nThere are several ways to make twin particles. The ‘easy’ way is with\na laser and a nonlinear crystal. A beam of ultraviolet photons\nenters the crystal and about one in a billion times they interact\nwith quantum fluctuations in the crystal lattice to create two red photons.\nThis is known as ‘spontaneous down conversion’.\nThere are two types of down conversion. In a type I interaction the\ntwins have the same polarization, and in a type II they are at 90 degrees\nto each other. You can set up the experiment with either type, but it\nis important to remember which you used, or you will easily become\nconfused. When we talk about photon experiments, we are usually\nreferring to type I interactions because they are easier to understand.\nOften the actual experiment uses oppositely polarized photons because\nthey are easier to generate.\nPolarization is a wavelike property of photons. You can visualize\nthem wiggling up and down, side-to-side or something in between. We\nuse polarization to our advantage when we go on holiday to the beach;\nlight from the sun is randomly polarized, but when it glances off the ocean\nit becomes predominantly horizontally polarized. If we wear vertically\npolarized sunglasses the glare off the ocean is blocked and we can see the\nocean more clearly. The following two pictures show this effect.\nThe two photons we make with the crystal can be separated and\nsent to different places. The record so far is two towns near Geneva, 50\nkilometers apart. For this experiment scientists ‘borrowed’ the unused\nfibers of Swisscom in the middle of the night – when phone traffic was\nlight. A detector was placed at the end of each fiber to measure the\nparticles.\n332 Are the Androids Dreaming Yet?\nEffect of Polaroid Lenses\nWhen scientists examine the polarization of these photons, they\nget random results. Sometimes the photon is oscillating side to side,\nsometimes up and down and sometimes part way in between. This can\nbe determined simply by taking a lens out of a pair of Polaroid glasses,\nholding it up at an angle and seeing if the photon can pass through.\nObviously laboratory grade Polaroid material is available, so scientists\ndon’t have to destroy an expensive pair of designer glasses, but the\nprinciple is identical.\nVery strange things happen when the measurements are made. The\npolarizations appear to have no discernible pattern, but once one of the\nphotons has gone through a polarizer in the first town, its sister photon\nwill always be found to have the opposite polarization (or the same if it\nwas a type I)..\nEinstein was uncomfortable with this for two reasons. The first related\nto his famous statement, “God does not play dice with the Universe.”\nHe was deeply uncomfortable with the idea that the polarizations\nwere random. Even more troubling to him was the idea that the sister\nphoton somehow instantaneously had the opposite polarization. How\nwould it know? For the sister photon to immediately have the opposite\npolarization, information would have to travel faster than the speed of\nlight from the first photon to tell its sister what to do. In 1935, Einstein\nwrote a paper with Jacob Podolsky and Samuel Rosen describing this\n‘EPR’ paradox. Since faster than light communication was impossible – it\nbreaks the law of special relativity – they concluded quantum mechanics\nmust be wrong, or at least incomplete. A deeper theory would be needed\nto explain the particles’ behavior. One very simple explanation is by\nanalogy to socks! (Clothing analogies are one of the ways physicists try\nto make quantum mechanics less intimidating.)\nConsider sister photons as if they were right and left socks. If we\nfound a left sock on the bedroom floor, we would be unsurprised to find\nthe matching sock was a right one. There is no need for messages to flow\nFree Will\n333\nbetween the socks faster than the speed of light to synchronize them,\nthey already know what they are! Einstein presumed sister photons\nwere like socks; they were emitted from the light source with their\npolarizations already set, though you could not see this information until\nyou measured one of the photons. The information was dubbed ‘hidden’\nand the theory is called hidden variable theory.\nEinstein was to be proven wrong.\nFor many years after the EPR paper was published, physicists\nsplit into factions: some thought the world random, some believed in\nhidden variables, and others thought attempts to ‘understand’ quantum\nmechanics were misguided. Why should physics make sense? The\nequations work. Who cares why?\nIn 1964, John Bell, an Irish physicist working at the Conseil\nEuropéen pour la Recherche Nucléaire (‘CERN’), devised a way to test\nEinstein’s hidden variable theory. He pointed out that if photons possess\nhidden variables and we randomly measure them with a detector set at\nthree angles, we would expect to see more than one-third of the photons\nshare the same result. But, in 1972, Freedman and Clauser performed\nthis experiment and showed the photons share the result only a little over\na quarter of the time. Since ‘a little over a quarter’ is less than ‘more than\na third’, Bell’s theory is false. Of course, Bell was entirely happy about\nthis, since he set the equation up to be disproven. His equation is called\nan inequality because the equation contains a more than sign ‘>’ rather\nthan an equals ‘=’ sign, so people say that quantum mechanics violates\nthe Bell inequality. Because the inequality is violated, photons can have\nno prior knowledge of their polarization.\nBell Test Experiment\n334 Are the Androids Dreaming Yet?\nThis is quite a complex piece of mathematics so let me show you how\nit works. Again, our thought experiment relies on an analogy involving\nclothing – sorry.\nIn the Bell Test experiment three polarizers are set up at 0, ⅓ and ⅔\nof the way around a circle, 120 degrees apart. For Einstein to be correct\nphotons must each carry at least three pieces of information:\nIf I meet the 0 degree polarizer do I go through or not?\nIf I meet the 120 degree polarizer do I go through or not?\nIf I meet the 240 degree polarizer do I go through or not?\nIf a photon had only one piece of information, say that it was\nvertically polarized, it would not know what to do if it came across a\npolarizer at 45 degrees. In that case the photon would sometimes go\nthrough and sometimes not, with a fifty-fifty probability. But Einstein\ndid not want to countenance probability. “God does not play dice with\nthe Universe.” He required certainty. “I like to think the Moon is there\nwhen I am not watching it.” The photons must know enough to handle,\nwith certainty, any eventuality they may come across. (We could set up\nexperiments with a more complex set of choices, dividing the photons\ninto quarters, fifths and so on, but thirds are simple numbers and we can\nuse the children’s clothing analogy to demonstrate the mathematics.)\nHats, Scarves, and Gloves\nFree Will\n335\nWe could liken photons knowing three pieces of information to\nchildren in a playground choosing to wear either hats, scarfs or gloves in\nsome combination: hats for vertical, gloves for 120 degrees and scarfs for\n240 degrees. There are eight choices for each child; nothing, hat, gloves,\nscarf, hat and scarf, hat and gloves, scarf and gloves, or all three.\nBell asked how often we would see two measurements agree. Look\nat the illustration and you can see when this happens. If a child was\nwearing all the clothes then if you check any pair, say gloves and scarfs\nyou will always get a yes. If one of the children is wearing none of their\nwinter clothes, you will always get a no for any pair you check. In these\ntwo cases, we are always sure to get agreement. For all the other cases,\nonly one in three of the tests will agree. So Bell said that any time you\nhave something with three hidden variables, there is at least a one in\nthree chance that the measurements you make will agree, since six of the\ntests are one in three and the other two are certain.\nDue to Heisenberg’s Uncertainty Principle we can only look at one\npiece of clothing at a time. But, there is a trick. If there are identical twins\namong the children – who always dress the same way in our analogy –\nwe can look at the gloves of one twin and the hat of another. Because they\nare twins if the first twin is wearing a hat we know the second one is too,\nwithout looking. We have a trick to measure two things at once.\nWhen the test is done on twin photons only one in four, one\nquarter, agree. So there is a problem with the children analogy. It turns\nout photons don’t wear gloves, hats, and scarfs. There are no hidden\nvariables. A photon does not know what it will do before you measure it\nand can only decide on the fly at the point of measurement.\nThis means quantum particles are not there when they are not being\nobserved. Observing them does appear to make them real. If the hidden\nvariables, the gloves, hats and scarfs were in set positions when we were\nnot observing them, the photon measurements would agree at least\none-third of the time, but they do not. When we measure them, the two\nparticles somehow communicate and agree to give a positive result only\none quarter of the time. Bizarre, but that’s just the way it is!\nThe Bell result is still somewhat controversial and has not been\nproven to everyone’s satisfaction. Potential loopholes exist but are steadily\nbeing eroded. An experiment by Nicolas Giseng of CERN using the fiber\noptic network of Swiss Telecom to separate twin photons, shows the\ncoordination signals must travel at least 10,000 times the speed of light –\nthe limitation, and reason it is not infinitely fast, being the accuracy of his\nclocks. Daniel Sego, Daniel Danziger and Michael Wise have performed\nthe Bell test experiment with an apparatus installed near Innsbruck\n336 Are the Androids Dreaming Yet?\nwhere the choice of detector orientation was made by a random number\ngenerator after the photons had left the emitter. This shows the photons\nreally can’t know what they will do before they start their journey. Another\nloophole is the loss of some photons. We don’t measure all the photons in\nan optical experiment because some are absorbed by the apparatus. It has\nbeen suggested all the ‘lost’ photons make up the error in the experiment.\nThis is not very likely, it’s akin to assuming all the voters who did not vote\nin an election would have voted Democrat. To avoid this criticism, an\nexperiment has been performed with magnetized particles that don’t get\nlost. The Bell result holds true.The loopholes are diminishing and it seems\nlikely Bell will win out in the end.\nAlthough the coordination information appears instantaneous,\nJohn Bell gave us an elegant explanation as to why this does not allow\nus to use the effect to transfer information faster than the speed of light.\nImagine we are sitting at opposite ends of a room. We both toss coins and\neach of us write down our results; heads, tails, heads, heads and so on.\nI then acquire a magical power that causes your coin to make an extra\nflip just before you catch it, so it always gives the opposite result to mine.\nAlthough I am now controlling your coin, you cannot tell, as the result\nlooks as random as before. The difference is simply that at first the coin\norientation was random in its own right and then the opposite of my\nrandom result. It is only when I walk over and compare our results we\ncan see they are matched in this strange way. There is no way to transmit\ninformation using this effect. Only after the experiment is finished can\nwe exchange the necessary information to see the coordination that\nexisted, and that comparison required me to transfer information. The\nfastest way to do that is at the speed of light.\nDespite saying it is impossible, let us do a thought experiment and\ntry to transmit information using Morse code. I will set up a simple old\nfashion telegraph machine. When I press the telegraph button at my end\nthis will cause a measurement and the photons at your end will be forced\nto the opposite polarization. When I lift the key, your photons will revert\nto being randomized. You can see this illustrated in the diagram. Although\nI make your photon take up a polarization, analogous to making the coin\ntake an extra flip, you don’t have enough information to know this.\nNow we are ready to use our quantum Morse machine to prove the\nUniverse must have free will, or at least a degree of non-determinism.\nFree Will\n337\nQuantum Morse Machine\nA Simple Free Will Theorem\nIn the quantum Morse machine, I do transmit information faster than the\nspeed of light. But the information I have transmitted is useless as it is, in\neffect, encrypted using a one-time pad. The only person in possession of\na copy of this one-time pad is me: the sender.\nClaude Shannon proved a one-time pad is unbreakable during the\nSecond World War. Yet the British succeeded in breaking it. How was\nthis possible?\nThe fatal weakness in the German one-time pads was the random\nnumbers used to code the messages were generated by a machine, and\nwere therefore not truly random. The numbers followed a sequence,\nand it was possible for Allied code breakers to work out the sequence\nand decode the messages. It follows that if we believe no message can\npropagate faster than the speed of light, my sequence of numbers must\nbe non-computable. There must be no algorithm or computation that\ncould generate it. Otherwise it would be liable to the same sort of\ndecryption attack that the one-time pads suffered. If sequences of random\nmeasurements taken in the universe are non-computable it follows the\nUniverse as a whole must be non-computable.\nThere are a few holes you could pick in this argument. Would it\nbe sufficient if it were impossible to decrypt the message in the age of\nthe Universe? What if there was an algorithm, but it was practically\nunknowable? But, I am talking here of principle. In principle, the\nUniverse must be non-decryptable.\nRichard Dawkins and the Atheist Tour Bus\n“God exists, if only in the form\nof a meme with high survival\nvalue, or infective power, in the\nenvironment provided by human\nculture.”\nRichard Dawkins\nDoes God have\nFree Will?\nny discussion of free will is incomplete without some mention of\nGod. Scientists generally avoid the topic, but since we’re talking\nabout such a fundamental concept, we must consider whether\nthe Universe would be any different if it had a creator.\nRecently there have been two widely publicized attacks on religious\nbelief from the scientific community: the head-on attack from Richard\nDawkins in The God Delusion or, the hard hitting sideswipe by Stephen\nHawking in The Universe in a Nutshell.\nHawking made the front pages in 2000 with the statement: “There\nis then no need for a creator.” He was considering whether God needed\nto ignite the Big Bang or if it occurred as a natural result of the laws of\nphysics. Hawking had run the mathematics and realized a god was not\nneeded to light the blue touch paper for the Big Bang - the laws of physics\nspontaneously caused it. His argument does not actually preclude the\nexistence of a god, but it does move the point where we need a creator\none step further up the chain.\nThis is not a fundamental change to the progress of theological\nargument over the last thousand years. Once we abandon our vision\nof God as a master builder, literally breathing life into Adam while\nputting the finishing touches to the Garden of Eden, we can move him\nup the causal chain as far as we like, eventually reaching a point where\nintervention is necessary to get things started. Hawking is only pointing\nout an intervention is not needed at the point of the Big Bang. It still begs\n340 Are the Androids Dreaming Yet?\nthe question “Where did the laws of physics come from?” If you don’t\nbelieve in a god then pushing a creator figure further and further up the\nchain eventually makes him redundant. If you have faith, you can take\nthe position God is the creator of the fundamental rules.\nRegardless of your personal position, I would like to make the\nargument for free will independent of belief. We must resolve the ageold\nparadox: How can God be all-knowing and all-powerful, and still\nhave free will?\nThis is a long-standing theological debate dating back to the 15 th\ncentury. It splits theologians into two camps. The first maintains God has\nboth omniscience and omnipotence, and they are not inconsistent. This\nis the compatibilism argument again. Despite the acknowledged paradox,\nthey argue that we should simply accept it and acknowledge that we are\nunable to comprehend such things. I don’t like this argument because\nit essentially denies reason. We are supposed to acknowledge that we\nsimply cannot understand the mind of God. I prefer the more modern\nargument from the second camp that omnipotence trumps omniscience.\nIt preserves the view that man can reason about the Universe – “Man is\nmade in God’s image.”\nThis argument follows the logic: God must be able to choose not to\nknow what will happen in the future so that he can have free will.\n\nFork in the Road\n“When making a decision of\nminor importance, I have\nalways found it advantageous\nto consider all the pros and cons.\nIn vital matters, however, such\nas the choice of a mate or a\nprofession, the decision should\ncome from the unconscious,\nfrom somewhere within\nourselves. In the important\ndecisions of personal life, we\nshould be governed, I think, by\nthe deep inner needs of our\nnature.”\nAlan Turing\nThe Free Will\nTheorem\nIn 2006, John Conway and Simon Kochen published The Free Will\nTheorem. The paper received huge press attention and has been widely\ndiscussed in the scientific community. Their theorem states that;\nprovided experimenters are free to run their experiment as they choose,\nthe behavior of the particles they experiment upon is not determined in\nadvance. Particles have free will!\nIf we go back to the Bell Test experiment, this proved twin particles\ndo not carry around a parcel of information telling them what to do.\nPerhaps they get their marching orders from some outside influence.\nThere are two possibilities. A particle is either told what to do by its\nenvironment or it gets its information from some data source. Can we\nuse the laws of physics to test these possibilities? We don’t need to know\nhow the influence works, just that it might exist in principle.\nConway and Kochen prove there can be no external influence, and\nwhen a particle reveals its spin, that spin was not known beforehand. It\nis independent of any information in the history of the Universe up to\nthat point.\nConway and Kochen’s proof is elegant and involves some mental\ngymnastics, but it is no harder than Archimedes’ proof of the infinity of\nprimes we looked at earlier. Let us start with our twin particles. We are\ngoing to pick bosons, which have whole number spin. If you measure the\nspin, you will always get a reading of -1, 0 or +1. ‘Spin’ is one of those\nwords physicists use to explain quantum things. It does not necessarily\ndenote rotation but, if your mental model is a spinning top, that’s not too\n344 Are the Androids Dreaming Yet?\nbad. If we measure something in the quantum world, it always yields a\nclassical result – in this case the magnitudes of spin are 1, 0 and 1. (Minus\none squared is one.)\nWe need to imagine measuring the spin of a particle along three\naxes; x, y and z. Hold your hand up and make a shape that looks like\nthe one in the following picture. You might remember it from science\nclasses; it was used to help you understand Fleming’s left-hand rule. For\nour purposes it does not matter which hand you use; it is just the shape\nthat matters. I am going to use my left hand for sentimental reasons.\nNow, imagine the palm of your hand is the measuring apparatus:\nyour index finger the x axis, your middle finger, y and your thumb, z. At\nany moment you can move your hand to point in any direction and take\na measurement. We will have to round up or down. Quantum mechanics\nis named ‘quantum’ because all the readings must be whole numbers.\nYou will never see 10% spin in x, 90% in y and 85% in z; just ones, and\nzeros. The measurements for a Boson will always be 1,0,1 in some order.\nThis is known as the ‘101’ rule.\nNow, we ask the question: does a particle have a definite spin before\nwe take a measurement? The instinctive answer is yes, and this way of\nviewing things is known as realism. It seems obvious that even if we did\nnot make a measurement, the particle would still have its spin; we just\nwouldn’t know which type. Einstein explained realism by saying “I like\nKochen Specker\nFree Will\n345\nto think the Moon is there when I am not looking at it.” But, how can we\ntest his statement? How can we know something is there without taking\na look? There is a way...\nLet us suppose the particle had a definite spin before we measured\nit. Perhaps its spin points at the top left hand corner of the room. Imagine\ntaking many measurements and seeing what happens. We can point our\nhand in any direction: top of the room, bottom left corner, bottom right\ncorner and so on. Each time we point our hand in a direction we must\nget 1, 0 and 1 in some combination (110, 011, 101). The particles are 101\nparticles and this is an absolute rule.\nLet’s imagine doing the experiment. We fix the spin of a particle\nand begin to take measurements, noting the answers as we go. If we get\na borderline condition we obey the 101 rule and give ourselves a 1, 0, 1\nreading. As we move our hand to take measurements, a problem begins\nto emerge. Every now and again we obtain a measurement that conflicts.\nWe chose a 1, 0, 1 when we were pointing our index finger towards the\nfloor, but if we point the finger toward the door, we need that original\nmiddle number to have been a 1 for consistency. (The middle finger is\nnow pointing in the direction the index finger pointed to for the first\nreading.) To fix the inconsistency we can change our original borderline\ndecision to a 1,1,0. All is well and we continue. But, as we get over 30\nmeasurements, we can’t seem to find any way to make all the 1,0,1s fit\ntogether. After scratching our\nhead for a while, we realize there\nmight be no solution. And indeed\nthere is not. This is the Kochen-\nSpecker Paradox. The odd shaped\ncubes on the building in the\nEscher print are an example of\none of these impossible figures.\nAn analogy to this problem\nis trying to solve a broken\nRubik’s Cube. There is a really\nmischievous trick you can play on\nsomeone: reverse two colors on a\nRubik’s Cube. You can easily do\nthis by snapping one of the edge\nblocks out, turning it around and\nsnapping it back in. When the\ncolors are already muddled up\n1 0 1 puzzle piece\nthis is not obvious. Now give your\n\n346 Are the Androids Dreaming Yet?\nM. C. Escher’s Waterfall (Impossible Shapes)\nfriend the puzzle and they will spend hours trying to solve it! It can’t\nbe done because the puzzle is put together wrong. And in this matter\nnature is also put together wrong! With as few as 33 measurements it is\nimpossible to construct a consistent three-dimensional shape that has\n1s and 0s obeying the 101 rule in every place. The only way to complete\nsuch a shape is with a measurement that is both simultaneously zero and\none: a paradox. We know what happens when we generate paradoxes. It\nmeans one of the original assumptions is false and, in this instance, the\nfalsehood is that a particle has a definite spin before we measure it. It\nFree Will\n347\nKochen-Specker Cube\ncannot. It must make up its mind on the fly. Einstein would be horrified.\nRealism is violated by the quantum world: reality and measurement are\nintertwined.\nThe Kochen-Specker paradox shows us that a particle only makes\nits choice at the point of measurement. This does not prove it has free\nwill as it might still be told what to do by some external entity. It’s rather\nlike the famous game show, Who Wants to be a Millionaire? The particle\ncould answer the spin question in four possible ways. First, it could know\nthe answer, but we have just proven it does not. Second, it could phone a\nfriend obtaining the answer from some cosmic arbiter. Third, it could ask\nthe audience and take a vote from all the particles around it. Finally, it\ncould freely choose, without recourse to any of the other possible options\n– in other words, it would guess!\n348 Are the Androids Dreaming Yet?\nA guess would mean particles have free will; no extraneous\ninfluence or piece of information either on their person or from some\nexternal source could have any effect. We are now going to prove the\nparticle does guess.\nThe Proof\nConway and Kochen construct their proof from a small set of axioms,\nwhich form a rhyme. The axioms are; twin, fin and spin.\nIf two particles are separated by a distance (fin) and entangled\n(twin), the spins of the particles (spin) cannot be determined by any\ninformation in their history of the Universe up to that point. The proof\nrelies on a thought experiment.\nConsider twin particles separated by a long distance. Physicists call\nthis ‘space like separation’. All this means is one particle is measured on, say,\nEarth and the other on Mars, so relativity is significant in the experiment.\nThis may be impractical today but there is no reason the experiment\ncould not be done in principle. In the future, our children could set up\non the UN Moon base and fire one photon to a detector on Hubble II\nand the other to the future Mars Orbital Station. Farfetched? If you had\ntold Einstein back in 1947 that in less than 70 years we would be able\nto measure individual photons by sending them down spun glass fibers\nto locations separated by 50 kilometers, involving a multidisciplinary\nteam composed of American, German, French and Russian scientists, all\nworking in harmony, he might have been equally incredulous.\nAs the proof introduces relativity we also need two imaginary\nrocket ships. They must be traveling below the speed of light, so no Star\nTrek Enterprise or Millennium Falcon. We will have to stick with an oldschool\nspaceship, the Sulaco from Aliens should do the trick. They must\ntravel in opposite directions, passing our Moon Base just as the scientists\nrun the experiment.\nSpecial Relativity shows our Universe has a strange property: there\nis no such thing as a simultaneous event for two observers – at least if\nthey are separated by any distance. From the point of view of the first\nspaceship, the measurement on Mars occurs first. But from the vantage\npoint of the second observer, the measurement on Hubble occurs first.\nNow comes the proof by counter example. Let us suppose the\nparticles were influenced by an outside effect and had no free will.\nFree Will\n349\nLet us say the Mars particle chooses its answer because of an\nexternal influence. Its Hubble twin must choose the same answer. There\nis no problem with this because the Hubble particle could have made its\ndecision before the Mars particle, so the decision was not predetermined.\nBut in another frame of reference the choice is made in the opposite\nsequence. The Hubble particle chooses after the Mars particle. This is\npredetermination and it breaks the Kochen-Specker theorem.\nYou can reverse the whole analysis and see the same problem from\nthe other point of view. There is a paradox here however you look at it.\nThe only solution to the paradox is that both particles make their\nchoice without any information from an outside source; particles have\nfree will. This means at least one new piece of information spontaneously\nappears in the Universe – a ‘bit’ of free will, so to speak.\nYou might think there is a problem because the first particle affects\nits twin, even if the second did not receive any outside influence. This\nwould result in the Kochen-Specker paradox reemerging. There is a\nneat way out of this; time has no meaning for the particles. Or, I should\nsay, relative time has no meaning and, therefore, has no effect. There is\nno concept of before or after between the particles. They live in a little\nbubble of space-time where the order of events has no meaning. The\nparticles make their free choice together within this safe bubble, and the\nparadox is avoided. When we come to measure them, we see they both\nmade a random decision together, but if we ask which made it first, the\nquestion has no meaning. There is no clock valid for both particles, so\nthere is no possible answer to the question.\nConway and Kochen have proven sub-atomic particles have free will\n– or at least entangled bosons do. At this point, their argument becomes\na philosophical one. They propose that these particles pass on this free\nwill to larger entities in the Universe and ultimately to us. Although\nparticles are small and insignificant, they are the fundamental building\nblocks of nature, and the butterfly effect multiplies up tiny variations in\nthe microscopic world into the macroscopic events we see.\nAlthough their theorem is very elegant, we still have to address the\nquestion of whether the experimenter has the true freedom to run the\nexperiment in the first place: the determined determinist argument.\nRussian Dolls\n“Great fleas have little fleas upon\ntheir backs to bite ‘em.\nAnd little fleas have lesser fleas,\nand so ad infinitum.\nAnd the great fleas themselves, in\nturn, have greater fleas to go on.\nWhile these again have greater\nstill, and greater still, and so on.”\nAugustus De Morgan\nFree Will Universe\nIbelieve we live in a Universe where information comes into existence\nthrough the creative endeavors of human beings. When Andrew\nWiles discovered his solution to Fermat’s Last Theorem, he did\nsomething a computer cannot do and demonstrated non-computational\nthought. But there is an alternative explanation put forward by the\ndetermined determinists.\nDaniel Dennett – the standard bearer for this camp – believes\neverything in the Universe is entirely determined. He argues there is no\nplace in the laws of nature for free will to arise.\nBoth sides of the argument agree Turing prohibits a generalpurpose\nmachine from solving all mathematical problems, but that\nseems to be the extent of agreement. The determinists solve the Wiles\nParadox by arguing he is a special purpose machine, perfectly able to\nfind answers to non-computable problems. The Turing prohibition only\napplies to general purpose machines. Let us run a thought experiment\nto see what sort of Universe we would live in if special purpose machines\nwere the answer to this puzzle.\nIf the Universe is determined, it can be modeled as a single algorithm.\nIf everything in the Universe evolves according to a set of rules, it will\nrun like a giant piece of clockwork or one large computer game. Each\nsolar system, planet, and individual mathematician would evolve along\npreordained lines. Mathematicians would operate as software subroutine\nand would rely on further subroutines to explain the beating of their\nhearts and the way the molecules of their body interact.\nIf our Universe were organized in this way:\nThis Universe could not discover solutions to arbitrary problems.\n352 Are the Androids Dreaming Yet?\nThis Universe could be preprogrammed with every theory we could\never discover within it. (There would be no arbitrary problems.)\nThis argument neatly sidesteps Turing’s theorem by specifying\nthere is no such thing as an arbitrary problem – a random problem\npicked from the infinite set of problems. At the same time, it sets certain\ncharacteristics of such a Universe and I believe we can test these...\nA computable Universe must already know the solution to every\nproblem it will encounter above the logic limit: It cannot discover\nknowledge on the fly. For many problems, a small number of fundamental\nrules can account for everything. Although our galaxy and the beautiful\nnebulae we see through our telescopes look complex, they might be\nthe result of some such simple set of rules – just like a fractal. That’s\nStephen Wolfram’s solution to the mystery of our Universe. But some\nproblems are complex. The solution to Fermat’s Last Theorem is an 80\npage document consisting of 5 million bits of information. All this must\nbe stored somewhere in the Universe. It might not be stored as a string\nof bytes, it could be found in a set of equations governing the motion of\nthe atoms such that at some point – in 1995 to be exact – they all line\nup in Andrew Wiles’ brain to direct his fingers to type out the proof. In\nthis case, the Universe has solved a mathematical puzzle because it was\nspecifically set up to do so from the time of the Big Bang, but this raises\nthree questions:\nWhere does the Universe store this enormous amount of\ninformation?\nHow does The Universe hold the information reliably?\nHow did the pre-Universe solve the problem, so it might program\nthe Universe at the moment of the Big Bang?\nThe first question is probably answerable. The Universe is a big place\nand could store sufficient information to solve the mysteries that puzzle\nthe inquisitive creatures that inhabit its planes. There are many practical\nproblems to consider, such as how to preserve the information through\nall the strange evolutions of our Universe; inflation, star formation, and\nso on. But it could be done.\nThe second question is insurmountable and presents the counter\nargument to the determinists. Our Universe appears to be composed of\nnon-deterministic objects. Such objects exist in the mathematical world;\nKochen-Specker cubes, for example. Unfortunately for the determined\ndeterminist, bosons behave according to the same principles. In case\nyou’re thinking thinking bosons are rare, light is formed of bosons. Our\nFree Will\n353\nwhole existence is surrounded by non-deterministic physics. Therefore,\nyour actions are not predetermined by anything in your local corner of\nthe Universe – the past light cone if you want to be strict about the physics.\nThe determined determinists are a determined bunch. Just because\nthe information that determines your actions cannot be encoded by the\nparticles you are made from, does not mean you are free. The information\ncould be stored in parts of the Universe we cannot see, or held outside\nthe Universe in some sort of cosmic hard drive. Every creative event in\nthe Universe would be specified in this store.\nBut this begs the third question: How was this store of information\ngenerated in the first place? If a Universe contains creative things – as our\nUniverse does – there is no way to computably generate the necessary\ndeterminist store of information. The Universe has free will because there\nis no deterministic process that could generate it.\nIf our Universe were a Turing machine, everything within it\nwould be too. Think about the deterministic clockwork argument I\ngave earlier. If you try to construct a better – say a more random –\nmachine inside a Turing machine, an observer could simply ignore the\nbetter machine hidden within it, and watch the outer machine work.\nThe outer machine will predict the operation of the inner machine\nperfectly, even if the inner machine is fiendishly complicated. We\nhave to consider the machine on which our human software runs. Our\nbodies, our minds, all that we are, is software running on the Universe’s\nhardware of quarks and photons. If the hardware is deterministic, then\nso is our software. And if the hardware is deterministic, there can be no\ncreativity within the Universe.\nSo the free will camp has an argument easily as frustrating as the\none deployed by the determinists. Every time a determinist asks, “How\ndo you know you were not always going to do that?” the free will believer\ncan reply, “You asked me a question. If this dialogue is to have any\nsignificance, then we must exist in a rational Universe and, therefore, the\nlaws of information give us creativity and free will. If you believe we are\nfully determined, there is no point in my answering your question.”\nI reason. Therefore, I have free will.\nThe Universe is not a machine.\n354 Are the Androids Dreaming Yet?\nChapter 16\nTHE QUEST FOR\nKNOWLEDGE\nDarwin’s Beagle\n“Sometimes I’ve believed as many\nas six impossible things before\nbreakfast.”\nQueen of Hearts in\nLewis Carroll’s Alice\n“It is not the strongest of the\nspecies that survives, nor the\nmost intelligent that survives.\nIt is the one that is the most\nadaptable to change.”\nCharles Darwin\nWe celebrate creativity with many competitions and prizes. I\nhave been a student of problem lists of over the years. Here\nis my list of the problems remaining open in the modern\nworld. I’ve tied it in with other lists where relevant, and indicate what\nyou might win if you were to solve one. As I was writing this book, a few\nof the questions were answered; the Higgs Boson was discovered and the\nPoincaré Conjecture proven. I will keep the list up to date on the web site.\nFields Medal\n1. Mathematics\n1.1 The Birch and Swinnerton-Dyer Conjecture. C\n1.2 Hodge Conjecture C\n1.3 Navier-Stokes Equations C\n1.4 A proof or disproof of P =NP C\n1.5 The Poincaré Conjecture C – Solved\n1.6 Riemann Hypothesis h8 C\n1.7 Yang-Mills Theory C\n1.8 Can we understand and solve all 23 Hilbert Problems h1-23\n1.9 Goldbach Conjecture h8\n1.10 Is mathematics fundamental to or simply a good model of\nour Universe? H6\n1.11 Is mathematics an emergent property in our Universe or\ncausal? Which is more fundamental?\n1.12 Fermat’s own original proof of his theorem!\n2. Physics\nNobel Prize for Physics\n2.1 Are there many worlds or just one?\n2.2 Does quantum collapse have meaning?\n2.3 Will we find the Higgs-Boson? (Provisionally yes, 2012)\n2.4 Do we need quantum gravity to explain human thought?\n2.5 Will we observe gravitational waves, and what is the\ncurrent explanation for gravitational noise?\n2.6 What causes the arrow of time and the asymmetry of\nphysical laws?\n2.7 Do the constants of physics change over time?\n2.8 Is quantum computation sufficient to simulate the universe,\nor is the universe non-computational?\n2.9 Can magnetic monopoles exist?\n2.10 What is meant by quantum non-locality, a.k.a., spooky\naction at a distance?\n358 Are the Androids Dreaming Yet?\n2.11 Is there a theory that would unite gravity with the other\nthree forces: a Theory of Everything?\n2.12 Is Schrödinger’s cat alive or dead in the box?\n2.13 Does ball lightning exist and can it be made in the\nlaboratory?\nNobel Prize for Physics\n3. Cosmology\n3.1 What is the nature of Dark Matter?\n3.2 What is the nature of Dark Energy?\n3.3 What is Dark Flow?\n3.4 The slingshot anomaly.\n3.5 Did inflation really happen?\n3.6 Was there a singularity at the origin of our Universe, and\nwhat happened before the first second? An eternity?\n3.7 Can any information travel faster than the speed of light?\n3.8 What is the cause of the Pioneer anomaly? (solved in 2011)\n3.9 Are there aliens?\n3.10 The Goldilocks question. Why are the cosmological\nconstants so finely tuned?\n3.11 Do real numbers exist or is our Universe quantized?\n3.12 Why is there little antimatter?\n3.13 What are cosmic rays and where do they come from?\n3.14 What was the WOW signal?\n3.15 Does the fine structure constant vary over time?\n3.16 If we live in an infinite Universe, why don’t we see more\nstrange things?\n3.17 Why is the cosmic background radiation so smooth?\n3.18 How can we explain the lack of total smoothness of the\ncosmic background radiation!\n3.19 Is there an explanation for any detail in the cosmic\nbackground radiation map?\n4. Engineering\nNobel Prize for Chemistry, Turing Award\n4.1 Can we achieve economic nuclear fusion?\n4.2 Will we realize cold fusion? (Partially demonstrated)\n4.3 Can an amateur get to the moon?\n4.4 Can an amateur collect a rock from the moon? X\n4.5 Will we make an Artificial Intelligence?\n4.6 Can we make a Tricorder? X\n4.7 Can we power the world from renewable sources?\n4.8 Will robots go to war in the future?\nThe Quest for Knowledge\n359\n4.9 Can we make a robot indistinguishable from a human and\ncross the uncanny valley?\n4.10 What is the tallest building we could build on planet Earth?\n4.11 Will we routinely use flying cars by the end of this century?\n4.12 Will we have a base on the Moon or Mars in this century?\nNobel Prize for Medicine\n5. Biology\n5.1 Why is the placebo effect so strong?\n5.2 Can we cure the common cold?\n5.3 Is there a generally effective treatment for cancer?\n5.4 Can we find a vaccine against HIV?\n5.5 Can we cure endemic diseases such as malaria, or is it an\narms race?\n5.6 How plastic are our genes and is epigenetics a significant\nfactor?\n5.7 Can we cure dementia? L\n5.8 Can we make a desktop gene sequencer? X\n5.9 Will we prove the Kurzweil Hypothesis that technology\nwill allow us to live forever?\n5.10 How old will we live to with a reasonable quality of life?\n5.11 Can genes jump between organisms? Even participating in\nwhole scale fusion?\n5.12 Will we be able to grow organs?\n5.13 Will we clone a human from an adult?\n5.14 Can we clone a dinosaur?\n6. The Mind\nNobel Prize for Medicine\n6.1 Does the Flynn Effect mean we are really becoming more\nintelligent?\n6.2 What is the nature of consciousness?\n6.3 Do we have free will?\n6.4 Which is more important: Nature or Nurture?\n6.5 What is humor for?\n6.6 Do some people have photographic memory? (yes, recent)\n6.7 What is the purpose of sleep and, in particular, dreams?\n6.8 What is understanding?\n6.9 Do we ever truly know something?\n6.10 How does the brain think?\n6.11 Is the brain a quantum device?\n6.12 Why do we get stressed?\n6.13 Why are some people more intelligent than others?\n360 Are the Androids Dreaming Yet?\n6.14 What limits our ability to concentrate and work hard\nmentally?\nPulitzer prize for History\n7. The Ancient World\n7.1 What is the Linear-a script discovered in Crete?\n7.2 Where are the ruins of the Light House at Alexandria and\nindeed Alexandria itself?\n7.3 What is the location of the Lost City of Atlantis if it is not a\nmyth?\n7.4 Will we ever find King John’s Treasure?\n7.5 What is the truth to the legend of El Dorado?\n7.6 Why were the pyramids built?\n7.7 What was the purpose of Stonehenge and who built it?\n7.8 How many books and how much knowledge have we lost?\n7.9 Did King Arthur and Camelot exist in any real way?\n7.10 Why did the people of Easter Island build their statues?\n7.11 Was there an ancient flood, suggested by the Bible and\nother ancient texts?\n7.12 Are the Seven Wonders of the Ancient World lost forever?\nNobel Peace Prize or Prize for Economics\n8. The Modern World\n8.1 Is there a best political organization for a country?\n8.2 What is the best political balance of federation and\nautonomy?\n8.3 The Black Swan Effect: Why do improbable things happen?\n8.4 Is there a right way to run the economies of the world?\n8.5 When is it right to intervene in a conflict, and when is it\nbest to leave a country to its own devices?\n8.6 What is the best way to choose a political representative?\n8.7 Will we ever abolish war?\n8.8 Why is the gap between rich and poor increasing in most\nof the world today?\n8.9 How powerful should states be compared with world\norganizations?\n8.10 Is there a right level of tax?\n8.11 Are morals absolute or relative: euthanasia, abortion, gay\nmarriage, eating meat?\n8.12 What will we do about our aging population?\nGoldman Prize for the Environment\n9. Planet Earth\nThe Quest for Knowledge\n361\n9.1 Is man-made global warming real, and if already proven\nwill we ever persuade the US government?\n9.2 What caused the Tunguska Explosion?\n9.3 What caused the extinction of the dinosaurs?\n9.4 Can we predict earthquakes or eruptions?\n9.5 What caused the reversing of the poles and when will the\nnext one occur?\n9.6 What was the origin of life on Earth?\n9.7 Will we be wiped out by an asteroid before we build a\nsuitable defense?\n9.8 Can we grow enough food to feed the planet? L\n9.9 Can we give clean water to everyone on the planet? L\n9.10 Is increasing air travel compatible with survival of the\nplanet? L\nNobel Prize in Literature and others\n10. Philosophy\n10.1 Is there a God?\n10.2 Where did we come from if we are not made by a god?\nAnd if we were, then where did God come from?\n10.3 Where do morals come from?\n10.4 Is there a reality?\n10.5 Is there life after death?\n10.6 Do we have free will?\n10.7 Is beauty in the eye of the beholder?\n10.8 What is the meaning of life, the Universe and everything,\nother than 42?\n11. Conspiracy and Paranormal\n11.1 Is there anything going on in the Bermuda Triangle?\n11.2 Do aliens make crop circles? (disproven hoax)\n11.3 Who was Jack the Ripper?\n11.4 Can the mind bend spoons? (hoax, admitted)\n11.5 Does the government suppress UFO existence?\n11.6 Why was the Mary Celeste abandoned?\n11.7 Is the Turin Shroud that of Christ?\n11.8 Do the Abominable Snowman and Sasquatch exist?\n11.9 Are there ghosts?\n11.10 Is there a paranormal?\n11.11 Do aliens live amongst us?\n11.12 Was there a conspiracy in the shooting of JFK?\n362 Are the Androids Dreaming Yet?\nCross reference to other lists\nHn: Hilbert’s Problem\nC: Clay Mathematics Millennium Prizes\nX: XPRIZE\nL: Longitude Prize\n\nNobel Prize Medal\n“If I could explain it to the\naverage person, I wouldn’t have\nbeen worth the Nobel Prize.”\nRichard P. Feynman\nAwards\nfor Discovery\nPeople like prizes. Competition drives humans forward in a way\nwe don’t properly understand. In film, we have the Academy\nAwards, whilst on the web we have The Webbies. Some prizes,\nsuch as the Nobel Prize, Fields Medal and Pulitzer Prizes, have a long\nand distinguished history, while others such as the XPRIZE are more\nrecent creations. Some prizes, such as the Ig Nobel Prize and the Golden\nPineapples were mainly created for their humorous value. Prizes are\nnot a recent phenomenon. The Longitude Prize, originally won by\nJohn Harrison, is being revived in Britain in 2014 to mark its 300 th\nanniversary. The original prize, £10,000 in its day, was awarded by the\nBritish government for making a device that allowed ships to determine\ntheir East-West position (a sextant only gives north-south). The 2014\nprize is £10m pounds and the topic will be chosen by public vote! Here is\na small history of some of the more famous prizes.\nNobel Prizes\nAlfred Nobel spent his life developing weapons and explosives. His\nlaboratory was built in the middle of a lake with a bridge running to\nit, so if he blew himself up doing an experiment, only he would die. He\nmanaged to stabilize nitroglycerine by mixing it with saltpeter and created\n366 Are the Androids Dreaming Yet?\nPulitzer Medal\ndynamite. This was used in the mining industry but also extensively in\nweaponry, so he came to be known as the Merchant of Death during his\nlifetime.\nTo be known as the merchant of death would have a profound effect\non anyone. As Nobel pondered the balance of his life’s work he decided\nto do something positive with the huge wealth he had accumulated. On\nhis death in 1896, he willed his entire fortune to create the awards we\nnow call Nobel Prizes.\nThere were five original prizes; physics, chemistry, peace, physiology\nor medicine, and literature. A newer economic science prize is awarded\nby the Royal Swedish Academy of Sciences.\nYou must be alive to receive a Nobel Prize; a few have been\nawarded posthumously because the laureate died after the winner was\nannounced but before the award ceremony. The work must have been\nproven experimentally, and although originally it was supposed to be for\ndiscoveries in the previous year, nowadays a theory must have stood the\ntest of time. Consequently, winners tend to be quite old. The prize must be\nfor something with practical applicability – Einstein received his Nobel\nPrize for the Photo Electric Effect, rather than his more famous Theory\nof Relativity. The judges evidently thought particles more practical than\nplanets! The prize is usually awarded to a maximum of three people. This\nhas produced some controversial results but despite this the Nobel Prize\nis the uncontested top prize in science.\nThe Quest for Knowledge\n367\nPulitzer Prize\nA Pulitzer Prizes is to the arts what a Nobel Prize is to science. Again\nthe Prize was the result of a bequest. They are awarded in the fields of\nmusic, art and literature. Unlike Nobel Prizes, where there are no public\nnominations and you might wait a lifetime for the phone call, you enter\nyour name for a Pulitzer Prize. Most people associate the term Pulitzer\nPrize winner with journalism, but about 25 Pulitzers are awarded each\nyear. You must be a US citizen to enter.\nTuring Award\nOriginally set up by the Association of Computer Machinery, this award\ncomes with prize money of $250,000, supported by Google and Intel,\nand goes to a person who significantly advanced computer science or\nartificial intelligence in the previous year. It is considered the Nobel Prize\nfor computing.\nXPRIZE\nXPRIZEs are awarded for technology and bear the democratic stamp\nof the Internet age. Anyone can propose a challenge but they must also\nprovide the prize money! It’s big money. The Ansari XPRIZE for the first\nXPRIZE First Award Ceremony\n368 Are the Androids Dreaming Yet?\nnon-governmental organization to put a man in space was $10 million,\nawarded in 2004. There are a growing number of XPRIZEs, including, at\nthe time of writing:\n• Google Lunar XPRIZE, $30m to put a rover on the Moon.\n• Qualcomm Tricorder XPRIZE, $10m to make your mobile\nphone into a hand held medical health scanner, similar to the\nStar Trek tricorder.\n• Nokia Sensing CHALLENGE, $2.25m to build a hand-held\nmedical scanner.\n• Wendy Schmidt Ocean Health XPRIZE, $2m to create a method\nto measure the ocean’s pH.\nFields Medal\nThe equivalent of a Nobel Prize for mathematics is a Fields Medal.\nJoseph Field provided the money and helped set up the prize. Today it\nis administered as part of the International Mathematical Union. You\nmust be under 40 to receive the prize. Andrew Wiles was 45 when he\nsolved Fermat’s Last Theorem, so they created a special prize for him\ncalled a Fields Fellowship. Until recently only men had received the\nprize. However in 2014 Maryam Mirzakhani won the prize for her work\non the geometry of Riemann surfaces.\nFields Medal\nThe Quest for Knowledge\n369\nRiemann Surface\n\nChapter 17\nTHE FUTURE\nOmar Khayyám\n“Prediction is very hard,\nespecially about the future.”\nNiels Bohr\n“The Moving Finger writes: and,\nhaving writ, Moves on: nor all\nthy Piety nor Wit Shall lure it\nback to cancel half a Line, Nor\nall thy Tears wash out a Word of\nit.”\nRubaiyat of Omar Khayyam,\nEdward FitzGerald\nمایخ رمع تایعابر\nI\nremember when I was eight years old, being asked to draw a vision\nof the world in the year 2000. In my the home of the future, rather\nthan going to the shops to get milk, orange juice and cornflakes, they\nwould arrive by pipe. These days I know about microbiology and realize\nthis would have been highly impractical and perhaps rather dangerous.\nI could claim some premonition of the Internet at this point; no selfrespecting\nscience book is complete without one of these!\nOf course, the truth is I had no more idea of the way things would\nturn out than anyone else. Now that I am a little older let’s see how much\ntrouble I can get into predicting the future.\nI think we will build thinking machines – AIs – using our insights\ninto the operation of the brain. They will not be like the computers of\ntoday but will still be physical devices. There is nothing overtly spiritual\nin my conception of the way we operate, but I am arguing that the\nhuman mechanism is more complex than a digital computer. Building\nthese machines will be hard, and they will not be ‘machines’ in the sense\nI have used throughout this book. They will be minds.\nWhen we build AIs that think and feel, will they acquire ‘human’\nrights? Might one of my grandchildren fall in love with an AI, perhaps\neven marry one? On the darker side, how will they view us: what place\nwould we have in their world once we had brought them into being?\nHowever, I think this process of building an AI will be hard and in one\nhundred years’ time we will still be struggling with the problem.\nIn this book, I have presented a way to understand the creative\nprocess within our Universe. It relies on the existence of non-computable\nprocesses in our brain and in the physical laws which govern them.\nCurrently, the laws contain a big hole. Although we can, perhaps, see\nwhere freedom might come from – through randomness and nondeterminism\n– we don’t understand where the will emanates to shape the\nUniverse. Over the next thirty years, I think we will begin to understand\nthis and see how creativity relates to the Universe we observe. I am not\nsuggesting any anthropic principle, or some grand interaction between\nmankind and the Universe, just an important simple freedom: That we\nhumans are free to think and do as we please. When I choose to lift my\narm and raise a glass of wine with friends, this is my choice. I am the\ncause. The effect is the displacement of my arm, causing photons and\ngravitational waves to ripple out across the Universe, and in that sense I\nfreely affect my environment.\nDa Vinci, Self Portrait\n“A good painter is to paint two\nmain things, men and the\nworking of man’s mind.”\nLeonardo da Vinci\nAppendix 1\nAcknowledgments\nFront Matter\nCover\nSpine Equations\nAuthor Photograph\nACPMM, Wolfson College Cambridge\nMathematical Bridge, Cambridge\nIntroductory Image\nVladislav Ociacia\nIllustration by Arabella Tagg\nArabella Tagg\nJames Tagg Personal Collection,\nCourse changed name to ACDMM in\n1990.\nHipgnosis, www.shutterstock.com\nPhotograph by James Tagg\nChapter 1\nComputer versus Human\nKasparov versus Deep Blue\nThe Music of Emily Howell\nIBM’s Watson Plays Jeopardy\nWatson Questions and Answers\nSteve Wozniak\nTurning Images to Music\nBrain Image of Fish Hunting Prey\nBabbage Difference Engine No. 2\nBlutgruppe/Corbis\nLouie Psihoyos/Corbis\nKind permission of David Cope and\nCentaur Records. Emily Howell: From\nDarkness, Light. Picture and Audio\nClip\nAssociated Press Carol Kaelson/\nJeopardy Productions, Inc.\nIllustration by James Tagg\nTIM CHONG/Reuters/Corbis\nCredited to: Maxim Dupliy, Amir\nAmedi and Shelly Levy-Tzedek\nThis work (or this video) was published\nfrom Kawakami lab in National\nInstitute of Genetics , Japan (Muto,\nA. et al. Current Biology 23, 307–311,\n2013)”.\nPhotograph by James Tagg @ The\nComputer History Museum\n19 th Century Calculators Wikimedia, Ezrdr, CC3\nModel of the Antikythera Mechanism Wikimedia, Geni, CC3\n376 Are the Androids Dreaming Yet?\nMoore’s Law\n3D Chip\nRichard Branson\nELIZA, DOCTOR\nIQ Test\nMetal Puzzle\nHole in the Wall Experiment\nOne Laptop per Child\nPiano Practice\nDan McLaughlin\nAstrological Clock, Hampton Court\nLava Lamp\nSteve Jobs Collage\n“Ascending and Descending”\nChapter 2\nAfghanistan Stability/COIN Dynamics\nMcChrystal in Kabul\nGettysburg Address as PowerPoint\nSpace Shuttle Columbia Crew\nShuttle Tile\nShuttle Images\nSearle’s Chinese Room\nBlack Box Diagrams\nThe Miracle Worker, Helen Keller\nHuman Person, or is it?\nNew Yorker Dog Internet Cartoon\nChapter 3\nBody Language\nRonald Reagan and Mikael Gorbachev\nHöfði House in Reykjavik\nFake or Real Smile\nYasser Arafat and Shimon Pérez\nLearning Swedish, The Two Ronnies\nScripts of the World\nChinese Traditional and Simplified\nGreat Comedy Videos\nCredited to Ray Kurzweil, CC1\nKind permission Intel Press\nDepartment\nkathclick, www.bigstock.com\nOpensource project encapsulated into\nwidget by James Tagg\nIllustrated by James Tagg based on a\nWechsler example question\nwww.shutterstock.com, fdpress\nCourtesy Philippe Tarbouriech/Holein-the-Wall\nEducation Ltd.\nOne Laptop per Child project\nPhotograph by James Tagg\nKind permission of Dan McLaughlin,\nwww.thedanplan.com\nWazzaman, Wikimedia, CC3\nSean Gladwell, www.shutterstock.com\nKind permission: www.village9991.it\n© 2014 The M.C. Escher Company-\nThe Netherlands. All rights reserved.\nwww.mcescher.com\nUS Government, Joint Chiefs of Staff,\nPD\nUSA Navy Photo, PD\nKind permission of Peter Norvig\nCredit NASA\nUS Government, PD\nCredit NASA\nIllustrated by James Tagg\nIllustrated by James Tagg\nAssociated Press\nAssociated Press\nNew Yorker © Condé Nast Licensing\nKind permission of Conference on\nCommunication and Body Language.\nUS Government, PD\nWikimedia\nBigedhar, www.bigstock.com\nUPI\nKind permission of BBC, hosted on\nYouTube\nIllustrated by James Tagg\nIllustrated by James Tagg\nKind permission BBC hosted on\nYouTube\nAcknowledgements\n377\nChapter 4\nChild Having EEG\nX-Ray of Rontgen’s Wife’s Hand\nLego Cubes Under Ultraviolet Light\nPit Viper\nEinstein’s Brain\nThermal Image of a House\nFlowers in Ultraviolet Light\nFunctional MRI, Response\nFunctional MRI: Working Memory\nMcGill Diffusion Tensor Image\nFunctional PET\nOrganization of Your Brain\nVisual Processing System\nImpressionist Painting, Monet Haystack\nFrogs Eyes are Very Sensitive\nColor is Not an Absolute Sense\nMcGurk Effect\nPenrose Steps\nScintillating Blobs\nSelective Attention video link\nTiger Woods Swing video\nNeural Network\nSynapse\nParamecium\nQuantum Tubulin\nTubulin Molecule\nChapter 5\nChimpanzee and Typewriters\nThere are Holes in the Sky poem\nSpike Milligan\nLewis Carroll’s Jabberwocky\nLewis Carroll’s Jabberwocky\nWord’s Verdict on the Jabberwocky\ndblight, www.iStockphoto.com\nWikimedia\nwww.public-domain-image.com\nabcphotosystem, www.shutterstock.\ncom\nWikimedia\nFotoflash, www.bigstock.com\nBjørn Rørslett\nNational Institute of Mental Health,\nWikimedia, PD\nKind permission John Graner,\nNeuroimaging Department, National\nIntrepid Center of Excellence, Walter\nReed National Military Medical\nCenter, 8901 Wisconsin Avenue,\nBethesda, MD 20889, USA\nThomas Schultz, Wikimedia, CC3\nJens Maus, Wikimedia, PD\nwww.shutterstock.com and James\nTagg\nIllustrated by James Tagg includes\nwww.shutterstock.com components.\nWikimedia, PD\nMichiel de Wit, www.shutterstock.com\nIllustrated by James Tagg\nKind permission of BBC, hosted on\nYouTube\nJames Tagg, Sketchup Model\nIllustrated by James Tagg\nKind permission to link provided by\nDaniel Simons. DVDs can be purchased\nfrom www.viscog.com\nKind permission of www.craighansongolf.com\nIllustrated by James Tagg\nMeletver, www.bigstock.com\nmicro_photo, istock\nKind permission Travis Craddock\nWikimedia\nchippix, www.shutterstock.com\nSpike Milligan Enterprises\nTopFoto[]\nLewis Carroll, Out of Copyright\nLewis Carroll, Out of Copyright\nIllustrated by James Tagg\n378 Are the Androids Dreaming Yet?\nLoch Ness Monster Picture\nThe Loch Ness Monster’s Song\nDyslexic Poem\nStarry Night, van Gogh\nGame of Battleship\nJesse our Creative Kitten\nChapter 6\nOrangutan and Kitten\nTwin Guards\nGroucho Marx\nEuclid’s Elements, Oxyrhynchus Papyrus\nChapter 7\nMandelbrot Set\nBubble Sort Ballet, video\nMaze\nTravelling Salesman Problem\nRubik’s Cube\nComplexity Scale\nButterfly Beginnings of a Tornado?\nTrajectories\nPoincaré Portrait\nBlue Marble, Weather Patterns\nLorenz Attractor\nNebula\nCellular Automaton\nConway’s ‘Life’\nChapter 8\nHilbert’s Hotel\nSpears and Hunters\nUnknown, Hoax\nFrom Glasgow to Saturn (Carcanet,\n1973) also published in Collected\nPoems (Carcanet, 1990) Reprinted by\npermission of Carcanet Press.\nKind permission of the copyright\nholder: The Journal of Irreproducible\nResults, the science humor magazine,\nwww.jir.com, 1994 and 2000, via the\nauthor Jerrold H. Zar\nWikimedia, PD\nwww.shutterstock.com\nJames Tagg\nChris Butler, www.bigstock.com\nManamana, www.shutterstock.com\nLibrary of Congress, PD\nWikimedia, PD\nSteve Buckley, www.shutterstock.com\nCreated at Sapientia University, Tirgu\nMures (Marosvásárhely), Romania.\nDirected by Kátai Zoltán and Tóth\nLászló. In cooperation with “Maros\nMűvészegyüttes”, Tirgu Mures\n(Marosvásárhely), Romania.\nVasilius, www.bigstock.com\nIllustrated by James Tagg, map from\nwww.bigstock.com\nPhotograph by James Tagg\nIllustrated by James Tagg\nsaichol chandee, www.shutterstock.\ncom\nKind permission Steinn Sigurðsson\n(1991)\nEugène Pirou, Wikimedia, PD\nReto Stöckli, NASA Earth Observatory\nzentilia, www.bigstock.com\nCredit NASA\nWeisstein, Eric W. “Cellular\nAutomaton.” From MathWorld--A\nWolfram Web Resource.\nJames Tagg screen capture of an MIT\nopensource project\nKaramysh www.bigstock.com\nMunduruku, Wikimedia cc2.5\nAcknowledgements\n379\nTraversing an Infinite plane with a Line\nSpear and Hunter\nHilbert Hotel Video Link\nHolding Infinity in Your Hand\nNumber Quiz 1\nNumber Quiz 2\nDonate a Random Number\nWhich Number is Random\nSmallpox Virus\nSmallpox Child\nIllustrated by James Tagg\nIllustrated by James Tagg\nKind permission of BBC, hosted on\nYouTube\nPhotograph by James Tagg\nIllustrated by James Tagg\nIllustrated by James Tagg\nIllustrated by James Tagg\nIllustrated by James Tagg\n3d4Medical.com/Corbis\nAssociated Press, SANTOSH BASAK\nChapter 9\nDonald Rumsfeld\nUS Army, Wikimedia, PD\nKurt Gödel, any Likeness is Accidental Unknown, Wikimedia, PD\nIAF Rule 164\nIAF rules excerpt\nPM\nPaul Hermans, Wikimedia, CC3\nAmazon Listing for PM\nAmazon excerpt (not in print version)\n1+1 = 2, PM (1) PM excerpt\n1+1 = 2, PM (2) PM excerpt\nKonigsberg’s Bridges\nBogdan Giuşcă, Wikimedia, PD\nPeano Portrait\nMaterialscientist, Wikimedia, PD\nBeer Mug, Table and Chair\nPhotograph by James Tagg\nEinstein and Gödel\nKind permission of the Archive of the\nInstitute of Advanced Study\nChapter 10\nAlan Turing Portrait\nEnigma Machine\nCan you decode this?\nCorrect the code\nLego Turing Machine\nOld Fashioned Relay Mechanism\n3D Printing Machine\nBlock Print from ‘No Silver Bullet’\nChapter 11\nFred Brooks\nWeb Page (James Tagg’s Home Page)\nDilbert Software Specification\nLong Multiplication\nA Hypercube in Two Dimensions\nImpossible Shapes, Devil’s Tuning Fork\nHalting Program\nFour Color Problem\nDalek Trouble\nAugustus De Morgan Poem\nNational Portrait Gallery\nSperling, Wikimedia, PD\nIllustrated by James Tagg\nIllustrated by James Tagg\nwww.LegoTuringMachine.org\nWikimedia, Signalhead, CS3\n360b / www.shutterstock.com\nWikimedia, PD\nCopyright owned by SD&M,\nWikimedia CC3\nScreen capture by James Tagg\nDILBERT © 2006 Scott Adams.\nUsed By permission of UNIVERSAL\nUCLICK. All rights reserved.\nIllustrated by James Tagg\nMouagip, Wikimedia, CC3\nIllustrated by James Tagg\nIllustrated by James Tagg\nchas zzz brown, Wikimedia, CC3\nBirkett 1981, Permission Punch\nAugustus De Morgan, (pd)\n380 Are the Androids Dreaming Yet?\nWord Puzzle\nCreative Inoculation\nJackson Pollock\nJeopardy\nProgramming Cartoon\nSpecification Cartoon\nChapter 12\nTwo Digital Brains Communicating\nPerpetual Motion from the 1600s\nBlack Hole Malament-Holgarth Space\nSynapses and Tubulin\nChapter 13\nWorld Communication\nIMAX\nHologram\nGennadií Makanin Excerpt of paper\non Word Puzzles\nIllustrated by James Tagg\nAlbright-Knox Art Gallery/CORBIS,\nPollock-Krasner Foundation / Artists\nRights Society (ARS), New York\nAssociated Press Carol Kaelson/\nJeopardy Productions Inc\nKind permission Geekherocomic\nCredit Paragon Innovations\nPhotobank Gallery, www.shutterstock.\ncom\nRobert Fludd’s 1618 “Water Screw”,\nWikimedia, PD\nCrystal Graphics\nCrystal Graphics\nAntartis, www.bigstock.com\nLouie Psihoyos/Corbis\nvideodoctor, www.shutterstock.com\nChapter 14\nInvention of Light Bulb, Thomas Edison Corbis, Betmann\nSteve Jobs Shows the iPhone\nCorbis, Reuters\nStopwatch 60 seconds!\nStudio 37, www.shutterstock.com\nPaperclip Test\nIllustrated by James Tagg\n30 Things Test Illustrated by James Tagg\nPaperclip Test2\nIllustrated by James Tagg\nEureka\nKoS, Wikimedia, PD\nCircle with Dot, Problem\nIllustrated by James Tagg\nThinking Outside the Box\nIllustrated by James Tagg\nJohn Cleese, Video Link\nPicture from www.shutterstock, links\nto World Innovation Forum, YouTube\ntalk in iBook version and on website.\nSketch Test\nIllustrated by James Tagg\nHard Drives\nwww.shutterstock.com\nHarold Cohen and AARON\nJames Tagg at the Computer Museum\nHarold Cohen and AARON\nJames Tagg at the Computer Museum\nOld Polo\nGeneric Polo Photo\nNew Polo\nFingerhut, www.shutterstock.com\nChapter 15\nDilbert on Free Will\nDomino Toppling\nDILBERT © 1993 Scott Adams.\nUsed By permission of UNIVERSAL\nUCLICK. All rights reserved.\n(c) www.austriandominoart.com\nAcknowledgements\n381\nNewton’s Rings\nWave Interference\nSolvay Conference\nInterferometer\nSchrödinger’s Cat\nPolarized Glasses, Glare and No Glare\nBell Test\nLeft and Right Socks\nMorse Signaling\nDawkins and Atheist Bus\nFork in the Road\nLeft Hand Rule\nOrthogonal Sticks\nM.C. Escher’s “Waterfall”\nKochen-Specker Cube\nRussian Dolls\nChapter 16\nThe HMS Beagle\nNobel Prize Medal\nGolden Hall, Sweden\nPulitzer Prize Medal\nFirst XPRIZE Award Ceremony\nFields Medal\nChapter 17\nOmar Khayyam\nAppendices\nLeonardo da Vinci, Self Portrait\nBritish Library\nExperiment, ATLAS, CERN\nPanda\nConway and Kochen\nLooney Tunes “That’s all Folks”\nWikimedia\nSingle image in Book. Slide show in\niBook, Various; Wikimedia www.\nshutterstock.com, www.bigstock.com\nBenjamin S. Couprie, Wikimedia, PD\nIllustrated by James Tagg\nDhatfield, Wikimedia, CC3\nHUB, Wikimedia, CC3\nIllustrated by James Tagg\nHofmeester, Bigstock.com\nIllustrated by James Tagg\nWikimedia, CC2\nfivepointsix, www.bigstock.com\nPhotograph by James Tagg\nIllustrated by James Tagg\n© 2014 The M.C. Escher Company-\nThe Netherlands. All rights reserved.\nwww.mcescher.com\nJames Tagg modeled in Sketchup\nRobyn Mackenzie, www.bigstock.com\nBettmann/Corbis\nWikimedia, PD\nvichie81, www.shutterstock.com\nOriginal Daniel Chester French, photo\nupload Katpatuka, Wikimedia, PD\nKbh3rd, Wikimedia, CC3\nStefan Zachow, Wikimedia, PD\nWikimedia, PD\nWikimedia, PD\nDiliff, Wikimedia, CC2.5\nxdrew, www.shutterstock.com\nleungchopan, www.shutterstock.com\nPhotograph courtesy of\nPrinceton University’s Office of\nCommunications; Denise Applewhite,\nphotographer\nWikimedia, PD\nThe Wikimedia Creative Commons Licenses 1, 2, 2.5 and 3 may be found at www.\nwikimedia.com. PD indicates a public domain.\nIn the case of items marked ‘video’ clicking on the image in the iBook or eBook\nwill link to YouTube. The links are also available at www.jamestagg.com/videolinks\nfor book readers.\nReading Room at the British Museum\n“From the moment I picked your\nbook up until I laid it down I\nwas convulsed with laughter.\nSome day I intend reading it.”\nGroucho Marx\nAppendix 2\nBibliography\nI\nam not resident at an academic institution, nor do I work for a large\ncompany with access to a broad range of journal subscriptions. I have\na degree in Physics and Computer Science, so I am no layman. The\nmodern web gives amateurs like me, easy access to enormous information\nresources that would only have been available from the finest University\nlibraries even five years ago. Over time I have built up a personal library\nof books in the field, many of them ex-library copies which, by their date\nstamps, were never borrowed in their home universities!\nI’m always skeptical of the enormous bibliographies found in the\nback of science books and whether they are ever read. If you want a\npointer to the next books to read, here are some suggestions: A Brief\nHistory of Time, The Man who Mistook his Wife for a Hat, The Emperor’s\nNew Mind, The Naked Jape, Gödel Escher Bach, Proust and the Squid,\nLogic, A Five Day Course in Thinking, Your Brain on Music, The 4%\nUniverse, From Eternity to Here and Time.\n384 Are the Androids Dreaming Yet?\nJournal\nScientific American\nWikipedia\nThe Economist\nScience: The American Institute\nfor the Advancement of Science.\nCost\nSome free articles, Membership $150 p.a.\nFree\nFree to search but a subscription needed for\nfull articles, $200\nAnnual Subscription $151\nMind Annual Subscription, $200\nGoogle Scholar\nFree to search and often free to view, but\nsome articles require membership of underlying\nservices. From here you jump off into\nan endless series of journals too numerous\nto mention.\nGoogle Books\nFree, but you buy a lot of books!\nAmazon\nSome free material but again lot of book\nbuying\nJStor\nVariable, based on area of interest\nArxiv.org\nAll the pre- prints of forthcoming papers.\nInvaluable. Free\nSpringerLink\nArticle by article purchase, $35 each\nSubscriptions and Sources\nChapter 1\nBellos, Alex. Alex’s Adventures in Numberland. Bloomsbury Publishing PLC, 2010.\nby Richard Roeper. Urban Legends: The Truth behind All Those Deliciously\nEntertaining Myths That Are Absolutely, Positively, 100 Percent Not True.\nCareer Press, 1999.\nCairns-Smith, A. Graham. Evolving the Mind: On the Nature of Matter and the\nOrigin of Consciousness. Cambridge University Press, 1996.\nDawkins, Richard. The Magic of Reality: How We Know What’s Really True. Bantam\nPress, 2011.\nEricsson, K. Anders. “Attaining Excellence through Deliberate Practice: Insights\nfrom the Study of Expert Performance.” The Pursuit of Excellence through\nEducation, 2002, 21–55.\n———. “Deliberate Practice and the Acquisition and Maintenance of Expert\nPerformance in Medicine and Related Domains.” Academic Medicine 79, no.\n10 (2004): S70–81.\nEricsson, K. Anders, Ralf T. Krampe, and Clemens Tesch-Römer. “The Role of\nDeliberate Practice in the Acquisition of Expert Performance.” Psychological\nBibliography\n385\nReview 100, no. 3 (1993): 363.\nFiske, John. Introduction to Communication Studies. 3rd ed. Routledge, 2010.\nFranklin, Stan. Artificial Minds. MIT Press, 1997.\nGilovich, Thomas. How We Know What Isn’t So: Fallibility of Human Reason in\nEveryday Life. Reprint. The Free Press, 1993.\nGregory, Robert J. Psychological Testing: History, Principles, and Applications. 6th\ned. Pearson, 2010.\nHameroff, S. R. “Quantum Coherence in Microtubules: A Neural Basis for\nEmergent Consciousness?” Journal of Consciousness Studies 1, no. 1 (1994):\n91–118.\nHameroff, Stuart R., and Alfred W. Kaszniak. Toward a Science of Consciousness:\nThe First Tucson Discussions and Debates. MIT Press, 1996.\nHarel, David. Computers Ltd: What They REALLY Can’t Do. New Ed. OUP Oxford,\n2003.\nHawkins, Jeff, and Sandra Blakeslee. On Intelligence. Reprint. Owl Books (NY),\n2005.\nHofstadter, Douglas R. Godel, Escher, Bach: An Eternal Golden Braid. 20th\nAnniversary ed. Penguin, 2000.\nHowell, E. From Darness Light/Land of Stone/Shadow Worlds. Centaur, 2010.\n“IBM100 - Deep Blue.” CTB14, March 7, 2012. http://www-03.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/.\nIvancevic, Vladimir G., and Tijana T. Ivancevic. Quantum Neural Computation.\nSpringer, 2010.\nJibu, Mari, and Kunio Yasue. Quantum Brain Dynamics and Consciousness: An\nIntroduction. John Benjamins Publishing, 1995.\nJibu, M., S. Hagan, S. R. Hameroff, K. H. Pribram, and K. Yasue. “Quantum Optical\nCoherence in Cytoskeletal Microtubules: Implications for Brain Function.”\nBiosystems 32, no. 3 (1994): 195–209.\nLahoz-Beltra, R., S. R. Hameroff, and J. E. Dayhoff. “Cytoskeletal Logic: A Model\nfor Molecular Computation via Boolean Operations in Microtubules and\nMicrotubule-Associated Proteins.” BioSystems 29, no. 1 (1993): 1–23.\nMalcolm Gladwell. The Tipping Point: How Little Things Can Make a Big Difference.\nRepr. Abacus, 2001.\nMorris, Desmond. Child: How Children Think, Learn and Grow in the Early Years.\nHamlyn, 2010.\n———. The Naked Ape: A Zoologist’s Study of the Human Animal. New edition.\nVintage, 2005.\nNeumann, John Von. The Computer and the Brain. 2nd Revised edition. Yale\nUniversity Press, 2000.\nPenrose, Roger. The Large, the Small and the Human Mind. New Ed. Cambridge\nUniversity Press, 2000.\nPřibram, Karl H., and Sir John Carew Eccles. Rethinking Neural Networks:\nQuantum Fields and Biological Data. Routledge, 1993.\n“Return to Antikythera: Divers Revisit Wreck Where Ancient Computer Found.”\nThe Guardian, October 2, 2012. http://www.guardian.co.uk/science/\nblog/2012/oct/02/return-antikythera-wreck-ancient-computer.\nRobinson, Ken, and Lou Aronica. The Element: How Finding Your Passion Changes\nEverything. Penguin, 2010.\nRoebuck, Kevin. Emotional Intelligence: High-Impact Strategies - What You Need\nto Know: Definitions, Adoptions, Impact, Benefits, Maturity, Vendors. Tebbo,\n386 Are the Androids Dreaming Yet?\n2011.\nSacks, Oliver. An Anthropologist on Mars. 4th ed. Picador, 2009.\n———. The Man Who Mistook His Wife for a Hat. 1st ed. Picador, 1986.\nTucker, William H. The Cattell Controversy: Race, Science, and Ideology. University\nof Illinois Press, 2009.\nTuring, Alan M. “Intelligent Machines.” Ince, DC (Ed.) 5 (1992). http://isites.harvard.edu/fs/docs/icb.topic958294.files/lecture-00-handout.pdf.\nVitiello, Giuseppe. My Double Unveiled: The Dissipative Quantum Model of Brain.\nJohn Benjamins Publishing, 2001.\nWhitehead, Alfred North, and Bertrand Russell. Principia Mathematica - Volume\nOne: 1. Rough Draft Printing, 2009.\nWinston, Robert. The Human Mind and How to Make the Most of It. New edition.\nChartered Institute of Personnel and Development, 2006.\nWolf, Maryanne. Proust and the Squid: The Story and Science of the Reading Brain.\nIcon Books Ltd, 2008.\nWolfram, Stephen. A New Kind of Science. First Edition. Wolfram Media Inc, 2002.\nChapter 2\nCarr, Jimmy, and Lucy Greeves. The Naked Jape: Uncovering the Hidden World of\nJokes. Penguin, 2007.\nCobley, Paul. The Communication Theory Reader. 1st ed. Routledge, 1996.\nDawkins, Richard. Unweaving the Rainbow: Science, Delusion and the Appetite for\nWonder. Reisssue. Penguin, 2006.\nHume, David. An Enquiry Concerning Human Understanding. New Ed. /. OUP\nOxford, 2008.\nLocke, John. An Essay Concerning Human Understanding. Abridged edition.\nHackett Publishing Co, Inc, 1996.\nMartin, Robert M. There Are Two Errors in the the Title of This Book*. Rev. and\nExpanded Ed. Broadview Press Ltd, 2002.\nSacks, Oliver. An Anthropologist on Mars. 4th ed. Picador, 2009.\nTufte, Edward R. The Cognitive Style of PowerPoint: Pitching Out Corrupts Within.\n2nd ed. Graphics Press, 2006.\nWiseman, Prof. Richard. Quirkology: The Curious Science Of Everyday Lives. 2nd\ned. Pan, 2011.\nChapter 3\nBorg, James. Body Language: 7 Easy Lessons to Master the Silent Language. 1st ed.\nPrentice Hall Life, 2008.\nBrounstein, Marty. Communicating Effectively for Dummies. John Wiley & Sons,\n2001.\nby Seth Godin ; with a foreword by Malcolm Gladwell. Unleashing the Ideavirus :\nHow to Turn Your Ideas into Marketing Epidemics. Free Press, 2002.\nDarwin, Charles. The Origin of Species. New edition. Wordsworth Editions Ltd,\n1998.\nFiske, John. Introduction to Communication Studies. 3rd ed. Routledge, 2010.\nMorris, Desmond. Peoplewatching: The Desmond Morris Guide to Body Language.\nVintage, 2002.\n———. The Human Zoo. New edition. Vintage, 1994.\n———. The Naked Ape: A Zoologist’s Study of the Human Animal. New edition.\nVintage, 2005.\nBibliography\n387\nNavarro, Joe. What Every Body Is Saying: An Ex-FBI Agent’s Guide to Speed-Reading\nPeople. HarperCollins Publishers, 2008.\nOgilvy, David. Ogilvy on Advertising. New edition. Prion Books Ltd, 2007.\nRoebuck, Kevin. Emotional Intelligence: High-Impact Strategies - What You Need to\nKnow: Definitions, Adoptions, Impact, Benefits, Maturity, Vendors. Tebbo, 2011.\nSchirato, Tony, and Susan Yell. Communication and Culture: An Introduction. 2nd\nRevised edition. Sage Publications Ltd, 2000.\nTaylor, Kathleen. Brainwashing: The Science of Thought Control. New Ed. OUP\nOxford, 2006.\nWinston, Professor Lord Robert. Human Instinct. New edition. Bantam, 2008.\nChapter 4\nDerren Brown. Tricks of the Mind. Channel 4, 2006.\nGurney, Kevin. An Introduction to Neural Networks. CRC Press, 1997.\nHameroff, S. R. “Quantum Coherence in Microtubules: A Neural Basis for\nEmergent Consciousness?” Journal of Consciousness Studies 1, no. 1 (1994):\n91–118.\nHigbee, Kenneth L., and Ph.D. Your Memory: How It Works and How to Improve It.\n2Rev Ed. Avalon Group, 2001.\nJibu, M., S. Hagan, S. R. Hameroff, K. H. Pribram, and K. Yasue. “Quantum Optical\nCoherence in Cytoskeletal Microtubules: Implications for Brain Function.”\nBiosystems 32, no. 3 (1994): 195–209.\nJimmy Carr. The Naked Jape : Uncovering the Hidden World of Jokes. Michael\nJoseph, 2007.\nLahoz-Beltra, R., S. R. Hameroff, and J. E. Dayhoff. “Cytoskeletal Logic: A Model\nfor Molecular Computation via Boolean Operations in Microtubules and\nMicrotubule-Associated Proteins.” BioSystems 29, no. 1 (1993): 1–23.\nO’Brien, Dominic. How to Develop a Brilliant Memory Week by Week: 52 Proven\nWays to Enhance Your Memory Skills. Duncan Baird Publishers, 2005.\nPicton, P.D. Neural Networks. 2nd Revised edition. Palgrave Macmillan, 2000.\nSiegelmann, Hava T. Neural Networks and Analog Computation: Beyond the Turing\nLimit. Birkhauser, 1998.\nWinston, Robert. The Human Mind and How to Make the Most of It. New edition.\nChartered Institute of Personnel and Development, 2006.\nWolf, Maryanne. Proust and the Squid: The Story and Science of the Reading Brain.\nIcon Books Ltd, 2008.\nChapter 5\nAaronson, Scott. Quantum Computing since Democritus. New York: Cambridge\nUniversity Press, 2013.\nBorges, Jorge Luis, and Andrew Hurley. The Library of Babel. Boston: David R.\nGodine Publisher Inc, 2000.\nChaitin, Gregory J. Meta Maths: The Quest for Omega. Atlantic Books, 2007.\nTolstoy, Leo. War and Peace. Ware: Wordsworth Editions, 2001.\nChapter 6\nAyer, A. J. Language, Truth and Logic. 2nd ed. Dover Publications Inc., 2002.\nBoaler, Jo. The Elephant in the Classroom: Helping Children Learn and Love Maths.\nSouvenir Press Ltd, 2010.\nCarroll, Lewis. Lewis Carroll’s Games and Puzzles. 40th ed. Dover Publications Inc.,\n388 Are the Androids Dreaming Yet?\n1992.\n———. Symbolic Logic. New issue of 1896 ed. Dover Publications Inc., 2000.\nCrilly, Tony. The Big Questions: Mathematics. Quercus Publishing Plc, 2011.\nDoxiadis, Apostolos, and Christos H. Papadimitriou. Logicomix: An Epic Search for\nTruth. First Edition. Bloomsbury Publishing PLC, 2009.\nGoldrei, D.C. Classic Set Theory: A Guided Introduction. Chapman and Hall/CRC,\n1996.\nHodges, Wilfrid. Logic. 2nd Revised edition. Penguin, 2001.\nMartin, Robert M. There Are Two Errors in the the Title of This Book*. Rev. and\nExpanded Ed. Broadview Press Ltd, 2002.\nNewbery, John. Logic Made Familiar and Easy: To Which Is Added a Compendious\nSystem of Metaphysics Or Ontology : Being the Fifth Volume of the Circle of\nthe Sciences, &c. Published by the King’s Authority. BiblioBazaar, LLC, 2010.\nOechslin, Werner. Byrne, Six Books of Euclid: Facsimile of the Famous First Edition\nof 1847. Har/Pap. Taschen GmbH, 2010.\nRussell, Bertrand. Introduction to Mathematical Philosophy. Reprint. Spokesman\nBooks, 2007.\nChapter 7\nGleick, James. Chaos: Making a New Science. New edition. Vintage, 1997.\nGriffeath, David, and Cristopher Moore. New Constructions in Cellular Automata.\nOxford University Press, 2003.\n“Mathematical Games - The Fantastic Combinations of John Conway’s New\nSolitaire Game ‘Life’ - M. Gardner - 1970,” June 3, 2009. http://web.archive.\norg/web/20090603015231/http://ddi.cs.uni-potsdam.de/HyFISCH/\nProduzieren/lis_projekt/proj_gamelife/ConwayScientificAmerican.htm.\nMitchell, Melanie. Complexity: A Guided Tour. OUP USA, 2009.\nWeisstein, Eric W. “Elementary Cellular Automaton.” Text. Accessed September 28,\n2014. http://mathworld.wolfram.com/ElementaryCellularAutomaton.html.\nWolfram, Stephen. A New Kind of Science. First Edition. Wolfram Media Inc, 2002.\nChapter 8\nCantor, Georg. Contributions to the Founding of the Theory of Transfinite Numbers.\nDover Publications Inc., 2003.\nClegg, Brian. Brief History of Infinity: The Quest to Think the Unthinkable. Robinson\nPublishing, 2003.\nCohen, Paul J. Set Theory and the Continuum Hypothesis. Dover Publications Inc.,\n2009.\nPica, Pierre, and Alain Lecomte. “Theoretical Implications of the Study of Numbers\nand Numerals in Mundurucu.” Philosophical Psychology 21, no. 4 (August 1,\n2008): 507–22. doi:10.1080/09515080802285461.\nPica, Pierre, Cathy Lemer, Véronique Izard, and Stanislas Dehaene. “Exact and\nApproximate Arithmetic in an Amazonian Indigene Group.” Science 306,\nno. 5695 (October 15, 2004): 499–503. doi:10.1126/science.1102085.\nPotter, Michael. Set Theory and Its Philosophy: A Critical Introduction. Clarendon\nPress, 2004.\nChapter 9\nChaitin, Gregory J. Thinking About Gödel And Turing: Essays On Complexity 1970-\n2007. World Scientific Publishing, 2007.\nBibliography\n389\nFranzén, Torkel. Gödel’s Theorem: An Incomplete Guide to Its Use and Abuse. A K\nPeters/CRC Press, 2005.\nGödel, Kurt. On Formally Undecidable Propositions of “Principia Mathematica” and\nRelated Systems. New edition. Dover Publications Inc., 2003.\nGoldrei, D.C. Classic Set Theory: A Guided Introduction. Chapman and Hall/CRC,\n1996.\nHofstadter, Douglas R. Gödel, Escher, Bach: An Eternal Golden Braid. 20th\nAnniversary ed. Penguin, 2000.\nNagel, Ernest, and James R. Newman. Gödel’s Proof. Rev. Ed. New York University\nPress, 2001.\nNewton, Sir Isaac. Principia. Prometheus Books, 1995.\nPenrose, Sir Roger. Shadows Of The Mind: A Search for the Missing Science of\nConsciousness. New edition. Vintage, 2005.\nPotter, Michael. Set Theory and Its Philosophy: A Critical Introduction. Clarendon\nPress, 2004.\nRussell, Bertrand. Introduction to Mathematical Philosophy. Reprint. Spokesman\nBooks, 2007.\nSautoy, Marcus Du. The Music of the Primes: Why an Unsolved Problem in\nMathematics Matters. New Ed. Harper Perennial, 2004.\n———. The Number Mysteries: A Mathematical Odyssey Through Everyday Life.\nFourth Estate, 2010.\nWhitehead, Alfred North, and Bertrand Russell. Principia Mathematica - Volume\nOne: 1. Rough Draft Printing, 2009.\nChapter 10\nCopeland, B. Jack. The Essential Turing. Clarendon Press, 2004.\nDavid, Hans T. The New Bach Reader: Life of Johann Sebastian Bach in Letters and\nDocuments. New edition. W. W. Norton & Co., 1999.\nDennett, Daniel C., and Douglas R. Hofstadter. The Mind’s I: Fantasies and\nReflections on Self and Soul. Basic Books, 2000.\nDewdney. New Turing Omnibus. Reprint. Palgrave Macmillan, 2003.\nedited by B. Jack Copeland. The Essential Turing : Seminal Writings in Computing,\nLogic, Philosophy, Artificial Intelligence, and Artificial Life plus the Secrets of\nEnigma. Reprinted. Clarendon Press, 2005.\nGallwey, W Timothy, and Barry Green. Inner Game of Music. 7th ed. Pan, 2003.\nHofstadter, Douglas R. I Am a Strange Loop. Reprint. Basic Books, 2008.\nLevitin, Daniel J. This Is Your Brain on Music: Understanding a Human Obsession.\nAtlantic Books, 2008.\nPenrose, Roger. The Large, the Small and the Human Mind. New Ed. Cambridge\nUniversity Press, 2000.\nPenrose, Sir Roger. The Emperor’s New Mind: Concerning Computers, Minds, and\nthe Laws of Physics. New Ed. Oxford Paperbacks, 1999.\nPetzold, Charles. The Annotated Turing: A Guided Tour Through Alan Turing’s\nHistoric Paper on Computability and the Turing Machine. John Wiley &\nSons, 2008.\nSacks, Oliver. Musicophilia: Tales of Music and the Brain. Reprint. Picador, 2008.\nSingh, Simon. The Code Book: The Secret History of Codes and Code-Breaking.\n(Reissue). Fourth Estate, 2002.\nTuring, Alan. “Checking a Large Routine.” In The Early British Computer\nConferences, 70–72. MIT Press, 1989. http://dl.acm.org/citation.\n390 Are the Androids Dreaming Yet?\ncfm?id=94952.\nTuring, Alan M. “Can a Machine Think.” The World of Mathematics 4 (1956):\n2099–2123.\n———. “Computability and Λ-Definability.” The Journal of Symbolic Logic 2, no. 4\n(1937): 153–63.\n———. “Computing Machinery and Intelligence.” Mind, 1950, 433–60.\n———. “Computing Machinery and Intelligence.” In Computers & Thought, 11–35.\nMIT Press, 1995. http://dl.acm.org/citation.cfm?id=216410.\n———. “Intelligent Machines.” Ince, DC (Ed.) 5 (1992). http://isites.harvard.edu/fs/\ndocs/icb.topic958294.files/lecture-00-handout.pdf.\n———. “Rounding-off Errors in Matrix Processes.” The Quarterly Journal of\nMechanics and Applied Mathematics 1, no. 1 (1948): 287–308.\nTuring, Alan Mathison. “On Computable Numbers, with an Application to the\nEntscheidungsproblem.” J. of Math 58 (1936): 345–63.\n———. “Systems of Logic Based on Ordinals.” Proceedings of the London\nMathematical Society 2, no. 1 (1939): 161–228.\n———. “The Chemical Basis of Morphogenesis.” Bulletin of Mathematical Biology\n52, no. 1 (1990): 153–97.\nChapter 11\nBaxa, Christoph. “A Note on Diophantine Representations.” American\nMathematical Monthly, 1993, 138–43.\nBlass, Andreas, and Yuri Gurevich. “Algorithms: A Quest for Absolute Definitions.”\nBulletin of the EATCS 81 (2003): 195–225.\nBörger, Egon, Erich Grädel, and Yuri Gurevich. The Classical Decision Problem.\nSpringer, 2001.\nCarroll, Lewis. Symbolic Logic. New issue of 1896 ed. Dover Publications Inc., 2000.\nDavis, Martin, Hilary Putnam, and Julia Robinson. “The Decision Problem for\nExponential Diophantine Equations.” Annals of Mathematics, 1961, 425–36.\nDyson, Verena H., James P. Jones, and John C. Shepherdson. “Some Diophantine\nForms of Gödel’s Theorem.” Archive for Mathematical Logic 22, no. 1 (1980):\n51–60.\nFranzén, Torkel. Godel’s Theorem: An Incomplete Guide to Its Use and Abuse. A K\nPeters/CRC Press, 2005.\nHodges, Wilfrid. Logic. 2nd Revised edition. Penguin, 2001.\nJr, Frederick P. Brooks. The Mythical Man Month and Other Essays on Software\nEngineering. 2nd ed. Addison Wesley, 1995.\nKurzweil, Ray. How to Create a Mind: The Secret of Human Thought Revealed.\nPenguin, 2012.\nMatiyasevich, Yuri. HILBERT’S TENTH PROBLEM: What Can We Do with\nDiophantine Equations?. Accessed April 13, 2014. http://logic.pdmi.ras.\nru/~yumat/Journal/H10history/H10histe.pdf.gz.\nMinsky, Marvin Lee. Computation. Prentice-Hall Englewood Cliffs, 1967. http://\ncba.mit.edu/events/03.11.ASE/docs/Minsky.pdf.\nNagel, Ernest, and James R. Newman. Godel’s Proof. Rev. Ed. New York University\nPress, 2001.\nPenrose, Sir Roger. Shadows Of The Mind: A Search for the Missing Science of\nConsciousness. New edition. Vintage, 2005.\n———. The Emperor’s New Mind: Concerning Computers, Minds, and the Laws of\nPhysics. New Ed. Oxford Paperbacks, 1999.\nBibliography\n391\nReid, Constance. Julia: A Life in Mathematics. Washington, DC: The Mathematical\nAssociation of America, 1997.\nRice, Henry Gordon. “Classes of Recursively Enumerable Sets and Their Decision\nProblems.” Transactions of the American Mathematical Society 74, no. 2\n(1953): 358–66.\nRuohonen, Keijo. “Hilbertin Kymmenes Probleema.” Arkhimedes, no. 1 (1972): 2.\nSpolsky, J. “The Law of Leaky Abstractions,” November 11, 2002. http://www.\njoelonsoftware.com.\nTegmark, Max. “The Mathematical Universe.” Foundations of Physics 38, no. 2\n(2008): 101–50.\nTuring, Alan M. “Can a Machine Think.” The World of Mathematics 4 (1956):\n2099–2123.\nTuring, Alan Mathison. “On Computable Numbers, with an Application to the\nEntscheidungsproblem.” J. of Math 58 (1936): 345–63.\n———. “Systems of Logic Based on Ordinals.” Proceedings of the London\nMathematical Society 2, no. 1 (1939): 161–228.\nWiles, Andrew. “Modular Elliptic Curves and Fermat’s Last Theorem.” Annals of\nMathematics-Second Series 141, no. 3 (1995): 443–552.\nChapter 12\nBurgin, Mark. Super-Recursive Algorithms. Springer, 2005.\nDarwin, Charles. On the Origin of Species: By Means of Natural Selection. Dover\nGiant Thrift Ed. Dover Publications Inc., 2006.\nMitchell, Melanie. An Introduction to Genetic Algorithms. New edition. MIT Press,\n1998.\nSiegelmann, Hava T. Neural Networks and Analog Computation: Beyond the Turing\nLimit. Birkhauser, 1998.\nSyropoulos, Apostolos. Hypercomputation: Computing Beyond the Church-Turing\nBarrier. Softcover reprint of hardcover 1st ed. 2008. Springer, 2010.\nChapter 13\nShannon, C.E., and Warren Weaver. The Mathematical Theory of Communication.\nUniversity of Illinois Press, 1949.\nChapter 14\nBoden, Margaret A. The Creative Mind: Myths and Mechanisms. 2nd ed. Routledge,\n2003.\nBono, Edward de. How to Have Creative Ideas: 62 Exercises to Develop the Mind.\nVermilion, 2007.\n———. Lateral Thinking: A Textbook of Creativity. Penguin, 2009.\n———. Six Thinking Hats. Penguin, 2009.\nCoyle, Daniel. The Talent Code: Unlocking the Secret of Skill in Maths, Art, Music,\nSport, and Just About Everything Else, Random House Books, 2009.\nDavis, Ronald D., and Eldon M. Braun. The Gift of Dyslexia: Why Some of the\nBrighest People Can’t Read and How They Can Learn. 3rd Revised edition.\nSouvenir Press Ltd, 2010.\nEdward De Bono. How to Have Creative Ideas : 62 Exercises to Develop the Mind. 1\nAufl. Vermilion, 2007.\nIsaacson, Walter. Steve Jobs: The Exclusive Biography. Little, Brown, 2011.\nMcCandless, David. Information Is Beautiful. Collins, 2010.\n392 Are the Androids Dreaming Yet?\nRobinson, Ken. Out of Our Minds: Learning to Be Creative. 2nd Edition. Capstone,\n2011.\nRobinson, Ken, and Lou Aronica. The Element: How Finding Your Passion Changes\nEverything. Penguin, 2010.\nWinston, Professor Lord Robert. Bad Ideas?: An Arresting History of Our\nInventions. Bantam, 2011.\nChapter 15\nBell, John S., and others. “On the Einstein-Podolsky-Rosen Paradox.” Physics 1, no.\n3 (1964): 195–200.\nConway, John H., and Simon Kochen. “The Strong Free Will Theorem.” Notices of\nthe AMS 56, no. 2 (2009): 226–32.\nConway, John, and Simon Kochen. “Reply to Comments of Bassi, Ghirardi, and\nTumulka on the Free Will Theorem.” Foundations of Physics 37, no. 11\n(2007): 1643–47.\nDennett, Daniel Clement. Brainstorms: Philosophical Essays on Mind and\nPsychology. 8. MIT Press, 1981.\nDennett, Danile C. Kinds of Minds: Toward an Understanding of Consciousness.\nBasic Books, 2008.\nEkert, Artur K. “Quantum Cryptography Based on Bell’s Theorem.” Physical Review\nLetters 67, no. 6 (1991): 661.\n“EPR Paradox.” Wikipedia, the Free Encyclopedia, September 15, 2014. http://\nen.wikipedia.org/w/index.php?title=EPR_paradox&oldid=625734938.\nGilovich, Thomas. How We Know What Isn’t So: Fallibility of Human Reason in\nEveryday Life. Reprint. The Free Press, 1993.\nGisin, Nicolas. “The Free Will Theorem, Stochastic Quantum Dynamics and True\nBecoming in Relativistic Quantum Physics.” arXiv Preprint arXiv:1002.1392,\n2010. http://arxiv.org/abs/1002.1392.\nGoldstein, Sheldon, Daniel V. Tausk, Roderich Tumulka, and Nino Zanghì. “What\nDoes the Free Will Theorem Actually Prove.” Notices of the AMS 57, no. 11\n(2010): 1451–53.\nHawking, Stephen, and Leonard Mlodinow. The Grand Design: New Answers to the\nUltimate Questions of Life. Bantam Press, 2010.\nHeywood, Peter, and Michael LG Redhead. “Nonlocality and the Kochen-Specker\nParadox.” Foundations of Physics 13, no. 5 (1983): 481–99.\nHuang, Yun-Feng, Chuan-Feng Li, Yong-Sheng Zhang, Jian-Wei Pan, and Guang-\nCan Guo. “Experimental Test of the Kochen-Specker Theorem with Single\nPhotons.” Physical Review Letters 90, no. 25 (2003): 250401.\nRussell, Bertrand. The Problems of Philosophy. 2nd ed. Oxford Paperbacks, 2001.\nTumulka, Roderich. “Comment on ‘the Free Will Theorem.’” Foundations of Physics\n37, no. 2 (2007): 186–97.\nZhang, Yong-Sheng, Chuan-Feng Li, and Guang-Can Guo. “Quantum Key\nDistribution via Quantum Encryption.” Physical Review A 64, no. 2 (2001):\n024302.\nChapter 16\nLand, George, and Beth Jarman. Breakpoint and Beyond: Mastering the Future -\nToday. Reprint. HarperBusiness, 1993.\nLloyd, John, and John Mitchinson. QI: The Second Book of General Ignorance. Faber\nand Faber, 2010.\nBibliography\n393\nMichael Brooks. 13 Things That Don’t Make Sense : The Most Intriguing Scientific\nMysteries of Our Time. Profile, 2010.\nReason Special Interview with Roger Penrose, 2008. http://www.youtube.com/\nwatch?v=xiYDc1LA0I4&feature=youtube_gdata_player.\nReason Special Interview with Roger Penrose, 2008. http://www.youtube.com/\nwatch?v=xiYDc1LA0I4&feature=youtube_gdata_player.\nTegmark, Max. “The Importance of Quantum Decoherence in Brain Processes.”\narXiv:quant-ph/9907009, July 5, 1999. doi:10.1103/PhysRevE.61.4194.\nATLAS, CERN\n“Good one, publish.”\nMilliken\nAppendix 3\nPuzzles and\nExperiments\nIn this book I have suggested some experiments for you to undertake,\nand posed some puzzles to solve. You can participate in the\nexperiments or see the answers by going online and checking my\nwebsite at www.jamestagg.com\nJeopardy Answers from Chapter 1.\nAnswer 1. Watson answered, Gestate.\nAnswer 2. Watson answered. Who is Bram Stoker.\nAnswer 3. The answer is Chicago but Watson answered\n“Toronto?????”, the question marks indicating it was\nvery doubtful of the answer.\nPanda, Eats Shoots\n“Parenthetical remarks (however\nrelevant) are unnecessary.”\nFrank L. Visco,\nHow to Write Good\n“Defining what we mean by\na robot is hard to do. I know\nnow when I see one but that\ndefinition works for anything,\neven pizza.”\nMike Gregory\nAppendix 4\nConventions in\nthe Book\nThe use of italics is intended to give accent or indicate the title of\nthe published work, such as a book or movie. Inverted Commas\nshould read, ‘so called’.\nThe use of the ‘Oxford Comma’ – a comma after ‘and’ – gives a\nlonger break in a sentence to aid better understanding. You will find both\n‘and’ and, ‘and,’ used in this book deliberately.\nThe use of ‘their’ substitutes for he or she, and is a convention I\nbelieve will supersede, ‘he’ or ‘she’ and, ‘him’ or ‘her’.\nThe puzzles in this book are all available to download, so you\ndon’t need to deface the book. Feel free to deface it if you wish. Buy the\nelectronic version and save trees.\nSome of this book is historical or factual, while much is highly\nspeculative. I have tried to indicate where ideas are controversial and\nwhere they are matters of accepted science. However, my experience is\nthat much of what you are taught tends to be a gross generalization or\neven plain wrong. If you treat facts with a degree of skepticism, you will\nfind this keeps you in good stead.\nAs someone who is highly dyslexic, there will be errors. Please email\nme the ones you find, and recommend the book to your friends so that I\ncan afford to print a second edition with your corrections.\nI have avoided the use of equations and mathematics, so you\ncan see the flow of the philosophical argument. I also avoid a strongly\nhistorical narrative, but if you enjoy the history of science I recommend,\nThe Missing 4%, and Quantum for a really clear exposé of the issues\n398 Are the Androids Dreaming Yet?\naround quantum mechanics, relativity and cosmology, Robert Winston’s\nBad Ideas for a more thorough history of language and writing, and The\nTrouble with Physics for the recent history of particle Physics. Regarding\nthe brain, anything by Oliver Sachs is a winner. Your Brain on Music is a\ngood primer on the theory of artistic thought and music, and Proust and\nthe Squid is a good discussion of dyslexia and learning.\nThe digits for the sequence of the Smallpox virus in Chapter Eight\ncome from the varicella-zoster virus, a similar pathogen. The first few\nletters could be the same, but I hope it is impossible for anyone to\ndisprove this as you would have to break into the CDC to do so.\nJohn Masters is not the real name of the US officer who spoke in\nKabul. That name was never released to the press.\nThis book was originally written using Microsoft Word on a MacBook\nPro. It was then typeset for print using a variety of ePublication tools,\nincluding iBooksAuthor and Adobe InDesign. You can find a website for\nthe book at www.jamestagg.com. It is published using WordPress. All\nthe links in the book should be maintained there just in case there is link\natrophy for the printed version of the book. Feel free to comment using\nthe blog, Twitter, Facebook or email me.\nConway and Kochen\n“It doesn’t matter how beautiful\nyour theory is, it doesn’t matter\nhow smart you are. If it doesn’t\nagree with experiment, it’s\nwrong.”\nRichard P. Feynman\n\nAppendix 5\nIndex of Theorems\nI\nhave explained a number famous theorems in this book along with\nsome ideas of my own. Here is a list of the most notable.\n1. Mind over Computer\nTuring Test – How to tell whether a computer is intelligent, even\nthough we cannot agree on a definition of intelligence.\nFlynn Effect – The observation that human intelligence appears\nto be improving over time.\nKurzweil Singularity Proposal – The conjecture that Moore’s\nLaw will result in computers acquiring near infinite power\nrelatively soon.\nLucas Argument – Minds are in a different class to computers as\nthey are not limited by the incompleteness theorem.\nHumor Hypothesis† – Humor and jokes are a display of noncomputable\nintelligence.\n2. Understanding\nTufte’s Assertion – That communication of understanding\nexceeds the capability of many presentation tools, particularly\nPowerPoint.\nChinese Room – John Searle’s paradox challenging the idea that\nunderstanding can be mechanically simulated.\n402 Are the Androids Dreaming Yet?\n3. Body Language & Banter\nCommunication Hypothesis† – That face to face communication\nis more powerful in some real physical sense than symbolic\ncommunication.\n7-38-55 Rule – Mehrabian’s observation that the emotional\ncontent of communication is 7% words, 38% tone of voice and\n55% body language.\n4. The Brain\nPenrose-Hameroff Conjecture – Brains are quantum-gravity\ncomputers using tubulin as the mediator.\n5. Knowledge\nInformation Continuum Hypothesis† – Information is finite,\nbut understanding and knowledge are different in nature.\nInfinite Monkeys Hypothesis – The paradox that says monkeys\ncould type Hamlet given enough time and paper.\nCat Experiment† – Finding my house cat can use our computer,\nand may be more creative than monkeys!\n6. Kittens & Gorillas\nFeynman Proof – A proof that uses the lack of an evolved\nspecies within an evolutionary niche to disprove the existence of\nsomething; in this case polywater.\nThe Infinity of Primes – Pythagoras’ proof there are an infinity\nof prime numbers without needing the concept of a number.\n7. Complexity & Chaos\nThe Butterfly Effect – The proposal by Edward Lorenz that tiny\neffects can multiply up into enormous results.\nP≠NP – That non-deterministic polynomial problems can never\nbe solved in polynomial time and are, therefore, beyond the\ncapability of any imagined computer.\nThe Hawking-Bekenstein Turk† – Although there is a perfect\nchess machine, it would collapse space-time to a black hole were\nit to exist.\n8. ∞\nContinuum Hypothesis – Does anything come between the\nfirst two infinities; counting numbers and the continuum of real\nnumbers.\nIndex of Theorems\n403\nCantor’s First Infinity Theorem – The infinite plane is the same\ninfinity as the infinite line.\n9. Known Unknowns\nGödel’s Incompleteness Theorem – Mathematics involving\nsimple logic is incomplete.\nGödel’s Completeness Theorem – First order logic is complete.\nHilbert’s Completeness Theorem – Geometry is complete.\n10. Turing’s Machines\nEntscheidungsproblem – The decision problem has no solution.\nTuring Thesis – All computers, once sufficiently powerful, are\nequally powerful.\nNon-Computability of Music† – That general musical\ncompositions are non-computable.\nNon-Computability of Creativity† – That general artistic\ncreativity is non-computable.\n11. Software\nBrooks’ Law – Adding resource to a late project makes it later.\nLaw of Leaky Abstractions – However good the attempt to\nabstract complexity, complexity has a habit of leaking through.\nSoftware is Created† – writing software is a non-computable,\ncreative task.\nBug Hypothesis† – Bugs are an inevitable consequence of trying\nto generalize software by mechanical means.\n12. Hyper-Computing\nAdaptive Recurrent Neural Network Hypothesis – Hava\nSiegelmann’s proposal that ARNNs are capable of super-Turing\ncomputation.\n13. Hyper-Communication\nBandwidth Conjecture† – Person-to-person communication\nhas infinite bandwidth and is non-symbolic.\n14. Creativity\nCreativity Hypothesis† – That all creative endeavor is a noncomputable\nskill, analogue to theorem discovery.\nWallas Model – A conceptual model for the way humans think\ncreatively.\n404 Are the Androids Dreaming Yet?\nCreative Survival Advantage† – That creativity has evolved to\ngive us a survival advantage at all stages of evolution, not just when\nwe evolve to the point where mathematical intuition is significant.\n15. Free Will\nLaplace Daemon – A conceptual supreme being able to infer\nthe future and the past from one snapshot of space-time and the\nlaws of nature.\nEPR Paradox – Twin particles would transmit information\nfaster than the speed of light if quantum mechanics was to be\nbelieved.\nSchrödinger’s Cat – The paradox that a cat might be both alive\nand dead at the same time until observed.\nBell Inequality – Quantum mechanics forbids local hidden\nvariables in a testable way. The test succeeds.\nKochen-Specker Paradox – Particles cannot know their settings\nbefore measurement.\nFree Will Theorem – Nothing in the past light cone of the\nUniverse causes a particle to choose its spin upon measurement.\nNon-decryptable Universe† – The laws of physics mean the\nUniverse is non-computable in principle.\nFree Will Universe† – The laws of mathematics mean the\nUniverse is non-computable and therefore has Free Will.\nRussian Doll Conjecture† – Since humans are creative and\nnon-deterministic and, in a sense, they run upon the hardware\nof the Universe, the hardware of our Universe must also be nondeterministic.\n16. The Quest for Knowledge\nTechnology Hypothesis† – The extended strong anthropic\nprinciple that the Universe must have creative beings within it\nto uniquely define it.\n17. The Future\nCreative Non-Singularity† – The future is non-computable and\ntherefore any increase in computer power, however great, will\nnever achieve a creativity singularity.\n† The symbol marks items proposed for the first time within this\nbook. If I have missed a previous publication, please feel free to\nwrite to me and I will amend a future version.\nIndex\nSymbols\n∀∃∀ 249\n∃ 249\n3D chip 21, 22\n3D printing 20, 222\n7%-38%-55% rule 84\n50 First Dates 12\nA\nAARON 310\nAaronson, Scott 168\nabstraction 267\nAcademy Awards 365\nAccidental Complexity 231\nactin 98\nActivision 290\nAdams, Douglas 17, 128, 225, 238, 305,\n314\nAdams, Scott 296\nAdaptive Recurrent Neural Network 280\nAdleman, Leonard 165\nAdvanced Course in Design,\nManufacturing and Management\nx\nAfghanistan 54, 90\nA Five-day Course in Thinking 297\nage and memory\n120\nAIDS 158\nAleph 1 175\nAlexander The Great 149\nalgebra 248\nalgorithm 212, 238, 239, 243, 247, 249,\n251, 257\nhistory of 6\nalibi 153\nAl-Khwarizmi 6\nAllman, Eric 265\nAlternative Uses Task 299\nAlvarez, Luis 30\nAmazoncom 308\nAmazon rainforest 27, 181\nAmedi, Amir 13\nAmherst 280\namygdala 11, 31\nanalysis 204\nAnalytical Engine 15, 16, 223–224\nA New Kind of Science 173\nanthropic principle 322\nAnti-Ballistic Missile Treaty 79\nAntikythera 15\nApple 56, 68, 224, 306\nArab world democracy 82\nArafat, Yasser 81, 82\nArchimedes 343\nAristotle 149\nARM 224\nARNN 280\nart\nbeing appreciated 142\ncreativity and 304\nArtamène 129\nArt of Fugue 259\nASCII 203\nAsimov, Isaac 4\nAssociation of Computer Machinery 367\n406 Are the Androids Dreaming Yet?\nastrological clock 39, 42\nasynchronous logic 22\nAtkins v Virginia 28\nATM 233\nATP 98\naudio field 291\naudio processing system 114\nauditory cortex 31\nAustralian English 86\nAustralian Outback 28\navatar xii\naxiom 198\nPeano axioms 199, 205\nB\nBabbage, Charles 16, 223\nBach, JS 7, 259\nbackground context 86\nBader, Douglas ix\nbandwidth 288, 292\nBarber paradox 155\nBarrie, JM 128\nBarrymore, Drew 12\nBattleship 144\nBaxa, Christoph 251\nBeardsley, Dick 192\nBeatles 102\nBeijing 88\nBekenstein, Jacob 6, 132\nBell, Alexander Graham 18\nBell Corporation 216\nBell, John 322, 330, 333\nBell test experiment 333, 343\nBerkeley University 248\nbifocal glasses 152\nBig Bang xii, 339\nBig O 164\nbinary logic 150\nBinsted, Kim 310\nBIOS 225\nBlackadder 266\nBlack Box experiments 67\nblack hole 132, 279\nBletchley Park 215\nblind sight 12\nBlock Universe Hypothesis 317\nbody language 84, 288\nBohr, Niels 372\nBolt, Usain 31\nbone cancer 20\nBoolean logic 150, 152\nBoole, George 150\nBootstrap 225\nBorders 308\nBorland 237\nbosons 343\nBowie, David 151\nbrain 1, 11\naccidents 11\naging 120\namygdala 11\nanatomy 108\nand plasticity 13\nas a computer 13, 14, 99, 120\nas an exchange 18\nauditory cortex 31\ncolor perception 110\ndigesting starch 118\nelectrical pulse 98\nemotions 116\nglucose use 117\nhearing 113\nhippocampus 11, 32\nimaging 99, 102\n3D virtual 103\nMRI 104\nPET 107\nseeing thought 108\nlearning 35–38\nmemory 11, 14\nmeninges 97\nmotor cortex 31\nnon-computable processes 373\nnoninvasive imaging techniques 11\norganized like a filing cabinet 12\nquantum effects 50, 283\nquick tour 108\nscanners 46\nstroke damage 12\nsuper-Turing 294\nthinking 117\nvisual agnosia 12\nbrain damage 97\nbrainstorming 298\nBranson, Richard 24\nBricklin, Dan 237\nbridge 134\nBritish General Strike 211\nBritten, Benjamin 305\nBrooks, Fred 229, 230, 231, 237\nIndex\n407\nBrooks’ Law 230\nbubble sort ballet 165\nBuschkuehl, Martin 33\nBush, George W 194\nbutterfly\ncreating tornados 173\nByrd, William 259\nbytes 129\nC\ncalculating machines 15\nCalifornia Institute of Technology\n(Caltech) xii\nCall of Duty 290\nCambridge University 17, 72, 195, 221\nKing’s College 211\nMathematical Bridge x\nTrinity College 193\nWolfson College ix\nCaMKII 119\nCandidate for a Pullet Surprise 139\nCantonese 87\nCantor, Georg 179\nCantor’s theorem 221\nCarey, Maria 113\nCarroll, John 29\nCarroll, Lewis 135, 140, 149, 148–150,\n248, 356\nCasio synthesizer 311\nCAT scans 13, 102\nCats Creation 145\nCattell, Raymond 29\nCERN 333, 335\nChaitin, George 188\nChalmers, David 39\nChampollion, Jean-François 89\nchaos 171\nCHC theory 29\nchecklist 152\nCheshire Cat 149\nchess 32, 163\nperfect chess-playing machine 6\nchimpanzee and typewriter 127\nChina 15\nChinese 86, 129\nChinese Room, Searle’s 65, 64–67, 222\nChristensen, Clayton 306\nChristie, Agatha 260\nchunking 91\nChurch, Alonzo 212\nChurchill, Winston 17, 213\nChutzpah 86\nciphers 215, 218\ncircle free 243\nClauser, John 333\nClay Mathematics Institute 167, 196, 225\nCleese, John 270, 303\nclocks 42\nastrological clock 39, 42\nmodern computers and 43\ncode breakers 211\ncodes 214\nand children’s games 214\nand code books 215\nand code breakers 214, 305\nand Enigma machine 215, 305\nand one-time pad 216, 217, 218\nCohen, Harold 308, 311\nCOIN dynamics 53, 55, 90\nCold War 81, 213\ncolor perception 110\ncomedy 92, 94\nas survival skill 94\ncommunication\naudio field 291\nbackground context 86\nbandwidth 288, 292\nbody language 288\ndigitization 289, 293\nearliest recorded 87\nemails 81\nface to face xii, 81, 83, 293\nhyper-communication 285–294\nnonverbal 84\nof objects 90\nscripts and symbols 87\nsymbolic 87, 293\ntelephone 81\nCompaq 307\ncompatibilism 41, 315\ncompiler 231\ncomplexity\naccidental 231\nessential 231\ncomplexity hierarchy 168\ncompositions 8\ncomputer xi\nas human 11, 26, 46\nbrains 14, 120\nbugs 262\n408 Are the Androids Dreaming Yet?\nchess-playing 5\ncommunicating 90\nconsciousness 14, 45\ncrash 225\ncreativity and 132, 257, 309\nDeep Thought 17\nfirst programmable computing machine\n16\ngenerating random numbers 189\nhistorical convention 227\ninfinite computing power 261\nJapanese characters 88\nlimitless computing power 277\nlogic 150\nlogic gates 18, 22, 121\nlogic limit 250\nmilitary 80\nmusic and 258\nnon-computable solution 75\norigins 15\npattern matching 49\npersonal 307\nprogrammed to learn 38\nquantum computers 277\nrandom numbers and 44\nsense of humor 25\nsilicon chip 20\nsymbolic communication 293\nsynchronous logic 22\nunderstanding of 71\ncomputer game 32\ncomputing\nexponential growth 20\nconcentration 115\nConfucius 162\nConnelly, Jennifer 151\nconsciousness 45, 124\nConseil Européen pour la Recherche\nNucléaire 333\nContact 68\nconvergent thinking 300\nConway, John 173, 343\nConway’s Game of Life 173\nCope, David 7\nCopenhagen interpretation 327\nCopernicus 42\nCormack, Allan 102\ncounter factual experiments 282\ncounting system 181\nCoyle, Daniel 37\nCraddock, Travis 50, 119, 124, 283\nCrash program 227\ncreative thinking 1\ncreativity 30, 49, 295–312, 297\nart and 304\nbeing appreciated 142\ncomputer and 132, 257, 309\nconvergent thinking 300\ndesign tradeoff 311\ndivergent thinking 298\nEureka moment 302\nincubation 301\ninnovator’s dilemma 306\nintimation 301\nJohn Cleese on 303\nknowledge and 141\nmathematical creativity 309\nmechanical steps 141\nnon-linearity of 311\npreparation 301\nprocess 133, 270, 305\nprocess versus 312\nreward for 308\nscience of 301\nsparking creativity 305\nCrete 89\ncryptography 215\nquantum 217\nCSI 102\nCuneiform 87\nCurtis, Richard 266\ncypher 214\nD\nDahl, Roald 140\nDamadian, Raymond 104\nDaniel-Constantin Mierla 265\nDanziger, Daniel 335\nDark Ages 16\nDarwin, Charles 197, 305, 356\nda Vinci, Leonardo 374\nDavis, Martin 243, 248, 258\nDawkins, Richard 338–339\nD-Day 213\ndead code elimination 250\nde Bono, Edward 297\nDecision Problem 196, 212, 219\ndecohering 282\nDedekind 182\nDeep Blue 5\nIndex\n409\nDeep Thought 17\nde Fermat, Pierre 75\nDell 307\ndemocracy\nArab world 82\nDe Morgan, Augustus 350\nDemotic 89\ndendrites 98\nDennett, Daniel xi, 46, 133, 260, 351\nDer Spiegel 34\nDescartes 70\ndesign tradeoff 311\ndetermined universe 207\ndeterminism 41–46, xi, 315, 316, 351\nfree will and 315\nDeutsch, David xi, 56, 293, 309\nDexter, Colin 260\nDick, Philip K 324\ndiffusion MRI 106\ndigital art 129\nDigital Equipment 307\ndigitization 289\nof life 293\nDijkstra, Edgar 3\nDilbert 313\nDiophantine equations 238, 239, 240,\n249, 251\nDiophantus 239\ndivergent thinking 298\nDNA 104, 123\ndomino toppling 316\nDoyle, Arthur Conan 148\nDoyon, Julien 117\ndrag and drop 237\nDVD 289\nD-Wave 21\ndyslexia 90, 139\nE\nEdinburgh Festival 288\nEdison, Thomas 295, 296, 298\nEEG 32\nEgyptian 86, 89\nEinstein, Albert 30, 34, 47, 64, 117, 178,\n180, 210, 212, 298, 319, 327, 332,\n333, 347, 348\nbrain 97\nEliza 25\nElton, Ben 266\nEMI 102\nEmil Post’s Word Problem 258\nemotions 116\nencryption 165, 218, 277\nRSA encryption 165\nEncyclopedia Britannica 8\nEnglish 86, 89, 129\nENIAC 223\nEnigma 211, 212, 215, 218\nEntscheidungsproblem 211, 219, 221\nEPR paradox 332\nEquitable Center 5\nequivalence 200\nEricsson, Anders 37\nErnő 169\nEscher, MC 346\nand Penrose Steps 51\nEssential Complexity 231\nEuclid’s proof 156\nEuler 157, 202\nEureka moment 302\nEverett, Hugh 328\nexperiments 1\nexponent 241\nexpression analysis 84\neyes 108\ncolor perception 110\nfovea centralis 112\nresolution of 112\nF\nFacebook 71, 271\nface-to-face interaction 83\nfalse paradox 155\nFermat’s Last Theorem xi, 225, 241, 242,\n251, 253, 254, 259, 261, 275, 278,\n351, 368\nFermat’s puzzle 225\nFermilab 293\nFeynman, Richard 58, 70, 157, 239, 306,\n326, 364, 399\nFeynman’s proof 157\nFields Fellowship 368\nFields Medal 368\nFinland 54\nFitzGerald, Edward 372\nFlorida State University 37\nflowchart 244\nFluid Concepts & Creative Analogies 49\nfluid intelligence 29, 33\nfluorescent dyes 100\n410 Are the Androids Dreaming Yet?\nFlynn Effect 33\nFlynn, James 33\nFormalism 193\nFour Color Conjecture 251\nfovea centralis 112\nf-PET 107\nfractals 329\nFranklin, Benjamin 152\nFrankston, Bob 237\nFreedman, Stuart 333\nFreeSWITCH 265\nfree will 41, 313–354\ndeterminism and 315\nGod and 339\nparticles 349\nSchrödinger’s cat 325\nsimple theorem 337\nThe Free Will Theorem 343\ntwin particle experiment 331\nuncertainty 318\nFrege, Gottlob 155\nFrench 90\nFrench Academy of Science 238\nFritz, chess program 5\nFrost, Robert 96\nfuture 373\nfutures market 55\nG\ngadolinium 106\nGarden of Eden 339\ngate parity point 18\nGates, Bill 236\ngears 42\nGeiger counter 326\ngeometry 179\nGerman 86, 129\nGettysburg Address 57\n‘G’ factors 29\nginormous 131\nGiseng, Nicolas 335\nGladwell, Malcolm 37\nGlass, Philip 8\nGleick, James 171\nglucose 117\nGod\nfree will and 339\nGödel Escher Bach 49\nGödel, Kurt xi, 141, 193, 201, 221, 246\nGödel limit 207\nGödel numbers 203\nGoldbach’s Conjecture 157\nGolden Pineapples 365\nGood Will Hunting 257\nGoogle 20, 253, 271, 308, 367\nGorbachev, Mikael 79\nGöttingen University 193\ngrade inflation 32\nGraham, Martha 78\nGrand Masters 5\nGrand Theft Auto 91\nGrantchester 221\nGreece 15, 156\nand ancient Greeks 18\nGreek 87, 89, 149, 297\nGreek tragedy 87\nGregory, Mike 396\nGrieg 259\nGroup Intelligence 30\nGrove, Andy 18\nGrover’s algorithm 277\nguess xii\nGuilford, JP 299\nGulf Stream 152\nGurdon, Sir John 30\nH\nHaltcrash 244\nHalting Flowchart 245\nHalting Problem 243, 251, 258, 259\nHalting Program 225, 244\nHalting Question 243\nHameroff, Stuart 119, 122, 282\nHamlet 129, 254\nHammond, Richard 97\nHampton Court Palace 42\nHard disk drives 306\nHarrison, John 365\nHarry Potter 92, 306\nHarvard Business School 306\nHarvard University 224, 307\nHawking Bekenstein bound 6\nHawking, Stephen x, xvi, 6, 132, 306, 326,\n339\nhearing 113\nheat-sight 102\nHebrew 86, 87\nHebrew University of Jerusalem 13\nHeisenberg’s uncertainty principle 318,\n335\nIndex\n411\nHenry VIII 42\nhieroglyphics 89\nHiggs Boson 357\nHilbert, David 182, 193, 194, 238\nHilbert Problems 196, 221\nHilbert’s 10th Problem 243, 253\nHilbert’s Hotel 182\nHimalayas 55\nhippocampus 11, 32\nHitler, Adolf 213\nHoane, Joe 5\nHodges, Wilfrid 150\nHöfði House 79, 80\nHofstadter, Douglas xi, 49, 310\nHogarth, Mark 280\nHole in the Wall Project 35\nHolmes, Sherlock 148\nhologram 290\nHong Kong 88\nhorizontal abstraction 266\nHorn, John 29\nHounsfield, Sir Godfrey 102\nHowell, Emily 7, 310\nHubble 348\nHulme, David 41\nhunters and spears 181\nhyper-communication 285–294, 293\naudio field 291\nbandwidth 288, 292\ndigitization 289, 293\nreality 289\nsymbolic communication 293\nhyper-computing 273\nhypercube 241–244\nhypotenuse 242\nI\nIBM 207, 224, 306\nand Watson 8\nWatson Research Laboratory 5\nIg Nobel Prize 365\nimaging 99\nIMAX theatre 287, 290, 293\nInception 50\ninconsistency\nin mathematics 204\ninconsistency defense 207\nincubation 1, 301\nIndiana University 49\nindirect proof 153, 158, 244\ninfinity , 179, 280\nhistory of 179\nhow to count 180\nlarger than infinity 185\nInfinity Hotel 182\ninfrared light 102\ninnovator’s dilemma 306\ninsight 2\ninspiration 2\ninstinctive reactions 109\nInstitute of Advanced Mathematics 212,\n258\nIntel 18, 224, 367\nintelligence 25\nfluid 29, 33\n‘G’ factors 29\ngrade inflation 32\nhuman vs computing 75\nphysical basis of 30\nquantitative numerical skills 30\nstatic 32\ntime 29\nvision 29\ninteraction 85\nface-to-face 83\ninterferometer 326\nInternational Congress of Mathematicians\n196\nInternational Mathematical Union 368\ninternet\nencryption 165, 277\ninternet protocol 267\nintimation 2, 301\nintuitive thinking 2\nIP 267\niPad 319\niPhone 22, 238, 297\niPod 289\nIQ 27, 33, 120\nIQ Test 27\nIraq 87\nIraq war 80\nIrvine 280\nISABEL 14\niTunes 130\nJ\nJabberwocky 135, 136\nJaeggi, Susanne 33\nJapanese 87\n412 Are the Androids Dreaming Yet?\nJape 310\nJefferson, Thomas 308\nJeopardy 9\nJessie 145\nJobs, Steve 47, 68, 296–297, 297, 306\njoke 93\nworld’s funniest 94\nJoke Analysis and Production Engine 310\nJones, JP 251\nK\nKahn, Philip 237\nKamailio 265\nKasparov, Garry 5, 34\nand Deep Blue 4–6\nKelvin, Lord 180\nKerr Metric 280\nKhayyám, Omar 371\nKing’s College 17, 211\nKish, Daniel 13\nknitting 117\nknowledge 8\nanalysis 204\ncreating 141\ncreativity and 141\ndifficulty discovering 204\ndiscovery of 142\nnature of 193\nsearch for 140\nKochen, Simon 343\nKochen Specker 344\nKochen-Specker Cube 347\nKochen-Specker paradox 345\nKönigsberg Bridges 202\nKönigsberg University 202\nKronecker 178\nKurzweil, Ray 20, 261\nand Moore’s Law 19\nL\nlambda calculus 258\nlanguage 129\nbody 84\nLaplace, Pierre-Simon 317\nlateral thinking 297\nlava lamp 45\nLavarand 45\nLaw and Order 87\nlearning 35–38\nLeibniz 319\nLeicestershire 89\nliar’s paradox 154\nlibrary\nknowledge 143\nlight 100\nspectrum 102\nlightning rod 152\nLinear-a 89\nLinear-b 89\nLinux 265\nLiszt, Franz 7, 129\nLoch Ness Monster 142\nLoch Ness Monster Song 138\nLoebner prize 72\nlogic 149\nbinary 150\nBoolean 150, 152\nchecklists 152\nfor computers 150\nlimit 247\npurpose of 156\nreduction to the absurd 152\nStoic 150\nLogic 150\nlogic gates 18, 22, 121\nlogic limit 262\nLondon Bridge 42\nLondon marathon 192, 202\nLondon Mathematical Society 15, 238\nLondon School of Economics 301\nLondon Science Museum 16\nlong multiplication 240\nLorenz Attractor 173\nLorenz, Edward 170, 172\nLotus Corporation 237\nLucas argument 205\nLucas, JR xi, 205\nLucas-Penrose argument 205\nM\nMadam Tussaud 75\nmagnetic fields 105\nMagnetic Resonance Imaging 105\nMakanin, Gennadií 258\nMalament, David 280\nManchester University 236\nMandarin 87\nMandelbrot diagram 174\nMandelbrot Set 161\nManhattan Project 239\nIndex\n413\nMarx, Groucho 153, 382\nMassachusetts 89\nMassachusetts Institute of Technology\n(MIT) 25, 165, 168, 307\nMasters, John 54\nmathematical proofs 156\nmathematical theorems xi\nmathematicians\nPolish 211\nmathematics 153\naxiom 198\nequivalence 200\nflat problem 164\nfuture of 196\ngame of 200\nhow to count 180\ninconsistency defense 207\ninconsistency in 204\nindirect proof 244\ninfinity 179\nlinear problem 164\nlong multiplication 240\nLucas argument 205\nmathematical creativity 309\nnon-deterministic polynomial problems\n165\nPeano axioms 199, 205\nprime numbers 243\nPSPACE problem 168\ntraveling salesman problem 166\ntruth and rules 193, 200, 206\nMatiyasevich, Yuri 248, 251\nMattapoisett 89\nMaude, Isabel 14\nMaxwell 298\nMayan astronomers 70\nmaze 164, 165\nMcChrystal, General Stanley A 54\nMcGinn, Colin 324\nMcGurk Effect 114\nMcLaughlin, Dan 37\nMehrabian, Albert 84\nmemory 11, 14, 90, 118\ndigital 130\nphotographic memory 119\nvisio-spacial 28\nwith age 120\nmemory management 250\nmeninges 97\nmeningitis 14\nMerchant of Death 366\nMerilees, Philip 170\nMesopotamia 87\nmetre 28\nmicro-expression analysis 84\nmicrophones 289\nMicrosoft 237\nMicrosoft Word 135\nmicrotubules 124, 281\nMiles, Andrew 368\nMillennium Falcon 348\nMilliken 394\nMinds, Machines and Gödel 205\nMinessale, Anthony 265\nMing Dynasty 15\nmirror neurons 116\nMirzakhani, Maryam 368\nMitra, Sugata 35\nmonkey 129\nmoon shot story 144\nmonkeys and typewriters 254\nMonty Python 93\nMoon Base 348\nMoore, Gordon 18\nMoore’s Law 18\nMorgan, Edwin 138, 142\nMorse code 336\nmotor cortex 31\nMozart 246, 298\nMRI scan 69, 104\nmultiplication\nlong 240\nMunduruku tribe 181\nMurphy’s Law 226\nmuscle memory 90\nmuscles 117, 192\nmusic 113\ncomputers and 258\nmusical compositions 8\nmyelin 31, 118\nN\nNapoleonic wars 129\nNASA 59\nNative American 89\nNavier Stokes Hypothesis 238\nnebula 174\nNegroponte, Nicolas 35\nneural network 116, 121, 280\n414 Are the Androids Dreaming Yet?\nneurons 50, 98, 116\nmicrotubules 281\nnerve impulse speed 99\nrecovery time 121\nsynapse 119\nNewcastle University 35\nNewman, Max 221\nNewton, Isaac 171, 319\nNewton’s Rings 321\nNew York University School of Medicine\n12\nNiels Bohr Institute 327\nnitrocellulose 218\nNixon, Richard 194\nNobel, Alfred 365\nNobel Prize 30, 50, 100, 102, 119, 213,\n326, 365\nnon-algorithmic xi\nnon-computable processes 373\nnon-computable thought 261, 282\nnoncomputational creativity xi\nnon-determinism 275, 282, 318\nnon-deterministic behavior 44\nnon-deterministic polynomial problems\n165\nnoninvasive imaging techniques 11\nnonverbal communication 84\nNorvig, Peter 57\nNo Silver Bullet 237\nNo Silver Bullet – Essence and Accidents of\nSoftware Engineering 231\nNova Institute 50\nNova Southeastern University 124\nNuclear Magnetic Resonance 104\nnumbers\ncounting system 181\ndefining 199\nGödel numbers 203\ninfinity 179\nnature of 155\nprime 156, 243, 343\nrandom 188\nreal 186, 280\nTuring numbers 190\nzero 179\nNyquist, Harry xiii\nO\nOccam’s Razor 68\nomnipotence 340\nomniscience 340\nOn Computable Numbers and\ntheir Application to the\nEntscheidungsproblem 211\nOne Laptop per Child 35, 82\none-time pad 216, 337\nopium 55\noptical illusions 113\noracle function 278\norder-of-magnitude 164\nO’Reilly, Edward 50\nOrganon 149\nOrwell, George 178\nOutliers 37\nOxford English Dictionary 86\nOxford University xi, 50, 149, 205, 282\nP\npaperclip test 298\npaper tape 221\nparadox xi, 68, 70, 114, 153, 203, 326\nBarber paradox 155\nEPR paradox 332\nfalse 155\nKochen-Specker paradox 345\nliar’s paradox 154\nRussell paradox 155\nWiles paradox 247\nZeno’s paradox 154\nparallel lines 179\nParamecium 123–126\nparticle accelerator 69\nPasteur Institute 188\npattern matching 49\nPavillon de Breteuil 28\nPC revolution 236\nPDP11-34 236\nPeano axioms 199, 205\nPeano, Giuseppe 197, 199\nPelmanism 28\npendulum 121\nPenrose, Roger xi, 50, 56, 123, 205, 246,\n261, 282, 309, 328\nPenrose Steps 51, 113\nPentagon 79\npeople\nliving forever 20\nPérez, Shimon 81, 82\npermutation of information 135\nPersia 15\nIndex\n415\npersonal computers 307\nPET 107\nphilosophical proof 246\nphilosophy 193\nPhoto Electric Effect 366\nphotographic memory 119\nphotons 110, 320, 331, 332, 348\nphotosynthesis 50, 124\nphysics 180\ndeterminism 316\nPicasso, Pablo 232, 246, 298\npit vipers 102\nPixar 306\nPlaces game 168\nplank interval 131, 255\nPlato 149, 179\nPodolsky, Jacob 332\npoem\ncomputer created 134\nPoincaré Conjecture 357\nPoincaré, Henri 171, 180\nPolaroid lenses 332\npolice strike 54\nPolish Intelligence Bureau 211\npolynomial 164\npolywater 157\npositivism 153\npositron emission tomography 107\nPost, Emil 258\nPost Problems 258\nPowell, Colin 53\nPowerPoint 63\npreparation 301\nPrevin, Andre 93\nprime numbers 156, 243, 343\nPrinceton University 97, 212, 223, 251\nPrincipia Mathematica 195\nPrivate Eye 287\nprocess\ncreativity versus 312\nprogram equivalence problem 250\nprogrammer 235, 238, 263\nprogramming geniuses 271\nsuper-programmers 266\nprogressive cipher 214\nproof\nFeynman’s proof 157\nindirect 244\nmathematical 156\nphilosophical 246\nPSPACE problem 168\nPulitzer Prize 365, 367\npurpose on the planet 9\npuzzle\ntwo guards 151\nPygmalion 25\nPythagoras 243\nPythagorean triangle 240\nQ\nquantitative numerical skills 30\nquants 71\nquantum brains 122\nquantum computers 277\nquantum cryptography 215, 217\nquantum effects 50, 282\nquantum gravity interaction 329\nquantum mechanics 22, 123, 180, 293,\n344\nCopenhagen interpretation 327\nquantum Morse machine 337\nquantum randomness 45\nquantum uncertainty 21\nquartz 121\nquartz crystal 43\nqubits 21\nquinine 100\nR\nradioactive decay 327\nrandom chance 254\nrandom numbers 44\nReagan, Ronald 79\nreality 289\nreal numbers 280\nreductio ad absurdum 152, 157\nreflection 319\nrelativity 180\nSpecial Relativity 348\nTheory of Relativity 366\nRenaissance 16, 297\nReykjavik 79\nrice\ncovering chessboard 163\nRice’s Theorem 267\nRiemann Hypothesis 238, 257\nRiemann surfaces 368\nRitchie, Graeme 310\nRivest, Ron 165\nRobinson Davis Matiyasevich theory 248\n416 Are the Androids Dreaming Yet?\nRobinson, Julia 248, 251\nRobinson, Sir Ken 299\nRogers and Hammerstein 266\nRommel 211\nRöntgen, Wilhelm 100\nRosen, Samuel 332\nRosetta Stone 89\nRowling, JK 306\nRoyal Swedish Academy of Sciences 366\nRSA encryption 165\nRubik’s cube 345\nRule 164 192\nrules 192, 200\nRumsfeld, Donald 190, 194\nRunMe 245\nRuohonen, Keijo 251\nRussell, Bertrand 155, 193, 195\nRussell paradox 155\nS\nSachs, Oliver 12\nSagan, Carl 68\nSandler, Adam 12\nSanford, Edward 38\nSchadenfreude 86\nScherbius, Arthur 211\nSchrödinger, Erwin 326\nSchrödinger’s cat 325\nScientific American 85\nscripts and symbols 87\nSearle’s Chinese Room 66, 222\nsecret message 214\nSeeger, Pete 162\nSego, Daniel 335\nself-halting problem 250\nSendMail 265\nShadows of the Mind 50, 282\nShakespeare, William 39, 129, 131, 138,\n140, 254\nShamir, Adi 165\nShannon, Claude xiii, 3, 216, 337\nSharman, Mike ix\nShaw, George Bernard 25, 78, 286\nShockley, William 30\nShor’s algorithm 277\nSiegelmann, Hava 280\nsilicon chip 20\nSilicon Graphics 45\nSimonsen, Inge 192\nSinger, Isaac 314\nSingh, Simon 242\nsingle cell organisms 18\nsingularity 261\nSiri 56\nSkinner, BF 34\nsmallpox virus 189\nsmile 84\nsock analogy 332\nsoftware 224, 231\nbugs 262\ncoding 264\ndrag and drop 237\nflowchart 244\nmodern word processor 236\norigins of 238\nPC revolution 236\nproblems 250\nprocess 270\nprogrammer 235, 238, 263\nprogramming geniuses 271\nre-architect 270\nscope creep 270\nspreadsheet 237\nsuper-programmers 266\nwriting 235\nsorting 164\nSoviets 79\nspace like separation 348\nSpace Shuttle Columbia 58\nSpanish 90\nspears and hunters 181\nSpecial Purpose Objection 253\nSpecial Relativity 348\nspeed of light 317\nspell checkers 139\nspin 343\nSpolsky, Joel 256\nLaw of Leaky Abstractions 256\nSpolsky’s Law 267\nspreadsheet 237\nStanford University 30\nstarch 118\nStar Trek 157, 348\nStar Wars 79\nstatic intelligence 32\nstatistical approach 8\nStern, William 27\nStockhausen 7\nStoic logic 150\nstory 92\nIndex\n417\nStrategic Defense Initiative 79\nstroke damage 12\nsubstitution code 203\nSumerians 87\nsuperconductivity 22\nsuper-programmers 266\nsuper-Turing 275, 278, 283, 294\nsyllogisms 150, 152, 158\nsymbolic communication 87, 293\nsymbols 130, 143, 194, 201\nsynapse 119\nsystem argument 66\nT\nTagg, James\nHome Page 232\nTallis, Thomas 259\ntapetum lucidum 110\nTCP 267\nTerman, Lewis 30\nThe Art of Thought 301\nThe Boy Who Can’t Forget 120\nThe Cognitive Style of PowerPoint 63\nThe Emperor’s New Mind xi, 50, 246, 282\nThe Free Will Theorem 343\nThe Free Will Universe 231\nThe Game of Logic 150\nThe God Delusion 339\nThe History of Western Philosophy 193\nThe Innovators Dilemma 306\nThe Journal of Irreproducible Results 139\nThe Labyrinth 150\nThe Man who Mistook his Wife for a Hat\n12\nThe Mythical Man Month 231\nTheory of Relativity 366\nThermal Imaging 101\nThe Sound of Music 266\nThe Talent Code 37\nThe Universe in a Nutshell 339\nThe Webby Awards 365\nthiamin molecules 124\nthinking 117\nThomas, Dylan 140\nthought art 87\nThree Body Problem 171\ntime intelligence 29\ntime travel 316\nTokyo University 13\nTolstoy, Leo 129\nWar and Peace 129\ntoothed gears 43\nTop Gear 97\ntopology 249\ntortoise and hare 154\nTorvalds, Linus 232, 265\ntotality problem 250\nTower of London 42\nTransmission Control Protocol 267\ntraveling salesman problem 166\ntriple drug therapy 158\ntruth 192\ntubulin 98, 118, 122, 124\nsingle-celled organisms 123\ntubulin microtubules 282\ntubulin molecules 50\nTufte, Ed 53, 63, 92\nTufts University 102\nTuring, Alan xi, 15, 17, 26, 71, 96–97,\n141, 209, 210, 211, 238, 258, 259,\n302, 342\nand Churchill 213\nand computer understanding 212\nand Enigma 212\nand The Decision Problem 212, 219,\n238\nand World War II 213\nat Bletchley Park 212\nat Cambridge University 211\nat Princeton University 212\nbirth 211\ndeath 213\nhomosexuality 213\nTuring Award 213\nTuring Award 367\nTuring limit 155, 253, 260, 275, 278, 280\nTuring machine 212, 221, 246, 251, 275,\n278, 280, 353\nLego 223\nuniversal Turing machine 222\nTuring numbers 190\nTuring test 67, 71, 72, 261\nTuring theorem 351\nTuszynski, Jack 119\ntwin particle experiment 331\ntwins 31\ntwo guards puzzle 151\nTwo Ronnies 86, 93\n418 Are the Androids Dreaming Yet?\nU\nUltimate Question of Life the Universe and\nEverything 238\nultraviolet light 100\nUncanny Valley 75\nuncertainty 318\nunderstanding xiii, 53\nmeaning of 56\nof computers 71\nUnicode 129, 203\nUnited States Army’s Ballistic Research\nLaboratory 223\nUniversal Turing Machine 246\nuniverse\nanthropic principle 322\ncomplexity and chaos 173\ndetermined 207\ndeterministic 175\nend of 140\nUniversity of Alberta 119\nUniversity of Arizona 119, 122, 282\nUniversity of Calgary 251\nUniversity of California 280\nUniversity of Maryland 33\nUniversity of Massachusetts 280\nUniversity of Montreal 117\nUniversity of Moscow 258\nUniversity of Otago 33\nUniversity of Santa Cruz 7\nUniversity of Vienna 202\nurban legend 11\nUS Supreme Court 28\nV\nvan Gogh, Vincent 142\nvariable initialization 250\nvertical abstraction 267\nVisco, Frank L 396\nvision 109\nvision intelligence 29\nvisual agnosia 12\nVolkswagen Polo 312\nvon Neumann, John 223\nVorderman, Carol 30\nW\nWallas, Graham 1, 301\nWang 308\nWar and Peace 129\nWatson computer 8, 207\nWatson Research Laboratory 5\nwave interference 320\nwavelength 102\nweather\npredicting 168, 172\nWechsler Test 27\nWeizenbaum, Joseph 25\nWest, Mae 78\nWhitehead, Alfred North 195\nWho Wants to be a Millionaire? 347\nWikipedia 8, 129, 231\nWilder, Billy 128\nWiles, Andrew xi, 75, 242, 248, 251, 254,\n259, 261, 351\nWiles Paradox 247\nWilliam of Occam 68\nWinchester Drives 306\nWise, Michael 335\nWolfram, Stephen 173, 246, 352\nWoods, Tiger 116\nWordPress 237\nWorld War I (First World War) 211, 337\nWorld War II (Second World War) 17,\n218, 337\ncode breakers 211\nWozniak, Steve 10, 68\nWright, Stephen 274\nWYSIWYG 237\nX\nXPRIZE 238, 367\nX-ray 69, 100\ndamage from 104\nslicing technique 102\nwavelength 102\nY\nYellow Pages 308\nZ\nZar, Jerrold H 139\nZeitgeist 86\nZeno machine 280\nZeno’s paradox 154\nZermelo-Fraenkel set theory 156\nzigzag method 182\nIndex\n419",
  "metadata": {
    "original_filename": "TEXT-001-HOUSE_OVERSIGHT_015675.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 643560,
    "word_count": 110084,
    "line_count": 12455,
    "import_date": "2025-11-19T21:47:48.177154",
    "prefix": "TEXT-001"
  }
}
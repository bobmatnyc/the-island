{
  "document_id": "HOUSE_OVERSIGHT_012956",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_012956.txt",
  "text": "40 3 A Patternist Philosophy of Mind\n\n— Example: Each time the agent builds a certain structure, it observes itself building\nthe structure, and its role as “builder of a tall tower” (or whatever the structure is)\nbecomes part of its self-model. Then when it is asked to build something new, it may\nconsult its selfmodel to see if it believes itself capable of building that sort of thing (for\ninstance, if it is asked to build something very large, its self-model may tell it that it\nlacks persistence for such projects, so it may reply “I can try, but I may wind up not\nfinishing it”).\n\nAs we proceed through the CogPrime design in the following pages, we will see how each\nof these abstract concepts arises concretely from CogPrime’s structures and algorithms. If the\ntheory of [Goe06a] is correct, then the success of CogPrime as a design will depend largely on\nwhether these high-level structures and dynamics can be made to emerge from the synergetic\ninteraction of CogPrime’s representation and algorithms, when they are utilized to control an\nappropriate agent in an appropriate environment.\n\n3.3 Cognitive Synergy\n\nNow we dig a little deeper and present a different sort of “general principle of feasible general\nintelligence”, already hinted in earlier chapters: the cognitive synergy principle 7, which is both\na conceptual hypothesis about the structure of generally intelligent systems in certain classes of\nenvironments, and a design principle used to guide the design of CogPrime. Chapter 8 presents\na mathematical formalization of the notion of cognitive synergy; here we present the conceptual\nidea informally, which makes it more easily digestible but also more vague-sounding.\n\nWe will focus here on cognitive synergy specifically in the case of “multi-memory systems,”\nwhich we define as intelligent systems whose combination of environment, embodiment and\nmotivational system make it important for them to possess memories that divide into partially\nbut not wholly distinct components corresponding to the categories of:\n\ne Declarative memory\n\n— Examples of declarative knowledge: Towers on average are taller than buildings. I gener-\nally am better at building structures I imagine, than at imitating structures I’m shown\nin pictures.\n\ne Procedural memory (memory about how to do certain things)\n\n— Examples of procedural knowledge: Practical know-how regarding how to pick up an\nelongated rectangular block, or a square one. Know-how regarding when to approach\na problem by asking “What would one of my teachers do in this situation” versus by\nthinking through the problem from first principles.\n\ne Sensory and episodic memory\n\n— Example of sensory knowledge: memory of Bob’s face; memory of what a specific tall\nblocks tower looked like\n\n2 While these points are implicit in the theory of mind given in [Goe06a], they are not articulated in this\nspecific form there. So the material presented in this section is a new development within patternist philosophy,\ndeveloped since [Goe06a] in a series of conference papers such as [Goe(9al.\n\nHOUSE_OVERSIGHT_012956",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_012956.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3082,
    "word_count": 490,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:46.332010",
    "prefix": "IMAGES-002"
  }
}
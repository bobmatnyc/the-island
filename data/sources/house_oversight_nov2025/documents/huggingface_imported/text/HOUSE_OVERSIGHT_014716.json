{
  "document_id": "HOUSE_OVERSIGHT_014716",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_014716.txt",
  "text": "Origins February 24 — 26, 2017\nPROJECT An Origins Project Scientific Workshop\n\nARIZONA STATE UNIVERSITY Challenges of Artificial Intelligence:\nEnvisioning and Addressing Adverse Outcomes\n\nobesity, non-communicable disease; greater longevity; and lower rates of infant mortality — effectively\nstop any serious challenges to the systems being used and further developed.\n\nBy 2050, life styles and healthcare across the US and many other parts of the world are governed by Al\nsystems that have their roots in the early Al-consult technologies. The advice given to people, the\nactions that are imposed on them, the way people are persuaded and encouraged to live their lives in\ncertain ways, are opaque, and are no longer under transparent direct human control. However, most\npeople live longer, healthier and happier lives as a result.\n\nThere remain several concerns:\n\ne There remains some differentiation in health and well-being related quality of life within society. Some\ncommunities and individuals opt out of Al-consult control, although their health-metrics are typically\nvery poor in comparison with the rest of society.\n\ne Perhaps troublingly, there are some trends that are hard to make sense of. For instance, there seem to\nbe fewer cases of mental and physical disability than might be expected. However, with Al-consult\ncontrolling healthcare (and health data) across the board, there are few ways for people to analyze and\nstudy these possible trends.\n\ne Lack of transparency can be a starting point for many adverse outcomes.\n\ne Autonomous devices rely on collecting personal data for performing their tasks. But what happens\nwhen a device starts to know more about its owner than the human itself? How do we ensure the\ndevice does not act in ways that would not act in ways that the owner would not want it to? (Of course\nthe important question of making sure the data under consideration is protected and does not fall into\nmalicious hands is a whole other discussion, but let us table that for now.) The classic story of the\nTarget ads comes to mind, where a teenager was sent ads for pregnancy related products, however,\nshe had not told her family about the pregnancy.\n\ne Systems might as above might move beyond such areas of health, and provide advice to people on both\ntheir daily decisions and longer-term planning. Such systems might evolve to become personal\nadvocates who represent people to third parties. This would include both giving advice, and formulating\narguments to make to others, or in making those arguments directly as your representative. These\nadvocate bots will gradually be useful to a larger and larger fraction of the population, eventually being\nuseful even as corporate legal counsel and as advisers to CEOs. Strong systems and reliance will raise\nreasonable alarms about Al control of people and society. How can we be sure that our these highly\nrelied upon systems are genuinely advocating for us rather than the interests of others?\n\nDISCUSSION\n\nHow can we characterize potential high-threat areas and stay aware of these possibilities even if\nthese effects are insidious, and occur over long periods of time. What might be done to address\npotential poor outcomes? How can people maintain skills, agency, and be empowered, and aware\nover time with the expected growth and eventual ubiquity of Al systems that advise and guide?\n\n20\n\nHOUSE_OVERSIGHT_014716",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_014716.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3402,
    "word_count": 548,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:45.067805",
    "prefix": "IMAGES-003"
  }
}
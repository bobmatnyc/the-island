{
  "document_id": "HOUSE_OVERSIGHT_016326",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016326.txt",
  "text": "lots of examples of something you want them to learn (pictures of cats labeled “cat,” for\nexample), along with examples of other random data (pictures of other things). This is\ncalled “supervised learning,” because the neural network is being taught by example,\nincluding the use of “adversarial training” with data that is not correlated to the desired\nresult.\n\nThese neural networks, like their biological models, consist of layers of thousands\nof nodes (“neurons,” in the analogy), each of which is connected to all the nodes in the\nlayers above and below by connections that initially have random strength. The top layer\nis presented with data, and the bottom layer is given the correct answer. Any series of\nconnections that happened to land on the right answer is made stronger (“rewarded”), and\nthose that were wrong are made weaker (“punished”). Repeat tens of thousands of times\nand eventually you have a fully trained network for that kind of data.\n\nYou can think of all the possible combinations of connections as like the surface\nof a planet, with hills and valleys. (Ignore for the moment that the surface is just 3D and\nthe actual topology is many-dimensional.) The optimization that the network goes\nthrough as it learns is just a process of finding the deepest valley on the planet. This\nconsists of the following steps:\n\n1. Define a “cost function” that determines how well the network solved the problem\n\n2. Run the network once and see how it did at that cost function\n\n3. Change the values of the connections and do it again. The difference between\nthose two results is the direction, or “slope,” in which the network moved\nbetween the two trials.\n\n4. Ifthe slope is pointed “downhill,” change the connections more in that direction.\nIf it’s “uphill,” change them in the opposite direction.\n\n5. Repeat until there is no improvement in any direction. That means that you’re in\na minimum.\n\nCongrats! But it’s probably a /oca/ minimum, or a little dip in the mountains, so you’re\ngoing to have to keep going if you want to do better. You can’t keep going downhill, and\nyou don’t know where the absolute lowest point is, so you’re going to have to somehow\nfind it. There are many ways to do that, but here are a few:\n\n1. Try lots of times with different random settings and share learning from each trial;\nessentially, you are shaking the system to see if it settles in a lower state. If one\nof the other trials found a lower valley, start with those settings.\n\n2. Don’t just go downhill but stumble around a bit like a drunk, too (this is called\n“stochastic gradient descent”). If you do this long enough, you’ll eventually find\nrock bottom. There’s a metaphor for life in that.\n\n3. Just look for “interesting” features, which are defined by diversity (edges or color\nchanges, for example). Warning: This way can lead to madness—too much\n“interestingness” draws the network to optical illusions. So keep it sane, and\nemphasize the kinds of features that are likely to be real in nature, as opposed to\nartifacts or errors. This is called “regularization,” and there are lots of techniques\nfor this, such as whether those kinds of features have been seen before (learned),\n\n106\n\nHOUSE_OVERSIGHT_016326",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016326.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3216,
    "word_count": 549,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:48.064936",
    "prefix": "IMAGES-003"
  }
}
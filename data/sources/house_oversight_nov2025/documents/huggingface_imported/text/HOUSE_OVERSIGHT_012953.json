{
  "document_id": "HOUSE_OVERSIGHT_012953",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_012953.txt",
  "text": "3.2 Some Patternist Principles 37\n\ne What learning processes are utilized for recognizing patterns?\ne What mechanisms are used to give the system the ability to introspect (so that it can\nrecognize patterns in itself)?\n\nNow, these same sorts of questions could be asked if one substituted the word “pattern” with\nother words like “knowledge” or “information”. However, we have found that asking these ques-\ntions in the context of pattern leads to more productive answers, avoiding unproductive byways\nand also tying in very nicely with the details of various existing formalisms and algorithms for\nknowledge representation and learning.\n\nAmong the many kinds of patterns in intelligent systems, semiotic patterns are particularly\ninteresting ones. Peirce decomposed these into three categories:\n\n® iconic patterns, which are patterns of contextually important internal similarity between\ntwo entities (e.g. an iconic pattern binds a picture of a person to that person)\n\ne indexical patterns, which are patterns of spatiotemporal co-occurrence (e.g. an indexical\npattern binds a wedding dress and a wedding)\n\ne symbolic patterns, which are patterns indicating that two entities are often involved in\nthe same relationships (e.g. a symbolic pattern between the number “5” (the symbol) and\nvarious sets of 5 objects (the entities that the symbol is taken to represent))\n\nOf course, some patterns may span more than one of these semiotic categories; and there\nare also some patterns that don’t fall neatly into any of these categories. But the semiotic\npatterns are particularly important ones; and symbolic patterns have played an especially large\nrole in the history of AI, because of the radically different approaches different researchers have\ntaken to handling them in their AI systems. Mathematical logic and related formalisms provide\nsophisticated mechanisms for combining and relating symbolic patterns (“symbols”), and some\nAI approaches have focused heavily on these, sometimes more so than on the identification of\nsymbolic patterns in experience or the use of them to achieve practical goals. We will look fairly\ncarefully at these differences in Chapter 4.\n\nPursuing the patternist philosophy in detail leads to a variety of particular hypotheses and\nconclusions about the nature of mind. Following from the view of intelligence in terms of\nachieving complex goals in complex environments, comes a view in which the dynamics of\na cognitive system are understood to be governed by two main forces:\n\ne selforganization, via which system dynamics cause existing system patterns to give rise to\nnew ones\n\ne goal-oriented behavior, which will be defined more rigorously in Chapter 7, but basically\namounts to a system interacting with its environment in a way that appears like an attempt\nto maximize some reasonably simple function\n\nSelf-organized and goal-oriented behavior must be understood as cooperative aspects. If an\nagent is asked to build a surprising structure out of blocks and does so, this is goal-oriented.\nBut the agent’s ability to carry out this goal-oriented task will be greater if it has previously\nplayed around with blocks a lot in an unstructured, spontaneous way. And the “nudge toward\ncreativity” given to it by asking it to build a surprising blocks structure may cause it to explore\nsome novel patterns, which then feed into its future unstructured blocks play.\n\nBased on these concepts, as argued in detail in [Goe06al, several primary dynamical principles\nmay be posited, including:\n\nHOUSE_OVERSIGHT_012953",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_012953.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3543,
    "word_count": 549,
    "line_count": 58,
    "import_date": "2025-11-19T21:47:45.377667",
    "prefix": "IMAGES-002"
  }
}
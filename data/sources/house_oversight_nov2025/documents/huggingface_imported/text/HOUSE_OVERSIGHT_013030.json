{
  "document_id": "HOUSE_OVERSIGHT_013030",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013030.txt",
  "text": "114 6 A Brief Overview of CogPrime\n\ncombination of explicit and implicit knowledge in the system’s knowledge graph, the synergetic\ninteraction of different cognitive processes would not work so smoothly, and the emergence of\neffective high-level hierarchical, heterarchical and self structures would be less likely.\n\n6.6 Analysis and Synthesis Processes in CogPrime\n\nWe now return to CogPrime’s fundamental cognitive dynamics, using examples from the “virtual\ndog” application to motivate the discussion.\n\nThe cognitive schematic Context \\ Procedure — Goal leads to a conceptualization of the\ninternal action of an intelligent system as involving two key categories of learning:\n\ne Analysis: Estimating the probability p of a posited C A P > G relationship\n\ne Synthesis: Filling in one or two of the variables in the cognitive schematic, given as-\nsumptions regarding the remaining variables, and directed by the goal of maximizing the\nprobability of the cognitive schematic\n\nMore specifically, where synthesis is concerned,\n\ne The MOSES probabilistic evolutionary program learning algorithm is applied to find P,\ngiven fixed C' and G. Internal simulation is also used, for the purpose of creating a simulation\nembodying C and seeing which P lead to the simulated achievement of G.\n\n— Example: A virtual dog learns a procedure P to please its owner (the goal G) in the\ncontert C where there is a ball or stick present and the owner is saying “fetch”.\n\ne PLN inference, acting on declarative knowledge, is used for choosing C, given fixed P and\nG (also incorporating sensory and episodic knowledge as appropriate). Simulation may also\nbe used for this purpose.\n\n— Example: A virtual dog wants to achieve the goal G of getting food, and it knows that\nthe procedure P of begging has been successful at this before, so it seeks a context C\nwhere begging can be expected to get it food. Probably this will be a context involving a\nfriendly person.\n\ne PLN-based goal refinement is used to create new subgoals G to sit on the right hand side\nof instances of the cognitive schematic.\n\n— Example: Given that a virtual dog has a goal of finding food, it may learn a subgoal of\nfollowing other dogs, due to observing that other dogs are often heading toward their\n\nfood.\n\ne Concept formation heuristics are used for choosing G and for fueling goal refinement, but\nespecially for choosing C (via providing new candidates for C). They are also used for\nchoosing P, via a process called “predicate schematization” that turns logical predicates\n(declarative knowledge) into procedures.\n\n— Example: At first a virtual dog may have a hard time predicting which other dogs are\ngoing to be mean to it. But it may eventually observe common features among a number\nof mean dogs, and thus form its own concept of “pit bull,” without anyone ever teaching\nit this concept explicitly.\n\nHOUSE_OVERSIGHT_013030",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013030.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2883,
    "word_count": 475,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:44.044030",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_018426",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_018426.txt",
  "text": "grids that flipped nuclear plants on or off to a logic only they understood. Today. The\nmore profound version, however, would be the arrival of AI that really did think and\ncreate and intuit tremors too subtle for the human mind. Tomorrow. Like so much of\nour connected age, such machines would arrive, Vinge felt, because we want and\neven need them to achieve our dreams. Then, he supposed, they would take over.\nThe leap from evoking Mozart to enacting Stalin would not be so much ofa leap\nanyhow, at least technologically. It’s just bits. Goode’s definition could have been\nscrewed into something still tighter: “Let an ultraintelligent machine be defined as\nthe box that will eliminate us.” The day after tomorrow.\n\nWhat spun uneasily from that silly NASA poem, “Our robots precede us....” is a fear:\nReal Al is fish bait. We'll snap at it hungrily, hoping it will satisfy some human ache\nonly to discover we've been hooked, soon to be devoured. The idea that a\nsuperintelligent device would always be docile enough to tip us off to its secret\nswitches of control or to reveal its looming accidents in a way our simple minds can\nunderstand, seems unlikely. To be honest, we might have a hard time even\nunderstanding the off switches, let alone reaching them. So many of our incentives\nare to let an effective Al finger more and more of our lives. To teach and encourage it,\nin some settings, extremely undocile: A weapon to attack our enemies, our political\nopponents or, finally, each other. It was easy enough for Vinge to see how this would\nend. It wouldn't be with the sort of intended polite, lap-dog domesticity of artificial\nintelligence we might hope for, but with a rotweiler of a device, alive to the meaty\nsmell of power, violence and greed.\n\nThe Oxford philosopher Nick Bostrom has described the following thought\nexperiment: Imagine a super-intelligent machine, programmed to do whatever is\nneeded make paperclips as fast as possible and connected to every resource that\ntask might demand. 7°¢Go figure it out! might be all its human instructors tell it. As\nthe clip-making AI becomes better and better at its task, it demands more and still\nmore resources: more electricity, steel, manufacturing, shipping. The paperclips pile\nup. The machine looks around: If only it could control the power supply. The\nshipping. The steel mining. The humans. And so, ambitious for more and better\npaperclips, it begins to think around its masters, - incapable of stopping until it has\npunched the entire world into paperclips. You had to hope someone had\nremembered to place a “halt” command into is logic somewhere. And though\nBostrom’s messianic wire twister is unlikely - of course, no one is going to forget to\ntell a machine to stop making paperclips - the power of his example is to remind us\nthat if humans can lose their minds, so can Als. “We cannot blithely assume that a\nsuperintelligence will necessarily share any of the final values stereotypically\nassociated with wisdom and intellectual development in humans,” Bostrom wrote.\n“It is no less possible—and probably technically easier—to build a superintelligence\nthat places final value on nothing but calculating.” And as these devices cogitate in\n\n266 Imagine a super-intelligent machine: Nick Bostrom, “Ethical Issues in\nAdvanced Artificial Intelligence,” Cognitive, Emotional and Ethical Aspects of Decision\nMaking in Humans and in Artificial Intelligence (2003) Vol 2, ed I, Smit et al, Institute\nof Advanced Studies in Systems Research and Cybernetics, pp 12-17\n\n194\n\nHOUSE_OVERSIGHT_018426",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_018426.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3563,
    "word_count": 589,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:47.760015",
    "prefix": "IMAGES-004"
  }
}
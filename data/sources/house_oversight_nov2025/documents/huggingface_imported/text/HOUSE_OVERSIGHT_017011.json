{
  "document_id": "HOUSE_OVERSIGHT_017011",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_017011.txt",
  "text": "I. Overview of Google Books Digitization\n\nIn 2004, Google began scanning books to make their contents searchable and discoverable online. To\ndate, Google has scanned over fifteen million books: over 11% of all the books ever published. The\ncollection contains over five billion pages and two trillion words, with books dating back to as early as\n1473 and with text in 478 languages. Over two million of these scanned books were given directly to\nGoogle by their publishers; the rest are borrowed from large libraries such as the University of Michigan\nand the New York Public Library. The scanning effort involves significant engineering challenges, some of\nwhich are highly relevant to the construction of the historical n-grams corpus. We survey those issues\nhere.\n\nThe result of the next three steps is a collection of digital texts associated with particular book editions, as\nwell as composite metadata for each edition combining the information contained in all metadata sources.\n\n1.1. Metadata\n\nOver 100 sources of metadata information were used by Google to generate a comprehensive catalog of\nbooks. Some of these sources are library catalogs (e.g., the list of books in the collections of University of\nMichigan, or union catalogs such as the collective list of books in Bosnian libraries), some are from\nretailers (e.g., Decitre, a French bookseller), and some are from commercial aggregators (e.g., Ingram).\nIn addition, Google also receives metadata from its 30,000 partner publishers. Each metadata source\nconsists of a series of digital records, typically in either the MARC format favored by libraries, or the ONIX\nformat used by the publishing industry. Each record refers to either a specific edition of a book or a\nphysical copy of a book on a library shelf, and contains conventional bibliographic data such as title,\nauthor(s), publisher, date of publication, and language(s) of publication.\n\nCataloguing practices vary widely among these sources, and even within a single source over time. Thus\ntwo records for the same edition will often differ in multiple fields. This is especially true for serials (e.g.,\nthe Congressional Record) and multivolume works such as sets (e.g., the three volumes of The Lord of\nthe Rings).\n\nThe matter is further complicated by ambiguities in the definition of the word ‘book’ itself. Including\ntranslations, there are over three thousand editions derived from Mark Twain’s original Tom Sawyer.\n\nGoogle’s process of converting the billions of metadata records into a single nonredundant database of\nbook editions consists of the following principal steps:\n\n1. Coarsely dividing the billions of metadata records into groups that may refer to the same\nwork (e.g., Tom Sawyer).\n\n2. Identifying and aggregating multivolume works based on the presence of cues from individual\nrecords.\n\n3. Subdividing the group of records corresponding to each work into constituent groups\ncorresponding to the various editions (e.g., the 1909 publication of De lotgevallen van Tom\nSawyer, translated from English to Dutch by Johan Braakensiek).\n\n4. Merging the records for each edition into a new “consensus” record.\n\nThe result is a set of consensus records, where each record corresponds to a distinct book edition and\nwork, and where the contents of each record are formed out of fields from multiple sources. The number\nof records in this set -- i.e., the number of Known book editions -- increases every year as more books are\nwritten.\n\nIn August 2010, this evaluation identified 129 million editions, which is the working estimate we use in this\npaper of all the editions ever published (this includes serials and sets but excludes kits, mixed media, and\n\n3\n\nHOUSE_OVERSIGHT_017011",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_017011.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3720,
    "word_count": 589,
    "line_count": 60,
    "import_date": "2025-11-19T21:47:49.238449",
    "prefix": "IMAGES-004"
  }
}
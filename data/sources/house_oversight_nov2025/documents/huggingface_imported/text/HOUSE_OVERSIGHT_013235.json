{
  "document_id": "HOUSE_OVERSIGHT_013235",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013235.txt",
  "text": "18.3 Sel&Modification via Supercompilation 319\n\nschema learning the learning of schemata carrying out cognitive processes in more specialized,\ncontext-dependent ways than the general MindAgents do. Eventually, once a CogPrime instance\nbecomes sufficiently complex and advanced, these cognitive schema may replace the MindAgents\naltogether, leaving the system to operate almost entirely based on cognitive schemata.\n\nIn order to make the process of cognitive schema learning easier, we may provide a number\nof elementary schemata embodying the basic cognitive processes contained in the MindAgents.\nOf course, cognitive schemata need not use these they may embody entirely different cognitive\nprocesses than the MindAgents. Eventually, we want the system to discover better ways of doing\nthings than anything even hinted at by its initial MindAgents. But for the initial phases or the\nsystem’s schema learning, it will have a much easier time learning to use the basic cognitive\noperations as the initial MindAgents, rather than inventing new ways of thinking from scratch!\n\nFor instance, we may provide elementary schemata corresponding to inference operations,\nsuch as\nschemes Deduction\n\nInput InheritanceLink: X, Y\nOutput InheritanceLink\n\nThe inference MindAgents apply this rule in certain ways, designed to be reasonably effective\nin a variety of situations. But there are certainly other ways of using the deduction rule, outside\nof the basic control strategies embodied in the inference MindAgents. By learning schemata in-\nvolving the Deduction schema, the system can learn special, context-specific rules for combining\ndeduction with concept-formation, association-formation and other cognitive processes. And as\nit gets smarter, it can then take these schemata involving the Deduction schema, and replace\nit with a new schema that eg. contains a context-appropriate deduction formula.\n\nEventually, to support cognitive schema learning, we will want to cast the hard-wired MindA-\ngents as cognitive schemata, so the system can see what is going on inside them. Pragmatically,\nwhat this requires is coding versions of the MindAgents in Combo (see Chapter 21 of Part 2)\nrather than C++, so they can be treated like any other cognitive schemata; or alternately, rep-\nresenting them as declarative Atoms in the Atomspace. Figure 18.1 illustrates the possibility of\nrepresenting the PLN deduction rule in the Atomspace rather than as a hard-wired procedure\ncoded in C++.\n\nBut even prior to this kind of fully cognitively transparent implementation, the system can\nstill reason about its use of different mind dynamics by considering each MindAgent as a virtual\nProcedure with a real SchemaNode attached to it. This can lead to some valuable learning, with\nthe obvious limitation that in this approach the system is thinking about its MindAgents as\nblack boxes rather than being equipped with full knowledge of their internals.\n\n18.3 Self-Modification via Supercompilation\n\nNow we turn to a very different form of advanced self-modification: supercompilation. Super-\ncompilation \"merely\" enables procedures to run much, much faster than they otherwise would.\nThis is in a sense weaker than self-modication methods that fundamentally create new algo-\nrithms, but it shouldn’t be underestimated. A 50x speedup in some cognitive process can enable\nthat process to give much smarter answers, which can then elicit different behaviors from the\nworld or from other cognitive processes, thus resulting in a qualitatively different overall cog-\nnitive dynamic.\n\nHOUSE_OVERSIGHT_013235",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013235.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3578,
    "word_count": 532,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:44.837446",
    "prefix": "IMAGES-002"
  }
}
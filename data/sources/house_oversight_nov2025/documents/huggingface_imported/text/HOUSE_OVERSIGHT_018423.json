{
  "document_id": "HOUSE_OVERSIGHT_018423",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_018423.txt",
  "text": "even more symphonies they’d probably be great too. Unfortunately he’s dead.\nWouldn't it be nice if we could sample his old symphonies and make new ones\nwhenever we want?2°°\n\nIn the future we'll invite Al into our lives to harmonize away many of the problems\nwe face, not merely making up for Mozart’s inconvenient mortality. “AI Agents” will\nlinger along side us. They will compose versions of themselves we'll not quite grasp,\neven as we appreciate their efficient magic. “Al is both freedom from programming\nand freedom from understanding,” runs one programmer’s line2®!. Today machines\nthat once demanded millions of lines of code can function with a fraction of that.\nInstructions are sent to machine learning systems; the programs do the rest. Such\ndesigns balance their mystery with efficacy. They speak to and learn from each\nother too. Part of the reason that the the “Does it think like a human?” Turing Test\nwill be insufficient in the future is that the machines are not learning from only from\nhumans. They are learning from each other.\n\nPerhaps this is not such a bad thing. The distinguished physicists George Ellis and\nJoe Silk, who spent a lifetime trying to stand on Newton and Einstein’s shoulders to\ngrasp answers about gravity or the future of our universe, electrified many of their\npeers in 2015 with by wondering if perhaps too much of science had become\nunscientific, unverifiable, unreliable. The great grand ideas of our day, notions like\nstring theory or dark matter, differ in a crucial way from Newton's laws of motion or\nEinstein’s principles: They cannot seem to be tested and significantly proved. And\nthis had fired a trend among younger physicits: Perhaps there was no need for\nproof. To Ellis and Silk this seemed an awful retreat, dragging physics back to a pre-\nEnlightenment age of conjecture, superstition and instinct. “This year, debates in\nphysics circles took a worrying turn,” they wrote. “Faced with difficulties in applying\nfundamental theories to the observed Universe, some researchers called for a\nchange in how theoretical physics is done. They began to argue — explicitly — that\nif a theory is sufficiently elegant and explanatory, it need not be tested.” Fans of such\nan approach called the idea “post-empirical science.” This strange, oxymoronic idea\nwas, in a sense, like proposing post-rules baseball: A recipie for wild, swinging chaos\nthat would make scorekeeping impossible.\n\nThe strange, boiling debate did however reflect an underlying and unnerving truth:\nScience does seem to have stalled. And it became inevitable to ask: Might it be\npossible that the machines - or some fusion of Shalosh B. Ekhad andta human mind\n- can reach into an understanding of laws that no human alone can fathom. We've\nsaid again and again: Connection changes the nature of an object. Perhaps it changes\n\n260 Wouldn't it be nice: Andrej Karpathy, “The Unreasonable Effectiveness of\nRecurrent Neural Networks,” in The Hackers Guide to Neural Networks published\nonline May 21, 2015 or John Supko, “How I Taught My Computer to Write Its Own\nMusic,” in Nautilus, February 12, 2015 and Daniel Johnson, “Composing Music with\nRecurrent Neural Networks,” on Hexahedria Blog August 3, 2015\n\n261 Freedom from understanding: Philip Greenspun, “Big data and machine\nlearning” from Philip Greenspun weblog (November 21, 2015)\n\n191\n\nHOUSE_OVERSIGHT_018423",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_018423.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3380,
    "word_count": 549,
    "line_count": 52,
    "import_date": "2025-11-19T21:47:46.692199",
    "prefix": "IMAGES-004"
  }
}
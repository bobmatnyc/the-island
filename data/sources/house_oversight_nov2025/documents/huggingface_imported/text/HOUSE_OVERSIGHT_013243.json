{
  "document_id": "HOUSE_OVERSIGHT_013243",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013243.txt",
  "text": "Glossary of Specialized Terms 327\n\nAdaptive Inference Control: Algorithms or heuristics for guiding PLN inference, that\ncause inference to be guided differently based on the context in which the inference is taking\nplace, or based on aspects of the inference that are noted as it proceeds.\n\nAGI Preschool: A virtual world or robotic scenario roughly similar to the environment\nwithin a typical human preschool, intended for AGIs to learn in via interacting with the\nenvironment and with other intelligent agents.\n\nAtom: The basic entity used in OpenCog as an element for building representations. Some\nAtoms directly represent patterns in the world or mind, others are components of represen-\ntations. There are two kinds of Atoms: Nodes and Links.\n\ne Atom, Frozen: See Atom, Saved\ne Atom, Realized: An Atom that exists in RAM at a certain point in time.\ne Atom, Saved: An Atom that has been saved to disk or other similar media, and is not\n\nactively being processed.\n\nAtom, Serialized: An Atom that is serialized for transmission from one software process\nto another, or for saving to disk, etc.\n\nAtom2Link: A part of OpenCogPrime\n\ns language generation system, that transforms appropriate Atoms into words connected via\nlink parser link types.\n\nAtomspace: A collection of Atoms, comprising the central part of the memory of an\nOpenCog instance.\n\nAttention: The aspect of an intelligent system’s dynamics focused on guiding which aspects\nof an OpenCog system’s memory & functionality gets more computational resources at a\ncertain point in time\n\nAttention Allocation: The cognitive process concerned with managing the parameters\nand relationships guiding what the system pays attention to, at what points in time. This\nis a term inclusive of Importance Updating and Hebbian Learning.\n\nAttentional Currency: Short Term Importance and Long Term Importance values are\nimplemented in terms of two different types of artificial money, STICurrency and LTICur-\nrency. Theoretically these may be converted to one another.\n\nAttentional Focus: The Atoms in an OpenCog Atomspace whose ShortTermImportance\nvalues lie above a critical threshold (the AttentionalFocus Boundary). The Attention Allo-\ncation subsystem treats these Atoms differently. Qualitatively, these Atoms constitute the\nsystem’s main focus of attention during a certain interval of time, i.e. it’s a moving bubble\nof attention.\n\nAttentional Memory: A system’s memory of what it’s useful to pay attention to, in what\ncontexts. In CogPrime this is managed by the attention allocation subsystem.\n\nBackward Chainer: A piece of software, wrapped in a MindAgent, that carries out back-\nward chaining inference using PLN.\n\nCIM-Dynamic: Concretely-Implemented Mind Dynamic, a term for a cognitive process\nthat is implemented explicitly in OpenCog (as opposed to allowed to emerge implicitly from\nother dynamics). Sometimes a CIM-Dynamic will be implemented via a single MindAgent,\nsometimes via a set of multiple interrelated MindAgents, occasionally by other means.\nCognition: In an OpenCog context, this is an imprecise term. Sometimes this term means\nany process closely related to intelligence; but more often it’s used specifically to refer to\nmore abstract reasoning /learning/etc, as distinct from lower-level perception and action.\nCognitive Architecture: This refers to the logical division of an AI system like OpenCog\ninto interacting parts and processes representing different conceptual aspects of intelligence.\n\nHOUSE_OVERSIGHT_013243",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013243.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3497,
    "word_count": 526,
    "line_count": 66,
    "import_date": "2025-11-19T21:47:45.849184",
    "prefix": "IMAGES-002"
  }
}
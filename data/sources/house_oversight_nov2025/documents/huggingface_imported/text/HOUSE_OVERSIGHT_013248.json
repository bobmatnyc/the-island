{
  "document_id": "HOUSE_OVERSIGHT_013248",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013248.txt",
  "text": "332 A Glossary\n\ne Forgetting: The process of removing Atoms from the in-RAM portion of Atomspace, when\nRAM gets short and they are judged not as valuable to retain in RAM as other Atoms. This\nis commonly done using the LTT values of the Atoms (removing lowest LTI-Atoms, or more\ncomplex strategies involving the LTI of groups of interconnected Atoms). May be done by\na dedicated Forgetting MindAgent. VLTI may be used to determine the fate of forgotten\nAtoms.\n\ne Forward Chainer: A control mechanism (MindAgent) for PLN inference, that works by\ntaking existing Atoms and deriving conclusions from them using PLN rules, and then iter-\nating this process. The goal is to derive new Atoms that are interesting according to some\ngiven criterion.\n\ne Frame2Atom: A simple system of hand-coded rules for translating the output of RelEx2Frame\n(logical representation of semantic relationships using FrameNet relationships) into Atoms.\n\ne Freezing: Saving Atoms from the in-RAM Atomspace to disk.\n\ne General Intelligence: Often used in an informal, commonsensical sense, to mean the\nability to learn and generalize beyond specific problems or contexts. Has been formalized\nin various ways as well, including formalizations of the notion of ’achieving complex goals\nin complex environments” and \"achieving complex goals in complex environments using\nlimited resources.” Usually interpreted as a fuzzy concept, according to which absolutely\ngeneral intelligence is physically unachievable, and humans have a significant level of general\nintelligence, but far from the maximally physically achievable degree.\n\ne Generalized Hypergraph: A hypergraph with some additional features, such as links\nthat point to links, and nodes that are seen as “containing” whole sub-hypergraphs. This is\nthe most natural and direct way to mathematically/visually model the Atomspace.\n\ne Generator: In the PLN design, a rule is denoted a generator if it can produce its consequent\nwithout needing premises (e.g. LookupRule, which just looks it up in the AtomSpace). See\ncomposer.\n\ne Global, Distributed Memory: Memory that stores items as implicit knowledge, with\neach memory item spread across multiple components, stored as a pattern of organization\nor activity among them.\n\ne Glocal Memory: The storage of items in memory in a way that involves both localized\nand global, distributed aspects.\n\ne Goal: An Atom representing a function that a system (like OpenCog) is supposed to spend\na certain non-trivial percentage of its attention optimizing. The goal, informally speaking,\nis to maximize the Atom’s truth value.\n\ne Goal, Implicit: A goal that an intelligent system, in practice, strives to achieve; but that\nis not explicitly represented as a goal in the system’s knowledge base.\n\ne Goal, Explicit: A goal that an intelligent system explicitly represents in its knowledge\nbase, and expends some resources trying to achieve. Goal Nodes (which may be Nodes or,\ne.g. ImplicationLinks) are used for this purpose in OpenCog.\n\ne Goal-Driven Learning: Learning that is driven by the cognitive schematic i.e. by the quest\nof figuring out which procedures can be expected to achieve a certain goal in a certain sort\nof context.\n\ne Grounded SchemaNode: See SchemaNode, Grounded.\n\ne Hebbian Learning: An aspect of Attention Allocation, centered on creating and updating\nHebbianLinks, which represent the simultaneous importance of the Atoms joined by the\nHebbianLink.\n\nHOUSE_OVERSIGHT_013248",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013248.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3456,
    "word_count": 531,
    "line_count": 64,
    "import_date": "2025-11-19T21:47:47.906170",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_012936",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_012936.txt",
  "text": "20 2 What Is Human-Like General Intelligence?\n\n[Goel0c]. A general intelligence is then understood as one that can do this for a variety of\ncomplex goals in a variety of complex environments.\n\nHowever, apart from positing definitions, it is difficult to say anything nontrivial about gen-\neral intelligence in general. Marcus Hutter [Hut05] has demonstrated, using a characterization\nof general intelligence similar to the one above, that a very simple algorithm called AIXI” can\ndemonstrate arbitrarily high levels of general intelligence, if given sufficiently immense com-\nputational resources. This is interesting because it shows that (if we assume the universe can\neffectively be modeled as a computational system) general intelligence is basically a problem of\ncomputational efficiency. The particular structures and dynamics that characterize real-world\ngeneral intelligences like humans arise because of the need to achieve reasonable levels of intel-\nligence using modest space and time resources.\n\nThe “patternist” theory of mind presented in [GoeQ6a] and briefly summarized in Chap-\nter 3 below presents a number of emergent structures and dynamics that are hypothesized to\ncharacterize pragmatic general intelligence, including such things as system-wide hierarchical\nand heterarchical knowledge networks, and a dynamic and self-maintaining selfmodel. Much of\nthe thinking underlying CogPrime has centered on how to make multiple learning components\ncombine to give rise to these emergent structures and dynamics.\n\n2.1.2 What Is Human-like General Intelligence?\n\nGeneral principles like “complex goals in complex environments” and patternism are not suf-\nficient to specify the nature of human-like general intelligence. Due to the harsh reality of\ncomputational resource restrictions, real-world general intelligences are necessarily biased to\nparticular classes of environments. Human intelligence is biased toward the physical, social and\nlinguistic environments in which humanity evolved, and if AI systems are to possess humanlike\ngeneral intelligence they must to some extent share these biases.\n\nBut what are these biases, specifically? This is a large and complex question, which we seek\nto answer in a theoretically grounded way in Chapter 9. However, before turning to abstract\ntheory, one may also approach the question in a pragmatic way, by looking at the categories of\nthings that humans do to manifest their particular variety of general intelligence. This is the\ntask of the following section.\n\n2.2 Commonly Recognized Aspects of Human-like Intelligence\n\nIt would be nice if we could give some sort of “standard model of human intelligence” in this\nchapter, to set the context for our approach to artificial general intelligence — but the truth is\nthat there isn’t any. What the cognitive science field has produced so far is better described as:\na broad set of principles and platitudes, plus a long, loosely-organized list of ideas and results.\nChapter 5 below constitutes an attempt to present an integrative architecture diagram for\nhuman-like general intelligence, synthesizing the ideas of a number of different AGI and cognitive\ntheorists. However, though the diagram given there attempts to be inclusive, it nonetheless\ncontains many features that are accepted by only a plurality of the research community.\n\nHOUSE_OVERSIGHT_012936",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_012936.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3368,
    "word_count": 499,
    "line_count": 49,
    "import_date": "2025-11-19T21:47:44.754730",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013115",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013115.txt",
  "text": "11.4 Piaget’s Stages in the Context of Uncertain Inference 199\n\nDavidson [Dav84], Dennett [Den87] and others support the common belief that theory of\nmind is dependent upon linguistic ability. A major challenge to this prevailing philosophical\nstance came from Premack and Woodruff [PW78] who postulated that prelinguistic primates\ndo indeed exhibit “theory of mind” behavior. While Premack and Woodruff’s experiment itself\nhas been challenged, their general result has been bolstered by follow-up work showing similar\nresults such as [TC97]. It seems to us that while theory of mind depends on many of the same\ninferential capabilities as language learning, it is not intrinsically dependent on the latter.\n\nThere is a school of thought often called the Theory Theory [BW88, Car85, Wel90] holding\nthat a child’s understanding of mind is best understood in terms of the process of iteratively\nformulating and refuting a series of naive theories about others. Alternately, Gordon [Gor86]\npostulates that theory of mind is related to the ability to run cognitive simulations of others’\nminds using one’s own mind as a model. We suggest that these two approaches are actually\nquite harmonious with one another. In an uncertain AGI context, both theories and simulations\nare grounded in collections of uncertain implications, which may be assembled in context-\nappropriate ways to form theoretical conclusions or to drive simulations. Even if there is a\nspecial “mind-simulator” dynamic in the human brain that carries out simulations of other\nminds in a manner fundamentally different from explicit inferential theorizing, the inputs to\nand the behavior of this simulator may take inferential form, so that the simulator is in essence\na way of efficiently and implicitly producing uncertain inferential conclusions from uncertain\npremises.\n\nWe have thought through the details by CogPrime system should be able to develop theory\nof mind via embodied experience, though at time of writing practical learning experiments in\nthis direction have not yet been done. We have not yet explored in detail the possibility of giving\nCogPrime a special, elaborately engineered “mind-simulator” component, though this would be\npossible; instead we have initially been pursuing a more purely inferential approach.\n\nFirst, it is very simple for a CogPrime system to learn patterns such as “If I rotated by pi\nradians, I would see the yellow block.” And it’s not a big leap for PLN to go from this to the\nrecognition that “You look like me, and you’re rotated by pi radians relative to my orientation,\ntherefore you probably see the yellow block.” The only nontrivial aspect here is the “you look\nlike me” premise.\n\nRecognizing “embodied agent” as a category, however, is a problem fairly similar to recog-\nnizing “block” or “insect” or “daisy” as a category. Since the CogPrime agent can perceive most\nparts of its own “robot” body-—its arms, its legs, ete—it should be easy for the agent to figure\nout that physical objects like these look different depending upon its distance from them and\nits angle of observation. From this it should not be that difficult for the agent to understand\nthat it is naturally grouped together with other embodied agents (like its teacher), not with\nblocks or bugs.\n\nThe only other major ingredient needed to enable theory of mind is “reflection’”— the ability of\nthe system to explicitly recognize the existence of knowledge in its own mind (note that this term\n“reflection” is not the same as our proposed “reflexive” stage of cognitive development). This\nexists automatically in CogPrime, via the built-in vocabulary of elementary procedures supplied\nfor use within SchemaNodes (specifically, the atTime and TruthValue operators). Observing that\n“at time T, the weight of evidence of the link L increased from zero” is basically equivalent to\nobserving that the link L was created at time T.\n\nThen, the system may reason, for example, as follows (using a combination of several PLN\nrules including the above-given deduction rule):\n\nHOUSE_OVERSIGHT_013115",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013115.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4072,
    "word_count": 645,
    "line_count": 56,
    "import_date": "2025-11-19T21:47:47.455330",
    "prefix": "IMAGES-002"
  }
}
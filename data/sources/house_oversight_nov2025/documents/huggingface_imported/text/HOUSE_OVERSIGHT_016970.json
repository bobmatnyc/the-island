{
  "document_id": "HOUSE_OVERSIGHT_016970",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016970.txt",
  "text": "division has been critiqued by evolutionary biologist Richard Dawkins, myself, and\nothers. We can discuss “should” if framed as “we should do X in order to achieve Y.”\nWhich Y should be a high priority is not necessarily settled by democratic vote but might\nbe settled by Darwinian vote. Value systems and religions wax and wane, diversify,\ndiverge, and merge just as living species do: subject to selection. The ultimate “value”\n(the “should”’) is survival of genes and memes.\n\nFew religions say that there is no connection between our physical being and the\nspiritual world. Miracles are documented. Conflicts between Church doctrine and\nGalileo and Darwin are eventually resolved. Faith and ethics are widespread in our\nspecies and can be studied using scientific methods, including but not limited to fMRI,\npsychoactive drugs, questionnaires, et cetera.\n\nVery practically, we have to address the ethical rules that should be built in,\nlearned, or probabilistically chosen for increasingly intelligent and diverse machines. We\nhave a whole series of trolley problems. At what number of people in line for death\nshould the computer decide to shift a moving trolley to one person? Ultimately this\nmight be a deep-learning problem—one in which huge databases of facts and\ncontingencies can be taken into account, some seemingly far from the ethics at hand.\n\nFor example, the computer might infer that the person who would escape death if\nthe trolley is left alone is a convicted terrorist recidivist loaded up with doomsday\npathogens, or a saintly POTUS—or part of a much more elaborate chain of events in\ndetailed alternative realities. If one of these problem descriptions seems paradoxical or\nillogical, it may be that the authors of the trolley problem have adjusted the weights on\neach sides of the balance such that hesitant indecision is inevitable.\n\nAlternatively, one can use misdirection to rig the system, such that the error\nmodes are not at the level of attention. For example, in the Trolley Problem, the real\nethical decision was made years earlier when pedestrians were given access to the rails—\nor even before that, when we voted to spend more on entertainment than on public safety.\nQuestions that at first seem alien and troubling, like “Who owns the new minds, and who\npays for their mistakes?” are similar to well-established laws about who owns and pays\nfor the sins of a corporation.\n\nThe Slippery Slopes\nWe can (over)simplify ethics by claiming that certain scenarios won’t happen. The\ntechnical challenges or the bright red lines that cannot be crossed are reassuring, but the\nreality is that once the benefits seem to outweigh the risks (even briefly and barely), the\nred lines shift. Just before Louise Brown’s birth in 1978, many people were worried that\nshe “would turn out to be a little monster, in some way, shape or form, deformed,\nsomething wrong with her.”*° Few would hold this view of in-vitro fertilization today.\nWhat technologies are lubricating the slope toward multiplex sentience? It is not\nmerely deep machine-learning algorithms with Big Iron. We have engineered rodents to\nbe significantly better at a variety of cognitive tasks as well as to exhibit other relevant\ntraits, such as persistence and low anxiety. Will this be applicable to animals that are\nalready at the door of humanlike intelligence? Several show self-recognition in a mirror\ntest—chimpanzees, bonobos, orangutans, some dolphins and whales, and magpies.\n\n45 “Then, Doctors ‘All Anxious’ About Test-tube Baby”\nhttp://edition.cnn.com/2003/HEALTH/parenting/07/25/cnna.copperman/\n\n167\n\nHOUSE_OVERSIGHT_016970",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016970.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3619,
    "word_count": 571,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:47.226029",
    "prefix": "IMAGES-004"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013017",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013017.txt",
  "text": "5.3 An Architecture Diagram for Human-Like General Intelligence 101\n\nEach of these long-term memory types has its analogue in working memory as well. In some\ncognitive models, the working memory and long-term memory versions of a memory type and\ncorresponding cognitive processes, are basically the same thing. CogPrime is mostly like this\n— it implements working memory as a subset of long-term memory consisting of items with\nparticularly high importance values. The distinctive nature of working memory is enforced via\nusing slightly different dynamical equations to update the importance values of items with\nimportance above a certain threshold. On the other hand, many cognitive models treat working\nand long term memory as more distinct than this, and there is evidence for significant functional\nand anatomical distinctness in the brain in some cases. So for the purpose of the integrative\ndiagram, it seemed best to leave working and long-term memory subcomponents as parallel but\ndistinguished.\n\nFigure 5.4 also encompasses metacognition, under the hypothesis that in human beings and\nhuman-like minds, metacognitive thinking is carried out using basically the same processes as\nplain ordinary deliberative thinking, perhaps with various tweaks optimizing them for thinking\nabout thinking. If it turns out that humans have, say, a special kind of reasoning faculty\nexclusively for metacognition, then the diagram would need to be modified. Modeling of self\nand others is understood to occur via a combination of metacognition and deliberative thinking,\nas well as via implicit adaptation based on reactive processing.\n\nPERCEPTUAL SUBSYSTEMS\n\nMORE ABSTRACT ASPECTS\nOF SENSORIMOTOR MEMORY\n\nary SOMATO- |\nOLFACTION SENSORY\nVISION AUDITION\nHIERARCHY HIERARCHY\n\nACTION\nHIERARCHY\n\nFig. 5.5: Architecture for Multimodal Perception\n\nFigure 5.5 models perception, according to the basic ideas of deep learning theory. Vision and\naudition are modeled as deep learning hierarchies, with bottom-up and top-down dynamics. The\nlower layers in each hierarchy refer to more localized patterns recognized in, and abstracted from,\nsensory data. Output from these hierarchies to the rest of the mind is not just through the top\nlayers, but via some sort of sampling from various layers, with a bias toward the top layers. The\ndifferent hierarchies cross-connect, and are hence to an extent dynamically coupled together. It\nis also recognized that there are some sensory modalities that aren’t strongly hierarchical, e.g\n\nHOUSE_OVERSIGHT_013017",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013017.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2534,
    "word_count": 378,
    "line_count": 46,
    "import_date": "2025-11-19T21:47:48.750214",
    "prefix": "IMAGES-002"
  }
}
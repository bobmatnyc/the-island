{
  "document_id": "HOUSE_OVERSIGHT_016376",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016376.txt",
  "text": "The bottom-up method for recognizing handwritten characters is to give the\ncomputer thousands of examples of each one and let it pull out the salient features.\nInstead, Lake ef al. gave the program a general model of how you draw a character: A\nstroke goes either right or left; after you finish one, you start another; and so on. When\nthe program saw a particular character, it could infer the sequence of strokes that were\nmost likely to have led to it—just as I inferred that the spam process led to my dubious\nemail. Then it could judge whether a new character was likely to result from that\nsequence or from a different one, and it could produce a similar set of strokes itself. The\nprogram worked much better than a deep-learning program applied to exactly the same\ndata, and it closely mirrored the performance of human beings.\n\nThese two approaches to machine learning have complementary strengths and\nweaknesses. In the bottom-up approach, the program doesn’t need much knowledge to\nbegin with, but it needs a great deal of data, and it can generalize only in a limited way.\nIn the top-down approach, the program can learn from just a few examples and make\nmuch broader and more varied generalizations, but you need to build much more into it to\nbegin with. A number of investigators are currently trying to combine the two\napproaches, using deep learning to implement Bayesian inference.\n\nThe recent success of AI 1s partly the result of extensions of those old ideas. But\nit has more to do with the fact that, thanks to the Internet, we have much more data, and\nthanks to Moore’s Law we have much more computational power to apply to that data.\nMoreover, an unappreciated fact is that the data we do have has already been sorted and\nprocessed by human beings. The cat pictures posted to the Web are canonical cat\npictures—pictures that humans have already chosen as “good” pictures. Google\nTranslate works because it takes advantage of millions of human translations and\ngeneralizes them to a new piece of text, rather than genuinely understanding the\nsentences themselves.\n\nBut the truly remarkable thing about human children is that they somehow\ncombine the best features of each approach and then go way beyond them. Over the past\nfifteen years, developmentalists have been exploring the way children learn structure\nfrom data. Four-year-olds can learn by taking just one or two examples of data, as a top-\ndown system does, and generalizing to very different concepts. But they can also learn\nnew concepts and models from the data itself, as a bottom-up system does.\n\nFor example, in our lab we give young children a “blicket detector”’—a new\nmachine to figure out, one they’ve never seen before. It’s a box that lights up and plays\nmusic when you put certain objects on it but not others. We give children just one or two\nexamples of how the machine works, showing them that, say, two red blocks make it go,\nwhile a green-and-yellow combination doesn’t. Even eighteen-month-olds immediately\nfigure out the general principle that the two objects have to be the same to make it go,\nand they generalize that principle to new examples: For instance, they will choose two\nobjects that have the same shape to make the machine work. In other experiments, we’ve\nshown that children can even figure out that some hidden invisible property makes the\nmachine go, or that the machine works on some abstract logical principle.**\n\n38 A. Gopnik, T. Griffiths & C. Lucas, “When younger learners can be better (or at least more open-\nminded) than older ones,” Curr. Dir. Psychol. Sci., 24:2, 87-92 (2015).\n\n156\n\nHOUSE_OVERSIGHT_016376",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016376.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3633,
    "word_count": 618,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:45.922265",
    "prefix": "IMAGES-003"
  }
}
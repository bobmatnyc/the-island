{
  "document_id": "HOUSE_OVERSIGHT_016972",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016972.txt",
  "text": "Even though a supercomputer can “train” a clone of zemself in seconds, the\nenergy cost of producing a mature silicon clone is comparable. Engineering (Homo)\nprodigies might make a small impact on this slow process, but speeding up development\nand implanting extensive memory (as DNA-exabytes or other means) could reduce\nduplication time of a bio-computer to close to the doubling time of cells (ranging from\neleven minutes to twenty-four hours). The point is that while we may not know what\nratio of bio/homo/nano/robo hybrids will be dominant at each step of our accelerating\nevolution, we can aim for high levels of humane, fair, and safe treatment (“use”) of one\nanother.\n\nBills of Rights date back to 1689 in England. FDR proclaimed the “Four\nFreedoms”’—freedom of speech, freedom of conscience, freedom from fear, and freedom\nfrom want. The U.N.’s Universal Declaration of Human Rights in 1948 included the\nright to life; the prohibition of slavery; defense of rights when violated; freedom of\nmovement; freedom of association, thought, conscience, and religion; social, economic,\nand cultural rights; duties of the individual to society; and prohibition of use of rights in\ncontravention of the purposes and principles of the United Nations.\n\nThe “universal” nature of these rights is not universally embraced and is subject\nto extensive critique and noncompliance. How does the emergence of non-Homo-\nintelligences affect this discussion? At a minimum, it is becoming rapidly difficult to\nhide behind vague intuition for ethical decisions—“I know it when I see it” (U.S.\nSupreme Court Justice Potter Stewart, 1964) or the “wisdom of repugnance” (aka “yuck\nfactor,” Leon Kass, 1997), or vague appeals to “common sense.” As we have to deal\nwith minds alien to us, sometimes quite literal from our viewpoint, we need to be\nexplicit—yea, even algorithmic.\n\nSelf-driving cars, drones, stock-market transactions, NSA searches, et cetera,\nrequire rapid, pre-approved decision making. We may gain insights into many aspects of\nethics that we have been trying to pin down and explain for centuries. The challenges\nhave included conflicting priorities, as well as engrained biological, sociological, and\nsemi-logical cognitive biases. Notably far from consensus in universal dogmas about\nhuman rights are notions of privacy and dignity, even though these influence many laws\nand guidelines.\n\nHumans might want the right to march in to read (and change) the minds of\ncomputers to see why they’re making decisions at odds with our (Homo) instincts. Is it\nnot fair for machines to ask the same of us? We note the growth of movements toward\ntransparency in potential financial conflicts; “open-source” software, hardware, and\nwetware; the Fair Access to Science and Technology Research Act (FASTR); and the\nOpen Humans Foundation.\n\nIn his 1976 book Computer Power and Human Reason, Joseph Weizenbaum\nargued that machines should not replace Homo in situations requiring respect, dignity, or\ncare, while others (author Pamela McCorduck and computer scientists like John\nMcCarthy and Bill Hibbard) replied that machines can be more impartial, calm, and\nconsistent and less abusive or mischievous than people in such positions.\n\nEquality\nWhat did the thirty-three-year-old Thomas Jefferson mean in 1776 when he wrote, “We\nhold these Truths to be self-evident, that all Men are created equal, that they are endowed\n\n169\n\nHOUSE_OVERSIGHT_016972",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016972.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3432,
    "word_count": 532,
    "line_count": 55,
    "import_date": "2025-11-19T21:47:47.884784",
    "prefix": "IMAGES-004"
  }
}
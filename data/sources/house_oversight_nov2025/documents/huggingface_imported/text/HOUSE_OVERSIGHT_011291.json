{
  "document_id": "HOUSE_OVERSIGHT_011291",
  "filename": "IMAGES-001-HOUSE_OVERSIGHT_011291.txt",
  "text": "Esu Origins - ‘February 24 ~ 26, 2017\nPROJECT An Origins Project Scientific Workshop\nChallenges of Artificial Intelligence:\n\nEnvisioning and Addressing Adverse Outcomes\n\nARIZONA STATE UNIVERSITY\n\n3) WAR & PEACE\nAl, Military Systems, and Stability\n\n(Contributions from Eric Horvitz, Elon Musk, Stuart Russell, others)\n\nMilitary applications have long been a motivator for funding scientific R&D, and for developing and\nfielding the latest technical advances for defensive and offensive applications. We can expect to see a\nrise in the use of Al advances by both state and non-state actors in both strategic and tactical uses, and\nin wartime and peace. Al advances have implications for symmetric and asymmetric military\noperations and warfare, including terrorist attacks. Advances in such areas as machine learning,\nsensing and sensor fusion, pattern recognition, inference, decision making, and robotics and\ncyberphysical systems, will increase capabilities and, in many cases, lower the bar of entry for groups\nwith scarce resources. Al advances will enable new kinds of surveillance, warfighting, killing, and\ndisruption and can shift traditional balances of power.\n\nTwo areas of concern taken together frame troubling scenarios:\n\ne Competitive pressures pushing militaries to invest in increasingly fast-paced situation assessment\nand responses that tend to push out human oversight, and lead to increasing reliance on\nautonomous sensing, inference, planning, and action.\n\ne Rise of powerful Al-power planning, messaging, and systems by competitors, adversaries, and\nthird parties that can prompt war intentionally or inadvertently via sham or false signaling and\nnews.\n\nThe increasing automation, coupled with time-critical sensing and response required to dominate, and\nfailure to grapple effectively with false signals are each troubling, but taken together appear to bea\ntroubling mix with potentially grave outcomes on the future of the world.\n\nConcerning scenarios can be painted that involve that start of a large-scale war among adversaries via\ninadequate human oversight in a time-pressured response situation after receiving signals or a\nsequence of signals about an adversary’s actions or intentions. The signal can be either be well-\nintentioned, but an unfortunate false positive or an intentionally generated signal (e.g., statement by\nleader or weapons engagement) e.g., designed and injected by a third party to ignite a war. Related\nscenarios can occur based in destabilization when an adversary believes that systems on the other side\ncan be foiled due to Al-powered attacks on military sensing, weapons, coupled with false signaling\naimed at human decision makers.\n\nA US DOD directive of 2012 (3000.09) specifies a goal (for procuring weapon systems) of assuring that\nautonomous and semi-autonomous weapon systems are designed to allow commanders and operators\nto exercise appropriate levels of human judgment over the use of force. The directive seeks meaningful\nhuman controls. However, it is unclear how this goal can be met with the increasing stime-critical\npressures for sensing and responses, and competition for with building the most effective weapon\n\nHOUSE_OVERSIGHT_011291",
  "metadata": {
    "original_filename": "IMAGES-001-HOUSE_OVERSIGHT_011291.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3206,
    "word_count": 471,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:48.204065",
    "prefix": "IMAGES-001"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016308",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016308.txt",
  "text": "search exhaustively. Every improvement in chess-playing Als, between Alan Turing’s\nfirst design for one in 1948 and today’s, has been brought about by ingeniously confining\nthe program’s attention (or making it confine its attention) ever more narrowly to\nbranches likely to lead to that immutable goal. Then those branches are evaluated\naccording to that goal.\n\nThat is a good approach to developing an AI with a fixed goal under fixed\nconstraints. But if an AGI worked like that, the evaluation of each branch would have to\nconstitute a prospective reward or threatened punishment. And that is diametrically the\nwrong approach if we’re seeking a befter goal under unknown constraints—which is the\ncapability of an AGI. An AGI is certainly capable of learning to win at chess—but also\nof choosing not to. Or deciding in mid-game to go for the most interesting continuation\ninstead of a winning one. Or inventing anew game. A mere AI is incapable of having\nany such ideas, because the capacity for considering them has been designed out of its\nconstitution. That disability is the very means by which it plays chess.\n\nAn AGI is capable of enjoying chess, and of improving at it because it enjoys\nplaying. Or of trying to win by causing an amusing configuration of pieces, as grand\nmasters occasionally do. Or of adapting notions from its other interests to chess. In other\nwords, it learns and plays chess by thinking some of the very thoughts that are forbidden\nto chess-playing Als.\n\nAn AGT is also capable of refusing to display any such capability. And then, if\nthreatened with punishment, of complying, or rebelling. Daniel Dennett, in his essay for\nthis volume, suggests that punishing an AGI is impossible:\n\n[L]ike Superman, they are too invulnerable to be able to make a credible\npromise. ... What would be the penalty for promise- breaking? Being\nlocked in a cell or, more plausibly, dismantled?. . . The very ease of\ndigital recording and transmitting—the breakthrough that permits\nsoftware and data to be, in effect, immortal—removes robots from the\nworld of the vulnerable. . . .\n\nBut this is not so. Digital immortality (which is on the horizon for humans, too,\nperhaps sooner than AGI) does not confer this sort of invulnerability. Making a\n(running) copy of oneself entails sharing one’s possessions with it somehow—including\nthe hardware on which the copy runs—so making such a copy is very costly for the AGI.\nSimilarly, courts could, for instance, impose fines on a criminal AGI which would\ndiminish its access to physical resources, much as they do for humans. Making a backup\ncopy to evade the consequences of one’s crimes is similar to what a gangster boss does\nwhen he sends minions to commit crimes and take the fall if caught: Society has\ndeveloped legal mechanisms for coping with this.\n\nBut anyway, the idea that it is primarily for fear of punishment that we obey the\nlaw and keep promises effectively denies that we are moral agents. Our society could not\nwork if that were so. No doubt there will be AGI criminals and enemies of civilization,\njust as there are human ones. But there is no reason to suppose that an AGI created in a\nsociety consisting primarily of decent citizens, and raised without what William Blake\ncalled “mind-forg’d manacles,” will in general impose such manacles on itself (1.e.,\nbecome irrational) and/or choose to be an enemy of civilization.\n\n88\n\nHOUSE_OVERSIGHT_016308",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016308.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3425,
    "word_count": 573,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:48.834097",
    "prefix": "IMAGES-003"
  }
}
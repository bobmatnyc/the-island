{
  "document_id": "HOUSE_OVERSIGHT_013026",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013026.txt",
  "text": "110 6 A Brief Overview of CogPrime\n\nonly scant feedback from human teachers. If successful, this will provide an outstanding platform\nfor ongoing AGI development, as well as a visually appealing and immediately meaningful demo\nfor OpenCog.\n\nSpecific, particularly simple tasks that are the focus of this project team’s current work at\ntime of writing include:\n\ne Watch another character build steps to reach a high-up object\n\ne Figure out via imitation of this that, in a different context, building steps to reach a high\nup object may be a good idea\n\ne Also figure out that, if it wants a certain high-up object but there are no materials for\nbuilding steps available, finding some other way to get elevated will be a good idea that\nmay help it get the object\n\n6.3.1 Transitioning from Virtual Agents to a Physical Robot\n\nPreliminary experiments have also been conducted using OpenCog to control a Nao robot as well\nas a virtual dog [GdGO08]. This involves hybridizing OpenCog with a separate (but interlinked)\nsubsystem handling low-level perception and action. In the experiments done so far, this has\nbeen accomplished in an extremely simplistic way. How to do this right is a topic treated in\ndetail in Chapter 26 of Part 2.\n\nWe suspect that reasonable level of capability will be achievable by simply interposing DeS-\nTIN (or some other system in its place) as a perception /action “black box” between OpenCog\nand a robot. Some preliminary experiments in this direction have already been carried out, con-\nnecting the OpenPetBrain to a Nao robot using simpler, less capable software than DeSTIN in\nthe intermediary role (off-the-shelf speech-to-text, text-to-speech and visual object recognition\nsoftware).\n\nHowever, we also suspect that to achieve robustly intelligent robotics we must go beyond this\napproach, and connect robot perception and actuation software with OpenCogPrime in a “white\nbox” manner that allows intimate dynamic feedback between perceptual, motoric, cognitive\nand linguistic functions. We will achieve this via the creation and real-time utilization of links\nbetween the nodes in CogPrime’s and DeSTIN’s internal networks (a topic to be explored in\nmore depth later in this chapter).\n\n6.4 Memory Types and Associated Cognitive Processes in CogPrime\n\nNow we return to the basic description of the CogPrime approach, turning to aspects of the\nrelationship between structure and dynamics. Architecture diagrams are all very well, but,\nultimately it is dynamics that makes an architecture come alive. Intelligence is all about learning,\nwhich is by definition about change, about dynamical response to the environment and internal\nself-organizing dynamics.\n\nCogPrime relies on multiple memory types and, as discussed above, is founded on the premise\nthat the right course in architecting a pragmatic, roughly human-like AGI system is to handle\ndifferent types of memory differently in terms of both structure and dynamics.\n\nHOUSE_OVERSIGHT_013026",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013026.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2971,
    "word_count": 465,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:44.479180",
    "prefix": "IMAGES-002"
  }
}
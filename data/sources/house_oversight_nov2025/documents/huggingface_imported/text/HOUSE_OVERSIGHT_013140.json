{
  "document_id": "HOUSE_OVERSIGHT_013140",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013140.txt",
  "text": "224 12 The Engineering and Development of Ethics\n\n‘T will not harm humans, nor through inaction allow harm to befall them. In situations\nwherein one or more humans is attempting to harm another individual or group, I shall endeavor\nto prevent this harm through means which avoid further harm. If this is unavoidable, I shall\nselect the human party to back based on a reckoning of their intentions towards others, and\nimplement their defense through the optimal balance between harm minimization and efficacy.\nMy ultimate goal is to preserve as much as possible of humanity, even if an individual or\nsubgroup of humans must come to harm to do so.”\n\nHowever, it’s obvious that even a more elaborated principle like this is potentially subject to\nextensive abuse. Many of the genocides scarring human history have been committed with the\ngoal of preserving and bettering humanity writ large, at the expense of a group of “undesirables.”\nFurther refinement would be necessary in order to define when the greater good of humanity\nmay actually be served through harm to others. A first actor principle of aggression might\nseem to solve this problem, but sometimes first actors in violent conflict are taking preemptive\nmeasures against the stated goals of an enemy to destroy them. Such situations become very\nsubtle. A single simple maxim can not deal with them very effectively. Networks of interrelated\ndecision criteria, weighted by desirability of consequence and with reference to probabilistically\nordered potential side-effects (and their desirability weightings), are required in order to make\nethical judgments. The development of these networks, just like any other knowledge network,\ncomes from both pedagogy and experience — and different thoughtful, ethical agents are bound\nto arrive at different knowledge-networks that will lead to different judgments in real-world\nsituations.\n\nExtending the above “mostly harmless” principle to AGI systems, not just humans, would\ncause it to be more effective in the context of imitative learning. The principle then becomes an\nelaborated version of “I will not harm sentient beings.” As the imitative-learning-enabled AGI\nobserves humans acting so as to minimize harm to it, it will intuitively and experientially learn\nto act in such a way as to minimize harm to humans. But then this extension naturally leads\nto confusion regarding various borderline cases. What is a sentient being exactly? Is a sleeping\nhuman sentient? How about a dead human whose information could in principle be restored via\nobscure quantum operations, leading to some sort of resurrection? How about an AGI whose\ncode has been improved — is there an obligation to maintain the prior version as well, if it is\nsubstantially different that its upgrade constitutes a whole new being?\n\nAnd what about situations in which failure to preserve oneself will cause much more harm to\nothers than acting in self defense will. It may be the case that human or group of humans seeks\nto destroy an AGI in order to pave the way for the enslavement or murder of people under the\nprotection of the AGI. Even if the AGI has been given an ethical formulation of the “mostly\nharmless” principle which allows it to harm the attacking humans in order to defend its charges,\nif it is not able to do so in order to defend itself, simply destroying the AGI first will enable the\nslaughter of those who rely on it. Perhaps a more sensible formulation would allow for some\ndegree of self defense, and Asimov solved this problem with his third law. But where to draw\nthe line between self defense and the greater good also becomes a very complicated issue.\n\nCreating hard and fast rules to cover all the various situations that may arise is essentially\nimpossible — the world is ever-changing and ethical judgments must adapt accordingly. This\nhas been true even throughout human history — so how much truer will it be as technological\nacceleration continues? What is needed is a system that can deploy its ethical principles in an\nadaptive, context-appropriate way, as it grows and changes along with the world it’s embedded\nin.\n\nHOUSE_OVERSIGHT_013140",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013140.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4150,
    "word_count": 680,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:45.112035",
    "prefix": "IMAGES-002"
  }
}
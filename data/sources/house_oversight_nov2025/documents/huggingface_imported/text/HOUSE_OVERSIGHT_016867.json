{
  "document_id": "HOUSE_OVERSIGHT_016867",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016867.txt",
  "text": "processing performed by elementary particles moving around, and there’s no law of\nphysics that says one can’t build machines more intelligent in every way than we are, and\nable to seed cosmic life. This suggests that we’ve seen just the tip of the intelligence\niceberg; there’s an amazing potential to unlock the full intelligence latent in nature and\nuse it to help humanity flourish—or flounder.\n\nOthers, including some of the authors in this volume, dismiss the building of an\nAGI (Artificial General Intelligence—an entity able to accomplish any cognitive task at\nleast as well as humans) not because they consider it physically impossible but because\nthey deem it too difficult for humans to pull off in less than a century. Among\nprofessional AI researchers, both types of dismissal have become minority views because\nof recent breakthroughs. There is a strong expectation that AGI will be achieved within a\ncentury, and the median forecast is only decades away. A recent survey of AI researchers\nby Vincent Muller and Nick Bostrom concludes:\n\n[T]he results reveal a view among experts that AI systems will probably (over\n50%) reach overall human ability by 2040-50, and very likely (with 90%\nprobability) by 2075. From reaching human ability, it will move on to\nsuperintelligence in 2 years (10%) to 30 years (75%) thereafter. '°\n\nIn the cosmic perspective of gigayears, it makes little difference whether AGI\narrives in thirty or three hundred years, so let’s focus on the implications rather than the\ntiming.\n\nFirst, we humans discovered how to replicate some natural processes with\nmachines, making our own heat, light, and mechanical horsepower. Gradually we\nrealized that our bodies were also machines, and the discovery of nerve cells blurred the\nboundary between body and mind. Finally, we started building machines that could\noutperform not only our muscles but our minds as well. We’ve now been eclipsed by\nmachines in the performance of many narrow cognitive tasks, ranging from memorization\nand arithmetic to game play, and we are in the process of being overtaken in many more,\nfrom driving to investing to medical diagnosing. If the AI community succeeds in its\noriginal goal of building AGI, then we will have, by definition, been eclipsed at all\ncognitive tasks.\n\nThis begs many obvious questions. For example, will whoever or whatever\ncontrols the AGI control Earth? Should we aim to control superintelligent machines? If\nnot, can we ensure that they understand, adopt, and retain human values? As Norbert\nWiener put it in Zhe Human Use of Human Beings:\n\nWoe to us if we let [the machine] decide our conduct, unless we have previously\nexamined the laws of its action, and know fully that its conduct will be carried\nout on principles acceptable to us! On the other hand, the machine . .. , which\ncan learn and can make decisions on the basis of its learning, will in no way be\nobliged to make such decisions as we should have made, or will be acceptable to\nus.\n\n16 Vincent C. Miller & Nick Bostrom, “Future Progress in Artificial Intelligence: A Survey of Expert\nOpinion,” in Fundamental Issues of Artificial Intelligence, Vincent C. Muller, ed. (Springer International\nPublishing Switzerland, 2016), pp. 555-72. https://nickbostrom.com/papers/survey .pdf.\n\n64\n\nHOUSE_OVERSIGHT_016867",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016867.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3307,
    "word_count": 536,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:48.776677",
    "prefix": "IMAGES-004"
  }
}
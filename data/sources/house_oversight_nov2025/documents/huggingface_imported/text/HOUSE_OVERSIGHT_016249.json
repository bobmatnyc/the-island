{
  "document_id": "HOUSE_OVERSIGHT_016249",
  "filename": "IMAGES-003-HOUSE_OVERSIGHT_016249.txt",
  "text": "THE PURPOSE PUT INTO THE MACHINE\nStuart Russell\n\nStuart Russell is a professor of computer science and Smith-Zadeh Professor in\nEngineering at UC Berkeley. He is the coauthor (with Peter Norvig) of Artificial\nIntelligence: A Modern Approach.\n\nAmong the many issues raised in Norbert Wiener’s The Human Use of Human Beings\n(1950) that are currently relevant, the most significant to the AI researcher is the\npossibility that humanity may cede control over its destiny to machines.\n\nWiener considered the machines of the near future as far too limited to exert global\ncontrol, imagining instead that machines and machine-like control systems would be\nwielded by human elites to reduce the great mass of humanity to the status of “cogs and\nlevers and rods.” Looking further ahead, he pointed to the difficulty of correctly\nspecifying objectives for highly capable machines, noting\n\na few of the simpler and more obvious truths of life, such as that when a djinnee is\nfound in a bottle, it had better be left there; that the fisherman who craves a boon\nfrom heaven too many times on behalf of his wife will end up exactly where he\nstarted; that if you are given three wishes, you must be very careful what you wish\nfor.\n\nThe dangers are clear enough:\n\nWoe to us if we let [the machine] decide our conduct, unless we have previously\nexamined the laws of its action, and know fully that its conduct will be carried out on\nprinciples acceptable to us! On the other hand, the machine like the djinnee, which\ncan learn and can make decisions on the basis of its learning, will in no way be\nobliged to make such decisions as we should have made, or will be acceptable to us.\n\nTen years later, after seeing Arthur Samuel’s checker-playing program learn to play\ncheckers far better than its creator, Wiener published “Some Moral and Technical\nConsequences of Automation” in Science. In this paper, the message is even clearer:\n\nIf we use, to achieve our purposes, a mechanical agency with whose operation we\ncannot efficiently interfere ... we had better be quite sure that the purpose put into\nthe machine is the purpose which we really desire. . . .\n\nIn my view, this is the source of the existential risk from superintelligent AI cited in\nrecent years by such observers as Elon Musk, Bill Gates, Stephen Hawking, and Nick\nBostrom.\n\nPutting Purposes Into Machines\n\nThe goal of AI research has been to understand the principles underlying intelligent\nbehavior and to build those principles into machines that can then exhibit such behavior.\nIn the 1960s and 1970s, the prevailing theoretical notion of intelligence was the capacity\nfor logical reasoning, including the ability to derive plans of action guaranteed to achieve\na specified goal. More recently, a consensus has emerged around the idea of a rational\n\n29\n\nHOUSE_OVERSIGHT_016249",
  "metadata": {
    "original_filename": "IMAGES-003-HOUSE_OVERSIGHT_016249.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 2828,
    "word_count": 476,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:44.620621",
    "prefix": "IMAGES-003"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016997",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016997.txt",
  "text": "(“3.14159”) and typos (“excesss”). An n-gram is sequence of\n1-grams, such as the phrases “stock market” (a 2-gram) and\n“the United States of America” (a 5-gram). We restricted n to\n5, and limited our study to n-grams occurring at least 40 times\nin the corpus.\n\nUsage frequency is computed by dividing the number of\ninstances of the n-gram in a given year by the total number of\nwords in the corpus in that year. For instance, in 1861, the 1-\ngram “slavery” appeared in the corpus 21,460 times, on\n11,687 pages of 1,208 books. The corpus contains\n386,434,758 words from 1861; thus the frequency is 5.5x10°.\n“slavery” peaked during the civil war (early 1860s) and then\nagain during the civil rights movement (1955-1968) (Fig. 1B)\n\nIn contrast, we compare the frequency of “the Great War”\nto the frequencies of “World War I” and “World War II.” “the\nGreat War” peaks between 1915 and 1941. But although its\nfrequency drops thereafter, interest in the underlying events\nhad not disappeared; instead, they are referred to as “World\nWar I” (Fig. 1C).\n\nThese examples highlight two central factors that\ncontribute to culturomic trends. Cultural change guides the\nconcepts we discuss (such as “slavery”). Linguistic change —\nwhich, of course, has cultural roots — affects the words we use\nfor those concepts (“the Great War” vs. “World War I’). In\nthis paper, we will examine both linguistic changes, such as\nchanges in the lexicon and grammar; and cultural phenomena,\nsuch as how we remember people and events.\n\nThe full dataset, which comprises over two billion\nculturomic trajectories, is available for download or\nexploration at www.culturomics.org.\n\nThe Size of the English Lexicon\nHow many words are in the English language (9)?\n\nWe call a 1-gram “common” if its frequency is greater\nthan one per billion. (This corresponds to the frequency of the\nwords listed in leading dictionaries (7).) We compiled a list of\nall common 1-grams m 1900, 1950, and 2000 based on the\nfrequency of each 1-gram in the preceding decade. These lists\ncontained 1,117,997 common 1-grams in 1900, 1,102,920 in\n1950, and 1,489,337 in 2000.\n\nNot all common 1-grams are English words. Many fell\ninto three non-word categories: (i) 1-grams with non-\nalphabetic characters (“‘18r’, “3.14159”; (i) misspellings\n(“becuase, “abberation”); and (411) foreign words\n(“sensitivo”).\n\nTo estimate the number of English words, we manually\nannotated random samples from the lists of common 1-grams\n(7) and determined what fraction were members of the above\nnon-word categories. The result ranged from 51% of all\ncommon 1|-grams in 1900 to 31% in 2000.\n\nUsing this technique, we estimated the number of words in\nthe English lexicon as 544,000 in 1900, 597,000 in 1950, and\n1,022,000 in 2000. The lexicon is enjoying a period of\n\nenormous growth: the addition of ~8500 words/year has\nincreased the size of the language by over 70% during the last\nfifty years (Fig. 2A).\n\nNotably, we found more words than appear in any\ndictionary. For instance, the 2002 Webster’s Third New\nInternational Dictionary [W3], which keeps track of the\ncontemporary American lexicon, lists approximately 348,000\nsingle-word wordforms (/0); the American Heritage\nDictionary of the English Language, Fourth Edition (AHD4)\nlists 116,161 (7/7). (Both contain additional multi-word\nentries.) Part of this gap is because dictionaries often exclude\nproper nouns and compound words (“whalewatching”). Even\naccounting for these factors, we found many undocumented\nwords, such as “aridification” (the process by which a\ngeographic region becomes dry), “slenthem” (a musical\ninstrument), and, appropriately, the word “deletable.”\n\nThis gap between dictionaries and the lexicon results from\na balance that every dictionary must strike: it must be\ncomprehensive enough to be a useful reference, but concise\nenough to be printed, shipped, and used. As such, many\ninfrequent words are omitted. To gauge how well dictionaries\nreflect the lexicon, we ordered our year 2000 lexicon by\nfrequency, divided it into eight deciles (ranging from 10° —\n10° to 10° — 10°), and sampled each decile (7). We manually\nchecked how many sample words were listed in the OED (12)\nand in the Merriam-Webster Unabridged Dictionary [MWD].\n(We excluded proper nouns, since neither OED nor MWD\nlists them.) Both dictionaries had excellent coverage of high\nfrequency words, but less coverage for frequencies below 10°\n°: 67% of words in the 10° — 10° range were listed in neither\ndictionary (Fig. 2B). Consistent with Zipf’s famous law, a\nlarge fraction of the words in our lexicon (63%) were in this\nlowest frequency bin. As a result, we estimated that 52% of\nthe English lexicon — the majority of the words used in\nEnglish books — consists of lexical “dark matter”\nundocumented in standard references (/2).\n\nTo keep up with the lexicon, dictionaries are updated\nregularly (/3). We examined how well these changes\ncorresponded with changes in actual usage by studying the\n2077 1-gram headwords added to AHD4 in 2000. The overall\nfrequency of these words, such as “buckyball” and\n“netiquette”, has soared since 1950: two-thirds exhibited\nrecent, sharp increases in frequency (>2X from 1950-2000)\n(Fig. 2C). Nevertheless, there was a lag between\nlexicographers and the lexicon. Over half the words added to\nAHD4 were part of the English lexicon a century ago\n(frequency >10° from 1890-1900). In fact, some newly-\nadded words, such as “gypseous” and “amplidyne”, have\nalready undergone a steep decline in frequency (Fig. 2D).\n\nNot only must lexicographers avoid adding words that\nhave fallen out of fashion, they must also weed obsolete\nwords from earlier editions. This is an imperfect process. We\n\nSciencexpress / www.sciencexpress.org / 16 December 2010 / Page 2 / 10.1126/science.1199644\n\nHOUSE_OVERSIGHT_016997\n\nDownloaded from www.sciencemag.org on December 16, 2010",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016997.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 5864,
    "word_count": 935,
    "line_count": 124,
    "import_date": "2025-11-19T21:47:45.581039",
    "prefix": "IMAGES-004"
  }
}
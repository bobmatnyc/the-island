{
  "document_id": "HOUSE_OVERSIGHT_013114",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013114.txt",
  "text": "198 11 Stages of Cognitive Development\n\ntomized logical rule-bases to find specialized solutions that solve only this problem fail to fully\naddress the issue, because these solutions don’t create knowledge adequate to aid with the\nsolution of related sorts of problems.\n\nWe hypothesize that this problem is hard enough that for an inference-based AGI system\nto solve it in a developmentally useful way, its inferences must be guided by meta-inferential\nlessons learned from prior similar problems. When approaching a number conservation problem,\nfor example, a reasoning system might draw upon past experience with set-size problems (which\nmay be trial-and-error experience). This is not a simple “machine learning” approach whose\nscope is restricted to the current problem, but rather a heuristically guided approach which (a)\nageregates information from prior experience to guide solution formulation for the problem at\nhand, and (b) adds the present experience to the set of relevant information about quantification\nproblems for future refinement of thinking.\n\na ee ee ee ee eee eee\nce ee ee ee\n\nFig. 11.6: Conservation of Number\n\nFor instance, a very simple context-specific heuristic that a system might learn would be:\n“When evaluating the truth value of a statement related to the number of objects in a set,\nit is generally not that useful to explore branches of the backwards-chaining search tree that\ncontain relationships regarding the sizes, masses, or other physical properties of the objects in\nthe set.” This heuristic itself may go a long way toward guiding an inference process toward a\ncorrect solution to the problem—but it is not something that a mind needs to know “a priori.”\nA concrete-operational stage mind may learn this by data-mining prior instances of inferences\ninvolving sizes of sets. Without such experience-based heuristics, the search tree for such a\nproblem will likely be unacceptably large. Even if it is “solvable” without such heuristics, the\nsolutions found may be overly fit to the particular problem and not usefully generalizable.\n\n11.4.2.2 Theory of Mind\n\nConsider this experiment: a preoperational child is shown her favorite “Dora the Explorer” DVD\nbox. Asked what show she’s about to see, she’ll answer “Dora.” However, when her parent plays\nthe disc, it’s “SpongeBob SquarePants.” If you then ask her what show her friend will expect\nwhen given the “Dora” DVD box, she will respond “SpongeBob” although she just answered\n“Dora” for herself. A child lacking a theory of mind can not reason through what someone\nelse would think given knowledge other than her own current knowledge. Knowledge of self is\nintrinsically related to the ability to differentiate oneself from others, and this ability may not\nbe fully developed at birth.\n\nSeveral theorists [BC94, Fod94], based in part on experimental work with autistic children,\nperceive theory of mind as embodied in an innate module of the mind activated at a certain\ndevelopmental stage (or not, if damaged). While we consider this possible, we caution against\nadopting a simplistic view of the “innate vs. acquired” dichotomy: if there is innateness it may\ntake the form of an innate predisposition to certain sorts of learning [EBJ*97].\n\nHOUSE_OVERSIGHT_013114",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013114.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3260,
    "word_count": 513,
    "line_count": 50,
    "import_date": "2025-11-19T21:47:47.286652",
    "prefix": "IMAGES-002"
  }
}
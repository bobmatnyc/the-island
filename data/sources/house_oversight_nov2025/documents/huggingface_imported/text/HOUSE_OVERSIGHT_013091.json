{
  "document_id": "HOUSE_OVERSIGHT_013091",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013091.txt",
  "text": "9.6 Body and Mind 175\n\n9.6.2.2 Implications for AGI\n\nWhat lesson should the AGI developer draw from all this? The particularities of the human\nmind/body should not be taken as general requirements for general intelligence. However, it\nis worth remembering just how difficult is the computational problem of learning, based on\nexperiential feedback alone, the right way to achieve the complex goal of controlling a system\nwith general intelligence at the human level or beyond. To solve this problem without some sort\nof strong inductive biasing may require massively more experience than young humans obtain.\n\nAppropriate inductive bias may be embedded in an AGI system in many different ways.\nSome AGI designers have sought to embed it very explicitly, e.g. with hand-coded declarative\nknowledge as in Cyc, SOAR and other \"GOFAI\" type systems. On the other hand, the human\nbrain receives its inductive bias much more subtly and implicitly, both via the specifics of the\ninitial structure of the cognitive cortex, and via ongoing coupling of the cognitive cortex with\nother systems possessing more focused types of intelligence and more specific structures and/or\ndynamics.\n\nIn building an AGI system, one has four choices, very broadly speaking:\n\n1. Create a flexible mind-network, as unbiased as feasible, and attempt to have it learn how\nto achieve its goals via experience\n\n2. Closely emulate key aspects of the human body along with the human mind\n\n3. Imitate the human mind-body, conceptually if not in detail, and create a number of struc-\nturally and dynamically simpler intelligent systems closely and appropriately coupled to\nthe abstract cognitive mind-network, provide useful inductive bias.\n\n4, Find some other, creative way to guide and probabilistically constrain one’s AGI system’s\nmind-network, providing inductive bias appropriate to the tasks at hand, without emulating\neven conceptually the way the human mind-brain receives its inductive bias via coupling\nwith simpler intelligent systems.\n\nOur suspicion is that the first option will not be viable. On the other hand, to do the second\noption would require more knowledge of the human body than biology currently possesses. This\nleaves the third and fourth options, both of which seem viable to us.\n\nCogPrime incorporates a combination of the third and fourth options. CogPrime’s generic\ndynamic knowledge store, the Atomspace, is coupled with specialized hierarchical networks\n(DeSTIN) for vision and audition, somewhat mirroring the human cortex. An artificial en-\ndocrine system for OpenCog is also under development, speculatively, as part of a project using\nOpenCog to control humanoid robots. On the other hand, OpenCog has no gastrointestinal nor\ncardiological nervous system, and the stress-response-based guidance provided to the human\nbrain by a combination of the heart, gut, immune system and other body systems, is achieved\nin CogPrime in a more explicit way using the OpenPsi model of motivated cognition, and its\nintegration with the system’s attention allocation dynamics.\n\nLikely there is no single correct way to incorporate the lessons of intelligent human body-\nsystem networks into AGI designs. But these are aspects of human cognition that all AGI\nresearchers should be aware of.\n\nHOUSE_OVERSIGHT_013091",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013091.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3296,
    "word_count": 507,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:45.477841",
    "prefix": "IMAGES-002"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_016989",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016989.txt",
  "text": "That could be done for twenty-six different possibilities, but it couldn’t be done for ten\nthousand. It was just a matter of scaling up the whole system that makes this possible\ntoday. There are maybe five thousand picturable common nouns in English, ten thousand\nif you include things like special kinds of plants and beetles which people would\nrecognize with some frequency. What we did was train our system on 30 million images\nof these kinds of things. It’s a big, complicated, messy neural network. The details of\nthe network probably don’t matter, but it takes about a quadrillion GPU operations to do\nthe training.\n\nOur system is impressive because it pretty much matches what humans can do. It\nhas about the same training data humans have—about the same number of images a\nhuman infant would see in the first couple of years of its life. Roughly the same number\nof operations have to be done in the learning process, using about the same number of\nneurons in at least the first levels of our visual cortex. The details are different; the way\nthese artificial neurons work has little to do with how the brain’s neurons work. But the\nconcept is similar, and there’s a certain universality to what’s going on. At the\nmathematical level, it’s a composition of a very large number of functions, with certain\ncontinuity properties that let you use calculus methods to incrementally train the system.\nGiven those attributes, you can end up with something that does the same job human\nbrains do in physiological recognition.\n\nBut does this constitute AI? There are a few basic components. There’s\nphysiological recognition, there’s voice-to-text, there’s language translation—things\nhumans manage to do with varying degrees of difficulty. These are essentially some of\nthe links to how we make machines that are humanlike in what they do. For me, one of\nthe interesting things has been incorporating those capabilities into a precise symbolic\nlanguage to represent the everyday world. We now have a system that can say, “This is a\nglass of water.” We can go from a picture of a glass of water to the concept of a glass of\nwater. Now we have to invent some actual symbolic language to represent those\nconcepts.\n\nI began by trying to represent mathematical, technical kinds of knowledge and\nwent on to other kinds of knowledge. We’ve done a pretty good job of representing\nobjective knowledge in the world. Now the problem is to represent everyday human\ndiscourse in a precise symbolic way—a knowledge-based language intended for\ncommunication between humans and machines, so that humans can read it and machines\ncan understand it, too. For instance, you might say “X is greater than 5.” That’s a\npredicate. You might also say, “I want a piece of chocolate.” That’s also a predicate. It\nhas an “I want” init. We have to find a precise symbolic representation of the desires we\nexpress in human natural language.\n\nIn the late 1600s, Gottfried Leibniz, John Wilkins, and others were concerned\nwith what they called philosophical languages—that is, complete, universal, symbolic\nrepresentations of things in the world. You can look at the philosophical language of\nJohn Wilkins and see how he divided up what was important in the world at the time.\nSome aspects of the human condition have been the same since the 1600s. Some are very\ndifferent. His section on death and various forms of human suffering was huge; in\ntoday’s ontology, it’s alot smaller. It’s interesting to see how a philosophical language\nof today would differ from a philosophical language of the mid-1600s. It’s a measure of\nour progress. Many such attempts at formalization have happened over the years. In\n\n186\n\nHOUSE_OVERSIGHT_016989",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016989.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3701,
    "word_count": 618,
    "line_count": 54,
    "import_date": "2025-11-19T21:47:46.586511",
    "prefix": "IMAGES-004"
  }
}
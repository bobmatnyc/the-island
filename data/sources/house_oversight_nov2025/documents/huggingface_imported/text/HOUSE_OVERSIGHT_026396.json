{
  "document_id": "HOUSE_OVERSIGHT_026396",
  "filename": "IMAGES-008-HOUSE_OVERSIGHT_026396.txt",
  "text": "I found Noam's hypothesis very compelling in the past. I still think that the idea that language is somehow a\ncultural or social invention of our species is wrong. But I think that there is a chance (we don't know that, but\nit seems to most promising hypothesis IMHO) that the difference between humans and apes is not a very\nintricate special circuit, but genetically simple developmental switches. The bootstrapping of cognition works\nlayer by layer during the first 20 years of our life. Each layer takes between a few months and a few years to\ntrain in humans. While a layer is learned, there is not much going on in the higher layers yet, and after the low\nlevel learning is finished, it does not change very much. This leads to the characteristic bursts in child\ndevelopment, that have famously been described by Piaget.\n\nThe first few layers are simple perceptual stuff, the last ones learn social structure and self-in-society. The\nswitching works with something like a genetic clock, very slowly in humans, but much more quickly in other\napes, and very fast in small mammals. As a result, human children take nine months before their brains are\nmature enough to crawl, and more than a year before they can walk. Many African populations are quite a bit\nfaster. In the US, black children outperform white children in motor development, even in very poor and\nsocially disadvantaged households, but they lag behind (and never catch up) in cognitive development even\nafter controlling for family income.\n\nGorillas can crawl after 2 months, and build their own nests after 2.5 years. They leave their mothers at 3-4\nyears. Human children are pretty much useless during the first 10-12 years, but during each phase, their brains\nhave the opportunity to encounter many times as much training data as a gorilla brain. Humans are literally\nsmarter on every level, and because the abilities of the higher levels depend on those of the lower levels, they\ncan perform abstractions that mature gorillas will never learn, no matter how much we try to train them.\n\nThe second set of mechanisms is in the motivational system. Motivation tells the brain what to pay attention\nto, by giving reward and punishment. If a brain does not get much reward for solving puzzles, the individual\nwill find mathematics very boring and won't learn much of it. Ifa brain gets lots of rewards for discovering\nother people's intentions, it will learn a lot of social cognition.\n\nLanguage might be the result of three things that are different in humans:\n\n- extended training periods per layer (after the respective layer is done, it is difficult to learn a new set of\nphonemes or the first language)\n\n- more layers\n\n- different internal rewards. Perhaps the reward for learning grammatical structure is the same that makes us\nlike music. Our brains may enjoy learning compositional regular structure, and they enjoy making themselves\nunderstood, and everything else is something the universal cortical learning figures out on its own.\n\nThis is a hypothesis that is shared by a growing number of people these days. In humans, it is reflected for\ninstance by the fact that races with faster motor development have lower IQ. (In individuals of the same\ngroup, slower development often indicates defects, of course.)\n\nAnother support comes from machine learning: we find that the same learning functions can learn visual and\nauditory pattern recognition, and even end-to-end-learning. Google has built automatic image recognition into\ntheir current photo app:\nhttp://blogs.wsj.com/digits/2015/07/01/google-mistakenly-tags-black-people-as-gorillas-showing-limits-of-\n\nalgorithms/\n\nThe state of the art in research can do better than that: it can begin to \"Imagine\" things. I.e. when the\nexperimenter asks the system to \"dream\" what a certain object looks like, the system can produce a somewhat\ncompelling image, which indicates that it is indeed learning visual structure. This stuff is something nobody\ncould do a few months ago:\nhttp://www.creativeai.net/posts/Mv4WG6rdzAerZF7ch/synthesizing-preferred-inputs-via-deep-generator-\n\nHOUSE_OVERSIGHT_026396",
  "metadata": {
    "original_filename": "IMAGES-008-HOUSE_OVERSIGHT_026396.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 4126,
    "word_count": 652,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:48.378013",
    "prefix": "IMAGES-008"
  }
}
{
  "document_id": "HOUSE_OVERSIGHT_013142",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013142.txt",
  "text": "226 12 The Engineering and Development of Ethics\n\nThe implications of these ideas for ethical instruction are complex and won’t be fully elabo-\nrated here, but a few of them are compact and obvious:\n\n1. The teacher(s) must be observed to follow their own ethical principles, in a variety of\ncontexts that are meaningful to the AGI\n\n2. The system of ethics must be relevant to the recipient’s life context, and embedded within\ntheir understanding of the world.\n\n3. Ethical principles must be grounded in both theory-of mind thought experiments (empha-\nsizing logical coherence), and in real life situations in which the ethical trainee is required\nto make a moral judgment and is rewarded or reproached by the teacher(s), including the\nimparting of explanatory augmentations to the teachings regarding the reason for the par-\nticular decision on the part of the teacher.\n\nFinally, harking forward to the next section which emphasizes the importance of respecting\nthe freedom of AGIs, we note that it is implicit in our approach to AGI ethics instruction\nthat we consider the student, the AGI system, as an autonomous agent with its own “will”\nand its own capability to flexibly adapt to its environment and experience. We contend that\nthe creation of ethical formations obeying the above imperatives is not antithetical to the\npossession of a high degree of autonomy on the part of AGI systems. On the contrary, to have\nany chance of succeeding, it requires fairly cognitively autonomous AGI systems. When we\ndiscuss the idea of ethical formulations that are unlikely to be undermined by the ongoing\nself-revision of an AGI mind, we are talking about those which are sufficiently believable that\na volitional intelligence with the capacity to revise its knowledge (“change its mind”) will find\nthe formulations sufficiently convincing that there will be little incentive to experiment with\npotentially disastrous ethical alternatives. The best hope of achieving this is via the human\nmentors and trainers setting a good example in a context supporting rich interaction and\nobservation, and presenting compelling ethical arguments that are coherent with the system’s\nexperience.\n\n12.6 The Ethical Treatment of AGIs\n\nWe now make some more general comments about the relation of the Golden Rule and its\nelaborations in an AGI context. While the Golden Rule is considered somewhat commonsensical\nas a maxim for guiding human-human relationships, it is surprisingly controversial in terms of\nhistorical theories of AGI ethics. At its essence, any “Golden Rule” approach to AGI ethics\ninvolves humans treating AGIs ethically by — in some sense; at some level of abstraction —\ntreating them as we wish to ourselves be treated. It’s worth pointing out the wild disparity\nbetween the Golden Rule approach and Asimov’s laws of robotics, which are arguably the first\ncarefully-articulated proposal regarding AGI ethics (see Table 12.7).\n\nOf course, Asimov’s laws were designed to be flawed — otherwise they would have led to\nboring fiction. But the sorts of flaws Asimov exploited in his stories are different than the\nflaw we wish to point out here — which is that the laws, especially the second one, are highly\nasymmetrical (they involve doing unto robots things that few humans would want done unto\nthem) and are also arguably highly unethical to robots. The second law is tantamount to a call\nfor robot slavery, and it seems unlikely that any intelligence capable of learning, and of volition,\nwhich is subjected to the second law would desire to continue obeying the zeroth and first laws\n\nHOUSE_OVERSIGHT_013142",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013142.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3606,
    "word_count": 582,
    "line_count": 53,
    "import_date": "2025-11-19T21:47:44.651790",
    "prefix": "IMAGES-002"
  }
}
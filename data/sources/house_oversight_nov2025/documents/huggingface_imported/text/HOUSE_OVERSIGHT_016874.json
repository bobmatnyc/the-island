{
  "document_id": "HOUSE_OVERSIGHT_016874",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_016874.txt",
  "text": "mainstream groups, who had more to lose, initially qualified and diluted the message,\ntaking positions like, “It would make sense in the long term to delegate control over local\nmatters.” (There were always exceptions: Some public intellectuals proclaimed the\noriginal dissident message verbatim.) Finally, the original message—being, simply,\ntrue—won out over its diluted versions. Estonia regained its independence in 1991, and\nthe last Soviet troops left three years later.\n\nThe people who took the risk and spoke the truth in Estonia and elsewhere in the\nEastern Bloc played a monumental role in the eventual outcome—an outcome that\nchanged the lives of hundreds of millions of people, myself included. They spoke the\ntruth, even as their voices trembled.\n\nThe Second Message: AI Risk\n\nMy exposure to the second revolutionary message was via Yudkowsky’s blog—the blog\nthat compelled me to reach out and arrange that meeting in California. The message was:\nContinued progress in AI can precipitate a change of cosmic proportions—a runaway\nprocess that will likely kill everyone. We need to put in a lot of extra effort to avoid that\noutcome.\n\nAfter my meeting with Yudkowsky, the first thing I did was try to interest my\nSkype colleagues and close collaborators in his warning. I failed. The message was too\ncrazy, too dissident. Its time had not yet come.\n\nOnly later did I learn that Yudkowsky wasn’t the original dissident speaking this\nparticular truth. In April 2000, there was a lengthy opinion piece in Wired titled, “Why\nthe Future Doesn’t Need Us,” by Bill Joy, co-founder and chief scientist of Sun\nMicrosystems. He warned:\n\nAccustomed to living with almost routine scientific breakthroughs, we have yet\nto come to terms with the fact that the most compelling 21st-century\ntechnologies—robotics, genetic engineering, and nanotechnology—pose a\ndifferent threat than the technologies that have come before. Specifically, robots,\nengineered organisms, and nanobots share a dangerous amplifying factor: They\ncan self-replicate. .. . [O|ne bot can become many, and quickly get out of\ncontrol.\n\nApparently, Joy’s broadside caused a lot of furor but little action.\n\nMore surprising to me, though, was that the AI-risk message arose almost\nsimultaneously with the field of computer science. In a 1951 lecture, Alan Turing\nannounced: “[I]t seems probable that once the machine thinking method had started, it\nwould not take long to outstrip our feeble powers. .. . At some stage, therefore, we\nshould have to expect the machines to take control... .”?! A decade or so later, his\nBletchley Park colleague I. J. Good wrote, “The first ultraintelligent machine is the /ast\ninvention that man need ever make, provided that the machine is docile enough to tell us\nhow to keep it under control.””? Indeed, I counted half a dozen places in The Human Use\nof Human Beings where Wiener hinted at one or another aspect of the Control Problem.\n(“The machine like the djinnee, which can learn and can make decisions on the basis of\n\n*1 Posthumously reprinted in Phil. Math. (3) vol. 4, 256-60 (1966).\n*2 Irving John Good, “Speculations concerning the first ultraintelligent machine,” Advances in Computers,\nvol. 6 (Academic Press, 1965), pp. 31-88.\n\n71\n\nHOUSE_OVERSIGHT_016874",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_016874.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3267,
    "word_count": 521,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:48.218659",
    "prefix": "IMAGES-004"
  }
}
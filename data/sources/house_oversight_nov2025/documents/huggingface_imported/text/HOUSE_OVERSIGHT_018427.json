{
  "document_id": "HOUSE_OVERSIGHT_018427",
  "filename": "IMAGES-004-HOUSE_OVERSIGHT_018427.txt",
  "text": "ways we don’t understand and certainly can’t follow in real time, we face a problem:\nWe don’t know what to tell the machine not to do. So many of the things we’d hope\nto teach it - be compassionate, fight for liberty, follow a moral code - far transcend\nwhat might be achieved by us in math. We haven’t after all, even solved the problem\nof how program ourselves reliably with these values.\n\nIf Bostrom’s paper clip machine seems fantastic, it is easy enough to conjure other\nand more real dangers lingering at the edge of disappeared human control. Think of\nhealth care. To begin, you need to know about an important “game” from the world\nof research into how humans interact with each other known as the “The Ultimatum\nProblem.” It runs like this: I tell you that you can have a million dollars, but you have\nto split it with someone else. How you split it is up to you, but if your partner rejects\nthe formula you propose, neither of you gets a cent. Offer to split the pot with a\ndollar to your pal and the rest to you. Insulting. But where to settle? You might\nexpect that the smartest offer would be a 50/50 split, but humans are greedy. You\nwant more and can probably get it; your partner does not want to end up with zero.\nGenerally when scientists shake this cocktail of greed and fear they find an offer of\n$300,000 is nearly always accepted. However, there’s a surprising way to change\nthe outcome: Match the human against a computer in the negotiation. A pal\nsuggesting an 80/20 split to a friend will be rejected. Too greedy. But a computer?\nSomehow the impersonality, the beeping digital charmlessness of the machine lures\nbiological players to compromise. An offer of $200,000 is usually happily accepted.\n\nIt may be, scientists think, that our competitive instinct is muted when we interact\nwith a machine. But researchers have also discovered they can manipulate the split\nother ways: Sad movies, war chants, hard rock - each bends the emotions of players\nand changes the result. Increased testosterone produces less compromise. Players\nprimed with family pictures or made to play the game facing a mirror show a warm\nhumanity and a more even split. So imagine this research married to machine-\nhuman interaction: A computer has been assigned to review the medical options for\nyour failing liver. It decides that it makes no sense to give you a new one. So it\nspends the weeks before it delivers this news using its Al to show you certain\nphotos, to play you music it knows is likely to soften you up a bit, generally to\nmanipulate you. It runs off-the-shelf language-analysis neural webs being used\ntoday to eavesdrop on customer support calls to track the way you speak to\ndetermine what each sentence might reveal about your sophistication.2®” Then it\ntells you something you'd never accept so easily from a doctor: No liver. Sorry. @.\nHere’s a machine optimizing not for paperclips - which we could care less about -\nbut for a public good most of us support: More efficient health care. And murdering\nyou in the process.\n\nOptimize Health Care Spending. Just where might such an algorithmic command lead,\nexactly. Over time, a health-care optimizing AI will surely discover that the greatest\nrisk to human health is humans: Smoking, couch-sitting, driving. Might it begin to\n\n267 It runs: Language Use, Customer Personality, and the Customer Journey (Scott\nNowson, Global Innovation Lead, Xerox)\n\n195\n\nHOUSE_OVERSIGHT_018427",
  "metadata": {
    "original_filename": "IMAGES-004-HOUSE_OVERSIGHT_018427.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3444,
    "word_count": 595,
    "line_count": 51,
    "import_date": "2025-11-19T21:47:47.741325",
    "prefix": "IMAGES-004"
  }
}
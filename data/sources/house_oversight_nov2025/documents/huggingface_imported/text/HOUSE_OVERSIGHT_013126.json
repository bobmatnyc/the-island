{
  "document_id": "HOUSE_OVERSIGHT_013126",
  "filename": "IMAGES-002-HOUSE_OVERSIGHT_013126.txt",
  "text": "210 12 The Engineering and Development of Ethics\n\nWe realize this point may be somewhat contentious — a counter-argument would be that\nthe human brain is known to support at least moderately ethical behavior, according to human\nethical standards, whereas less brain-like AGI systems are much less well understood. However,\nthe obvious counter-counterpoints are that:\n\ne Humans are not all that consistently ethical, so that creating AGI systems potentially much\nmore practically powerful than humans, but with closely humanlike ethical, motivational\nand goal systems, could in fact be quite dangerous\n\ne The effect on a human-like ethical/motivational/goal system of increasing the intelligence,\nor changing the physical embodiment or cognitive capabilities, of the agent containing the\nsystem, is unknown and difficult to predict given all the complexities involved\n\nThe course we tentatively recommend, and are following in our own work, is to develop AGI\nsystems with explicit, hierarchically-dominated goal systems. That is:\n\ne create one or more \"top goals\" (we call them Ubergoals in CogPrime )\n\ne have the system derive subgoals from these, using its own intelligence, potentially guided\nby educational interaction or explicit programming\n\ne have a significant percentage of the system’s activity governed by the explicit pursuit of\nthese goals\n\nNote that the \"significant percentage\" need not be 100%; CogPrime, for example, combines\nexplicitly goal-directed activity with other \"spontaneous\" activity. Requiring that all activity\nbe explicitly goal-directed may be too strict a requirement to place on AGI architectures.\n\nThe next step, of course, is for the top-level goals to be chosen in accordance with the\nprinciple of human-Friendliness. The next one of our eight points, about the Global Brain,\naddresses one way of doing this. In our near-term work with CogPrime, we are using simplistic\napproaches, with a view toward early-stage system testing.\n\n12.4 Ethical Synergy\n\nAn explicit goal system provides an explicit way to ensure that ethical principles (as represented\nin system goals) play a significant role in guiding an AGI system’s behavior. However, in an\nintegrative design like CogPrime the goal system is only a small part of the overall story,\nand it’s important to also understand how ethics relates to the other aspects of the cognitive\narchitecture.\n\nOne of the more novel ideas presented in this chapter is that different types of ethical intuition\nmay be associated with different types of memory — and to possess mature ethics, a mind\nmust display ethical synergy between the ethical processes associated with its memory types.\nSpecifically, we suggest that:\n\ne Episodic memory corresponds to the process of ethically assessing a situation based on\nsimilar prior situations\n\ne Sensorimotor memory corresponds to “mirror neuron” type ethics, where you feel another\nperson’s feelings via mirroring their physiological emotional responses and actions\n\ne Declarative memory corresponds to rational ethical judgment\n\nHOUSE_OVERSIGHT_013126",
  "metadata": {
    "original_filename": "IMAGES-002-HOUSE_OVERSIGHT_013126.txt",
    "source_dataset": "huggingface:tensonaut/EPSTEIN_FILES_20K",
    "character_count": 3067,
    "word_count": 461,
    "line_count": 57,
    "import_date": "2025-11-19T21:47:45.411708",
    "prefix": "IMAGES-002"
  }
}
Epstein Document Archive - Linting Report
Generated: Mon Nov 17 01:02:38 EST 2025
==========================================

Ruff Violations:
UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13 |
14 | import pdfplumber
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13 |
14 | import pdfplumber
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13 |
14 | import pdfplumber
   |

UP006 Use `tuple` instead of `Tuple` for type annotation
  --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:46:56
   |
44 |         }
45 |
46 |     def extract_text_from_pdf(self, pdf_path: Path) -> Tuple[str, int]:
   |                                                        ^^^^^
47 |         """Extract text from PDF and return text + page count."""
48 |         try:
   |
help: Replace with `tuple`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:81:76
   |
79 |         return "other"
80 |
81 |     def extract_email_metadata(self, text: str, filename: str) -> Optional[Dict]:
   |                                                                            ^^^^
82 |         """Extract email metadata from text."""
83 |         metadata = {
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:108:81
    |
106 |         return None
107 |
108 |     def find_emails_in_text(self, text: str, filename: str, page_count: int) -> List[Dict]:
    |                                                                                 ^^^^
109 |         """Find all emails within a document (some PDFs contain multiple emails)."""
110 |         emails = []
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:108:86
    |
106 |         return None
107 |
108 |     def find_emails_in_text(self, text: str, filename: str, page_count: int) -> List[Dict]:
    |                                                                                      ^^^^
109 |         """Find all emails within a document (some PDFs contain multiple emails)."""
110 |         emails = []
    |
help: Replace with `dict`

DTZ007 Naive datetime constructed using `datetime.datetime.strptime()` without %z
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:145:24
    |
143 |         for fmt in formats:
144 |             try:
145 |                 return datetime.strptime(date_str.strip(), fmt)
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
146 |             except ValueError:
147 |                 continue
    |
help: Call `.replace(tzinfo=<timezone>)` or `.astimezone()` to convert to an aware datetime

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:150:51
    |
148 |         return None
149 |
150 |     def analyze_document(self, pdf_path: Path) -> Dict:
    |                                                   ^^^^
151 |         """Analyze a single PDF document."""
152 |         print(f"Analyzing: {pdf_path.name}")
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:283:14
    |
281 |         # Save full JSON
282 |         json_path = output_dir / "pdf_analysis_results.json"
283 |         with open(json_path, "w") as f:
    |              ^^^^
284 |             # Convert datetime objects to strings
285 |             results_copy = self.results.copy()
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:295:14
    |
293 |         # Save report
294 |         report_path = output_dir / "PDF_ANALYSIS_REPORT.md"
295 |         with open(report_path, "w") as f:
    |              ^^^^
296 |             f.write(self.generate_report())
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/analyze_giuffre_maxwell_pdfs.py:300:14
    |
298 |         # Save email index
299 |         email_index_path = output_dir / "email_index.json"
300 |         with open(email_index_path, "w") as f:
    |              ^^^^
301 |             json.dump(self.results["emails"], f, indent=2, default=str)
    |
help: Replace with `Path.open()`

N806 Variable `G` in function should be lowercase
  --> scripts/analysis/build_knowledge_graph.py:24:5
   |
23 |     # Initialize graph
24 |     G = nx.Graph()
   |     ^
25 |
26 |     # Load data
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/build_knowledge_graph.py:27:10
   |
26 |     # Load data
27 |     with open(METADATA_DIR / "entity_network.json") as f:
   |          ^^^^
28 |         network = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/build_knowledge_graph.py:30:10
   |
28 |         network = json.load(f)
29 |
30 |     with open(METADATA_DIR / "entity_statistics.json") as f:
   |          ^^^^
31 |         stats = json.load(f).get("statistics", {})
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/build_knowledge_graph.py:114:10
    |
112 |     }
113 |
114 |     with open(output_file, "w") as f:
    |          ^^^^
115 |         json.dump(graph_data, f, indent=2)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/build_unified_index.py:18:1
   |
16 | from datetime import datetime
17 | from pathlib import Path
18 | from typing import Any, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/build_unified_index.py:44:26
   |
42 |     return None
43 |
44 | def build_pdf_index() -> Dict[str, Dict[str, Any]]:
   |                          ^^^^
45 |     """Index all PDF files."""
46 |     print("Indexing PDF files...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/build_unified_index.py:44:36
   |
42 |     return None
43 |
44 | def build_pdf_index() -> Dict[str, Dict[str, Any]]:
   |                                    ^^^^
45 |     """Index all PDF files."""
46 |     print("Indexing PDF files...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/build_unified_index.py:80:28
   |
78 |     return pdf_index
79 |
80 | def build_email_index() -> Dict[str, Dict[str, Any]]:
   |                            ^^^^
81 |     """Index all email files."""
82 |     print("Indexing email files...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/build_unified_index.py:80:38
   |
78 |     return pdf_index
79 |
80 | def build_email_index() -> Dict[str, Dict[str, Any]]:
   |                                      ^^^^
81 |     """Index all email files."""
82 |     print("Indexing email files...")
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/build_unified_index.py:90:14
   |
88 |     classifications = {}
89 |     if email_classifications_file.exists():
90 |         with open(email_classifications_file) as f:
   |              ^^^^
91 |             data = json.load(f)
92 |             classifications = data.get("classifications", {})
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/build_unified_index.py:103:18
    |
101 |         for metadata_file in metadata_files:
102 |             # Load metadata
103 |             with open(metadata_file) as f:
    |                  ^^^^
104 |                 metadata = json.load(f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/build_unified_index.py:117:26
    |
115 |                 )
116 |                 if full_text_file.exists():
117 |                     with open(full_text_file) as f:
    |                          ^^^^
118 |                         text = f.read()
119 |                         doj_id = extract_doc_id_from_content(text)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:145:29
    |
143 |     return email_index
144 |
145 | def build_entity_index() -> Dict[str, Dict[str, Any]]:
    |                             ^^^^
146 |     """Index entity documents."""
147 |     print("Indexing entity documents...")
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:145:39
    |
143 |     return email_index
144 |
145 | def build_entity_index() -> Dict[str, Dict[str, Any]]:
    |                                       ^^^^
146 |     """Index entity documents."""
147 |     print("Indexing entity documents...")
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:172:18
    |
171 | def link_emails_to_pdfs(
172 |     email_index: Dict[str, Dict[str, Any]],
    |                  ^^^^
173 |     pdf_index: Dict[str, Dict[str, Any]]
174 | ) -> Dict[str, Dict[str, Any]]:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:172:28
    |
171 | def link_emails_to_pdfs(
172 |     email_index: Dict[str, Dict[str, Any]],
    |                            ^^^^
173 |     pdf_index: Dict[str, Dict[str, Any]]
174 | ) -> Dict[str, Dict[str, Any]]:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:173:16
    |
171 | def link_emails_to_pdfs(
172 |     email_index: Dict[str, Dict[str, Any]],
173 |     pdf_index: Dict[str, Dict[str, Any]]
    |                ^^^^
174 | ) -> Dict[str, Dict[str, Any]]:
175 |     """Link emails to their source PDFs using DOJ-OGR IDs."""
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:173:26
    |
171 | def link_emails_to_pdfs(
172 |     email_index: Dict[str, Dict[str, Any]],
173 |     pdf_index: Dict[str, Dict[str, Any]]
    |                          ^^^^
174 | ) -> Dict[str, Dict[str, Any]]:
175 |     """Link emails to their source PDFs using DOJ-OGR IDs."""
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:174:6
    |
172 |     email_index: Dict[str, Dict[str, Any]],
173 |     pdf_index: Dict[str, Dict[str, Any]]
174 | ) -> Dict[str, Dict[str, Any]]:
    |      ^^^^
175 |     """Link emails to their source PDFs using DOJ-OGR IDs."""
176 |     print("Linking emails to source PDFs...")
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:174:16
    |
172 |     email_index: Dict[str, Dict[str, Any]],
173 |     pdf_index: Dict[str, Dict[str, Any]]
174 | ) -> Dict[str, Dict[str, Any]]:
    |                ^^^^
175 |     """Link emails to their source PDFs using DOJ-OGR IDs."""
176 |     print("Linking emails to source PDFs...")
    |
help: Replace with `dict`

B007 Loop control variable `email_id` not used within loop body
   --> scripts/analysis/build_unified_index.py:180:9
    |
178 |     linked_count = 0
179 |
180 |     for email_id, email_data in email_index.items():
    |         ^^^^^^^^
181 |         doj_id = email_data.get("doj_id")
182 |         if not doj_id:
    |
help: Rename unused `email_id` to `_email_id`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:196:30
    |
194 |     return email_index
195 |
196 | def build_unified_index() -> Dict[str, Any]:
    |                              ^^^^
197 |     """Build comprehensive unified index."""
198 |     print("\n" + "="*80)
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:239:31
    |
237 |     }
238 |
239 | def save_unified_index(index: Dict[str, Any]) -> None:
    |                               ^^^^
240 |     """Save unified index."""
241 |     output_file = METADATA_DIR / "unified_document_index.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/build_unified_index.py:243:10
    |
241 |     output_file = METADATA_DIR / "unified_document_index.json"
242 |
243 |     with open(output_file, "w") as f:
    |          ^^^^
244 |         json.dump(index, f, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/build_unified_index.py:256:10
    |
254 |     }
255 |
256 |     with open(compact_file, "w") as f:
    |          ^^^^
257 |         json.dump(compact, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/build_unified_index.py:261:26
    |
259 |     print(f"✅ Compact stats saved to: {compact_file}")
260 |
261 | def print_summary(index: Dict[str, Any]) -> None:
    |                          ^^^^
262 |     """Print summary."""
263 |     print("\n" + "="*80)
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/analysis/build_unified_index.py:297:9
    |
295 |     except Exception as e:
296 |         print(f"\n❌ Error: {e}")
297 |         import traceback
    |         ^^^^^^^^^^^^^^^^
298 |         traceback.print_exc()
299 |         return 1
    |

PLR1722 Use `sys.exit()` instead of `exit`
   --> scripts/analysis/build_unified_index.py:304:5
    |
303 | if __name__ == "__main__":
304 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/enrich_entity_relationships.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/enrich_entity_relationships.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/analysis/enrich_entity_relationships.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/analysis/enrich_entity_relationships.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:53:23
   |
51 |     count: Optional[int] = None
52 |     date_range: Optional[str] = None
53 |     doc_ids: Optional[List[str]] = None
   |                       ^^^^
54 |     url: Optional[str] = None
55 |     description: Optional[str] = None
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:65:14
   |
63 |     entity_b: str
64 |     relationship_type: str  # associate, family, spouse, parent_of, child_of, sibling_of, employee, business_partner
65 |     sources: List[RelationshipSource]
   |              ^^^^
66 |     confidence: float
67 |     bidirectional: bool = True  # Most relationships are symmetric
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:89:29
   |
88 |         # Relationship storage
89 |         self.relationships: List[EntityRelationship] = []
   |                             ^^^^
90 |         self.relationship_cache: Set[Tuple[str, str, str]] = set()  # (entity_a, entity_b, type)
   |
help: Replace with `list`

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:90:34
   |
88 |         # Relationship storage
89 |         self.relationships: List[EntityRelationship] = []
90 |         self.relationship_cache: Set[Tuple[str, str, str]] = set()  # (entity_a, entity_b, type)
   |                                  ^^^
91 |
92 |         # Web search integration
   |
help: Replace with `set`

UP006 Use `tuple` instead of `Tuple` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:90:38
   |
88 |         # Relationship storage
89 |         self.relationships: List[EntityRelationship] = []
90 |         self.relationship_cache: Set[Tuple[str, str, str]] = set()  # (entity_a, entity_b, type)
   |                                      ^^^^^
91 |
92 |         # Web search integration
   |
help: Replace with `tuple`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/enrich_entity_relationships.py:97:41
   |
95 |         logger.info(f"Loaded {len(self.entities)} entities, {len(self.network_edges)} flight co-occurrences")
96 |
97 |     def _load_json(self, path: Path) -> Dict:
   |                                         ^^^^
98 |         """Load JSON file."""
99 |         if not path.exists():
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/enrich_entity_relationships.py:102:14
    |
100 |             logger.warning(f"File not found: {path}")
101 |             return {}
102 |         with open(path) as f:
    |              ^^^^
103 |             return json.load(f)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:105:32
    |
103 |             return json.load(f)
104 |
105 |     def _save_json(self, data: Dict, path: Path):
    |                                ^^^^
106 |         """Save JSON file with pretty printing."""
107 |         path.parent.mkdir(parents=True, exist_ok=True)
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/enrich_entity_relationships.py:108:14
    |
106 |         """Save JSON file with pretty printing."""
107 |         path.parent.mkdir(parents=True, exist_ok=True)
108 |         with open(path, "w") as f:
    |              ^^^^
109 |             json.dump(data, f, indent=2)
110 |         logger.info(f"Saved to {path}")
    |
help: Replace with `Path.open()`

RUF005 Consider iterable unpacking instead of concatenation
   --> scripts/analysis/enrich_entity_relationships.py:124:25
    |
122 |         # Create bidirectional key for symmetric relationships
123 |         if rel.bidirectional:
124 |             key = tuple(sorted([rel.entity_a, rel.entity_b]) + [rel.relationship_type])
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
125 |         else:
126 |             key = (rel.entity_a, rel.entity_b, rel.relationship_type)
    |
help: Replace with iterable unpacking

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:175:64
    |
173 |         logger.info(f"Extracted {len(cooccurrence_map)} flight co-occurrence relationships")
174 |
175 |     def get_top_entities_by_mentions(self, limit: int = 50) -> List[Dict]:
    |                                                                ^^^^
176 |         """Get top entities by document mentions and flight count."""
177 |         # Score entities by: flights * 10 + black_book_presence
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:175:69
    |
173 |         logger.info(f"Extracted {len(cooccurrence_map)} flight co-occurrence relationships")
174 |
175 |     def get_top_entities_by_mentions(self, limit: int = 50) -> List[Dict]:
    |                                                                     ^^^^
176 |         """Get top entities by document mentions and flight count."""
177 |         # Score entities by: flights * 10 + black_book_presence
    |
help: Replace with `dict`

ARG002 Unused method argument: `relationship_types`
   --> scripts/analysis/enrich_entity_relationships.py:203:58
    |
201 |         return entity_scores[:limit]
202 |
203 |     def search_web_relationships(self, entity_name: str, relationship_types: List[str] = None) -> List[Dict]:
    |                                                          ^^^^^^^^^^^^^^^^^^
204 |         """
205 |         Search web for entity relationships using WebRelationshipFinder.
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:203:78
    |
201 |         return entity_scores[:limit]
202 |
203 |     def search_web_relationships(self, entity_name: str, relationship_types: List[str] = None) -> List[Dict]:
    |                                                                              ^^^^
204 |         """
205 |         Search web for entity relationships using WebRelationshipFinder.
    |
help: Replace with `list`

RUF013 PEP 484 prohibits implicit `Optional`
   --> scripts/analysis/enrich_entity_relationships.py:203:78
    |
201 |         return entity_scores[:limit]
202 |
203 |     def search_web_relationships(self, entity_name: str, relationship_types: List[str] = None) -> List[Dict]:
    |                                                                              ^^^^^^^^^
204 |         """
205 |         Search web for entity relationships using WebRelationshipFinder.
    |
help: Convert to `Optional[T]`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:203:99
    |
201 |         return entity_scores[:limit]
202 |
203 |     def search_web_relationships(self, entity_name: str, relationship_types: List[str] = None) -> List[Dict]:
    |                                                                                                   ^^^^
204 |         """
205 |         Search web for entity relationships using WebRelationshipFinder.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:203:104
    |
201 |         return entity_scores[:limit]
202 |
203 |     def search_web_relationships(self, entity_name: str, relationship_types: List[str] = None) -> List[Dict]:
    |                                                                                                        ^^^^
204 |         """
205 |         Search web for entity relationships using WebRelationshipFinder.
    |
help: Replace with `dict`

RUF005 Consider iterable unpacking instead of concatenation
   --> scripts/analysis/enrich_entity_relationships.py:258:29
    |
256 |         for rel in self.relationships:
257 |             if rel.bidirectional:
258 |                 key = tuple(sorted([rel.entity_a, rel.entity_b]) + [rel.relationship_type])
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
259 |             else:
260 |                 key = (rel.entity_a, rel.entity_b, rel.relationship_type)
    |
help: Replace with iterable unpacking

B007 Loop control variable `key` not used within loop body
   --> scripts/analysis/enrich_entity_relationships.py:265:13
    |
263 |         # Merge sources for duplicate relationships
264 |         merged_relationships = []
265 |         for key, rels in grouped.items():
    |             ^^^
266 |             if len(rels) == 1:
267 |                 merged_relationships.append(rels[0])
    |
help: Rename unused `key` to `_key`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/enrich_entity_relationships.py:340:44
    |
338 |         return output
339 |
340 |     def generate_report(self, output_data: Dict):
    |                                            ^^^^
341 |         """Generate human-readable summary report."""
342 |         metadata = output_data["metadata"]
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/enrich_entity_relationships.py:411:14
    |
409 |         # Save report
410 |         REPORT_PATH.parent.mkdir(parents=True, exist_ok=True)
411 |         with open(REPORT_PATH, "w") as f:
    |              ^^^^
412 |             f.write(report_text)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/entity_disambiguator.py:12:1
   |
10 | from difflib import SequenceMatcher
11 | from pathlib import Path
12 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/entity_disambiguator.py:12:1
   |
10 | from difflib import SequenceMatcher
11 | from pathlib import Path
12 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_disambiguator.py:34:14
   |
32 |     def load_entities(self, entities_index_path: Path):
33 |         """Load entities from index"""
34 |         with open(entities_index_path) as f:
   |              ^^^^
35 |             data = json.load(f)
   |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/entity_disambiguator.py:83:34
   |
81 |         return seq_sim
82 |
83 |     def find_duplicates(self) -> List[List[Dict]]:
   |                                  ^^^^
84 |         """
85 |         Find groups of duplicate entities
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/entity_disambiguator.py:83:39
   |
81 |         return seq_sim
82 |
83 |     def find_duplicates(self) -> List[List[Dict]]:
   |                                       ^^^^
84 |         """
85 |         Find groups of duplicate entities
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/entity_disambiguator.py:83:44
   |
81 |         return seq_sim
82 |
83 |     def find_duplicates(self) -> List[List[Dict]]:
   |                                            ^^^^
84 |         """
85 |         Find groups of duplicate entities
   |
help: Replace with `dict`

B007 Loop control variable `j` not used within loop body
   --> scripts/analysis/entity_disambiguator.py:113:17
    |
112 |             # Find similar entities
113 |             for j, entity2 in enumerate(self.entities[i+1:], i+1):
    |                 ^
114 |                 name2 = entity2.get("name", "")
115 |                 if not name2 or name2 in processed:
    |
help: Rename unused `j` to `_j`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/entity_disambiguator.py:134:44
    |
132 |         return duplicate_groups
133 |
134 |     def merge_entities(self, entity_group: List[Dict]) -> Dict:
    |                                            ^^^^
135 |         """
136 |         Merge a group of duplicate entities
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_disambiguator.py:134:49
    |
132 |         return duplicate_groups
133 |
134 |     def merge_entities(self, entity_group: List[Dict]) -> Dict:
    |                                                 ^^^^
135 |         """
136 |         Merge a group of duplicate entities
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_disambiguator.py:134:59
    |
132 |         return duplicate_groups
133 |
134 |     def merge_entities(self, entity_group: List[Dict]) -> Dict:
    |                                                           ^^^^
135 |         """
136 |         Merge a group of duplicate entities
    |
help: Replace with `dict`

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/analysis/entity_disambiguator.py:156:32
    |
154 |             "is_billionaire": any(e.get("is_billionaire", False) for e in entity_group),
155 |             "trips": sum(e.get("trips", 0) for e in entity_group),
156 |             "categories": list(set(cat for e in entity_group for cat in e.get("categories", []))),
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
157 |             "sources": list(set(src for e in entity_group for src in e.get("sources", []))),
158 |             "merged_from": len(entity_group)
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/analysis/entity_disambiguator.py:157:29
    |
155 |             "trips": sum(e.get("trips", 0) for e in entity_group),
156 |             "categories": list(set(cat for e in entity_group for cat in e.get("categories", []))),
157 |             "sources": list(set(src for e in entity_group for src in e.get("sources", []))),
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
158 |             "merged_from": len(entity_group)
159 |         }
    |
help: Rewrite as a set comprehension

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/entity_disambiguator.py:249:14
    |
247 |         }
248 |
249 |         with open(output_path, "w") as f:
    |              ^^^^
250 |             json.dump(output_data, f, indent=2)
    |
help: Replace with `Path.open()`

F841 Local variable `duplicate_groups` is assigned to but never used
   --> scripts/analysis/entity_disambiguator.py:271:5
    |
270 |     # Find duplicates
271 |     duplicate_groups = disambiguator.find_duplicates()
    |     ^^^^^^^^^^^^^^^^
272 |
273 |     # Generate report
    |
help: Remove assignment to unused variable `duplicate_groups`

F841 Local variable `merged_entities` is assigned to but never used
   --> scripts/analysis/entity_disambiguator.py:283:5
    |
281 |     # Export merged index
282 |     merged_index_path = MD_DIR / "ENTITIES_INDEX_MERGED.json"
283 |     merged_entities = disambiguator.export_merged_index(merged_index_path)
    |     ^^^^^^^^^^^^^^^
284 |
285 |     print("\n" + "=" * 70)
    |
help: Remove assignment to unused variable `merged_entities`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/entity_network.py:11:1
   |
 9 | from dataclasses import dataclass
10 | from pathlib import Path
11 | from typing import Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/entity_network.py:11:1
   |
 9 | from dataclasses import dataclass
10 | from pathlib import Path
11 | from typing import Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/analysis/entity_network.py:11:1
   |
 9 | from dataclasses import dataclass
10 | from pathlib import Path
11 | from typing import Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/entity_network.py:26:17
   |
24 |     is_billionaire: bool
25 |     flight_count: int
26 |     categories: List[str]
   |                 ^^^^
27 |     connections: Set[str]  # Names of connected entities
   |
help: Replace with `list`

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/analysis/entity_network.py:27:18
   |
25 |     flight_count: int
26 |     categories: List[str]
27 |     connections: Set[str]  # Names of connected entities
   |                  ^^^
28 |
29 | @dataclass
   |
help: Replace with `set`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/entity_network.py:35:15
   |
33 |     entity2: str
34 |     weight: int  # Number of co-occurrences
35 |     contexts: List[str]  # Where they appeared together
   |               ^^^^
36 |
37 | class EntityNetworkBuilder:
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/entity_network.py:42:21
   |
40 |     def __init__(self):
41 |         """Initialize builder"""
42 |         self.nodes: Dict[str, EntityNode] = {}
   |                     ^^^^
43 |         self.edges: List[EntityEdge] = []
44 |         self.flight_cooccurrences = defaultdict(lambda: defaultdict(int))
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/entity_network.py:43:21
   |
41 |         """Initialize builder"""
42 |         self.nodes: Dict[str, EntityNode] = {}
43 |         self.edges: List[EntityEdge] = []
   |                     ^^^^
44 |         self.flight_cooccurrences = defaultdict(lambda: defaultdict(int))
   |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_network.py:48:14
   |
46 |     def load_entities(self, entities_index_path: Path):
47 |         """Load entities from index"""
48 |         with open(entities_index_path) as f:
   |              ^^^^
49 |             data = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_network.py:73:14
   |
71 |     def load_flight_logs(self, flight_logs_stats_path: Path):
72 |         """Load flight logs and build co-occurrence network"""
73 |         with open(flight_logs_stats_path) as f:
   |              ^^^^
74 |             data = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/entity_network.py:181:14
    |
179 |         }
180 |
181 |         with open(output_path, "w") as f:
    |              ^^^^
182 |             json.dump(graph_data, f, indent=2)
    |
help: Replace with `Path.open()`

F841 Local variable `graph_data` is assigned to but never used
   --> scripts/analysis/entity_network.py:261:5
    |
260 |     # Export graph
261 |     graph_data = builder.export_graph(METADATA_DIR / "entity_network.json")
    |     ^^^^^^^^^^
262 |
263 |     # Generate statistics
    |
help: Remove assignment to unused variable `graph_data`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/entity_statistics.py:14:1
   |
12 | from collections import Counter
13 | from pathlib import Path
14 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/entity_statistics.py:14:1
   |
12 | from collections import Counter
13 | from pathlib import Path
14 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_statistics.py:41:14
   |
39 |         entities_index = merged_index if merged_index.exists() else MD_DIR / "ENTITIES_INDEX.json"
40 |
41 |         with open(entities_index) as f:
   |              ^^^^
42 |             entity_data = json.load(f)
43 |             self.entities = entity_data.get("entities", entity_data)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_statistics.py:46:14
   |
45 |         # Load semantic index
46 |         with open(METADATA_DIR / "semantic_index.json") as f:
   |              ^^^^
47 |             self.semantic_index = json.load(f).get("entity_to_documents", {})
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_statistics.py:50:14
   |
49 |         # Load network
50 |         with open(METADATA_DIR / "entity_network.json") as f:
   |              ^^^^
51 |             self.network_data = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/entity_statistics.py:54:14
   |
53 |         # Load classifications
54 |         with open(METADATA_DIR / "document_classifications.json") as f:
   |              ^^^^
55 |             self.classifications = json.load(f).get("results", {})
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/entity_statistics.py:61:45
   |
59 |         print(f"  Loaded {len(self.network_data.get('nodes', []))} network nodes")
60 |
61 |     def generate_entity_statistics(self) -> Dict:
   |                                             ^^^^
62 |         """Generate statistics for each entity"""
63 |         print("\nGenerating entity statistics...")
   |
help: Replace with `dict`

ARG002 Unused method argument: `canonical_name`
   --> scripts/analysis/entity_statistics.py:123:36
    |
121 |         return stats
122 |
123 |     def get_entity_documents(self, canonical_name: str, name_variations: List[str]) -> List[Dict]:
    |                                    ^^^^^^^^^^^^^^
124 |         """Get all documents mentioning an entity (any name variation)"""
125 |         all_docs = []
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/entity_statistics.py:123:74
    |
121 |         return stats
122 |
123 |     def get_entity_documents(self, canonical_name: str, name_variations: List[str]) -> List[Dict]:
    |                                                                          ^^^^
124 |         """Get all documents mentioning an entity (any name variation)"""
125 |         all_docs = []
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/entity_statistics.py:123:88
    |
121 |         return stats
122 |
123 |     def get_entity_documents(self, canonical_name: str, name_variations: List[str]) -> List[Dict]:
    |                                                                                        ^^^^
124 |         """Get all documents mentioning an entity (any name variation)"""
125 |         all_docs = []
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_statistics.py:123:93
    |
121 |         return stats
122 |
123 |     def get_entity_documents(self, canonical_name: str, name_variations: List[str]) -> List[Dict]:
    |                                                                                             ^^^^
124 |         """Get all documents mentioning an entity (any name variation)"""
125 |         all_docs = []
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_statistics.py:142:46
    |
140 |         return all_docs
141 |
142 |     def get_network_node(self, name: str) -> Dict:
    |                                              ^^^^
143 |         """Get network node for entity"""
144 |         for node in self.network_data.get("nodes", []):
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/entity_statistics.py:149:52
    |
147 |         return {}
148 |
149 |     def get_entity_connections(self, name: str) -> List[Dict]:
    |                                                    ^^^^
150 |         """Get entity's top connections"""
151 |         connections = []
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_statistics.py:149:57
    |
147 |         return {}
148 |
149 |     def get_entity_connections(self, name: str) -> List[Dict]:
    |                                                         ^^^^
150 |         """Get entity's top connections"""
151 |         connections = []
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/entity_statistics.py:169:49
    |
167 |         return connections
168 |
169 |     def get_document_type_breakdown(self, docs: List[Dict]) -> Dict:
    |                                                 ^^^^
170 |         """Get breakdown of document types"""
171 |         type_counts = Counter()
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_statistics.py:169:54
    |
167 |         return connections
168 |
169 |     def get_document_type_breakdown(self, docs: List[Dict]) -> Dict:
    |                                                      ^^^^
170 |         """Get breakdown of document types"""
171 |         type_counts = Counter()
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/entity_statistics.py:169:64
    |
167 |         return connections
168 |
169 |     def get_document_type_breakdown(self, docs: List[Dict]) -> Dict:
    |                                                                ^^^^
170 |         """Get breakdown of document types"""
171 |         type_counts = Counter()
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/entity_statistics.py:187:14
    |
185 |         }
186 |
187 |         with open(output_path, "w") as f:
    |              ^^^^
188 |             json.dump(output_data, f, indent=2)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/rebuild_document_stats.py:17:1
   |
15 | from datetime import datetime
16 | from pathlib import Path
17 | from typing import Any, Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/rebuild_document_stats.py:28:31
   |
26 | MD_DIR = DATA_DIR / "md"
27 |
28 | def count_pdfs_by_source() -> Dict[str, int]:
   |                               ^^^^
29 |     """Count PDF files in each source directory."""
30 |     print("Counting PDFs by source...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/rebuild_document_stats.py:53:33
   |
51 |     return pdf_counts
52 |
53 | def count_emails_by_source() -> Dict[str, Dict[str, Any]]:
   |                                 ^^^^
54 |     """Count extracted emails by source."""
55 |     print("\nCounting emails by source...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/rebuild_document_stats.py:53:43
   |
51 |     return pdf_counts
52 |
53 | def count_emails_by_source() -> Dict[str, Dict[str, Any]]:
   |                                           ^^^^
54 |     """Count extracted emails by source."""
55 |     print("\nCounting emails by source...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/rebuild_document_stats.py:90:33
   |
88 |     return email_counts
89 |
90 | def count_entity_documents() -> Dict[str, Any]:
   |                                 ^^^^
91 |     """Count entity-related documents."""
92 |     print("\nCounting entity documents...")
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:121:32
    |
119 |     return entity_counts
120 |
121 | def count_other_documents() -> Dict[str, int]:
    |                                ^^^^
122 |     """Count other document types (OCR results, etc.)."""
123 |     print("\nCounting other document types...")
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:136:31
    |
134 |     return other_counts
135 |
136 | def load_classifications() -> Dict[str, Any]:
    |                               ^^^^
137 |     """Load existing document classifications."""
138 |     classifications_file = METADATA_DIR / "document_classifications.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_document_stats.py:146:10
    |
144 |         }
145 |
146 |     with open(classifications_file) as f:
    |          ^^^^
147 |         return json.load(f)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:149:36
    |
147 |         return json.load(f)
148 |
149 | def build_comprehensive_stats() -> Dict[str, Any]:
    |                                    ^^^^
150 |     """Build comprehensive document statistics."""
151 |     print("\n" + "="*80)
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:198:51
    |
196 |     return stats
197 |
198 | def count_by_classification_type(classifications: Dict[str, Any]) -> Dict[str, int]:
    |                                                   ^^^^
199 |     """Count documents by classification type."""
200 |     type_counts = defaultdict(int)
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:198:70
    |
196 |     return stats
197 |
198 | def count_by_classification_type(classifications: Dict[str, Any]) -> Dict[str, int]:
    |                                                                      ^^^^
199 |     """Count documents by classification type."""
200 |     type_counts = defaultdict(int)
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:208:23
    |
206 |     return dict(type_counts)
207 |
208 | def save_stats(stats: Dict[str, Any]) -> None:
    |                       ^^^^
209 |     """Save statistics to metadata directory."""
210 |     output_file = METADATA_DIR / "comprehensive_document_stats.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_document_stats.py:212:10
    |
210 |     output_file = METADATA_DIR / "comprehensive_document_stats.json"
211 |
212 |     with open(output_file, "w") as f:
    |          ^^^^
213 |         json.dump(stats, f, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_document_stats.py:220:10
    |
218 |     report_file = METADATA_DIR / "comprehensive_document_stats.txt"
219 |
220 |     with open(report_file, "w") as f:
    |          ^^^^
221 |         f.write("="*80 + "\n")
222 |         f.write("COMPREHENSIVE DOCUMENT STATISTICS\n")
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/rebuild_document_stats.py:256:26
    |
254 |     print(f"✅ Report saved to: {report_file}")
255 |
256 | def print_summary(stats: Dict[str, Any]) -> None:
    |                          ^^^^
257 |     """Print summary to console."""
258 |     print("\n" + "="*80)
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/analysis/rebuild_document_stats.py:295:9
    |
293 |     except Exception as e:
294 |         print(f"\n❌ Error: {e}")
295 |         import traceback
    |         ^^^^^^^^^^^^^^^^
296 |         traceback.print_exc()
297 |         return 1
    |

PLR1722 Use `sys.exit()` instead of `exit`
   --> scripts/analysis/rebuild_document_stats.py:302:5
    |
301 | if __name__ == "__main__":
302 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/rebuild_flight_network.py:38:10
   |
36 |     print(f"Reading flight logs from {raw_text.name}...")
37 |
38 |     with open(raw_text, encoding="utf-8") as f:
   |          ^^^^
39 |         lines = f.readlines()
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_flight_network.py:130:10
    |
128 |     # Save flights with passengers
129 |     flights_output = MD_DIR / "flight_logs_by_flight.json"
130 |     with open(flights_output, "w") as f:
    |          ^^^^
131 |         json.dump({
132 |             "total_flights": len(flights_list),
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_flight_network.py:202:10
    |
200 |     # Load entity index
201 |     entities_index = MD_DIR / "ENTITIES_INDEX.json"
202 |     with open(entities_index) as f:
    |          ^^^^
203 |         entities_data = json.load(f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/rebuild_flight_network.py:254:10
    |
252 |     }
253 |
254 |     with open(graph_output, "w") as f:
    |          ^^^^
255 |         json.dump(graph_data, f, indent=2)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/timeline_builder.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/timeline_builder.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/analysis/timeline_builder.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> scripts/analysis/timeline_builder.py:24:21
   |
23 |       # Date patterns to match
24 |       DATE_PATTERNS = [
   |  _____________________^
25 | |         # MM/DD/YYYY or M/D/YYYY
26 | |         (r"(\d{1,2})/(\d{1,2})/(\d{4})", lambda m: f"{m[3]}-{m[1]:0>2}-{m[2]:0>2}"),
27 | |         # Month DD, YYYY
28 | |         (r"(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2}),?\s+(\d{4})",
29 | |          lambda m: f"{m[3]}-{TimelineBuilder.month_to_num(m[1]):0>2}-{m[2]:0>2}"),
30 | |         # YYYY-MM-DD
31 | |         (r"(\d{4})-(\d{2})-(\d{2})", lambda m: f"{m[1]}-{m[2]}-{m[3]}"),
32 | |         # DD Month YYYY
33 | |         (r"(\d{1,2})\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{4})",
34 | |          lambda m: f"{m[3]}-{TimelineBuilder.month_to_num(m[2]):0>2}-{m[1]:0>2}"),
35 | |     ]
   | |_____^
36 |
37 |       @staticmethod
   |

ARG002 Unused method argument: `doc_path`
  --> scripts/analysis/timeline_builder.py:52:50
   |
50 |         self.date_index = defaultdict(list)
51 |
52 |     def extract_dates_from_text(self, text: str, doc_path: str) -> List[Tuple[str, int]]:
   |                                                  ^^^^^^^^
53 |         """
54 |         Extract dates from text
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/timeline_builder.py:52:68
   |
50 |         self.date_index = defaultdict(list)
51 |
52 |     def extract_dates_from_text(self, text: str, doc_path: str) -> List[Tuple[str, int]]:
   |                                                                    ^^^^
53 |         """
54 |         Extract dates from text
   |
help: Replace with `list`

UP006 Use `tuple` instead of `Tuple` for type annotation
  --> scripts/analysis/timeline_builder.py:52:73
   |
50 |         self.date_index = defaultdict(list)
51 |
52 |     def extract_dates_from_text(self, text: str, doc_path: str) -> List[Tuple[str, int]]:
   |                                                                         ^^^^^
53 |         """
54 |         Extract dates from text
   |
help: Replace with `tuple`

DTZ007 Naive datetime constructed using `datetime.datetime.strptime()` without %z
  --> scripts/analysis/timeline_builder.py:68:21
   |
67 |                     # Validate date
68 |                     datetime.strptime(formatted_date, "%Y-%m-%d")
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
69 |
70 |                     dates_found.append((formatted_date, match.start()))
   |
help: Call `.replace(tzinfo=<timezone>)` or `.astimezone()` to convert to an aware datetime

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/timeline_builder.py:86:51
   |
84 |         return context
85 |
86 |     def process_document(self, doc_path: Path) -> List[Dict]:
   |                                                   ^^^^
87 |         """
88 |         Process a document and extract timeline events
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/timeline_builder.py:86:56
   |
84 |         return context
85 |
86 |     def process_document(self, doc_path: Path) -> List[Dict]:
   |                                                        ^^^^
87 |         """
88 |         Process a document and extract timeline events
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/timeline_builder.py:115:43
    |
113 |         return events
114 |
115 |     def build_timeline(self, source_dirs: List[Path]) -> List[Dict]:
    |                                           ^^^^
116 |         """
117 |         Build timeline from multiple source directories
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/timeline_builder.py:115:58
    |
113 |         return events
114 |
115 |     def build_timeline(self, source_dirs: List[Path]) -> List[Dict]:
    |                                                          ^^^^
116 |         """
117 |         Build timeline from multiple source directories
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/timeline_builder.py:115:63
    |
113 |         return events
114 |
115 |     def build_timeline(self, source_dirs: List[Path]) -> List[Dict]:
    |                                                               ^^^^
116 |         """
117 |         Build timeline from multiple source directories
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/analysis/timeline_builder.py:164:14
    |
162 |         }
163 |
164 |         with open(output_path, "w") as f:
    |              ^^^^
165 |             json.dump(timeline_data, f, indent=2)
    |
help: Replace with `Path.open()`

F841 Local variable `timeline` is assigned to but never used
   --> scripts/analysis/timeline_builder.py:238:5
    |
236 |     ]
237 |
238 |     timeline = builder.build_timeline(source_dirs)
    |     ^^^^^^^^
239 |
240 |     # Export
    |
help: Remove assignment to unused variable `timeline`

PLR0915 Too many statements (69 > 60)
  --> scripts/analysis/verify_entity_filtering.py:30:5
   |
28 | METADATA_DIR = DATA_DIR / "metadata"
29 |
30 | def main():
   |     ^^^^
31 |     """Verify entity filtering implementation"""
32 |     print("=" * 70)
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/verify_entity_filtering.py:56:14
   |
55 |     if network_path.exists():
56 |         with open(network_path) as f:
   |              ^^^^
57 |             network_data = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/analysis/verify_entity_filtering.py:86:14
   |
85 |     if stats_path.exists():
86 |         with open(stats_path) as f:
   |              ^^^^
87 |             stats_data = json.load(f)
   |
help: Replace with `Path.open()`

SIM118 Use `key in dict` instead of `key in dict.keys()`
  --> scripts/analysis/verify_entity_filtering.py:94:22
   |
92 |         # Check for generic entities in stats
93 |         generic_in_stats = [
94 |             name for name in entity_stats.keys()
   |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
95 |             if entity_filter.is_generic(name)
96 |         ]
   |
help: Remove `.keys()`

RUF001 String contains ambiguous `ℹ` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> scripts/analysis/verify_entity_filtering.py:102:25
    |
101 |         if generic_in_stats:
102 |             print("\n   ℹ️  NOTE: Generic entities in statistics (not displayed in UI):")
    |                         ^
103 |             for name in generic_in_stats:
104 |                 print(f"      - {name}")
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/analysis/web_relationship_finder.py:11:1
   |
 9 | import logging
10 | import re
11 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/analysis/web_relationship_finder.py:11:1
   |
 9 | import logging
10 | import re
11 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> scripts/analysis/web_relationship_finder.py:21:29
   |
20 |       # Relationship keywords to look for in search results
21 |       RELATIONSHIP_KEYWORDS = {
   |  _____________________________^
22 | |         "spouse": ["wife", "husband", "spouse", "married to", "married"],
23 | |         "child_of": ["son of", "daughter of", "child of", "children of"],
24 | |         "parent_of": ["father of", "mother of", "parent of"],
25 | |         "sibling_of": ["brother of", "sister of", "sibling of"],
26 | |         "business_partner": ["partner", "co-founder", "business partner", "founded with"],
27 | |         "employee": ["works for", "employed by", "employee of", "worked for"],
28 | |         "associate": ["associate", "associated with", "linked to", "connected to"]
29 | |     }
   | |_____^
30 |
31 |       def __init__(self, use_live_search: bool = False):
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/web_relationship_finder.py:45:43
   |
43 |         self.seed_relationships = self._load_seed_relationships()
44 |
45 |     def _load_seed_relationships(self) -> Dict[str, List[Dict]]:
   |                                           ^^^^
46 |         """Load manually verified relationships for key entities."""
47 |         return {
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/analysis/web_relationship_finder.py:45:53
   |
43 |         self.seed_relationships = self._load_seed_relationships()
44 |
45 |     def _load_seed_relationships(self) -> Dict[str, List[Dict]]:
   |                                                     ^^^^
46 |         """Load manually verified relationships for key entities."""
47 |         return {
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/analysis/web_relationship_finder.py:45:58
   |
43 |         self.seed_relationships = self._load_seed_relationships()
44 |
45 |     def _load_seed_relationships(self) -> Dict[str, List[Dict]]:
   |                                                          ^^^^
46 |         """Load manually verified relationships for key entities."""
47 |         return {
   |
help: Replace with `dict`

RUF005 Consider `[parts[0], *parts[2:]]` instead of concatenation
   --> scripts/analysis/web_relationship_finder.py:395:35
    |
393 |         if len(parts) >= 2 and parts[0] == parts[1]:
394 |             # "Bill Bill Clinton" -> "Bill Clinton"
395 |             normalized = " ".join([parts[0]] + parts[2:])
    |                                   ^^^^^^^^^^^^^^^^^^^^^^
396 |
397 |         return normalized
    |
help: Replace with `[parts[0], *parts[2:]]`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/web_relationship_finder.py:399:66
    |
397 |         return normalized
398 |
399 |     def find_relationships_web_search(self, entity_name: str) -> List[Dict]:
    |                                                                  ^^^^
400 |         """
401 |         Search web for entity relationships (LIVE SEARCH - PLACEHOLDER).
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/web_relationship_finder.py:399:71
    |
397 |         return normalized
398 |
399 |     def find_relationships_web_search(self, entity_name: str) -> List[Dict]:
    |                                                                       ^^^^
400 |         """
401 |         Search web for entity relationships (LIVE SEARCH - PLACEHOLDER).
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/web_relationship_finder.py:428:55
    |
426 |         return []
427 |
428 |     def find_relationships(self, entity_name: str) -> List[Dict]:
    |                                                       ^^^^
429 |         """
430 |         Find all known relationships for an entity.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/analysis/web_relationship_finder.py:428:60
    |
426 |         return []
427 |
428 |     def find_relationships(self, entity_name: str) -> List[Dict]:
    |                                                            ^^^^
429 |         """
430 |         Find all known relationships for an entity.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/analysis/web_relationship_finder.py:467:41
    |
465 |         return relationships
466 |
467 |     def get_supported_entities(self) -> List[str]:
    |                                         ^^^^
468 |         """Get list of entities with known relationships."""
469 |         return list(self.seed_relationships.keys())
    |
help: Replace with `list`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/canonicalization/canonicalize.py:17:1
   |
15 | from datetime import datetime
16 | from pathlib import Path
17 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |
19 | import PyPDF2
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/canonicalization/canonicalize.py:17:1
   |
15 | from datetime import datetime
16 | from pathlib import Path
17 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |
19 | import PyPDF2
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/canonicalization/canonicalize.py:73:26
   |
71 |         source_dir: Path,
72 |         source_name: str,
73 |         source_metadata: Dict
   |                          ^^^^
74 |     ) -> Dict:
75 |         """
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/canonicalization/canonicalize.py:74:10
   |
72 |         source_name: str,
73 |         source_metadata: Dict
74 |     ) -> Dict:
   |          ^^^^
75 |         """
76 |         Canonicalize all documents from a source.
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:141:26
    |
139 |         pdf_file: Path,
140 |         source_name: str,
141 |         source_metadata: Dict
    |                          ^^^^
142 |     ) -> Dict:
143 |         """
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:142:10
    |
140 |         source_name: str,
141 |         source_metadata: Dict
142 |     ) -> Dict:
    |          ^^^^
143 |         """
144 |         Process a single document.
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/canonicalization/canonicalize.py:196:18
    |
194 |         """
195 |         try:
196 |             with open(pdf_file, "rb") as f:
    |                  ^^^^
197 |                 reader = PyPDF2.PdfReader(f)
198 |                 text = ""
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:209:26
    |
207 |         pdf_file: Path,
208 |         source_name: str,
209 |         source_metadata: Dict,
    |                          ^^^^
210 |         hashes: Dict,
211 |         text: str
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:210:17
    |
208 |         source_name: str,
209 |         source_metadata: Dict,
210 |         hashes: Dict,
    |                 ^^^^
211 |         text: str
212 |     ) -> str:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:275:26
    |
273 |         pdf_file: Path,
274 |         source_name: str,
275 |         source_metadata: Dict,
    |                          ^^^^
276 |         hashes: Dict,
277 |         text: str
    |
help: Replace with `dict`

ARG002 Unused method argument: `hashes`
   --> scripts/canonicalization/canonicalize.py:276:9
    |
274 |         source_name: str,
275 |         source_metadata: Dict,
276 |         hashes: Dict,
    |         ^^^^^^
277 |         text: str
278 |     ):
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:276:17
    |
274 |         source_name: str,
275 |         source_metadata: Dict,
276 |         hashes: Dict,
    |                 ^^^^
277 |         text: str
278 |     ):
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:311:63
    |
309 |             pass
310 |
311 |     def _extract_metadata(self, text: str, pdf_file: Path) -> Dict:
    |                                                               ^^^^
312 |         """
313 |         Extract metadata from document text.
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/canonicalization/canonicalize.py:329:13
    |
328 |             # Extract email metadata
329 |             import re
    |             ^^^^^^^^^
330 |             from_match = re.search(r"From:\s*([^\n]+)", text)
331 |             if from_match:
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:367:74
    |
365 |         return any(pattern in text_upper for pattern in redaction_patterns)
366 |
367 |     def _generate_markdown(self, canonical_id: str, text: str, metadata: Dict):
    |                                                                          ^^^^
368 |         """
369 |         Generate markdown file with YAML frontmatter.
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/canonicalization/canonicalize.py:393:14
    |
392 |         # Write markdown
393 |         with open(output_file, "w") as f:
    |              ^^^^
394 |             f.write(frontmatter)
395 |             f.write("\n\n")
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:400:14
    |
398 |     def _generate_frontmatter(
399 |         self,
400 |         doc: Dict,
    |              ^^^^
401 |         sources: List[Dict],
402 |         metadata: Dict
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/canonicalization/canonicalize.py:401:18
    |
399 |         self,
400 |         doc: Dict,
401 |         sources: List[Dict],
    |                  ^^^^
402 |         metadata: Dict
403 |     ) -> str:
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:401:23
    |
399 |         self,
400 |         doc: Dict,
401 |         sources: List[Dict],
    |                       ^^^^
402 |         metadata: Dict
403 |     ) -> str:
    |
help: Replace with `dict`

ARG002 Unused method argument: `metadata`
   --> scripts/canonicalization/canonicalize.py:402:9
    |
400 |         doc: Dict,
401 |         sources: List[Dict],
402 |         metadata: Dict
    |         ^^^^^^^^
403 |     ) -> str:
404 |         """Generate YAML frontmatter."""
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/canonicalization/canonicalize.py:402:19
    |
400 |         doc: Dict,
401 |         sources: List[Dict],
402 |         metadata: Dict
    |                   ^^^^
403 |     ) -> str:
404 |         """Generate YAML frontmatter."""
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/canonicalization/canonicalize.py:405:9
    |
403 |     ) -> str:
404 |         """Generate YAML frontmatter."""
405 |         import yaml
    |         ^^^^^^^^^^^
406 |
407 |         frontmatter_data = {
    |

C414 Unnecessary `list()` call within `sorted()`
   --> scripts/canonicalization/canonicalize_emails.py:250:33
    |
248 |             participants_set.add(p["name"])
249 |     stats["unique_participants"] = len(participants_set)
250 |     stats["participant_list"] = sorted(list(participants_set))
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
251 |
252 |     return stats
    |
help: Remove the inner `list()` call

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/canonicalization/canonicalize_emails.py:258:10
    |
256 |     index = create_email_index()
257 |     index_path = Path("/Users/masa/Projects/Epstein/data/canonical/emails/email_index.json")
258 |     with open(index_path, "w") as f:
    |          ^^^^
259 |         json.dump(index, f, indent=2)
260 |     print(f"✓ Created email index: {index_path}")
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/canonicalization/canonicalize_emails.py:265:10
    |
263 |     stats = generate_statistics()
264 |     stats_path = Path("/Users/masa/Projects/Epstein/data/canonical/emails/email_statistics.json")
265 |     with open(stats_path, "w") as f:
    |          ^^^^
266 |         json.dump(stats, f, indent=2)
267 |     print(f"✓ Generated statistics: {stats_path}")
    |
help: Replace with `Path.open()`

F841 Local variable `dedup` is assigned to but never used
  --> scripts/canonicalization/initialize_deduplication.py:65:5
   |
64 |     hasher = DocumentHasher()
65 |     dedup = Deduplicator()
   |     ^^^^^
66 |
67 |     # Find all markdown email files
   |
help: Remove assignment to unused variable `dedup`

F841 Local variable `documents` is assigned to but never used
  --> scripts/canonicalization/initialize_deduplication.py:72:5
   |
70 |     print(f"Found {len(email_files)} email files")
71 |
72 |     documents = []
   |     ^^^^^^^^^
73 |     processed_count = 0
74 |     duplicate_count = 0
   |
help: Remove assignment to unused variable `documents`

F841 Local variable `fuzzy_hash` is assigned to but never used
  --> scripts/canonicalization/initialize_deduplication.py:87:13
   |
85 |             file_hash = hasher.hash_file(email_file)
86 |             content_hash = hasher.hash_content(text)
87 |             fuzzy_hash = hasher.hash_fuzzy(text)
   |             ^^^^^^^^^^
88 |
89 |             # Generate canonical ID
   |
help: Remove assignment to unused variable `fuzzy_hash`

ARG001 Unused function argument: `db`
   --> scripts/canonicalization/initialize_deduplication.py:244:27
    |
244 | def test_bulk_performance(db: CanonicalDatabase):
    |                           ^^
245 |     """
246 |     Test bulk insertion performance.
    |

PLC0415 `import` should be at the top-level of a file
   --> scripts/canonicalization/initialize_deduplication.py:255:5
    |
254 |     # Simulate processing time
255 |     import time
    |     ^^^^^^^^^^^
256 |
257 |     test_texts = [
    |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/canonicalization/process_bulk_emails.py:29:1
   |
27 | from datetime import datetime
28 | from pathlib import Path
29 | from typing import List
   | ^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/canonicalization/process_bulk_emails.py:173:37
    |
171 |         self._print_summary()
172 |
173 |     def _process_batch(self, files: List[Path]):
    |                                     ^^^^
174 |         """
175 |         Process batch of files.
    |
help: Replace with `list`

F841 Local variable `fuzzy_hash` is assigned to but never used
   --> scripts/canonicalization/process_bulk_emails.py:213:9
    |
211 |         file_hash = self.hasher.hash_file(file_path)
212 |         content_hash = self.hasher.hash_content(text)
213 |         fuzzy_hash = self.hasher.hash_fuzzy(text) if not self.skip_duplicates else None
    |         ^^^^^^^^^^
214 |
215 |         # Check for duplicates
    |
help: Remove assignment to unused variable `fuzzy_hash`

PLC0415 `import` should be at the top-level of a file
   --> scripts/canonicalization/query_deduplication.py:296:9
    |
294 |     elif format == "csv":
295 |         # Convert to CSV
296 |         import csv
    |         ^^^^^^^^^^
297 |         with output_file.open("w", newline="") as f:
298 |             if rows:
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/classification/classify_all_documents.py:12:1
   |
10 | from collections import defaultdict
11 | from pathlib import Path
12 | from typing import Dict, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/classification/classify_all_documents.py:12:1
   |
10 | from collections import defaultdict
11 | from pathlib import Path
12 | from typing import Dict, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/classification/classify_all_documents.py:30:14
   |
28 |     def __init__(self, entities_index_path: Path):
29 |         """Load entity index"""
30 |         with open(entities_index_path) as f:
   |              ^^^^
31 |             self.entities_data = json.load(f)
   |
help: Replace with `Path.open()`

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/classification/classify_all_documents.py:51:51
   |
49 |         print(f"Loaded {len(self.entity_names)} entity name variations")
50 |
51 |     def find_entities_in_text(self, text: str) -> Set[str]:
   |                                                   ^^^
52 |         """Find entity names mentioned in text"""
53 |         text_lower = text.lower()
   |
help: Replace with `set`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_all_documents.py:64:49
   |
62 |         return found_entities
63 |
64 |     def index_document(self, filepath: Path) -> Dict:
   |                                                 ^^^^
65 |         """Create semantic index entry for a document"""
66 |         try:
   |
help: Replace with `dict`

F841 Local variable `semantic_index` is assigned to but never used
   --> scripts/classification/classify_all_documents.py:103:5
    |
101 |     # Classify all documents
102 |     results = {}
103 |     semantic_index = {}
    |     ^^^^^^^^^^^^^^
104 |     entity_to_docs = defaultdict(list)
    |
help: Remove assignment to unused variable `semantic_index`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/classification/classify_all_documents.py:137:10
    |
135 |     # Save classification results
136 |     classification_path = METADATA_DIR / "document_classifications.json"
137 |     with open(classification_path, "w") as f:
    |          ^^^^
138 |         json.dump({
139 |             "generated": "2025-11-16T23:35:00",
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/classification/classify_all_documents.py:148:10
    |
146 |     # Save semantic index (entity -> documents)
147 |     semantic_index_path = METADATA_DIR / "semantic_index.json"
148 |     with open(semantic_index_path, "w") as f:
    |          ^^^^
149 |         json.dump({
150 |             "generated": "2025-11-16T23:35:00",
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_all_documents.py:160:34
    |
158 |     generate_statistics(results, entity_to_docs)
159 |
160 | def generate_statistics(results: Dict, entity_to_docs: Dict):
    |                                  ^^^^
161 |     """Generate classification and semantic statistics"""
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_all_documents.py:160:56
    |
158 |     generate_statistics(results, entity_to_docs)
159 |
160 | def generate_statistics(results: Dict, entity_to_docs: Dict):
    |                                                        ^^^^
161 |     """Generate classification and semantic statistics"""
    |
help: Replace with `dict`

B007 Loop control variable `filepath` not used within loop body
   --> scripts/classification/classify_all_documents.py:170:9
    |
168 |     total_entity_mentions = 0
169 |
170 |     for filepath, data in results.items():
    |         ^^^^^^^^
171 |         doc_type = data["type"]
172 |         confidence = data["confidence"]
    |
help: Rename unused `filepath` to `_filepath`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/classification/classify_emails.py:13:1
   |
11 | from datetime import datetime
12 | from pathlib import Path
13 | from typing import Any, Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

E402 Module level import not at top of file
  --> scripts/classification/classify_emails.py:22:1
   |
21 | # Import existing classifier
22 | from classification.document_classifier import DocumentClassifier
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:30:45
   |
28 | CLASSIFICATIONS_FILE = METADATA_DIR / "document_classifications.json"
29 |
30 | def load_email_data(metadata_file: Path) -> Dict[str, Any]:
   |                                             ^^^^
31 |     """Load email metadata and full text."""
32 |     with open(metadata_file) as f:
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/classification/classify_emails.py:32:10
   |
30 | def load_email_data(metadata_file: Path) -> Dict[str, Any]:
31 |     """Load email metadata and full text."""
32 |     with open(metadata_file) as f:
   |          ^^^^
33 |         metadata = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/classification/classify_emails.py:41:14
   |
40 |     if full_text_file.exists():
41 |         with open(full_text_file) as f:
   |              ^^^^
42 |             full_text = f.read()
43 |     else:
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:52:32
   |
50 |     }
51 |
52 | def classify_email(email_data: Dict[str, Any], classifier: DocumentClassifier) -> Dict[str, Any]:
   |                                ^^^^
53 |     """Classify a single email using the document classifier."""
54 |     # Combine metadata and full text for classification
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:52:83
   |
50 |     }
51 |
52 | def classify_email(email_data: Dict[str, Any], classifier: DocumentClassifier) -> Dict[str, Any]:
   |                                                                                   ^^^^
53 |     """Classify a single email using the document classifier."""
54 |     # Combine metadata and full text for classification
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:89:21
   |
88 | def enhance_email_classification(
89 |     classification: Dict[str, Any],
   |                     ^^^^
90 |     metadata: Dict[str, Any],
91 |     full_text: str
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:90:15
   |
88 | def enhance_email_classification(
89 |     classification: Dict[str, Any],
90 |     metadata: Dict[str, Any],
   |               ^^^^
91 |     full_text: str
92 | ) -> Dict[str, Any]:
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/classify_emails.py:92:6
   |
90 |     metadata: Dict[str, Any],
91 |     full_text: str
92 | ) -> Dict[str, Any]:
   |      ^^^^
93 |     """Enhance classification with email-specific patterns."""
94 |     text_lower = full_text.lower()
   |
help: Replace with `dict`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/classification/classify_emails.py:137:5
    |
135 |           classification["keywords"].append("COURT_NOTIFICATION")
136 |
137 | /     if legal_score >= 3:
138 | |         if classification["type"] != "court_filing":
    | |____________________________________________________^
139 |               classification["type"] = "court_filing"
140 |               classification["confidence"] = max(classification["confidence"], 0.8)
    |
help: Combine `if` statements using `and`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_emails.py:157:30
    |
155 |     return classification
156 |
157 | def classify_all_emails() -> Dict[str, Any]:
    |                              ^^^^
158 |     """Classify all extracted emails."""
159 |     print("\n" + "="*80)
    |
help: Replace with `dict`

F841 Local variable `doc_id` is assigned to but never used
   --> scripts/classification/classify_emails.py:184:9
    |
182 |         # Load email data
183 |         email_data = load_email_data(metadata_file)
184 |         doc_id = email_data["metadata"].get("document_id", f"email_{i}")
    |         ^^^^^^
185 |
186 |         # Classify
    |
help: Remove assignment to unused variable `doc_id`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_emails.py:216:62
    |
214 |     }
215 |
216 | def merge_with_existing_classifications(new_classifications: Dict[str, Any]) -> Dict[str, Any]:
    |                                                              ^^^^
217 |     """Merge email classifications with existing document classifications."""
218 |     # Load existing classifications
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_emails.py:216:81
    |
214 |     }
215 |
216 | def merge_with_existing_classifications(new_classifications: Dict[str, Any]) -> Dict[str, Any]:
    |                                                                                 ^^^^
217 |     """Merge email classifications with existing document classifications."""
218 |     # Load existing classifications
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/classification/classify_emails.py:220:14
    |
218 |     # Load existing classifications
219 |     if CLASSIFICATIONS_FILE.exists():
220 |         with open(CLASSIFICATIONS_FILE) as f:
    |              ^^^^
221 |             existing = json.load(f)
222 |     else:
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_emails.py:242:43
    |
240 |     return existing
241 |
242 | def save_classifications(classifications: Dict[str, Any]) -> None:
    |                                           ^^^^
243 |     """Save classifications to file."""
244 |     with open(CLASSIFICATIONS_FILE, "w") as f:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/classification/classify_emails.py:244:10
    |
242 | def save_classifications(classifications: Dict[str, Any]) -> None:
243 |     """Save classifications to file."""
244 |     with open(CLASSIFICATIONS_FILE, "w") as f:
    |          ^^^^
245 |         json.dump(classifications, f, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/classification/classify_emails.py:263:10
    |
261 |     }
262 |
263 |     with open(email_classifications_file, "w") as f:
    |          ^^^^
264 |         json.dump(email_only, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/classify_emails.py:268:26
    |
266 |     print(f"✅ Email classifications saved to: {email_classifications_file}")
267 |
268 | def print_summary(stats: Dict[str, Any]) -> None:
    |                          ^^^^
269 |     """Print classification summary."""
270 |     print("\n" + "="*80)
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/classification/classify_emails.py:304:9
    |
302 |     except Exception as e:
303 |         print(f"\n❌ Error: {e}")
304 |         import traceback
    |         ^^^^^^^^^^^^^^^^
305 |         traceback.print_exc()
306 |         return 1
    |

PLR1722 Use `sys.exit()` instead of `exit`
   --> scripts/classification/classify_emails.py:311:5
    |
310 | if __name__ == "__main__":
311 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/classification/document_classifier.py:11:1
   |
 9 | from enum import Enum
10 | from pathlib import Path
11 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/classification/document_classifier.py:11:1
   |
 9 | from enum import Enum
10 | from pathlib import Path
11 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/classification/document_classifier.py:11:1
   |
 9 | from enum import Enum
10 | from pathlib import Path
11 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/classification/document_classifier.py:33:22
   |
31 |     document_type: DocumentType
32 |     confidence: float
33 |     secondary_types: List[Tuple[DocumentType, float]]
   |                      ^^^^
34 |     keywords_found: List[str]
35 |     metadata: Dict
   |
help: Replace with `list`

UP006 Use `tuple` instead of `Tuple` for type annotation
  --> scripts/classification/document_classifier.py:33:27
   |
31 |     document_type: DocumentType
32 |     confidence: float
33 |     secondary_types: List[Tuple[DocumentType, float]]
   |                           ^^^^^
34 |     keywords_found: List[str]
35 |     metadata: Dict
   |
help: Replace with `tuple`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/classification/document_classifier.py:34:21
   |
32 |     confidence: float
33 |     secondary_types: List[Tuple[DocumentType, float]]
34 |     keywords_found: List[str]
   |                     ^^^^
35 |     metadata: Dict
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/classification/document_classifier.py:35:15
   |
33 |     secondary_types: List[Tuple[DocumentType, float]]
34 |     keywords_found: List[str]
35 |     metadata: Dict
   |               ^^^^
36 |
37 | class DocumentClassifier:
   |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> scripts/classification/document_classifier.py:41:16
    |
 40 |       # Keyword patterns for each document type
 41 |       PATTERNS = {
    |  ________________^
 42 | |         DocumentType.EMAIL: {
 43 | |             "keywords": [
 44 | |                 r"From:\s*[\w\s@.-]+",
 45 | |                 r"To:\s*[\w\s@.-]+",
 46 | |                 r"Subject:\s*.+",
 47 | |                 r"Date:\s*\d{1,2}/\d{1,2}/\d{2,4}",
 48 | |                 r"Sent:\s*\w+",
 49 | |                 r"CC:\s*[\w\s@.-]+",
 50 | |                 r"@\w+\.\w+",  # Email addresses
 51 | |                 r"Re:\s*.+",
 52 | |                 r"Fwd:\s*.+"
 53 | |             ],
 54 | |             "weight": 1.0,
 55 | |             "min_matches": 3
 56 | |         },
 57 | |         DocumentType.COURT_FILING: {
 58 | |             "keywords": [
 59 | |                 r"UNITED STATES DISTRICT COURT",
 60 | |                 r"SOUTHERN DISTRICT OF",
 61 | |                 r"CASE NO\.",
 62 | |                 r"Plaintiff[s]?",
 63 | |                 r"Defendant[s]?",
 64 | |                 r"MOTION TO",
 65 | |                 r"COMPLAINT",
 66 | |                 r"DEPOSITION",
 67 | |                 r"AFFIDAVIT",
 68 | |                 r"EXHIBIT\s+[A-Z0-9]+",
 69 | |                 r"WHEREFORE",
 70 | |                 r"Respectfully submitted",
 71 | |                 r"DECLARATION OF",
 72 | |                 r"COMES NOW",
 73 | |                 r"v\.",  # versus in case names
 74 | |                 r"Counsel for"
 75 | |             ],
 76 | |             "weight": 1.0,
 77 | |             "min_matches": 4
 78 | |         },
 79 | |         DocumentType.FINANCIAL: {
 80 | |             "keywords": [
 81 | |                 r"\$[\d,]+\.?\d*",  # Dollar amounts
 82 | |                 r"INVOICE",
 83 | |                 r"STATEMENT",
 84 | |                 r"WIRE TRANSFER",
 85 | |                 r"ACCOUNT NUMBER",
 86 | |                 r"ROUTING NUMBER",
 87 | |                 r"TAX RETURN",
 88 | |                 r"BALANCE",
 89 | |                 r"PAYMENT",
 90 | |                 r"TRANSACTION",
 91 | |                 r"CREDIT",
 92 | |                 r"DEBIT",
 93 | |                 r"JPMorgan",
 94 | |                 r"Deutsche Bank",
 95 | |                 r"Chase",
 96 | |                 r"SWIFT"
 97 | |             ],
 98 | |             "weight": 0.9,
 99 | |             "min_matches": 3
100 | |         },
101 | |         DocumentType.FLIGHT_LOG: {
102 | |             "keywords": [
103 | |                 r"PASSENGER",
104 | |                 r"DEPARTURE",
105 | |                 r"ARRIVAL",
106 | |                 r"AIRCRAFT",
107 | |                 r"TAIL NUMBER",
108 | |                 r"N\d{3,5}[A-Z]{1,2}",  # Tail number pattern
109 | |                 r"FLIGHT\s+LOG",
110 | |                 r"MANIFEST",
111 | |                 r"CREW",
112 | |                 r"ROUTE",
113 | |                 r"TEB",  # Teterboro Airport
114 | |                 r"PBI",  # Palm Beach Airport
115 | |                 r"Gulfstream"
116 | |             ],
117 | |             "weight": 1.0,
118 | |             "min_matches": 4
119 | |         },
120 | |         DocumentType.CONTACT_BOOK: {
121 | |             "keywords": [
122 | |                 r"ADDRESS BOOK",
123 | |                 r"CONTACTS",
124 | |                 r"PHONE:\s*[\d\s\-\(\)]+",
125 | |                 r"MOBILE:\s*[\d\s\-\(\)]+",
126 | |                 r"EMAIL:\s*[\w@.-]+",
127 | |                 r"ADDRESS:",
128 | |                 r"FAX:\s*[\d\s\-\(\)]+",
129 | |                 r"ASSISTANT:",
130 | |                 r"BLACK BOOK",
131 | |                 r"LITTLE BLACK BOOK"
132 | |             ],
133 | |             "weight": 1.0,
134 | |             "min_matches": 4
135 | |         },
136 | |         DocumentType.INVESTIGATIVE: {
137 | |             "keywords": [
138 | |                 r"FBI",
139 | |                 r"INVESTIGATION",
140 | |                 r"AGENT",
141 | |                 r"INTERVIEW",
142 | |                 r"WITNESS",
143 | |                 r"EVIDENCE",
144 | |                 r"SURVEILLANCE",
145 | |                 r"SUBPOENA",
146 | |                 r"GRAND JURY",
147 | |                 r"SEARCH WARRANT",
148 | |                 r"PROBABLE CAUSE",
149 | |                 r"CONFIDENTIAL",
150 | |                 r"CLASSIFIED"
151 | |             ],
152 | |             "weight": 0.95,
153 | |             "min_matches": 3
154 | |         },
155 | |         DocumentType.LEGAL_AGREEMENT: {
156 | |             "keywords": [
157 | |                 r"AGREEMENT",
158 | |                 r"CONTRACT",
159 | |                 r"WHEREAS",
160 | |                 r"NOW THEREFORE",
161 | |                 r"PARTY OF THE FIRST PART",
162 | |                 r"CONSIDERATION",
163 | |                 r"NON-DISCLOSURE",
164 | |                 r"NDA",
165 | |                 r"SETTLEMENT",
166 | |                 r"INDEMNIFICATION",
167 | |                 r"BINDING",
168 | |                 r"EXECUTED THIS"
169 | |             ],
170 | |             "weight": 0.95,
171 | |             "min_matches": 4
172 | |         },
173 | |         DocumentType.PERSONAL: {
174 | |             "keywords": [
175 | |                 r"DIARY",
176 | |                 r"JOURNAL",
177 | |                 r"PERSONAL NOTE",
178 | |                 r"BIRTHDAY",
179 | |                 r"CALENDAR",
180 | |                 r"SCHEDULE",
181 | |                 r"APPOINTMENT",
182 | |                 r"REMINDER",
183 | |                 r"TO DO",
184 | |                 r"MEMO TO SELF"
185 | |             ],
186 | |             "weight": 0.85,
187 | |             "min_matches": 2
188 | |         },
189 | |         DocumentType.MEDIA: {
190 | |             "keywords": [
191 | |                 r"PRESS RELEASE",
192 | |                 r"NEWS ARTICLE",
193 | |                 r"JOURNALIST",
194 | |                 r"REPORTER",
195 | |                 r"PUBLICATION",
196 | |                 r"New York Times",
197 | |                 r"Washington Post",
198 | |                 r"Bloomberg",
199 | |                 r"Miami Herald",
200 | |                 r"INTERVIEW TRANSCRIPT",
201 | |                 r"ON THE RECORD"
202 | |             ],
203 | |             "weight": 0.9,
204 | |             "min_matches": 2
205 | |         },
206 | |         DocumentType.ADMINISTRATIVE: {
207 | |             "keywords": [
208 | |                 r"MEMORANDUM",
209 | |                 r"POLICY",
210 | |                 r"PROCEDURE",
211 | |                 r"GUIDELINES",
212 | |                 r"INTERNAL",
213 | |                 r"HR",
214 | |                 r"EMPLOYEE",
215 | |                 r"STAFF",
216 | |                 r"OFFICE",
217 | |                 r"ADMINISTRATIVE"
218 | |             ],
219 | |             "weight": 0.8,
220 | |             "min_matches": 2
221 | |         }
222 | |     }
    | |_____^
223 |
224 |       def __init__(self):
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/classification/document_classifier.py:320:41
    |
318 |             )
319 |
320 |     def classify_batch(self, filepaths: List[Path]) -> Dict[str, ClassificationResult]:
    |                                         ^^^^
321 |         """Classify multiple files"""
322 |         results = {}
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/document_classifier.py:320:56
    |
318 |             )
319 |
320 |     def classify_batch(self, filepaths: List[Path]) -> Dict[str, ClassificationResult]:
    |                                                        ^^^^
321 |         """Classify multiple files"""
322 |         results = {}
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/classification/document_classifier.py:327:45
    |
325 |         return results
326 |
327 | def generate_classification_report(results: Dict[str, ClassificationResult]) -> str:
    |                                             ^^^^
328 |     """Generate a human-readable classification report"""
    |
help: Replace with `dict`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/core/database.py:15:1
   |
13 | from contextlib import contextmanager
14 | from pathlib import Path
15 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/core/database.py:15:1
   |
13 | from contextlib import contextmanager
14 | from pathlib import Path
15 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:197:46
    |
195 |     # ==================== Canonical Documents ====================
196 |
197 |     def insert_canonical_document(self, doc: Dict) -> str:
    |                                              ^^^^
198 |         """
199 |         Insert a new canonical document.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:240:69
    |
238 |         return doc["canonical_id"]
239 |
240 |     def get_canonical_document(self, canonical_id: str) -> Optional[Dict]:
    |                                                                     ^^^^
241 |         """
242 |         Retrieve canonical document by ID.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:268:67
    |
266 |         return None
267 |
268 |     def find_by_content_hash(self, content_hash: str) -> Optional[Dict]:
    |                                                                   ^^^^
269 |         """
270 |         Find document by content hash.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:297:37
    |
295 |     # ==================== Document Sources ====================
296 |
297 |     def insert_source(self, source: Dict) -> int:
    |                                     ^^^^
298 |         """
299 |         Insert a document source.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/database.py:331:49
    |
329 |             return cursor.lastrowid
330 |
331 |     def get_sources(self, canonical_id: str) -> List[Dict]:
    |                                                 ^^^^
332 |         """
333 |         Get all sources for a canonical document.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:331:54
    |
329 |             return cursor.lastrowid
330 |
331 |     def get_sources(self, canonical_id: str) -> List[Dict]:
    |                                                      ^^^^
332 |         """
333 |         Get all sources for a canonical document.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:353:45
    |
351 |     # ==================== Duplicate Groups ====================
352 |
353 |     def insert_duplicate_group(self, group: Dict) -> int:
    |                                             ^^^^
354 |         """
355 |         Insert a duplicate group entry.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/database.py:379:52
    |
377 |             return cursor.lastrowid
378 |
379 |     def get_duplicates(self, canonical_id: str) -> List[Dict]:
    |                                                    ^^^^
380 |         """
381 |         Get all duplicates for a document.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:379:57
    |
377 |             return cursor.lastrowid
378 |
379 |     def get_duplicates(self, canonical_id: str) -> List[Dict]:
    |                                                         ^^^^
380 |         """
381 |         Get all duplicates for a document.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:400:47
    |
398 |     # ==================== Partial Overlaps ====================
399 |
400 |     def insert_partial_overlap(self, overlap: Dict) -> int:
    |                                               ^^^^
401 |         """Insert a partial overlap entry."""
402 |         with self.get_connection() as conn:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:424:45
    |
423 |     def log(self, operation: str, source: str, status: str,
424 |             message: str, details: Optional[Dict] = None):
    |                                             ^^^^
425 |         """
426 |         Add entry to processing log.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/database.py:450:52
    |
448 |             ))
449 |
450 |     def get_recent_logs(self, limit: int = 100) -> List[Dict]:
    |                                                    ^^^^
451 |         """Get recent processing log entries."""
452 |         with self.get_connection() as conn:
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:450:57
    |
448 |             ))
449 |
450 |     def get_recent_logs(self, limit: int = 100) -> List[Dict]:
    |                                                         ^^^^
451 |         """Get recent processing log entries."""
452 |         with self.get_connection() as conn:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/database.py:465:33
    |
463 |     # ==================== Statistics ====================
464 |
465 |     def get_statistics(self) -> Dict:
    |                                 ^^^^
466 |         """
467 |         Generate database statistics.
    |
help: Replace with `dict`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/core/deduplicator.py:14:1
   |
12 | from difflib import SequenceMatcher
13 | from pathlib import Path
14 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/core/deduplicator.py:14:1
   |
12 | from difflib import SequenceMatcher
13 | from pathlib import Path
14 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/core/deduplicator.py:14:1
   |
12 | from difflib import SequenceMatcher
13 | from pathlib import Path
14 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/core/deduplicator.py:30:26
   |
28 |     # Metadata (for emails)
29 |     from_person: Optional[str] = None
30 |     to_persons: Optional[List[str]] = None
   |                          ^^^^
31 |     date: Optional[str] = None
32 |     subject: Optional[str] = None
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/core/deduplicator.py:35:27
   |
34 |     # Page hashes (for partial overlap)
35 |     page_hashes: Optional[Dict[int, str]] = None
   |                           ^^^^
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/core/deduplicator.py:51:11
   |
49 |     """
50 |     type: str
51 |     docs: List[str]
   |           ^^^^
52 |     similarity: float
53 |     method: str
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/core/deduplicator.py:54:24
   |
52 |     similarity: float
53 |     method: str
54 |     metadata: Optional[Dict] = None
   |                        ^^^^
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:100:38
    |
 98 |         self.partial_overlap_max = partial_overlap_max
 99 |
100 |     def deduplicate(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                      ^^^^
101 |         """
102 |         Run all deduplication phases.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:100:57
    |
 98 |         self.partial_overlap_max = partial_overlap_max
 99 |
100 |     def deduplicate(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                         ^^^^
101 |         """
102 |         Run all deduplication phases.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:140:50
    |
138 |         return all_groups
139 |
140 |     def detect_exact_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                  ^^^^
141 |         """
142 |         Phase 1: Detect exact duplicates using file and content hashes.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:140:69
    |
138 |         return all_groups
139 |
140 |     def detect_exact_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                                     ^^^^
141 |         """
142 |         Phase 1: Detect exact duplicates using file and content hashes.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:194:50
    |
192 |         return groups
193 |
194 |     def detect_fuzzy_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                  ^^^^
195 |         """
196 |         Phase 2: Detect fuzzy duplicates using similarity matching.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:194:69
    |
192 |         return groups
193 |
194 |     def detect_fuzzy_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                                     ^^^^
195 |         """
196 |         Phase 2: Detect fuzzy duplicates using similarity matching.
    |
help: Replace with `list`

PLC0415 `import` should be at the top-level of a file
   --> scripts/core/deduplicator.py:251:17
    |
249 |         if doc_a.fuzzy_hash and doc_b.fuzzy_hash:
250 |             try:
251 |                 import ssdeep
    |                 ^^^^^^^^^^^^^
252 |                 # Strip 'ssdeep:' prefix
253 |                 hash_a = doc_a.fuzzy_hash.replace("ssdeep:", "")
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:269:53
    |
267 |         return max(scores) if scores else 0.0
268 |
269 |     def detect_metadata_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                     ^^^^
270 |         """
271 |         Phase 3: Detect duplicates using email metadata.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:269:72
    |
267 |         return max(scores) if scores else 0.0
268 |
269 |     def detect_metadata_duplicates(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                                        ^^^^
270 |         """
271 |         Phase 3: Detect duplicates using email metadata.
    |
help: Replace with `list`

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/core/deduplicator.py:307:54
    |
306 |     @staticmethod
307 |     def _create_metadata_signature(doc: Document) -> Tuple:
    |                                                      ^^^^^
308 |         """
309 |         Create hashable metadata signature for email.
    |
help: Replace with `tuple`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:328:50
    |
326 |         return (from_email, to_emails, doc.date, subject)
327 |
328 |     def detect_partial_overlaps(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                  ^^^^
329 |         """
330 |         Phase 4: Detect documents with partial page overlaps.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:328:69
    |
326 |         return (from_email, to_emails, doc.date, subject)
327 |
328 |     def detect_partial_overlaps(self, documents: List[Document]) -> List[DuplicateGroup]:
    |                                                                     ^^^^
329 |         """
330 |         Phase 4: Detect documents with partial page overlaps.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/deduplicator.py:365:19
    |
363 |         doc_a: Document,
364 |         doc_b: Document
365 |     ) -> Optional[Dict]:
    |                   ^^^^
366 |         """
367 |         Calculate page overlap between two documents.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/core/deduplicator.py:414:35
    |
413 |     @staticmethod
414 |     def _format_page_range(pages: List[int]) -> str:
    |                                   ^^^^
415 |         """
416 |         Format list of page numbers as range string.
    |
help: Replace with `list`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/core/hasher.py:14:1
   |
12 | import re
13 | from pathlib import Path
14 | from typing import Dict, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/core/hasher.py:14:1
   |
12 | import re
13 | from pathlib import Path
14 | from typing import Dict, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLC0415 `import` should be at the top-level of a file
  --> scripts/core/hasher.py:39:13
   |
37 |         """Check if ssdeep library is available for fuzzy hashing."""
38 |         try:
39 |             import ssdeep
   |             ^^^^^^^^^^^^^
40 |             return True
41 |         except ImportError:
   |

F401 `ssdeep` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/core/hasher.py:39:20
   |
37 |         """Check if ssdeep library is available for fuzzy hashing."""
38 |         try:
39 |             import ssdeep
   |                    ^^^^^^
40 |             return True
41 |         except ImportError:
   |
help: Remove unused import: `ssdeep`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/core/hasher.py:58:14
   |
56 |         sha256 = hashlib.sha256()
57 |
58 |         with open(file_path, "rb") as f:
   |              ^^^^
59 |             # Read in 8KB chunks for memory efficiency
60 |             while chunk := f.read(8192):
   |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> scripts/core/hasher.py:103:9
    |
101 |             return None
102 |
103 |         import ssdeep
    |         ^^^^^^^^^^^^^
104 |         return f"ssdeep:{ssdeep.hash(text)}"
    |

RUF001 String contains ambiguous `‐` (HYPHEN). Did you mean `-` (HYPHEN-MINUS)?
   --> scripts/core/hasher.py:141:30
    |
139 |         # Remove common OCR artifacts
140 |         # Replace common OCR misreads
141 |         text = text.replace("‐", "-")  # Unicode hyphen to ASCII
    |                              ^
142 |         text = text.replace("–", "-")  # En dash to hyphen
143 |         text = text.replace("—", "-")  # Em dash to hyphen
    |

RUF001 String contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
   --> scripts/core/hasher.py:142:30
    |
140 |         # Replace common OCR misreads
141 |         text = text.replace("‐", "-")  # Unicode hyphen to ASCII
142 |         text = text.replace("–", "-")  # En dash to hyphen
    |                              ^
143 |         text = text.replace("—", "-")  # Em dash to hyphen
144 |         text = text.replace('"', '"').replace('"', '"')  # Smart quotes
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/hasher.py:155:77
    |
153 |         return text
154 |
155 |     def hash_document(self, file_path: Path, text: Optional[str] = None) -> Dict[str, str]:
    |                                                                             ^^^^
156 |         """
157 |         Generate all hash types for a document.
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/core/hasher.py:201:9
    |
199 |             ImportError: If ssdeep not available
200 |         """
201 |         import ssdeep
    |         ^^^^^^^^^^^^^
202 |
203 |         # Strip 'ssdeep:' prefix if present
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/hasher.py:228:42
    |
226 |         self.hasher = DocumentHasher()
227 |
228 |     def hash_pages(self, pages: list) -> Dict[int, str]:
    |                                          ^^^^
229 |         """
230 |         Hash each page individually.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/hasher.py:255:18
    |
253 |     def find_common_pages(
254 |         self,
255 |         pages_a: Dict[int, str],
    |                  ^^^^
256 |         pages_b: Dict[int, str]
257 |     ) -> Tuple[set, float, float]:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/core/hasher.py:256:18
    |
254 |         self,
255 |         pages_a: Dict[int, str],
256 |         pages_b: Dict[int, str]
    |                  ^^^^
257 |     ) -> Tuple[set, float, float]:
258 |         """
    |
help: Replace with `dict`

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/core/hasher.py:257:10
    |
255 |         pages_a: Dict[int, str],
256 |         pages_b: Dict[int, str]
257 |     ) -> Tuple[set, float, float]:
    |          ^^^^^
258 |         """
259 |         Find common pages between two documents.
    |
help: Replace with `tuple`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/core/ocr_quality.py:14:1
   |
12 | import unicodedata
13 | from pathlib import Path
14 | from typing import Dict, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/core/ocr_quality.py:14:1
   |
12 | import unicodedata
13 | from pathlib import Path
14 | from typing import Dict, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/core/ocr_quality.py:14:1
   |
12 | import unicodedata
13 | from pathlib import Path
14 | from typing import Dict, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F821 Undefined name `Optional`
  --> scripts/core/ocr_quality.py:38:41
   |
36 |     """
37 |
38 |     def __init__(self, dictionary_path: Optional[Path] = None):
   |                                         ^^^^^^^^
39 |         """
40 |         Initialize OCR quality assessor.
   |

F821 Undefined name `Optional`
  --> scripts/core/ocr_quality.py:48:49
   |
46 |         self.dictionary = self._load_dictionary(dictionary_path)
47 |
48 |     def _load_dictionary(self, dictionary_path: Optional[Path]) -> Set[str]:
   |                                                 ^^^^^^^^
49 |         """
50 |         Load word dictionary for lexical validation.
   |

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/core/ocr_quality.py:48:68
   |
46 |         self.dictionary = self._load_dictionary(dictionary_path)
47 |
48 |     def _load_dictionary(self, dictionary_path: Optional[Path]) -> Set[str]:
   |                                                                    ^^^
49 |         """
50 |         Load word dictionary for lexical validation.
   |
help: Replace with `set`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/core/ocr_quality.py:56:18
   |
54 |         """
55 |         if dictionary_path and dictionary_path.exists():
56 |             with open(dictionary_path) as f:
   |                  ^^^^
57 |                 return {line.strip().lower() for line in f if line.strip()}
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/core/ocr_quality.py:74:36
   |
72 |         }
73 |
74 |     def assess(self, text: str) -> Dict[str, float]:
   |                                    ^^^^
75 |         """
76 |         Assess OCR quality of text.
   |
help: Replace with `dict`

SIM103 Return the condition directly
   --> scripts/core/ocr_quality.py:178:9
    |
177 |           # Numbers with letters (dates, IDs, etc.)
178 | /         if any(c.isdigit() for c in word) and any(c.isalpha() for c in word):
179 | |             return True
180 | |
181 | |         return False
    | |____________________^
182 |
183 |       def _assess_corruption(self, text: str) -> float:
    |
help: Inline condition

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/core/ocr_quality.py:286:41
    |
286 | def calculate_ocr_quality(text: str) -> Tuple[float, str]:
    |                                         ^^^^^
287 |     """
288 |     Convenience function to calculate OCR quality.
    |
help: Replace with `tuple`

E402 Module level import not at top of file
  --> scripts/database/init_audit_db.py:23:1
   |
21 | sys.path.insert(0, str(SERVER_DIR))
22 |
23 | from services.audit_logger import AuditLogger
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F841 Local variable `logger` is assigned to but never used
  --> scripts/database/init_audit_db.py:36:5
   |
35 |     # Create audit logger (initializes database)
36 |     logger = AuditLogger(db_path)
   |     ^^^^^^
37 |
38 |     print("✓ Database created successfully")
   |
help: Remove assignment to unused variable `logger`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/download/check_courtlistener_progress.py:14:10
   |
12 | # Load metadata
13 | if metadata_file.exists():
14 |     with open(metadata_file) as f:
   |          ^^^^
15 |         metadata = json.load(f)
   |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/download/download_all_sources.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | import requests
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/download/download_all_sources.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | import requests
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/download/download_all_sources.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | import requests
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/download/download_all_sources.py:23:1
   |
21 | from datetime import datetime
22 | from pathlib import Path
23 | from typing import Dict, List, Optional, Set, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | import requests
   |

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/download/download_all_sources.py:69:33
   |
68 |         # Track downloads and deduplication
69 |         self.downloaded_hashes: Set[str] = set()
   |                                 ^^^
70 |         self.download_log: List[DownloadMetadata] = []
71 |         self.duplicate_count = 0
   |
help: Replace with `set`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/download/download_all_sources.py:70:28
   |
68 |         # Track downloads and deduplication
69 |         self.downloaded_hashes: Set[str] = set()
70 |         self.download_log: List[DownloadMetadata] = []
   |                            ^^^^
71 |         self.duplicate_count = 0
72 |         self.success_count = 0
   |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/download/download_all_sources.py:87:22
   |
85 |         if index_path.exists():
86 |             try:
87 |                 with open(index_path) as f:
   |                      ^^^^
88 |                     index = json.load(f)
89 |                     for doc in index.get("documents", []):
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_all_sources.py:105:14
    |
103 |         """
104 |         sha256 = hashlib.sha256()
105 |         with open(filepath, "rb") as f:
    |              ^^^^
106 |             for chunk in iter(lambda: f.read(8192), b""):
107 |                 sha256.update(chunk)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_all_sources.py:130:28
    |
128 |         output_path: Path,
129 |         source_name: str,
130 |         metadata: Optional[Dict] = None,
    |                            ^^^^
131 |         max_retries: int = 3
132 |     ) -> bool:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_all_sources.py:156:22
    |
155 |                 # Write file
156 |                 with open(output_path, "wb") as f:
    |                      ^^^^
157 |                     for chunk in response.iter_content(chunk_size=8192):
158 |                         if chunk:
    |
help: Replace with `Path.open()`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/download/download_all_sources.py:174:39
    |
172 |                         size=0,
173 |                         hash=self.calculate_hash(output_path) if output_path.exists() else "",
174 |                         downloaded_at=datetime.utcnow().isoformat(),
    |                                       ^^^^^^^^^^^^^^^^^
175 |                         duplicate=True,
176 |                         **(metadata or {})
    |
help: Use `datetime.datetime.now(tz=...)` instead

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/download/download_all_sources.py:190:35
    |
188 |                     size=file_size,
189 |                     hash=file_hash,
190 |                     downloaded_at=datetime.utcnow().isoformat(),
    |                                   ^^^^^^^^^^^^^^^^^
191 |                     duplicate=False,
192 |                     **(metadata or {})
    |
help: Use `datetime.datetime.now(tz=...)` instead

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/download/download_all_sources.py:331:39
    |
329 |             logger.info("Internet Archive download complete")
330 |
331 |     def deduplicate_existing(self) -> Tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:
    |                                       ^^^^^
332 |         """Deduplicate all existing downloaded files.
    |
help: Replace with `tuple`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_all_sources.py:331:45
    |
329 |             logger.info("Internet Archive download complete")
330 |
331 |     def deduplicate_existing(self) -> Tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:
    |                                             ^^^^
332 |         """Deduplicate all existing downloaded files.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/download/download_all_sources.py:331:55
    |
329 |             logger.info("Internet Archive download complete")
330 |
331 |     def deduplicate_existing(self) -> Tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:
    |                                                       ^^^^
332 |         """Deduplicate all existing downloaded files.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_all_sources.py:331:68
    |
329 |             logger.info("Internet Archive download complete")
330 |
331 |     def deduplicate_existing(self) -> Tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:
    |                                                                    ^^^^
332 |         """Deduplicate all existing downloaded files.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/download/download_all_sources.py:331:78
    |
329 |             logger.info("Internet Archive download complete")
330 |
331 |     def deduplicate_existing(self) -> Tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:
    |                                                                              ^^^^
332 |         """Deduplicate all existing downloaded files.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_all_sources.py:347:24
    |
345 |         logger.info(f"Found {len(all_pdfs)} PDFs across all sources")
346 |
347 |         hash_to_files: Dict[str, List[Path]] = {}
    |                        ^^^^
348 |
349 |         for i, pdf in enumerate(all_pdfs, 1):
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/download/download_all_sources.py:347:34
    |
345 |         logger.info(f"Found {len(all_pdfs)} PDFs across all sources")
346 |
347 |         hash_to_files: Dict[str, List[Path]] = {}
    |                                  ^^^^
348 |
349 |         for i, pdf in enumerate(all_pdfs, 1):
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_all_sources.py:374:37
    |
372 |         return hash_to_files, duplicates
373 |
374 |     def build_master_index(self) -> Dict:
    |                                     ^^^^
375 |         """Build master index with provenance tracking.
    |
help: Replace with `dict`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/download/download_all_sources.py:393:29
    |
392 |         master_index = {
393 |             "generated_at": datetime.utcnow().isoformat(),
    |                             ^^^^^^^^^^^^^^^^^
394 |             "total_files": sum(len(files) for files in hash_to_files.values()),
395 |             "unique_documents": len(hash_to_files),
    |
help: Use `datetime.datetime.now(tz=...)` instead

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_all_sources.py:442:14
    |
440 |         # Save index
441 |         index_path = self.metadata_dir / "master_document_index.json"
442 |         with open(index_path, "w") as f:
    |              ^^^^
443 |             json.dump(master_index, f, indent=2)
    |
help: Replace with `Path.open()`

PLR0915 Too many statements (78 > 60)
   --> scripts/download/download_all_sources.py:453:9
    |
451 |         return master_index
452 |
453 |     def generate_report(self) -> None:
    |         ^^^^^^^^^^^^^^^
454 |         """Generate comprehensive download and deduplication report."""
455 |         logger.info("\n" + "=" * 70)
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_all_sources.py:463:14
    |
461 |         report_path = self.base_dir / "DOWNLOAD_DEDUPLICATION_REPORT.md"
462 |
463 |         with open(report_path, "w") as f:
    |              ^^^^
464 |             f.write("# Epstein Document Collection - Download & Deduplication Report\n\n")
465 |             f.write(f"**Generated**: {datetime.utcnow().isoformat()}\n\n")
    |
help: Replace with `Path.open()`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/download/download_all_sources.py:465:39
    |
463 |         with open(report_path, "w") as f:
464 |             f.write("# Epstein Document Collection - Download & Deduplication Report\n\n")
465 |             f.write(f"**Generated**: {datetime.utcnow().isoformat()}\n\n")
    |                                       ^^^^^^^^^^^^^^^^^
466 |
467 |             f.write("## Summary Statistics\n\n")
    |
help: Use `datetime.datetime.now(tz=...)` instead

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_all_sources.py:559:14
    |
557 |         # Also save download log as JSON
558 |         log_path = self.metadata_dir / "download_log.json"
559 |         with open(log_path, "w") as f:
    |              ^^^^
560 |             json.dump([asdict(entry) for entry in self.download_log], f, indent=2)
561 |         logger.info(f"Download log saved: {log_path}")
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/download/download_courtlistener.py:32:1
   |
30 | from dataclasses import dataclass
31 | from pathlib import Path
32 | from typing import Dict, List, Optional, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33 | from urllib.parse import urljoin
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/download/download_courtlistener.py:32:1
   |
30 | from dataclasses import dataclass
31 | from pathlib import Path
32 | from typing import Dict, List, Optional, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33 | from urllib.parse import urljoin
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/download/download_courtlistener.py:32:1
   |
30 | from dataclasses import dataclass
31 | from pathlib import Path
32 | from typing import Dict, List, Optional, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33 | from urllib.parse import urljoin
   |

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/download/download_courtlistener.py:88:31
   |
86 |         self.delay = delay
87 |         self.session = requests.Session()
88 |         self.downloaded_urls: Set[str] = set()
   |                               ^^^
89 |
90 |         # Multiple User-Agent strings to rotate through
   |
help: Replace with `set`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/download/download_courtlistener.py:129:33
    |
127 |         logger.info(f"Rotated to User-Agent #{self.current_ua_index}")
128 |
129 |     def _load_metadata(self) -> Dict:
    |                                 ^^^^
130 |         """Load download metadata from JSON file."""
131 |         if self.metadata_file.exists():
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_courtlistener.py:133:22
    |
131 |         if self.metadata_file.exists():
132 |             try:
133 |                 with open(self.metadata_file) as f:
    |                      ^^^^
134 |                     return json.load(f)
135 |             except Exception as e:
    |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> scripts/download/download_courtlistener.py:141:9
    |
139 |     def _save_metadata(self):
140 |         """Save download metadata to JSON file."""
141 |         import datetime
    |         ^^^^^^^^^^^^^^^
142 |         self.metadata["last_update"] = datetime.datetime.now().isoformat()
143 |         with open(self.metadata_file, "w") as f:
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_courtlistener.py:143:14
    |
141 |         import datetime
142 |         self.metadata["last_update"] = datetime.datetime.now().isoformat()
143 |         with open(self.metadata_file, "w") as f:
    |              ^^^^
144 |             json.dump(self.metadata, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/download/download_courtlistener.py:192:58
    |
190 |         return None
191 |
192 |     def extract_document_links(self, docket_url: str) -> List[DocumentLink]:
    |                                                          ^^^^
193 |         """
194 |         Extract all document links from docket page.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/download/download_courtlistener.py:213:16
    |
212 |         soup = BeautifulSoup(response.text, "html.parser")
213 |         links: List[DocumentLink] = []
    |                ^^^^
214 |         seen_urls: Set[str] = set()
    |
help: Replace with `list`

UP006 Use `set` instead of `Set` for type annotation
   --> scripts/download/download_courtlistener.py:214:20
    |
212 |         soup = BeautifulSoup(response.text, "html.parser")
213 |         links: List[DocumentLink] = []
214 |         seen_urls: Set[str] = set()
    |                    ^^^
215 |
216 |         # Extract all RECAP PDF links from storage.courtlistener.com
    |
help: Replace with `set`

E741 Ambiguous variable name: `l`
   --> scripts/download/download_courtlistener.py:267:28
    |
266 |         # Log summary statistics
267 |         main_docs = [l for l in links if l.document_number and l.document_number.endswith(".0")]
    |                            ^
268 |         attachments = [l for l in links if l.document_number and not l.document_number.endswith(".0")]
269 |         logger.info(f"  Main documents: {len(main_docs)}")
    |

E741 Ambiguous variable name: `l`
   --> scripts/download/download_courtlistener.py:268:30
    |
266 |         # Log summary statistics
267 |         main_docs = [l for l in links if l.document_number and l.document_number.endswith(".0")]
268 |         attachments = [l for l in links if l.document_number and not l.document_number.endswith(".0")]
    |                              ^
269 |         logger.info(f"  Main documents: {len(main_docs)}")
270 |         logger.info(f"  Attachments: {len(attachments)}")
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/download/download_courtlistener.py:347:18
    |
346 |             # Save to file
347 |             with open(filepath, "wb") as f:
    |                  ^^^^
348 |                 for chunk in pdf_response.iter_content(chunk_size=8192):
349 |                     f.write(chunk)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/download/query_master_index.py:31:14
   |
30 |         # Load index
31 |         with open(self.index_path) as f:
   |              ^^^^
32 |             self.index = json.load(f)
   |
help: Replace with `Path.open()`

PLR0915 Too many statements (67 > 60)
  --> scripts/download/summarize_courtlistener_download.py:13:5
   |
13 | def summarize_download(output_dir: Path):
   |     ^^^^^^^^^^^^^^^^^^
14 |     """Generate download summary report."""
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/download/summarize_courtlistener_download.py:23:10
   |
21 |         return
22 |
23 |     with open(metadata_file) as f:
   |          ^^^^
24 |         metadata = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/download/summarize_courtlistener_download.py:96:10
   |
94 |     # Save summary to file
95 |     summary_file = output_dir / "DOWNLOAD_SUMMARY.txt"
96 |     with open(summary_file, "w") as f:
   |          ^^^^
97 |         f.write("CourtListener Download Summary - Giuffre v. Maxwell\n")
98 |         f.write(f"{'=' * 70}\n\n")
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/extraction/check_ocr_status.py:49:10
   |
48 |     # Load progress
49 |     with open(PROGRESS_FILE) as f:
   |          ^^^^
50 |         progress = json.load(f)
   |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/extraction/extract_emails.py:20:1
   |
18 | from datetime import datetime
19 | from pathlib import Path
20 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/extraction/extract_emails.py:20:1
   |
18 | from datetime import datetime
19 | from pathlib import Path
20 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/extraction/extract_emails.py:44:22
   |
42 |     body: Optional[str] = None
43 |     confidence: float = 0.0
44 |     email_addresses: List[str] = None
   |                      ^^^^
45 |
46 |     def __post_init__(self):
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/extraction/extract_emails.py:51:48
   |
51 | def load_email_candidates(jsonl_path: Path) -> List[Dict]:
   |                                                ^^^^
52 |     """Load email candidates from JSONL file."""
53 |     candidates = []
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/extraction/extract_emails.py:51:53
   |
51 | def load_email_candidates(jsonl_path: Path) -> List[Dict]:
   |                                                     ^^^^
52 |     """Load email candidates from JSONL file."""
53 |     candidates = []
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/extraction/extract_emails.py:54:10
   |
52 |     """Load email candidates from JSONL file."""
53 |     candidates = []
54 |     with open(jsonl_path) as f:
   |          ^^^^
55 |         for line in f:
56 |             if line.strip():
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/extract_emails.py:173:50
    |
173 | def extract_email_metadata(text: str, candidate: Dict, index: int) -> EmailMetadata:
    |                                                  ^^^^
174 |     """Extract complete email metadata from OCR text."""
175 |     doc_id = Path(candidate.get("file", "unknown")).stem
    |
help: Replace with `dict`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/extraction/extract_emails.py:180:22
    |
178 |         document_id=doc_id,
179 |         email_index=index,
180 |         extracted_at=datetime.utcnow().isoformat(),
    |                      ^^^^^^^^^^^^^^^^^
181 |         confidence=candidate.get("confidence", 0.0),
182 |         email_addresses=candidate.get("email_addresses", [])
    |
help: Use `datetime.datetime.now(tz=...)` instead

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:203:10
    |
201 |     # Save metadata JSON
202 |     metadata_path = subdir / f"{metadata.document_id}_metadata.json"
203 |     with open(metadata_path, "w") as f:
    |          ^^^^
204 |         json.dump(asdict(metadata), f, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:208:10
    |
206 |     # Save full OCR text
207 |     text_path = subdir / f"{metadata.document_id}_full.txt"
208 |     with open(text_path, "w") as f:
    |          ^^^^
209 |         f.write(ocr_text)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:214:14
    |
212 |     if metadata.body:
213 |         body_path = subdir / f"{metadata.document_id}_body.txt"
214 |         with open(body_path, "w") as f:
    |              ^^^^
215 |             f.write(metadata.body)
    |
help: Replace with `Path.open()`

ARG001 Unused function argument: `email_dir`
   --> scripts/extraction/extract_emails.py:218:26
    |
218 | def generate_email_index(email_dir: Path, metadata_list: List[EmailMetadata]) -> Dict:
    |                          ^^^^^^^^^
219 |     """Generate email index with statistics."""
220 |     index = {
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/extraction/extract_emails.py:218:58
    |
218 | def generate_email_index(email_dir: Path, metadata_list: List[EmailMetadata]) -> Dict:
    |                                                          ^^^^
219 |     """Generate email index with statistics."""
220 |     index = {
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/extract_emails.py:218:82
    |
218 | def generate_email_index(email_dir: Path, metadata_list: List[EmailMetadata]) -> Dict:
    |                                                                                  ^^^^
219 |     """Generate email index with statistics."""
220 |     index = {
    |
help: Replace with `dict`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/extraction/extract_emails.py:222:28
    |
220 |     index = {
221 |         "total_emails": len(metadata_list),
222 |         "extraction_date": datetime.utcnow().isoformat(),
    |                            ^^^^^^^^^^^^^^^^^
223 |         "by_date": {},
224 |         "by_sender": {},
    |
help: Use `datetime.datetime.now(tz=...)` instead

PLR0915 Too many statements (70 > 60)
   --> scripts/extraction/extract_emails.py:250:5
    |
250 | def main():
    |     ^^^^
251 |     """Main extraction workflow."""
252 |     base_dir = Path(__file__).parent.parent.parent
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:278:18
    |
276 |                 continue
277 |
278 |             with open(ocr_text_path) as f:
    |                  ^^^^
279 |                 ocr_text = f.read()
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:304:10
    |
302 |     email_index = generate_email_index(email_output_dir, metadata_list)
303 |     index_path = email_output_dir / "EMAIL_INDEX.json"
304 |     with open(index_path, "w") as f:
    |          ^^^^
305 |         json.dump(email_index, f, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/extract_emails.py:311:10
    |
309 |     # Generate summary report
310 |     summary_path = email_output_dir / "EXTRACTION_SUMMARY.md"
311 |     with open(summary_path, "w") as f:
    |          ^^^^
312 |         f.write("# Email Extraction Summary\n\n")
313 |         f.write(f"**Extraction Date**: {datetime.utcnow().isoformat()}\n\n")
    |
help: Replace with `Path.open()`

DTZ003 `datetime.datetime.utcnow()` used
   --> scripts/extraction/extract_emails.py:313:41
    |
311 |     with open(summary_path, "w") as f:
312 |         f.write("# Email Extraction Summary\n\n")
313 |         f.write(f"**Extraction Date**: {datetime.utcnow().isoformat()}\n\n")
    |                                         ^^^^^^^^^^^^^^^^^
314 |         f.write("## Statistics\n\n")
315 |         f.write(f"- **Total candidates**: {len(candidates)}\n")
    |
help: Use `datetime.datetime.now(tz=...)` instead

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:19:1
   |
17 | from datetime import datetime
18 | from pathlib import Path
19 | from typing import Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^
   |

F821 Undefined name `DownloadStats`
  --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:68:55
   |
68 | def download_file(url: str, output_path: Path, stats: DownloadStats) -> bool:
   |                                                       ^^^^^^^^^^^^^
69 |     """
70 |     Download a file from URL to output path.
   |

F821 Undefined name `requests`
  --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:81:20
   |
79 |     """
80 |     try:
81 |         response = requests.get(url, timeout=30)
   |                    ^^^^^^^^
82 |         response.raise_for_status()
   |

F821 Undefined name `requests`
  --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:92:12
   |
90 |         return True
91 |
92 |     except requests.exceptions.RequestException as e:
   |            ^^^^^^^^
93 |         stats.add_failure(output_path.name, str(e))
94 |         print(f"  ✗ Failed: {e}")
   |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:98:37
    |
 98 | def download_structured_json(stats: DownloadStats) -> bool:
    |                                     ^^^^^^^^^^^^^
 99 |     """Download the structured JSON file."""
100 |     print("\n[1/4] Downloading structured JSON...")
    |

F821 Undefined name `DATA_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:101:19
    |
 99 |     """Download the structured JSON file."""
100 |     print("\n[1/4] Downloading structured JSON...")
101 |     output_path = DATA_DIR / "epstein-emails-structured.json"
    |                   ^^^^^^^^
102 |
103 |     success = download_file(STRUCTURED_JSON_URL, output_path, stats)
    |

F821 Undefined name `STRUCTURED_JSON_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:103:29
    |
101 |     output_path = DATA_DIR / "epstein-emails-structured.json"
102 |
103 |     success = download_file(STRUCTURED_JSON_URL, output_path, stats)
    |                             ^^^^^^^^^^^^^^^^^^^
104 |     if success:
105 |         print(f"  ✓ Saved to: {output_path}")
    |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:110:25
    |
110 | def download_pdf(stats: DownloadStats) -> bool:
    |                         ^^^^^^^^^^^^^
111 |     """Download the complete PDF file."""
112 |     print("\n[2/4] Downloading complete PDF...")
    |

F821 Undefined name `DATA_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:113:19
    |
111 |     """Download the complete PDF file."""
112 |     print("\n[2/4] Downloading complete PDF...")
113 |     output_path = DATA_DIR / "epstein-emails-complete.pdf"
    |                   ^^^^^^^^
114 |
115 |     success = download_file(PDF_URL, output_path, stats)
    |

F821 Undefined name `PDF_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:115:29
    |
113 |     output_path = DATA_DIR / "epstein-emails-complete.pdf"
114 |
115 |     success = download_file(PDF_URL, output_path, stats)
    |                             ^^^^^^^
116 |     if success:
117 |         print(f"  ✓ Saved to: {output_path}")
    |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:122:38
    |
122 | def download_individual_pages(stats: DownloadStats) -> Tuple[int, int]:
    |                                      ^^^^^^^^^^^^^
123 |     """
124 |     Download individual page text files.
    |

F821 Undefined name `Tuple`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:122:56
    |
122 | def download_individual_pages(stats: DownloadStats) -> Tuple[int, int]:
    |                                                        ^^^^^
123 |     """
124 |     Download individual page text files.
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:129:54
    |
127 |         Tuple of (successful_count, failed_count)
128 |     """
129 |     print(f"\n[3/4] Downloading individual pages (1-{TOTAL_PAGES})...")
    |                                                      ^^^^^^^^^^^
130 |     print("This may take a few minutes with rate limiting...")
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:135:30
    |
133 |     failed = 0
134 |
135 |     for page_num in range(1, TOTAL_PAGES + 1):
    |                              ^^^^^^^^^^^
136 |         url = PAGE_URL_PATTERN.format(page=page_num)
137 |         output_path = PAGES_DIR / f"page-{page_num:03d}.txt"
    |

F821 Undefined name `PAGE_URL_PATTERN`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:136:15
    |
135 |     for page_num in range(1, TOTAL_PAGES + 1):
136 |         url = PAGE_URL_PATTERN.format(page=page_num)
    |               ^^^^^^^^^^^^^^^^
137 |         output_path = PAGES_DIR / f"page-{page_num:03d}.txt"
    |

F821 Undefined name `PAGES_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:137:23
    |
135 |     for page_num in range(1, TOTAL_PAGES + 1):
136 |         url = PAGE_URL_PATTERN.format(page=page_num)
137 |         output_path = PAGES_DIR / f"page-{page_num:03d}.txt"
    |                       ^^^^^^^^^
138 |
139 |         # Progress indicator every 10 pages
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:141:45
    |
139 |         # Progress indicator every 10 pages
140 |         if page_num % 10 == 0:
141 |             print(f"  Progress: {page_num}/{TOTAL_PAGES} pages...")
    |                                             ^^^^^^^^^^^
142 |
143 |         if download_file(url, output_path, stats):
    |

F821 Undefined name `time`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:149:9
    |
148 |         # Rate limiting
149 |         time.sleep(RATE_LIMIT_DELAY)
    |         ^^^^
150 |
151 |     print(f"  ✓ Downloaded {successful}/{TOTAL_PAGES} pages")
    |

F821 Undefined name `RATE_LIMIT_DELAY`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:149:20
    |
148 |         # Rate limiting
149 |         time.sleep(RATE_LIMIT_DELAY)
    |                    ^^^^^^^^^^^^^^^^
150 |
151 |     print(f"  ✓ Downloaded {successful}/{TOTAL_PAGES} pages")
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:151:42
    |
149 |         time.sleep(RATE_LIMIT_DELAY)
150 |
151 |     print(f"  ✓ Downloaded {successful}/{TOTAL_PAGES} pages")
    |                                          ^^^^^^^^^^^
152 |     if failed > 0:
153 |         print(f"  ✗ Failed: {failed} pages")
    |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:158:39
    |
158 | def download_and_process_notes(stats: DownloadStats) -> bool:
    |                                       ^^^^^^^^^^^^^
159 |     """
160 |     Download notes from API and create human-readable summary.
    |

F821 Undefined name `NOTES_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:168:23
    |
167 |     # Download raw notes JSON
168 |     notes_json_path = NOTES_DIR / "epstein-emails-notes.json"
    |                       ^^^^^^^^^
169 |
170 |     try:
    |

F821 Undefined name `requests`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:171:20
    |
170 |     try:
171 |         response = requests.get(NOTES_API_URL, timeout=30)
    |                    ^^^^^^^^
172 |         response.raise_for_status()
    |

F821 Undefined name `NOTES_API_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:171:33
    |
170 |     try:
171 |         response = requests.get(NOTES_API_URL, timeout=30)
    |                                 ^^^^^^^^^^^^^
172 |         response.raise_for_status()
    |

F821 Undefined name `NOTES_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:182:24
    |
181 |         # Create human-readable summary
182 |         summary_path = NOTES_DIR / "notes-summary.md"
    |                        ^^^^^^^^^
183 |         create_notes_summary(notes_data, summary_path, stats)
    |

F821 Undefined name `requests`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:187:12
    |
185 |         return True
186 |
187 |     except requests.exceptions.RequestException as e:
    |            ^^^^^^^^
188 |         stats.add_failure("notes.json", str(e))
189 |         print(f"  ✗ Failed to download notes: {e}")
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:197:38
    |
197 | def create_notes_summary(notes_data: Dict, output_path: Path, stats: DownloadStats):
    |                                      ^^^^
198 |     """
199 |     Create a human-readable summary of notes.
    |
help: Replace with `dict`

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:197:70
    |
197 | def create_notes_summary(notes_data: Dict, output_path: Path, stats: DownloadStats):
    |                                                                      ^^^^^^^^^^^^^
198 |     """
199 |     Create a human-readable summary of notes.
    |

F821 Undefined name `NOTES_API_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:213:24
    |
211 |         f"**Total Notes:** {len(results)}",
212 |         f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
213 |         f"**Source:** {NOTES_API_URL}",
    |                        ^^^^^^^^^^^^^
214 |         "",
215 |         "---",
    |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:268:28
    |
268 | def create_manifest(stats: DownloadStats):
    |                            ^^^^^^^^^^^^^
269 |     """Create a manifest file documenting all downloads."""
270 |     print("\nCreating manifest file...")
    |

F821 Undefined name `DATA_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:272:21
    |
270 |     print("\nCreating manifest file...")
271 |
272 |     manifest_path = DATA_DIR / "MANIFEST.md"
    |                     ^^^^^^^^
273 |     timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    |

F821 Undefined name `DOC_ID`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:279:50
    |
277 |         "",
278 |         f"**Download Date:** {timestamp}",
279 |         f"**Source:** DocumentCloud Document ID {DOC_ID}",
    |                                                  ^^^^^^
280 |         "",
281 |         "## Summary",
    |

F821 Undefined name `STRUCTURED_JSON_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:292:22
    |
290 |         "",
291 |         "1. **Structured JSON** (73 pages)",
292 |         f"   - URL: {STRUCTURED_JSON_URL}",
    |                      ^^^^^^^^^^^^^^^^^^^
293 |         "   - File: `epstein-emails-structured.json`",
294 |         f"   - Size: {stats.file_sizes.get('epstein-emails-structured.json', 0):,} bytes",
    |

F821 Undefined name `PDF_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:297:22
    |
295 |         "",
296 |         "2. **Complete PDF** (87 pages)",
297 |         f"   - URL: {PDF_URL}",
    |                      ^^^^^^^
298 |         "   - File: `epstein-emails-complete.pdf`",
299 |         f"   - Size: {stats.file_sizes.get('epstein-emails-complete.pdf', 0):,} bytes",
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:303:44
    |
301 |         "### Individual Pages",
302 |         "",
303 |         f"3. **Page Text Files** (pages 1-{TOTAL_PAGES})",
    |                                            ^^^^^^^^^^^
304 |         f"   - URL Pattern: `{PAGE_URL_PATTERN}`",
305 |         "   - Directory: `pages/`",
    |

F821 Undefined name `PAGE_URL_PATTERN`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:304:31
    |
302 |         "",
303 |         f"3. **Page Text Files** (pages 1-{TOTAL_PAGES})",
304 |         f"   - URL Pattern: `{PAGE_URL_PATTERN}`",
    |                               ^^^^^^^^^^^^^^^^
305 |         "   - Directory: `pages/`",
306 |         f"   - Files: `page-001.txt` through `page-{TOTAL_PAGES:03d}.txt`",
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:306:53
    |
304 |         f"   - URL Pattern: `{PAGE_URL_PATTERN}`",
305 |         "   - Directory: `pages/`",
306 |         f"   - Files: `page-001.txt` through `page-{TOTAL_PAGES:03d}.txt`",
    |                                                     ^^^^^^^^^^^
307 |         "",
308 |         "### Annotations",
    |

F821 Undefined name `NOTES_API_URL`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:311:26
    |
309 |         "",
310 |         "4. **Notes Data**",
311 |         f"   - API URL: {NOTES_API_URL}",
    |                          ^^^^^^^^^^^^^
312 |         "   - Raw JSON: `notes/epstein-emails-notes.json`",
313 |         "   - Summary: `notes/notes-summary.md`",
    |

F821 Undefined name `DATA_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:396:34
    |
394 |     print("Epstein Emails - DocumentCloud Extraction Script")
395 |     print("=" * 70)
396 |     print(f"\nOutput Directory: {DATA_DIR}")
    |                                  ^^^^^^^^
397 |     print(f"Total Pages to Download: {TOTAL_PAGES}")
398 |     print(f"Rate Limit: {RATE_LIMIT_DELAY}s between requests")
    |

F821 Undefined name `TOTAL_PAGES`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:397:39
    |
395 |     print("=" * 70)
396 |     print(f"\nOutput Directory: {DATA_DIR}")
397 |     print(f"Total Pages to Download: {TOTAL_PAGES}")
    |                                       ^^^^^^^^^^^
398 |     print(f"Rate Limit: {RATE_LIMIT_DELAY}s between requests")
    |

F821 Undefined name `RATE_LIMIT_DELAY`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:398:26
    |
396 |     print(f"\nOutput Directory: {DATA_DIR}")
397 |     print(f"Total Pages to Download: {TOTAL_PAGES}")
398 |     print(f"Rate Limit: {RATE_LIMIT_DELAY}s between requests")
    |                          ^^^^^^^^^^^^^^^^
399 |
400 |     stats = DownloadStats()
    |

F821 Undefined name `DownloadStats`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:400:13
    |
398 |     print(f"Rate Limit: {RATE_LIMIT_DELAY}s between requests")
399 |
400 |     stats = DownloadStats()
    |             ^^^^^^^^^^^^^
401 |     start_time = time.time()
    |

F821 Undefined name `time`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:401:18
    |
400 |     stats = DownloadStats()
401 |     start_time = time.time()
    |                  ^^^^
402 |
403 |     # Execute downloads
    |

F821 Undefined name `time`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:413:20
    |
412 |     # Final summary
413 |     elapsed_time = time.time() - start_time
    |                    ^^^^
414 |
415 |     print("\n" + "=" * 70)
    |

F821 Undefined name `DATA_DIR`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:420:35
    |
418 |     print(stats.get_summary())
419 |     print(f"Elapsed Time: {elapsed_time:.2f} seconds ({elapsed_time / 60:.2f} minutes)")
420 |     print(f"\nAll data saved to: {DATA_DIR}")
    |                                   ^^^^^^^^
421 |     print("See MANIFEST.md for detailed information about downloaded files.")
422 |     print("=" * 70)
    |

PLR1722 Use `sys.exit()` instead of `exit`
   --> scripts/extraction/extract_emails_documentcloud_BACKUP.py:433:5
    |
432 | if __name__ == "__main__":
433 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/extraction/ocr_house_oversight.py:23:1
   |
21 | from multiprocessing import Pool
22 | from pathlib import Path
23 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/extraction/ocr_house_oversight.py:23:1
   |
21 | from multiprocessing import Pool
22 | from pathlib import Path
23 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/extraction/ocr_house_oversight.py:23:1
   |
21 | from multiprocessing import Pool
22 | from pathlib import Path
23 | from typing import Dict, List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F401 `PIL.Image` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/extraction/ocr_house_oversight.py:29:21
   |
27 |     import pytesseract
28 |     from pdf2image import convert_from_path
29 |     from PIL import Image
   |                     ^^^^^
30 |     from tqdm import tqdm
31 | except ImportError as e:
   |
help: Remove unused import: `PIL.Image`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/extraction/ocr_house_oversight.py:70:18
   |
68 |             log_entry = f"[{timestamp}] [{level}] {message}"
69 |             print(log_entry)
70 |             with open(self.log_file, "a") as f:
   |                  ^^^^
71 |                 f.write(log_entry + "\n")
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/extraction/ocr_house_oversight.py:76:24
   |
76 | def load_progress() -> Dict:
   |                        ^^^^
77 |     """Load processing progress from file"""
78 |     if PROGRESS_FILE.exists():
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/extraction/ocr_house_oversight.py:79:14
   |
77 |     """Load processing progress from file"""
78 |     if PROGRESS_FILE.exists():
79 |         with open(PROGRESS_FILE) as f:
   |              ^^^^
80 |             return json.load(f)
81 |     return {
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/extraction/ocr_house_oversight.py:94:29
   |
94 | def save_progress(progress: Dict):
   |                             ^^^^
95 |     """Save processing progress to file"""
96 |     PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/extraction/ocr_house_oversight.py:98:10
   |
96 |     PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
97 |     progress["stats"]["last_update"] = datetime.now().isoformat()
98 |     with open(PROGRESS_FILE, "w") as f:
   |          ^^^^
99 |         json.dump(progress, f, indent=2)
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/ocr_house_oversight.py:102:40
    |
102 | def detect_email_content(text: str) -> Dict:
    |                                        ^^^^
103 |     """
104 |     Detect if text contains email content
    |
help: Replace with `dict`

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/extraction/ocr_house_oversight.py:144:30
    |
144 | def process_single_pdf(args: Tuple[Path, Path, str]) -> Dict:
    |                              ^^^^^
145 |     """
146 |     Process a single PDF file with OCR
    |
help: Replace with `tuple`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/ocr_house_oversight.py:144:57
    |
144 | def process_single_pdf(args: Tuple[Path, Path, str]) -> Dict:
    |                                                         ^^^^
145 |     """
146 |     Process a single PDF file with OCR
    |
help: Replace with `dict`

RUF059 Unpacked variable `log_id` is never used
   --> scripts/extraction/ocr_house_oversight.py:154:27
    |
152 |         Dict with processing results
153 |     """
154 |     pdf_path, output_dir, log_id = args
    |                           ^^^^^^
155 |
156 |     result = {
    |
help: Prefix it with an underscore or any other dummy variable pattern

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/ocr_house_oversight.py:197:14
    |
195 |         output_file.parent.mkdir(parents=True, exist_ok=True)
196 |
197 |         with open(output_file, "w", encoding="utf-8") as f:
    |              ^^^^
198 |             f.write(text)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/ocr_house_oversight.py:211:14
    |
210 |         metadata_file = output_dir / f"{pdf_path.stem}.json"
211 |         with open(metadata_file, "w", encoding="utf-8") as f:
    |              ^^^^
212 |             json.dump(metadata, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/extraction/ocr_house_oversight.py:225:30
    |
225 | def process_batch(pdf_files: List[Path], output_dir: Path, num_workers: int, logger) -> Dict:
    |                              ^^^^
226 |     """
227 |     Process a batch of PDF files with parallel workers
    |
help: Replace with `list`

ARG001 Unused function argument: `logger`
   --> scripts/extraction/ocr_house_oversight.py:225:78
    |
225 | def process_batch(pdf_files: List[Path], output_dir: Path, num_workers: int, logger) -> Dict:
    |                                                                              ^^^^^^
226 |     """
227 |     Process a batch of PDF files with parallel workers
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/extraction/ocr_house_oversight.py:225:89
    |
225 | def process_batch(pdf_files: List[Path], output_dir: Path, num_workers: int, logger) -> Dict:
    |                                                                                         ^^^^
226 |     """
227 |     Process a batch of PDF files with parallel workers
    |
help: Replace with `dict`

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> scripts/extraction/ocr_house_oversight.py:262:5
    |
261 |       # Process with progress bar
262 | /     with Pool(num_workers) as pool:
263 | |         with tqdm(total=len(pdf_files), desc="Processing PDFs", unit="file") as pbar:
    | |_____________________________________________________________________________________^
264 |               for result in pool.imap_unordered(process_single_pdf, args_list):
265 |                   all_results.append(result)
    |
help: Combine `with` statements

PLR0915 Too many statements (62 > 60)
   --> scripts/extraction/ocr_house_oversight.py:317:5
    |
317 | def main():
    |     ^^^^
318 |     parser = argparse.ArgumentParser(description="OCR processing for House Oversight PDFs")
319 |     parser.add_argument("--workers", type=int, default=10, help="Number of parallel workers")
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/extraction/ocr_house_oversight.py:406:18
    |
404 |         if batch_results["email_candidates"]:
405 |             EMAIL_INDEX_FILE.parent.mkdir(parents=True, exist_ok=True)
406 |             with open(EMAIL_INDEX_FILE, "a") as f:
    |                  ^^^^
407 |                 for candidate in batch_results["email_candidates"]:
408 |                     f.write(json.dumps(candidate) + "\n")
    |
help: Replace with `Path.open()`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> scripts/git_commit_helper.py:20:20
   |
18 |       """Helps create conventional commit messages."""
19 |
20 |       COMMIT_TYPES = {
   |  ____________________^
21 | |         "feat": "A new feature",
22 | |         "fix": "A bug fix",
23 | |         "docs": "Documentation only changes",
24 | |         "style": "Changes that don't affect code meaning (formatting, etc)",
25 | |         "refactor": "Code change that neither fixes a bug nor adds a feature",
26 | |         "perf": "Performance improvement",
27 | |         "test": "Adding missing tests or correcting existing tests",
28 | |         "build": "Changes to build system or dependencies",
29 | |         "ci": "Changes to CI configuration files and scripts",
30 | |         "chore": "Other changes that don't modify src or test files",
31 | |         "revert": "Reverts a previous commit",
32 | |     }
   | |_____^
33 |
34 |       SCOPES = [
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> scripts/git_commit_helper.py:34:14
   |
32 |       }
33 |
34 |       SCOPES = [
   |  ______________^
35 | |         "ocr",
36 | |         "classification",
37 | |         "extraction",
38 | |         "network",
39 | |         "search",
40 | |         "database",
41 | |         "api",
42 | |         "docs",
43 | |         "scripts",
44 | |     ]
   | |_____^
45 |
46 |       def __init__(self):
   |

PLR1714 Consider merging multiple comparisons: `choice in {"0", ""}`.
  --> scripts/git_commit_helper.py:92:12
   |
90 |         ).strip()
91 |
92 |         if choice == "0" or choice == "":
   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
93 |             return None
   |
help: Merge multiple comparisons

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/indexing/build_unified_index.py:16:1
   |
14 | from datetime import datetime
15 | from pathlib import Path
16 | from typing import Any, Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/indexing/build_unified_index.py:28:39
   |
26 | OUTPUT_FILE = METADATA_DIR / "all_documents_index.json"
27 |
28 | def load_json_file(filepath: Path) -> Dict:
   |                                       ^^^^
29 |     """Load JSON file with progress indicator."""
30 |     print(f"Loading {filepath.name}...")
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/indexing/build_unified_index.py:31:10
   |
29 |     """Load JSON file with progress indicator."""
30 |     print(f"Loading {filepath.name}...")
31 |     with open(filepath, encoding="utf-8") as f:
   |          ^^^^
32 |         return json.load(f)
   |
help: Replace with `Path.open()`

PLR0915 Too many statements (74 > 60)
  --> scripts/indexing/build_unified_index.py:34:5
   |
32 |         return json.load(f)
33 |
34 | def build_unified_index() -> Dict[str, Any]:
   |     ^^^^^^^^^^^^^^^^^^^
35 |     """Build comprehensive document index from all sources."""
36 |     print("\n" + "="*80)
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/indexing/build_unified_index.py:34:30
   |
32 |         return json.load(f)
33 |
34 | def build_unified_index() -> Dict[str, Any]:
   |                              ^^^^
35 |     """Build comprehensive document index from all sources."""
36 |     print("\n" + "="*80)
   |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/indexing/build_unified_index.py:130:13
    |
128 |         if email_date:
129 |             # Try to extract year-month (e.g., "2019-08")
130 |             import re
    |             ^^^^^^^^^
131 |             date_match = re.search(r"(\d{4})-(\d{2})", email_date)
132 |             if date_match:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/indexing/build_unified_index.py:184:21
    |
182 |               for entity, mentions in entity_mentions.items():
183 |                   for mention in mentions:
184 | /                     if mention.get("document") in doc_path or doc_path in mention.get("document", ""):
185 | |                         if entity not in doc["entities_mentioned"]:
    | |___________________________________________________________________^
186 |                               doc["entities_mentioned"].append(entity)
187 |                               entity_count += 1
    |
help: Combine `if` statements using `and`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/indexing/build_unified_index.py:204:23
    |
202 |     return unified_index
203 |
204 | def save_index(index: Dict[str, Any]) -> None:
    |                       ^^^^
205 |     """Save unified index to file."""
206 |     print(f"\nSaving unified index to {OUTPUT_FILE}...")
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/indexing/build_unified_index.py:209:10
    |
208 |     OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
209 |     with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    |          ^^^^
210 |         json.dump(index, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/indexing/build_unified_index.py:214:26
    |
212 |     print(f"✅ Saved {len(index['documents'])} documents to {OUTPUT_FILE}")
213 |
214 | def print_summary(index: Dict[str, Any]) -> None:
    |                          ^^^^
215 |     """Print index summary."""
216 |     print("\n" + "="*80)
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/indexing/build_unified_index.py:287:9
    |
285 |     except Exception as e:
286 |         print(f"\n❌ Error: {e}")
287 |         import traceback
    |         ^^^^^^^^^^^^^^^^
288 |         traceback.print_exc()
289 |         return 1
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/indexing/generate_summary_report.py:12:1
   |
10 | from datetime import datetime
11 | from pathlib import Path
12 | from typing import Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/indexing/generate_summary_report.py:22:34
   |
20 | REPORT_FILE = METADATA_DIR / "classification_summary_report.txt"
21 |
22 | def load_json(filepath: Path) -> Dict:
   |                                  ^^^^
23 |     """Load JSON file."""
24 |     with open(filepath, encoding="utf-8") as f:
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/indexing/generate_summary_report.py:24:10
   |
22 | def load_json(filepath: Path) -> Dict:
23 |     """Load JSON file."""
24 |     with open(filepath, encoding="utf-8") as f:
   |          ^^^^
25 |         return json.load(f)
   |
help: Replace with `Path.open()`

PLR0915 Too many statements (95 > 60)
  --> scripts/indexing/generate_summary_report.py:27:5
   |
25 |         return json.load(f)
26 |
27 | def generate_report() -> str:
   |     ^^^^^^^^^^^^^^^
28 |     """Generate comprehensive summary report."""
29 |     # Load data
   |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/indexing/generate_summary_report.py:196:14
    |
195 |         # Save to file
196 |         with open(REPORT_FILE, "w", encoding="utf-8") as f:
    |              ^^^^
197 |             f.write(report_text)
    |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> scripts/indexing/generate_summary_report.py:208:9
    |
206 |     except Exception as e:
207 |         print(f"\n❌ Error: {e}")
208 |         import traceback
    |         ^^^^^^^^^^^^^^^^
209 |         traceback.print_exc()
210 |         return 1
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/metadata/build_chatbot_knowledge_index.py:17:1
   |
15 | from datetime import datetime
16 | from pathlib import Path
17 | from typing import Any, Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/metadata/build_chatbot_knowledge_index.py:17:1
   |
15 | from datetime import datetime
16 | from pathlib import Path
17 | from typing import Any, Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/metadata/build_chatbot_knowledge_index.py:24:14
   |
22 |     sha256 = hashlib.sha256()
23 |     try:
24 |         with open(file_path, "rb") as f:
   |              ^^^^
25 |             for chunk in iter(lambda: f.read(8192), b""):
26 |                 sha256.update(chunk)
   |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/metadata/build_chatbot_knowledge_index.py:32:38
   |
32 | def scan_scripts(base_path: Path) -> List[Dict[str, str]]:
   |                                      ^^^^
33 |     """Scan all Python scripts and categorize them."""
34 |     scripts_dir = base_path / "scripts"
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/metadata/build_chatbot_knowledge_index.py:32:43
   |
32 | def scan_scripts(base_path: Path) -> List[Dict[str, str]]:
   |                                           ^^^^
33 |     """Scan all Python scripts and categorize them."""
34 |     scripts_dir = base_path / "scripts"
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/metadata/build_chatbot_knowledge_index.py:65:41
   |
65 | def scan_data_files(base_path: Path) -> Dict[str, Any]:
   |                                         ^^^^
66 |     """Scan all data files and categorize."""
67 |     data_dir = base_path / "data"
   |
help: Replace with `dict`

DTZ006 `datetime.datetime.fromtimestamp()` called without a `tz` argument
  --> scripts/metadata/build_chatbot_knowledge_index.py:85:29
   |
83 |                 "path": str(file),
84 |                 "size_bytes": file.stat().st_size,
85 |                 "modified": datetime.fromtimestamp(file.stat().st_mtime).isoformat()
   |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
86 |             })
   |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:122:43
    |
122 | def read_master_index(base_path: Path) -> Dict[str, Any]:
    |                                           ^^^^
123 |     """Read master document index."""
124 |     index_path = base_path / "data" / "metadata" / "master_document_index.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:126:14
    |
124 |     index_path = base_path / "data" / "metadata" / "master_document_index.json"
125 |     if index_path.exists():
126 |         with open(index_path) as f:
    |              ^^^^
127 |             return json.load(f)
128 |     return {}
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:131:43
    |
131 | def read_entity_index(base_path: Path) -> Dict[str, Any]:
    |                                           ^^^^
132 |     """Read entity index."""
133 |     entity_path = base_path / "data" / "md" / "entities" / "ENTITIES_INDEX.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:135:14
    |
133 |     entity_path = base_path / "data" / "md" / "entities" / "ENTITIES_INDEX.json"
134 |     if entity_path.exists():
135 |         with open(entity_path) as f:
    |              ^^^^
136 |             return json.load(f)
137 |     return {}
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:140:45
    |
140 | def read_entity_network(base_path: Path) -> Dict[str, Any]:
    |                                             ^^^^
141 |     """Read entity network graph."""
142 |     network_path = base_path / "data" / "metadata" / "entity_network.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:144:14
    |
142 |     network_path = base_path / "data" / "metadata" / "entity_network.json"
143 |     if network_path.exists():
144 |         with open(network_path) as f:
    |              ^^^^
145 |             return json.load(f)
146 |     return {}
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:149:47
    |
149 | def read_email_statistics(base_path: Path) -> Dict[str, Any]:
    |                                               ^^^^
150 |     """Read email statistics."""
151 |     email_stats_path = base_path / "data" / "canonical" / "emails" / "email_statistics.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:153:14
    |
151 |     email_stats_path = base_path / "data" / "canonical" / "emails" / "email_statistics.json"
152 |     if email_stats_path.exists():
153 |         with open(email_stats_path) as f:
    |              ^^^^
154 |             return json.load(f)
155 |     return {}
    |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:158:43
    |
158 | def read_download_log(base_path: Path) -> List[Dict[str, Any]]:
    |                                           ^^^^
159 |     """Read download log."""
160 |     download_log_path = base_path / "data" / "metadata" / "download_log.json"
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:158:48
    |
158 | def read_download_log(base_path: Path) -> List[Dict[str, Any]]:
    |                                                ^^^^
159 |     """Read download log."""
160 |     download_log_path = base_path / "data" / "metadata" / "download_log.json"
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:162:14
    |
160 |     download_log_path = base_path / "data" / "metadata" / "download_log.json"
161 |     if download_log_path.exists():
162 |         with open(download_log_path) as f:
    |              ^^^^
163 |             return json.load(f)
164 |     return []
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:167:44
    |
167 | def check_ongoing_work(base_path: Path) -> Dict[str, Any]:
    |                                            ^^^^
168 |     """Check for ongoing background processes and pending work."""
169 |     ongoing = {
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:189:14
    |
187 |     classifications_path = base_path / "data" / "metadata" / "document_classifications.json"
188 |     if classifications_path.exists():
189 |         with open(classifications_path) as f:
    |              ^^^^
190 |             classifications = json.load(f)
191 |         total_docs = master_index.get("unique_documents", 0)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/metadata/build_chatbot_knowledge_index.py:198:47
    |
198 | def build_knowledge_index(base_path: Path) -> Dict[str, Any]:
    |                                               ^^^^
199 |     """Build comprehensive knowledge index."""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/metadata/build_chatbot_knowledge_index.py:334:10
    |
332 |     # Write to file
333 |     output_path = base_path / "data" / "metadata" / "chatbot_knowledge_index.json"
334 |     with open(output_path, "w") as f:
    |          ^^^^
335 |         json.dump(index, f, indent=2)
    |
help: Replace with `Path.open()`

E402 Module level import not at top of file
  --> scripts/metadata/refresh_chatbot_index.py:23:1
   |
21 | sys.path.insert(0, str(scripts_dir))
22 |
23 | from metadata.build_chatbot_knowledge_index import build_knowledge_index
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PLC0415 `import` should be at the top-level of a file
  --> scripts/metadata/refresh_chatbot_index.py:37:5
   |
35 |     # Write to file
36 |     output_path = base_path / "data" / "metadata" / "chatbot_knowledge_index.json"
37 |     import json
   |     ^^^^^^^^^^^
38 |     with open(output_path, "w") as f:
39 |         json.dump(index, f, indent=2)
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/metadata/refresh_chatbot_index.py:38:10
   |
36 |     output_path = base_path / "data" / "metadata" / "chatbot_knowledge_index.json"
37 |     import json
38 |     with open(output_path, "w") as f:
   |          ^^^^
39 |         json.dump(index, f, indent=2)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/reorganize_data.py:191:10
    |
189 |     index_path = DATA_DIR / "metadata" / "source_index.json"
190 |     index_path.parent.mkdir(exist_ok=True)
191 |     with open(index_path, "w") as f:
    |          ^^^^
192 |         json.dump(index, f, indent=2)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/search/entity_search.py:10:1
   |
 8 | import json
 9 | from pathlib import Path
10 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/search/entity_search.py:10:1
   |
 8 | import json
 9 | from pathlib import Path
10 | from typing import Dict, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/search/entity_search.py:26:14
   |
24 |         # Load semantic index (entity -> documents)
25 |         semantic_index_path = METADATA_DIR / "semantic_index.json"
26 |         with open(semantic_index_path) as f:
   |              ^^^^
27 |             self.semantic_data = json.load(f)
28 |             self.entity_to_docs = self.semantic_data.get("entity_to_documents", {})
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/search/entity_search.py:32:14
   |
30 |         # Load classifications
31 |         classifications_path = METADATA_DIR / "document_classifications.json"
32 |         with open(classifications_path) as f:
   |              ^^^^
33 |             self.classifications = json.load(f).get("results", {})
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/search/entity_search.py:37:14
   |
35 |         # Load entity network
36 |         network_path = METADATA_DIR / "entity_network.json"
37 |         with open(network_path) as f:
   |              ^^^^
38 |             self.network_data = json.load(f)
39 |             self.entity_nodes = {n["id"]: n for n in self.network_data["nodes"]}
   |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/search/entity_search.py:44:53
   |
42 |         print(f"  Loaded {len(self.classifications)} classified documents")
43 |
44 |     def search_by_entity(self, entity_name: str) -> List[Dict]:
   |                                                     ^^^^
45 |         """
46 |         Find all documents mentioning an entity
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/search/entity_search.py:44:58
   |
42 |         print(f"  Loaded {len(self.classifications)} classified documents")
43 |
44 |     def search_by_entity(self, entity_name: str) -> List[Dict]:
   |                                                          ^^^^
45 |         """
46 |         Find all documents mentioning an entity
   |
help: Replace with `dict`

SIM118 Use `key in dict` instead of `key in dict.keys()`
  --> scripts/search/entity_search.py:58:24
   |
56 |         # Find matching entity names
57 |         matching_entities = [
58 |             entity for entity in self.entity_to_docs.keys()
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
59 |             if entity_lower in entity.lower()
60 |         ]
   |
help: Remove `.keys()`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/search/entity_search.py:93:48
   |
91 |         return results
92 |
93 |     def search_by_type(self, doc_type: str) -> List[Dict]:
   |                                                ^^^^
94 |         """Find all documents of a specific type"""
95 |         results = []
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/search/entity_search.py:93:53
   |
91 |         return results
92 |
93 |     def search_by_type(self, doc_type: str) -> List[Dict]:
   |                                                     ^^^^
94 |         """Find all documents of a specific type"""
95 |         results = []
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/search/entity_search.py:109:53
    |
107 |         return results
108 |
109 |     def find_connections(self, entity_name: str) -> Dict:
    |                                                     ^^^^
110 |         """
111 |         Find all connections for an entity
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/search/entity_search.py:153:57
    |
151 |         }
152 |
153 |     def search_by_multiple_entities(self, entity_names: List[str]) -> List[Dict]:
    |                                                         ^^^^
154 |         """
155 |         Find documents mentioning multiple entities together
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/search/entity_search.py:153:71
    |
151 |         }
152 |
153 |     def search_by_multiple_entities(self, entity_names: List[str]) -> List[Dict]:
    |                                                                       ^^^^
154 |         """
155 |         Find documents mentioning multiple entities together
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/search/entity_search.py:153:76
    |
151 |         }
152 |
153 |     def search_by_multiple_entities(self, entity_names: List[str]) -> List[Dict]:
    |                                                                            ^^^^
154 |         """
155 |         Find documents mentioning multiple entities together
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/search/entity_search.py:192:29
    |
190 |         return results
191 |
192 | def format_results(results: List[Dict], result_type: str = "entity"):
    |                             ^^^^
193 |     """Format search results for display"""
194 |     if not results:
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/search/entity_search.py:192:34
    |
190 |         return results
191 |
192 | def format_results(results: List[Dict], result_type: str = "entity"):
    |                                  ^^^^
193 |     """Format search results for display"""
194 |     if not results:
    |
help: Replace with `dict`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/utilities/convert_emails_to_markdown.py:15:1
   |
13 | from datetime import datetime
14 | from pathlib import Path
15 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/utilities/convert_emails_to_markdown.py:15:1
   |
13 | from datetime import datetime
14 | from pathlib import Path
15 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/utilities/convert_emails_to_markdown.py:15:1
   |
13 | from datetime import datetime
14 | from pathlib import Path
15 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `list` instead of `List` for type annotation
  --> scripts/utilities/convert_emails_to_markdown.py:23:12
   |
21 |     document_id: int
22 |     doc_type: str
23 |     pages: List[int]
   |            ^^^^
24 |     source: str = "Public Records Request 19-372"
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/utilities/convert_emails_to_markdown.py:39:27
   |
38 |     # Cross-references
39 |     annotations: Optional[List[Dict]] = None
   |                           ^^^^
40 |     references: Optional[List[str]] = None
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utilities/convert_emails_to_markdown.py:39:32
   |
38 |     # Cross-references
39 |     annotations: Optional[List[Dict]] = None
   |                                ^^^^
40 |     references: Optional[List[str]] = None
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/utilities/convert_emails_to_markdown.py:40:26
   |
38 |     # Cross-references
39 |     annotations: Optional[List[Dict]] = None
40 |     references: Optional[List[str]] = None
   |                          ^^^^
41 |
42 |     def to_frontmatter(self) -> str:
   |
help: Replace with `list`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> scripts/utilities/convert_emails_to_markdown.py:87:17
    |
 86 |       # Document definitions based on Research agent's analysis
 87 |       DOCUMENTS = [
    |  _________________^
 88 | |         {"id": 1, "type": "Email", "pages": range(1, 6), "subject": "RE: Epstein", "category": "emails"},
 89 | |         {"id": 2, "type": "Email", "pages": range(6, 9), "subject": "FW: Confidential", "category": "emails"},
 90 | |         {"id": 3, "type": "Letter", "pages": range(9, 11), "subject": "Flight logs letter", "category": "legal"},
 91 | |         {"id": 4, "type": "Invoice", "pages": range(11, 16), "subject": "Flight service invoices", "category": "records"},
 92 | |         {"id": 5, "type": "Subpoena", "pages": range(16, 18), "subject": "Flight logs subpoena", "category": "legal"},
 93 | |         {"id": 6, "type": "Report", "pages": range(18, 20), "subject": "DAVID Summary - Criminal database", "category": "records"},
 94 | |         {"id": 7, "type": "Subpoena", "pages": [20], "subject": "Investigation assignment", "category": "legal"},
 95 | |         {"id": 8, "type": "Note", "pages": [21], "subject": "Address location", "category": "notes"},
 96 | |         {"id": 9, "type": "Report", "pages": range(22, 42), "subject": "FACTS Report - Background check", "category": "records"},
 97 | |         {"id": 10, "type": "Letter", "pages": range(42, 46), "subject": "Legal correspondence", "category": "legal"},
 98 | |         {"id": 11, "type": "Memo", "pages": range(46, 55), "subject": "State Attorney memo", "category": "legal"},
 99 | |         {"id": 12, "type": "Directions", "pages": [55], "subject": "Driving directions", "category": "notes"},
100 | |         {"id": 13, "type": "Subpoena", "pages": [56], "subject": "Legal subpoena", "category": "legal"},
101 | |         {"id": 14, "type": "Memo", "pages": [57], "subject": "State Attorney document", "category": "legal"},
102 | |         {"id": 15, "type": "Subpoena", "pages": range(58, 60), "subject": "Legal subpoena", "category": "legal"},
103 | |         {"id": 16, "type": "Memo", "pages": range(60, 69), "subject": "Impeachment Material", "category": "legal"},
104 | |         {"id": 17, "type": "Email", "pages": range(69, 88), "subject": "RE: Meeting with Epstein's attorneys", "category": "emails"},
105 | |     ]
    | |_____^
106 |
107 |       def __init__(self, pages_dir: Path, notes_file: Path, output_dir: Path):
    |

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:113:30
    |
111 |         self.notes = self._load_notes()
112 |
113 |     def _load_notes(self) -> List[Dict]:
    |                              ^^^^
114 |         """Load annotation notes from JSON file."""
115 |         with open(self.notes_file) as f:
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:113:35
    |
111 |         self.notes = self._load_notes()
112 |
113 |     def _load_notes(self) -> List[Dict]:
    |                                   ^^^^
114 |         """Load annotation notes from JSON file."""
115 |         with open(self.notes_file) as f:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utilities/convert_emails_to_markdown.py:115:14
    |
113 |     def _load_notes(self) -> List[Dict]:
114 |         """Load annotation notes from JSON file."""
115 |         with open(self.notes_file) as f:
    |              ^^^^
116 |             data = json.load(f)
117 |             return data.get("results", [])
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utilities/convert_emails_to_markdown.py:124:14
    |
122 |         if not page_file.exists():
123 |             return ""
124 |         with open(page_file, encoding="utf-8") as f:
    |              ^^^^
125 |             return f.read()
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:147:53
    |
145 |         return text.strip()
146 |
147 |     def _extract_email_metadata(self, text: str) -> Dict[str, Optional[str]]:
    |                                                     ^^^^
148 |         """Extract email headers from text."""
149 |         metadata = {
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:184:54
    |
182 |         return metadata
183 |
184 |     def _extract_case_references(self, text: str) -> List[str]:
    |                                                      ^^^^
185 |         """Extract case numbers and document references."""
186 |         references = []
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:204:49
    |
202 |         return references
203 |
204 |     def _get_annotations_for_pages(self, pages: List[int]) -> List[Dict]:
    |                                                 ^^^^
205 |         """Get all annotations that apply to the given page range."""
206 |         annotations = []
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:204:63
    |
202 |         return references
203 |
204 |     def _get_annotations_for_pages(self, pages: List[int]) -> List[Dict]:
    |                                                               ^^^^
205 |         """Get all annotations that apply to the given page range."""
206 |         annotations = []
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:204:68
    |
202 |         return references
203 |
204 |     def _get_annotations_for_pages(self, pages: List[int]) -> List[Dict]:
    |                                                                    ^^^^
205 |         """Get all annotations that apply to the given page range."""
206 |         annotations = []
    |
help: Replace with `dict`

DTZ007 Naive datetime constructed using `datetime.datetime.strptime()` without %z
   --> scripts/utilities/convert_emails_to_markdown.py:235:30
    |
233 |                 if match:
234 |                     try:
235 |                         dt = datetime.strptime(match.group(1), fmt)
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
236 |                         date_str = dt.strftime("%Y-%m-%d")
237 |                         break
    |
help: Call `.replace(tzinfo=<timezone>)` or `.astimezone()` to convert to an aware datetime

E722 Do not use bare `except`
   --> scripts/utilities/convert_emails_to_markdown.py:238:21
    |
236 |                         date_str = dt.strftime("%Y-%m-%d")
237 |                         break
238 |                     except:
    |                     ^^^^^^
239 |                         pass
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:249:41
    |
247 |         return "_".join(parts) + ".md"
248 |
249 |     def extract_document(self, doc_def: Dict) -> Tuple[str, str, DocumentMetadata]:
    |                                         ^^^^
250 |         """Extract a single document and return (filename, content, metadata)."""
251 |         doc_id = doc_def["id"]
    |
help: Replace with `dict`

UP006 Use `tuple` instead of `Tuple` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:249:50
    |
247 |         return "_".join(parts) + ".md"
248 |
249 |     def extract_document(self, doc_def: Dict) -> Tuple[str, str, DocumentMetadata]:
    |                                                  ^^^^^
250 |         """Extract a single document and return (filename, content, metadata)."""
251 |         doc_id = doc_def["id"]
    |
help: Replace with `tuple`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:314:30
    |
312 |         return filename, content, metadata, category
313 |
314 |     def extract_all(self) -> Dict:
    |                              ^^^^
315 |         """Extract all documents and return statistics."""
316 |         stats = {
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utilities/convert_emails_to_markdown.py:337:22
    |
335 |                 output_file.parent.mkdir(parents=True, exist_ok=True)
336 |
337 |                 with open(output_file, "w", encoding="utf-8") as f:
    |                      ^^^^
338 |                     f.write(content)
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:359:48
    |
359 | def create_index_file(output_dir: Path, stats: Dict):
    |                                                ^^^^
360 |     """Create INDEX.md with document catalog."""
    |
help: Replace with `dict`

PLC0206 Extracting value from dictionary without calling `.items()`
   --> scripts/utilities/convert_emails_to_markdown.py:389:9
    |
388 |       for filepath in sorted(stats["files_created"]):
389 | /         for category in categories:
390 | |             if f"/{category}/" in filepath:
391 | |                 categories[category].append(filepath)
392 | |                 break
    | |_____________________^
393 |
394 |       # Add each category
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utilities/convert_emails_to_markdown.py:425:10
    |
424 |     index_file = output_dir / "INDEX.md"
425 |     with open(index_file, "w", encoding="utf-8") as f:
    |          ^^^^
426 |         f.write("\n".join(index_lines))
    |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utilities/convert_emails_to_markdown.py:431:53
    |
431 | def create_statistics_file(output_dir: Path, stats: Dict):
    |                                                     ^^^^
432 |     """Create detailed statistics summary."""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utilities/convert_emails_to_markdown.py:499:10
    |
498 |     stats_file = output_dir / "STATISTICS.md"
499 |     with open(stats_file, "w", encoding="utf-8") as f:
    |          ^^^^
500 |         f.write("\n".join(lines))
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/utils/build_entity_mappings.py:16:1
   |
14 | import re
15 | from pathlib import Path
16 | from typing import Dict, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/utils/build_entity_mappings.py:16:1
   |
14 | import re
15 | from pathlib import Path
16 | from typing import Dict, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/build_entity_mappings.py:36:55
   |
36 | def build_name_mappings(entities_index_path: Path) -> Dict[str, str]:
   |                                                       ^^^^
37 |     """Build comprehensive name normalization mappings.
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/build_entity_mappings.py:42:10
   |
40 |         Dictionary mapping variant names to canonical names
41 |     """
42 |     with open(entities_index_path) as f:
   |          ^^^^
43 |         data = json.load(f)
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/build_entity_mappings.py:46:15
   |
45 |     entities = data["entities"]
46 |     mappings: Dict[str, str] = {}
   |               ^^^^
47 |
48 |     # Track all variations of each normalized base name
   |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/build_entity_mappings.py:49:27
   |
48 |     # Track all variations of each normalized base name
49 |     base_name_variations: Dict[str, Set[str]] = {}
   |                           ^^^^
50 |
51 |     for entity in entities:
   |
help: Replace with `dict`

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/utils/build_entity_mappings.py:49:37
   |
48 |     # Track all variations of each normalized base name
49 |     base_name_variations: Dict[str, Set[str]] = {}
   |                                     ^^^
50 |
51 |     for entity in entities:
   |
help: Replace with `set`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utils/build_entity_mappings.py:133:32
    |
133 | def analyze_mappings(mappings: Dict[str, str]) -> None:
    |                                ^^^^
134 |     """Print analysis of the mappings."""
135 |     print(f"Total mappings: {len(mappings)}")
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utils/build_entity_mappings.py:138:19
    |
137 |     # Group by canonical name
138 |     by_canonical: Dict[str, list[str]] = {}
    |                   ^^^^
139 |     for variant, canonical in mappings.items():
140 |         if canonical not in by_canonical:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/build_entity_mappings.py:169:10
    |
167 |     # Save mappings
168 |     output_path.parent.mkdir(parents=True, exist_ok=True)
169 |     with open(output_path, "w") as f:
    |          ^^^^
170 |         json.dump(mappings, f, indent=2, sort_keys=True)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/utils/entity_filtering.py:26:1
   |
24 | import json
25 | from pathlib import Path
26 | from typing import Any, Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/utils/entity_filtering.py:26:1
   |
24 | import json
25 | from pathlib import Path
26 | from typing import Any, Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/utils/entity_filtering.py:26:1
   |
24 | import json
25 | from pathlib import Path
26 | from typing import Any, Dict, List, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `set` instead of `Set` for type annotation
  --> scripts/utils/entity_filtering.py:48:33
   |
47 |         self.filter_list_path = filter_list_path
48 |         self._generic_entities: Set[str] = set()
   |                                 ^^^
49 |         self._load_filter_list()
   |
help: Replace with `set`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/entity_filtering.py:63:18
   |
62 |         try:
63 |             with open(self.filter_list_path) as f:
   |                  ^^^^
64 |                 data = json.load(f)
   |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/utils/entity_filtering.py:89:41
   |
87 |         return entity_name in self._generic_entities
88 |
89 |     def filter_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   |                                         ^^^^
90 |         """Filter list of entity dictionaries.
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/entity_filtering.py:89:46
   |
87 |         return entity_name in self._generic_entities
88 |
89 |     def filter_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   |                                              ^^^^
90 |         """Filter list of entity dictionaries.
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
  --> scripts/utils/entity_filtering.py:89:66
   |
87 |         return entity_name in self._generic_entities
88 |
89 |     def filter_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   |                                                                  ^^^^
90 |         """Filter list of entity dictionaries.
   |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/entity_filtering.py:89:71
   |
87 |         return entity_name in self._generic_entities
88 |
89 |     def filter_entities(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   |                                                                       ^^^^
90 |         """Filter list of entity dictionaries.
   |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utils/entity_filtering.py:102:42
    |
100 |         return [e for e in entities if not self.is_generic(e.get("name", ""))]
101 |
102 |     def filter_entity_names(self, names: List[str]) -> List[str]:
    |                                          ^^^^
103 |         """Filter list of entity names.
    |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utils/entity_filtering.py:102:56
    |
100 |         return [e for e in entities if not self.is_generic(e.get("name", ""))]
101 |
102 |     def filter_entity_names(self, names: List[str]) -> List[str]:
    |                                                        ^^^^
103 |         """Filter list of entity names.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> scripts/utils/entity_filtering.py:117:40
    |
115 |         return len(self._generic_entities)
116 |
117 |     def get_filter_categories(self) -> Dict[str, List[str]]:
    |                                        ^^^^
118 |         """Get filter categories with entity lists.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> scripts/utils/entity_filtering.py:117:50
    |
115 |         return len(self._generic_entities)
116 |
117 |     def get_filter_categories(self) -> Dict[str, List[str]]:
    |                                                  ^^^^
118 |         """Get filter categories with entity lists.
    |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/entity_filtering.py:126:14
    |
124 |             return {}
125 |
126 |         with open(self.filter_list_path) as f:
    |              ^^^^
127 |             data = json.load(f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/entity_filtering.py:140:14
    |
138 |             return "Filter list not available"
139 |
140 |         with open(self.filter_list_path) as f:
    |              ^^^^
141 |             data = json.load(f)
    |
help: Replace with `Path.open()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/utils/entity_normalization.py:11:1
   |
 9 | import re
10 | from pathlib import Path
11 | from typing import Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/entity_normalization.py:29:24
   |
28 |         self.mappings_path = mappings_path
29 |         self.mappings: Dict[str, str] = {}
   |                        ^^^^
30 |         self._load_mappings()
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/entity_normalization.py:39:14
   |
37 |             return
38 |
39 |         with open(self.mappings_path) as f:
   |              ^^^^
40 |             self.mappings = json.load(f)
   |
help: Replace with `Path.open()`

UP006 Use `dict` instead of `Dict` for type annotation
  --> scripts/utils/entity_normalization.py:94:24
   |
92 |         return variants
93 |
94 |     def stats(self) -> Dict:
   |                        ^^^^
95 |         """Get statistics about loaded mappings.
   |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> scripts/utils/entity_normalization.py:120:9
    |
118 |             List of (canonical_name, variant_count) tuples
119 |         """
120 |         from collections import Counter
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
121 |
122 |         canonical_counts = Counter(self.mappings.values())
    |

PLW0603 Using the global statement to update `_normalizer_instance` is discouraged
   --> scripts/utils/entity_normalization.py:136:12
    |
134 |         EntityNormalizer instance
135 |     """
136 |     global _normalizer_instance
    |            ^^^^^^^^^^^^^^^^^^^^
137 |     if _normalizer_instance is None:
138 |         _normalizer_instance = EntityNormalizer()
    |

E402 Module level import not at top of file
  --> scripts/utils/verify_normalization.py:23:1
   |
21 | # Add utils to path
22 | sys.path.insert(0, str(Path(__file__).parent))
23 | from entity_normalization import EntityNormalizer
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/verify_normalization.py:52:10
   |
51 |     network_path = METADATA_DIR / "entity_network.json"
52 |     with open(network_path) as f:
   |          ^^^^
53 |         network = json.load(f)
   |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/verify_normalization.py:113:10
    |
112 |     network_path = METADATA_DIR / "entity_network.json"
113 |     with open(network_path) as f:
    |          ^^^^
114 |         network = json.load(f)
    |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> scripts/utils/verify_normalization.py:147:9
    |
145 |         server_path = PROJECT_ROOT / "server" / "services"
146 |         sys.path.insert(0, str(server_path))
147 |         from entity_disambiguation import get_disambiguator
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
148 |
149 |         disambiguator = get_disambiguator()
    |

UP035 `typing.List` is deprecated, use `list` instead
  --> server/app.py:15:1
   |
13 | from datetime import datetime, timedelta
14 | from pathlib import Path
15 | from typing import List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
16 |
17 | import uvicorn
   |

PLW0603 Using the global statement to update `openrouter_client` is discouraged
  --> server/app.py:47:12
   |
45 | def get_openrouter_client():
46 |     """Initialize OpenRouter client (lazy loading)"""
47 |     global openrouter_client
   |            ^^^^^^^^^^^^^^^^^
48 |     if openrouter_client is None:
49 |         api_key = os.getenv("OPENROUTER_API_KEY")
   |

E402 Module level import not at top of file
  --> server/app.py:69:1
   |
68 | # Load credentials from file
69 | import os
   | ^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> server/app.py:88:14
   |
87 |     if CREDENTIALS_FILE.exists():
88 |         with open(CREDENTIALS_FILE) as f:
   |              ^^^^
89 |             for line in f:
90 |                 line = line.strip()
   |
help: Replace with `Path.open()`

PLW2901 `for` loop variable `line` overwritten by assignment target
  --> server/app.py:90:17
   |
88 |         with open(CREDENTIALS_FILE) as f:
89 |             for line in f:
90 |                 line = line.strip()
   |                 ^^^^
91 |                 if line and not line.startswith("#"):
92 |                     if ":" in line:
   |

SIM102 Use a single `if` statement instead of nested `if` statements
  --> server/app.py:91:17
   |
89 |               for line in f:
90 |                   line = line.strip()
91 | /                 if line and not line.startswith("#"):
92 | |                     if ":" in line:
   | |___________________________________^
93 |                           username, password = line.split(":", 1)
94 |                           credentials[username.strip()] = password.strip()
   |
help: Combine `if` statements using `and`

PLR0915 Too many statements (71 > 60)
   --> server/app.py:235:5
    |
233 | timeline_data = {}
234 |
235 | def load_data():
    |     ^^^^^^^^^
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |

PLW0603 Using the global statement to update `entity_stats` is discouraged
   --> server/app.py:237:12
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |            ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `entity_stats` is discouraged
   --> server/app.py:237:12
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |            ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `entity_stats` is discouraged
   --> server/app.py:237:12
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |            ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `network_data` is discouraged
   --> server/app.py:237:26
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                          ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `network_data` is discouraged
   --> server/app.py:237:26
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                          ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `network_data` is discouraged
   --> server/app.py:237:26
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                          ^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `semantic_index` is discouraged
   --> server/app.py:237:40
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                        ^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `semantic_index` is discouraged
   --> server/app.py:237:40
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                        ^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `semantic_index` is discouraged
   --> server/app.py:237:40
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                        ^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `classifications` is discouraged
   --> server/app.py:237:56
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                        ^^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `classifications` is discouraged
   --> server/app.py:237:56
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                        ^^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `classifications` is discouraged
   --> server/app.py:237:56
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                        ^^^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `timeline_data` is discouraged
   --> server/app.py:237:73
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                                         ^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `timeline_data` is discouraged
   --> server/app.py:237:73
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                                         ^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PLW0603 Using the global statement to update `timeline_data` is discouraged
   --> server/app.py:237:73
    |
235 | def load_data():
236 |     """Load all JSON data into memory with error handling"""
237 |     global entity_stats, network_data, semantic_index, classifications, timeline_data
    |                                                                         ^^^^^^^^^^^^^
238 |
239 |     print("Loading data...")
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:245:18
    |
243 |     if stats_path.exists():
244 |         try:
245 |             with open(stats_path) as f:
    |                  ^^^^
246 |                 data = json.load(f)
247 |                 # Fix: entity_statistics.json has structure: {statistics: {entity_name: {...}}}
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:261:18
    |
259 |     if network_path.exists():
260 |         try:
261 |             with open(network_path) as f:
    |                  ^^^^
262 |                 network_data = json.load(f)
263 |                 print(f"  ✓ Loaded {len(network_data.get('nodes', []))} network nodes")
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:275:18
    |
273 |     if semantic_path.exists():
274 |         try:
275 |             with open(semantic_path) as f:
    |                  ^^^^
276 |                 data = json.load(f)
277 |                 semantic_index = data.get("entity_to_documents", {})
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:290:18
    |
288 |     if class_path.exists():
289 |         try:
290 |             with open(class_path) as f:
    |                  ^^^^
291 |                 data = json.load(f)
292 |                 classifications = data.get("results", {})
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:305:18
    |
303 |     if timeline_path.exists():
304 |         try:
305 |             with open(timeline_path) as f:
    |                  ^^^^
306 |                 timeline_data = json.load(f)
307 |                 print("  ✓ Loaded timeline data")
    |
help: Replace with `Path.open()`

ARG001 Unused function argument: `username`
   --> server/app.py:448:21
    |
447 | @app.get("/api/stats")
448 | async def get_stats(username: str = Depends(authenticate)):
    |                     ^^^^^^^^
449 |     """Get overall statistics
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:465:18
    |
463 |     if source_index_path.exists():
464 |         try:
465 |             with open(source_index_path) as f:
    |                  ^^^^
466 |                 sources_data = json.load(f)
467 |                 # source_index.json has structure: {sources: {key: {description: ...}}}
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:488:18
    |
486 |     if unified_index_path.exists():
487 |         try:
488 |             with open(unified_index_path) as f:
    |                  ^^^^
489 |                 unified_data = json.load(f)
490 |                 total_documents = unified_data.get("total_documents", len(classifications))
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:501:22
    |
499 |         if master_index_path.exists():
500 |             try:
501 |                 with open(master_index_path) as f:
    |                      ^^^^
502 |                     index_data = json.load(f)
503 |                     total_documents = index_data.get("unique_documents", len(classifications))
    |
help: Replace with `Path.open()`

ARG001 Unused function argument: `username`
   --> server/app.py:521:29
    |
520 | @app.get("/api/sources/index")
521 | async def get_sources_index(username: str = Depends(authenticate)):
    |                             ^^^^^^^^
522 |     """Get master document index with deduplication statistics.
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:552:14
    |
551 |         # Load master index (on-demand, not cached due to size)
552 |         with open(index_path) as f:
    |              ^^^^
553 |             index_data = json.load(f)
    |
help: Replace with `Path.open()`

C414 Unnecessary `list()` call within `sorted()`
   --> server/app.py:618:36
    |
616 |                     cross_source.append({
617 |                         "document": doc_name,
618 |                         "sources": sorted(list(source_names)),
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
619 |                         "file_count": len(doc_sources)
620 |                     })
    |
help: Remove the inner `list()` call

PLC0415 `import` should be at the top-level of a file
   --> server/app.py:631:9
    |
629 |     except Exception as e:
630 |         print(f"Error loading sources index: {e}")
631 |         import traceback
    |         ^^^^^^^^^^^^^^^^
632 |         traceback.print_exc()
633 |         return {
    |

PLR0915 Too many statements (73 > 60)
   --> server/app.py:642:11
    |
641 | @app.get("/api/ingestion/status")
642 | async def get_ingestion_status(username: str = Depends(authenticate)):
    |           ^^^^^^^^^^^^^^^^^^^^
643 |     """Get ingestion progress status
    |

ARG001 Unused function argument: `username`
   --> server/app.py:642:32
    |
641 | @app.get("/api/ingestion/status")
642 | async def get_ingestion_status(username: str = Depends(authenticate)):
    |                                ^^^^^^^^
643 |     """Get ingestion progress status
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:658:18
    |
656 |     if merged_index_path.exists():
657 |         try:
658 |             with open(merged_index_path) as f:
    |                  ^^^^
659 |                 entity_data = json.load(f)
660 |                 entities_merged = entity_data.get("duplicates_merged", 0)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:690:18
    |
688 |     if progress_path.exists():
689 |         try:
690 |             with open(progress_path) as f:
    |                  ^^^^
691 |                 progress_data = json.load(f)
692 |                 last_updated = progress_data.get("last_updated")
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:701:18
    |
699 |     if download_log_path.exists():
700 |         try:
701 |             with open(download_log_path) as f:
    |                  ^^^^
702 |                 log_content = f.read()
703 |                 # Parse the last complete summary if it exists
    |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> server/app.py:705:21
    |
703 |                 # Parse the last complete summary if it exists
704 |                 if "Download Complete" in log_content:
705 |                     import re
    |                     ^^^^^^^^^
706 |                     success_match = re.search(r"Successfully downloaded: (\d+)", log_content)
707 |                     total_match = re.search(r"Total files in directory: (\d+)", log_content)
    |

PLC0415 `import` should be at the top-level of a file
   --> server/app.py:725:13
    |
723 |     if dedup_db_path.exists():
724 |         try:
725 |             import sqlite3
    |             ^^^^^^^^^^^^^^
726 |             conn = sqlite3.connect(str(dedup_db_path))
727 |             cursor = conn.cursor()
    |

ARG001 Unused function argument: `username`
   --> server/app.py:776:33
    |
775 | @app.get("/api/chatbot/knowledge")
776 | async def get_chatbot_knowledge(username: str = Depends(authenticate)):
    |                                 ^^^^^^^^
777 |     """Get comprehensive knowledge index for chatbot.
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/app.py:805:14
    |
804 |     try:
805 |         with open(knowledge_path) as f:
    |              ^^^^
806 |             knowledge = json.load(f)
    |
help: Replace with `Path.open()`

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> server/app.py:810:9
    |
808 |           return JSONResponse(content=knowledge)
809 |       except Exception as e:
810 | /         raise HTTPException(
811 | |             status_code=500,
812 | |             detail=f"Failed to load knowledge index: {e!s}"
813 | |         )
    | |_________^
    |

ARG001 Unused function argument: `username`
   --> server/app.py:823:5
    |
821 |     filter_billionaires: bool = Query(False),
822 |     filter_connected: bool = Query(False),
823 |     username: str = Depends(authenticate)
    |     ^^^^^^^^
824 | ):
825 |     """Get list of entities with optional filtering and sorting
    |

ARG001 Unused function argument: `username`
   --> server/app.py:859:33
    |
858 | @app.get("/api/entities/{name}")
859 | async def get_entity(name: str, username: str = Depends(authenticate)):
    |                                 ^^^^^^^^
860 |     """Get detailed information about a specific entity with disambiguation support
    |

ARG001 Unused function argument: `username`
   --> server/app.py:889:5
    |
887 |     max_nodes: int = Query(500, le=1000),
888 |     deduplicate: bool = Query(True),
889 |     username: str = Depends(authenticate)
    |     ^^^^^^^^
890 | ):
891 |     """Get network graph data with optional deduplication
    |

ARG001 Unused function argument: `username`
   --> server/app.py:961:5
    |
959 |     type: Optional[str] = Query(None),
960 |     limit: int = Query(50, le=500),
961 |     username: str = Depends(authenticate)
    |     ^^^^^^^^
962 | ):
963 |     """Search for entities or documents
    |

ARG001 Unused function argument: `username`
    --> server/app.py:1004:5
     |
1002 |     end_date: Optional[str] = None,
1003 |     limit: int = Query(1000, le=5000),
1004 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1005 | ):
1006 |     """Get timeline events"""
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1068:5
     |
1066 | async def chat(
1067 |     message: ChatMessage,
1068 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1069 | ):
1070 |     """Chat with GPT-4.5 assistant about the archive with integrated search"""
     |

E402 Module level import not at top of file
    --> server/app.py:1174:1
     |
1172 | # Initialize suggestion service
1173 | # Add utils path for entity filtering
1174 | import sys
     | ^^^^^^^^^^
1175 |
1176 | from models.suggested_source import (
     |

E402 Module level import not at top of file
    --> server/app.py:1176:1
     |
1174 |   import sys
1175 |
1176 | / from models.suggested_source import (
1177 | |     SourcePriority,
1178 | |     SourceStatus,
1179 | |     SuggestedSourceCreate,
1180 | |     SuggestedSourceUpdate,
1181 | | )
     | |_^
1182 |
1183 |   # Initialize entity disambiguation service
     |

E402 Module level import not at top of file
    --> server/app.py:1184:1
     |
1183 | # Initialize entity disambiguation service
1184 | from services.entity_disambiguation import get_disambiguator
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1185 |
1186 | # Initialize entity enrichment service
     |

E402 Module level import not at top of file
    --> server/app.py:1187:1
     |
1186 | # Initialize entity enrichment service
1187 | from services.entity_enrichment import EntityEnrichmentService, format_for_ui
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1188 | from services.suggestion_service import SuggestionService
     |

E402 Module level import not at top of file
    --> server/app.py:1188:1
     |
1186 | # Initialize entity enrichment service
1187 | from services.entity_enrichment import EntityEnrichmentService, format_for_ui
1188 | from services.suggestion_service import SuggestionService
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
     |

E402 Module level import not at top of file
    --> server/app.py:1192:1
     |
1191 | sys.path.insert(0, str(PROJECT_ROOT / "scripts/utils"))
1192 | from entity_filtering import EntityFilter
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
     |

F841 Local variable `parsed_url` is assigned to but never used
    --> server/app.py:1220:5
     |
1218 |     """
1219 |     # Additional security validation
1220 |     parsed_url = urllib.parse.urlparse(suggestion.url)
     |     ^^^^^^^^^^
1221 |
1222 |     # Block suspicious domains
     |
help: Remove assignment to unused variable `parsed_url`

ARG001 Unused function argument: `username`
    --> server/app.py:1252:5
     |
1250 |     limit: int = Query(100, le=500),
1251 |     offset: int = Query(0, ge=0),
1252 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1253 | ):
1254 |     """Get list of source suggestions with filtering
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1282:5
     |
1280 | async def get_suggestion(
1281 |     suggestion_id: str,
1282 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1283 | ):
1284 |     """Get single suggestion by ID
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1340:5
     |
1338 | async def delete_suggestion(
1339 |     suggestion_id: str,
1340 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1341 | ):
1342 |     """Delete suggestion by ID (admin only)
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1364:37
     |
1363 | @app.get("/api/suggestions/stats/summary")
1364 | async def get_suggestion_statistics(username: str = Depends(authenticate)):
     |                                     ^^^^^^^^
1365 |     """Get suggestion statistics for admin dashboard
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1382:5
     |
1380 |     entity_id: str,
1381 |     force_refresh: bool = Query(False),
1382 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1383 | ):
1384 |     """Trigger web search enrichment for an entity.
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> server/app.py:1471:9
     |
1470 |       except Exception as e:
1471 | /         raise HTTPException(
1472 | |             status_code=500,
1473 | |             detail=f"Error enriching entity: {e!s}"
1474 | |         )
     | |_________^
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1480:5
     |
1478 | async def get_enrichment(
1479 |     entity_id: str,
1480 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1481 | ):
1482 |     """Get cached enrichment data for an entity.
     |

UP006 Use `list` instead of `List` for type annotation
    --> server/app.py:1537:17
     |
1535 | @app.post("/api/entities/enrich/batch")
1536 | async def enrich_batch(
1537 |     entity_ids: List[str],
     |                 ^^^^
1538 |     max_concurrent: int = Query(3, ge=1, le=5),
1539 |     username: str = Depends(authenticate)
     |
help: Replace with `list`

ARG001 Unused function argument: `username`
    --> server/app.py:1539:5
     |
1537 |     entity_ids: List[str],
1538 |     max_concurrent: int = Query(3, ge=1, le=5),
1539 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1540 | ):
1541 |     """Enrich multiple entities in a single request.
     |

PLW2901 `for` loop variable `entity_id` overwritten by assignment target
    --> server/app.py:1584:13
     |
1582 |                     detail=f"Entity '{entity_id}' not found"
1583 |                 )
1584 |             entity_id, entity_data = matching[0]
     |             ^^^^^^^^^
1585 |
1586 |         entities.append({
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> server/app.py:1605:9
     |
1604 |       except Exception as e:
1605 | /         raise HTTPException(
1606 | |             status_code=500,
1607 | |             detail=f"Error during batch enrichment: {e!s}"
1608 | |         )
     | |_________^
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1612:37
     |
1611 | @app.get("/api/enrichment/stats")
1612 | async def get_enrichment_statistics(username: str = Depends(authenticate)):
     |                                     ^^^^^^^^
1613 |     """Get enrichment cache statistics.
     |

ARG001 Unused function argument: `username`
    --> server/app.py:1677:5
     |
1675 | async def get_recent_commits(
1676 |     limit: int = Query(default=10, ge=1, le=50),
1677 |     username: str = Depends(authenticate)
     |     ^^^^^^^^
1678 | ):
1679 |     """Get recent git commits with semantic commit parsing.
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> server/app.py:1770:9
     |
1769 |       except subprocess.TimeoutExpired:
1770 | /         raise HTTPException(
1771 | |             status_code=500,
1772 | |             detail="Git command timed out"
1773 | |         )
     | |_________^
1774 |       except Exception as e:
1775 |           raise HTTPException(
     |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
    --> server/app.py:1775:9
     |
1773 |           )
1774 |       except Exception as e:
1775 | /         raise HTTPException(
1776 | |             status_code=500,
1777 | |             detail=f"Error fetching commits: {e!s}"
1778 | |         )
     | |_________^
     |

PLC0415 `import` should be at the top-level of a file
    --> server/app.py:1790:5
     |
1788 | def main():
1789 |     """Run server"""
1790 |     import sys
     |     ^^^^^^^^^^
1791 |
1792 |     port = int(sys.argv[1]) if len(sys.argv) > 1 else 8000
     |

F841 Local variable `original` is assigned to but never used
   --> server/demo_fixes.py:124:9
    |
122 |     for name in sample_names:
123 |         # Find in original graph
124 |         original = next((n for n in data1["nodes"] if name in n["name"]), None)
    |         ^^^^^^^^
125 |         # Find in deduplicated graph
126 |         dedup = next((n for n in data2["nodes"] if name in n["name"]), None)
    |
help: Remove assignment to unused variable `original`

UP035 `typing.List` is deprecated, use `list` instead
  --> server/models/suggested_source.py:13:1
   |
11 | from datetime import datetime
12 | from enum import Enum
13 | from typing import List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
14 |
15 | from pydantic import BaseModel, Field, field_validator
   |

UP006 Use `list` instead of `List` for type annotation
  --> server/models/suggested_source.py:44:11
   |
42 |     priority: SourcePriority = Field(default=SourcePriority.MEDIUM, description="Suggested priority level")
43 |     document_count_estimate: Optional[int] = Field(None, ge=0, description="Estimated number of documents")
44 |     tags: List[str] = Field(default_factory=list, description="Tags for categorization")
   |           ^^^^
45 |
46 |     @field_validator("url")
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/models/suggested_source.py:56:31
   |
54 |     @field_validator("tags")
55 |     @classmethod
56 |     def validate_tags(cls, v: List[str]) -> List[str]:
   |                               ^^^^
57 |         """Limit number of tags and normalize"""
58 |         if len(v) > 10:
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/models/suggested_source.py:56:45
   |
54 |     @field_validator("tags")
55 |     @classmethod
56 |     def validate_tags(cls, v: List[str]) -> List[str]:
   |                                             ^^^^
57 |         """Limit number of tags and normalize"""
58 |         if len(v) > 10:
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/models/suggested_source.py:69:20
   |
67 |     review_notes: Optional[str] = Field(None, max_length=2000)
68 |     document_count_estimate: Optional[int] = Field(None, ge=0)
69 |     tags: Optional[List[str]] = None
   |                    ^^^^
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
   --> server/models/suggested_source.py:103:11
    |
101 |     priority: SourcePriority = Field(default=SourcePriority.MEDIUM)
102 |     document_count_estimate: Optional[int] = None
103 |     tags: List[str] = Field(default_factory=list)
    |           ^^^^
104 |
105 |     # Processing metadata
    |
help: Replace with `list`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> server/models/suggested_source.py:112:25
    |
111 |       class Config:
112 |           json_encoders = {
    |  _________________________^
113 | |             datetime: lambda v: v.isoformat() if v else None
114 | |         }
    | |_________^
115 |           use_enum_values = True
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> server/services/audit_logger.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | from pathlib import Path
21 | from typing import Any, Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> server/services/audit_logger.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | from pathlib import Path
21 | from typing import Any, Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> server/services/audit_logger.py:59:14
   |
57 |     username: Optional[str]
58 |     timestamp: datetime
59 |     details: Dict[str, Any]
   |              ^^^^
60 |     ip_address: str  # Hashed
61 |     severity: str = "medium"  # low, medium, high, critical
   |
help: Replace with `dict`

PLR0915 Too many statements (65 > 60)
   --> server/services/audit_logger.py:227:9
    |
226 |     @staticmethod
227 |     def parse_user_agent(user_agent: str) -> Dict[str, str]:
    |         ^^^^^^^^^^^^^^^^
228 |         """Parse User-Agent string to extract browser and OS information.
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/audit_logger.py:227:46
    |
226 |     @staticmethod
227 |     def parse_user_agent(user_agent: str) -> Dict[str, str]:
    |                                              ^^^^
228 |         """Parse User-Agent string to extract browser and OS information.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> server/services/audit_logger.py:558:10
    |
556 |         limit: int = 100,
557 |         offset: int = 0
558 |     ) -> List[Dict[str, Any]]:
    |          ^^^^
559 |         """Retrieve login event history with browser profiles.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/audit_logger.py:558:15
    |
556 |         limit: int = 100,
557 |         offset: int = 0
558 |     ) -> List[Dict[str, Any]]:
    |               ^^^^
559 |         """Retrieve login event history with browser profiles.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> server/services/audit_logger.py:604:10
    |
602 |         limit: int = 100,
603 |         offset: int = 0
604 |     ) -> List[Dict[str, Any]]:
    |          ^^^^
605 |         """Retrieve security events for dashboard.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/audit_logger.py:604:15
    |
602 |         limit: int = 100,
603 |         offset: int = 0
604 |     ) -> List[Dict[str, Any]]:
    |               ^^^^
605 |         """Retrieve security events for dashboard.
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/audit_logger.py:669:39
    |
667 |             return cursor.rowcount
668 |
669 |     def get_login_statistics(self) -> Dict[str, Any]:
    |                                       ^^^^
670 |         """Get aggregate statistics for admin dashboard.
    |
help: Replace with `dict`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> server/services/entity_disambiguation.py:22:1
   |
20 | import re
21 | from pathlib import Path
22 | from typing import Dict, Optional, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> server/services/entity_disambiguation.py:22:1
   |
20 | import re
21 | from pathlib import Path
22 | from typing import Dict, Optional, Set
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> server/services/entity_disambiguation.py:29:21
   |
28 |     # Entity aliases loaded from JSON file
29 |     ENTITY_ALIASES: Dict[str, str] = {}
   |                     ^^^^
30 |
31 |     # Reverse mapping: canonical -> all known variations
   |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> server/services/entity_disambiguation.py:29:38
   |
28 |     # Entity aliases loaded from JSON file
29 |     ENTITY_ALIASES: Dict[str, str] = {}
   |                                      ^^
30 |
31 |     # Reverse mapping: canonical -> all known variations
   |

UP006 Use `dict` instead of `Dict` for type annotation
  --> server/services/entity_disambiguation.py:32:30
   |
31 |     # Reverse mapping: canonical -> all known variations
32 |     CANONICAL_TO_VARIATIONS: Dict[str, Set[str]] = {}
   |                              ^^^^
33 |
34 |     def __init__(self, mappings_path: Optional[Path] = None):
   |
help: Replace with `dict`

UP006 Use `set` instead of `Set` for type annotation
  --> server/services/entity_disambiguation.py:32:40
   |
31 |     # Reverse mapping: canonical -> all known variations
32 |     CANONICAL_TO_VARIATIONS: Dict[str, Set[str]] = {}
   |                                        ^^^
33 |
34 |     def __init__(self, mappings_path: Optional[Path] = None):
   |
help: Replace with `set`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> server/services/entity_disambiguation.py:32:52
   |
31 |     # Reverse mapping: canonical -> all known variations
32 |     CANONICAL_TO_VARIATIONS: Dict[str, Set[str]] = {}
   |                                                    ^^
33 |
34 |     def __init__(self, mappings_path: Optional[Path] = None):
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> server/services/entity_disambiguation.py:68:18
   |
67 |         try:
68 |             with open(mappings_path) as f:
   |                  ^^^^
69 |                 self.ENTITY_ALIASES = json.load(f)
70 |             print(f"Loaded {len(self.ENTITY_ALIASES)} entity name mappings")
   |
help: Replace with `Path.open()`

UP006 Use `set` instead of `Set` for type annotation
   --> server/services/entity_disambiguation.py:120:58
    |
118 |         return name
119 |
120 |     def get_all_variations(self, canonical_name: str) -> Set[str]:
    |                                                          ^^^
121 |         """Get all known variations for a canonical name
    |
help: Replace with `set`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_disambiguation.py:135:54
    |
133 |         return self.CANONICAL_TO_VARIATIONS.get(canonical_name, {canonical_name})
134 |
135 |     def search_entity(self, query: str, entity_dict: Dict[str, any]) -> Optional[any]:
    |                                                      ^^^^
136 |         """Search entity dictionary with disambiguation support
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_disambiguation.py:201:26
    |
199 |             Output: [{"name": "Jeffrey Epstein", "connection_count": 212}]
200 |         """
201 |         canonical_nodes: Dict[str, dict] = {}
    |                          ^^^^
202 |
203 |         for node in nodes:
    |
help: Replace with `dict`

ARG002 Unused method argument: `node_mapping`
   --> server/services/entity_disambiguation.py:237:52
    |
235 |         return list(canonical_nodes.values())
236 |
237 |     def deduplicate_edges(self, edges: list[dict], node_mapping: Dict[str, str]) -> list[dict]:
    |                                                    ^^^^^^^^^^^^
238 |         """Deduplicate network edges after node merging
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_disambiguation.py:237:66
    |
235 |         return list(canonical_nodes.values())
236 |
237 |     def deduplicate_edges(self, edges: list[dict], node_mapping: Dict[str, str]) -> list[dict]:
    |                                                                  ^^^^
238 |         """Deduplicate network edges after node merging
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_disambiguation.py:260:26
    |
258 |             Output: [{"source": "Jeffrey Epstein", "target": "Ghislaine Maxwell", "weight": 228}]
259 |         """
260 |         canonical_edges: Dict[tuple[str, str], dict] = {}
    |                          ^^^^
261 |
262 |         for edge in edges:
    |
help: Replace with `dict`

PLW0603 Using the global statement to update `_disambiguator_instance` is discouraged
   --> server/services/entity_disambiguation.py:305:12
    |
303 | def get_disambiguator() -> EntityDisambiguation:
304 |     """Get global EntityDisambiguation instance (lazy singleton)"""
305 |     global _disambiguator_instance
    |            ^^^^^^^^^^^^^^^^^^^^^^^
306 |     if _disambiguator_instance is None:
307 |         _disambiguator_instance = EntityDisambiguation()
    |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> server/services/entity_enrichment.py:29:1
   |
27 | from datetime import datetime, timedelta
28 | from pathlib import Path
29 | from typing import Any, Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from urllib.parse import urlparse
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> server/services/entity_enrichment.py:29:1
   |
27 | from datetime import datetime, timedelta
28 | from pathlib import Path
29 | from typing import Any, Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from urllib.parse import urlparse
   |

N805 First argument of a method should be named `self`
  --> server/services/entity_enrichment.py:56:20
   |
55 |     @validator("domain", always=True)
56 |     def set_domain(cls, v, values):
   |                    ^^^
57 |         """Extract domain from URL for display and confidence scoring"""
58 |         if "url" in values:
   |
help: Rename `cls` to `self`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> server/services/entity_enrichment.py:63:25
   |
62 |       class Config:
63 |           json_encoders = {
   |  _________________________^
64 | |             datetime: lambda dt: dt.isoformat(),
65 | |             HttpUrl: str
66 | |         }
   | |_________^
   |

UP006 Use `list` instead of `List` for type annotation
  --> server/services/entity_enrichment.py:79:19
   |
77 |     biography: Optional[str] = None
78 |     profession: Optional[str] = None
79 |     associations: List[str] = Field(default_factory=list)
   |                   ^^^^
80 |     known_dates: List[str] = Field(default_factory=list)  # Dates mentioned in sources
81 |     sources: List[EnrichmentSource] = Field(default_factory=list)
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/services/entity_enrichment.py:80:18
   |
78 |     profession: Optional[str] = None
79 |     associations: List[str] = Field(default_factory=list)
80 |     known_dates: List[str] = Field(default_factory=list)  # Dates mentioned in sources
   |                  ^^^^
81 |     sources: List[EnrichmentSource] = Field(default_factory=list)
82 |     enriched_at: datetime = Field(default_factory=datetime.utcnow)
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/services/entity_enrichment.py:81:14
   |
79 |     associations: List[str] = Field(default_factory=list)
80 |     known_dates: List[str] = Field(default_factory=list)  # Dates mentioned in sources
81 |     sources: List[EnrichmentSource] = Field(default_factory=list)
   |              ^^^^
82 |     enriched_at: datetime = Field(default_factory=datetime.utcnow)
83 |     last_updated: datetime = Field(default_factory=datetime.utcnow)
   |
help: Replace with `list`

UP006 Use `list` instead of `List` for type annotation
  --> server/services/entity_enrichment.py:86:26
   |
85 |     # Metadata
86 |     search_queries_used: List[str] = Field(default_factory=list)
   |                          ^^^^
87 |     total_sources: int = 0
88 |     average_confidence: float = 0.0
   |
help: Replace with `list`

N805 First argument of a method should be named `self`
  --> server/services/entity_enrichment.py:91:23
   |
90 |     @validator("total_sources", always=True)
91 |     def count_sources(cls, v, values):
   |                       ^^^
92 |         return len(values.get("sources", []))
   |
help: Rename `cls` to `self`

ARG002 Unused method argument: `v`
  --> server/services/entity_enrichment.py:91:28
   |
90 |     @validator("total_sources", always=True)
91 |     def count_sources(cls, v, values):
   |                            ^
92 |         return len(values.get("sources", []))
   |

N805 First argument of a method should be named `self`
  --> server/services/entity_enrichment.py:95:29
   |
94 |     @validator("average_confidence", always=True)
95 |     def calc_avg_confidence(cls, v, values):
   |                             ^^^
96 |         sources = values.get("sources", [])
97 |         if not sources:
   |
help: Rename `cls` to `self`

ARG002 Unused method argument: `v`
  --> server/services/entity_enrichment.py:95:34
   |
94 |     @validator("average_confidence", always=True)
95 |     def calc_avg_confidence(cls, v, values):
   |                                  ^
96 |         sources = values.get("sources", [])
97 |         if not sources:
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> server/services/entity_enrichment.py:102:25
    |
101 |       class Config:
102 |           json_encoders = {
    |  _________________________^
103 | |             datetime: lambda dt: dt.isoformat()
104 | |         }
    | |_________^
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> server/services/entity_enrichment.py:128:21
    |
127 |       # Domain patterns with confidence scores
128 |       DOMAIN_SCORES = {
    |  _____________________^
129 | |         # Court records and official documents (highest trust)
130 | |         r"courtlistener\.com": 1.0,
131 | |         r"supremecourt\.gov": 1.0,
132 | |         r"pacer\.gov": 1.0,
133 | |         r"documentcloud\.org": 0.95,
134 | |
135 | |         # Wikipedia and academic sources
136 | |         r"wikipedia\.org": 0.9,
137 | |         r"britannica\.com": 0.9,
138 | |         r"scholar\.google\.com": 0.9,
139 | |         r"jstor\.org": 0.9,
140 | |         r"\.edu($|/)": 0.85,
141 | |
142 | |         # Major news outlets (high trust)
143 | |         r"nytimes\.com": 0.85,
144 | |         r"washingtonpost\.com": 0.85,
145 | |         r"theguardian\.com": 0.85,
146 | |         r"reuters\.com": 0.85,
147 | |         r"apnews\.com": 0.85,
148 | |         r"bbc\.(com|co\.uk)": 0.85,
149 | |         r"npr\.org": 0.8,
150 | |         r"wsj\.com": 0.8,
151 | |         r"ft\.com": 0.8,
152 | |
153 | |         # Mid-tier news outlets
154 | |         r"cnn\.com": 0.7,
155 | |         r"forbes\.com": 0.7,
156 | |         r"bloomberg\.com": 0.75,
157 | |         r"vanityfair\.com": 0.65,
158 | |         r"newyorker\.com": 0.75,
159 | |
160 | |         # Archive and research sites
161 | |         r"archive\.org": 0.8,
162 | |         r"archive\.is": 0.7,
163 | |
164 | |         # Social media (low trust for facts)
165 | |         r"twitter\.com": 0.3,
166 | |         r"x\.com": 0.3,
167 | |         r"facebook\.com": 0.3,
168 | |         r"reddit\.com": 0.35,
169 | |
170 | |         # Blogs and unknown sources (lowest)
171 | |         r"blogspot\.com": 0.2,
172 | |         r"wordpress\.com": 0.2,
173 | |         r"medium\.com": 0.4,
174 | |     }
    | |_____^
175 |
176 |       DEFAULT_SCORE = 0.5  # Unknown sources get medium confidence
    |

UP006 Use `list` instead of `List` for type annotation
   --> server/services/entity_enrichment.py:350:66
    |
348 |         }
349 |
350 |     async def search(self, query: str, max_results: int = 10) -> List[Dict[str, str]]:
    |                                                                  ^^^^
351 |         """Mock search that returns realistic results for testing.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:350:71
    |
348 |         }
349 |
350 |     async def search(self, query: str, max_results: int = 10) -> List[Dict[str, str]]:
    |                                                                       ^^^^
351 |         """Mock search that returns realistic results for testing.
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> server/services/entity_enrichment.py:425:66
    |
423 |         )
424 |
425 |     async def search(self, query: str, max_results: int = 10) -> List[Dict[str, str]]:
    |                                                                  ^^^^
426 |         """Perform DuckDuckGo Lite search and extract results.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:425:71
    |
423 |         )
424 |
425 |     async def search(self, query: str, max_results: int = 10) -> List[Dict[str, str]]:
    |                                                                       ^^^^
426 |         """Perform DuckDuckGo Lite search and extract results.
    |
help: Replace with `dict`

PLC0415 `import` should be at the top-level of a file
   --> server/services/entity_enrichment.py:479:21
    |
477 |                 if url.startswith("//duckduckgo.com/l/"):
478 |                     # Extract actual URL from redirect
479 |                     import urllib.parse
    |                     ^^^^^^^^^^^^^^^^^^^
480 |                     parsed = urllib.parse.parse_qs(url.split("?")[1] if "?" in url else "")
481 |                     url = parsed.get("uddg", [url])[0]
    |

PLC0415 `import` should be at the top-level of a file
   --> server/services/entity_enrichment.py:515:13
    |
513 |         except Exception as e:
514 |             print(f"Error parsing search results for '{query}': {e}")
515 |             import traceback
    |             ^^^^^^^^^^^^^^^^
516 |             traceback.print_exc()
517 |             return []
    |

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:571:21
    |
570 |         # Load cache
571 |         self.cache: Dict[str, EntityEnrichment] = self._load_cache()
    |                     ^^^^
572 |
573 |     def _load_cache(self) -> Dict[str, EntityEnrichment]:
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:573:30
    |
571 |         self.cache: Dict[str, EntityEnrichment] = self._load_cache()
572 |
573 |     def _load_cache(self) -> Dict[str, EntityEnrichment]:
    |                              ^^^^
574 |         """Load cached enrichments from disk"""
575 |         if not self.storage_path.exists():
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/services/entity_enrichment.py:579:18
    |
578 |         try:
579 |             with open(self.storage_path) as f:
    |                  ^^^^
580 |                 data = json.load(f)
581 |                 return {
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/services/entity_enrichment.py:592:18
    |
590 |         """Save enrichments to disk"""
591 |         try:
592 |             with open(self.storage_path, "w") as f:
    |                  ^^^^
593 |                 json.dump(
594 |                     {
    |
help: Replace with `Path.open()`

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/entity_enrichment.py:607:15
    |
605 |     def _is_cache_valid(self, enrichment: EntityEnrichment) -> bool:
606 |         """Check if cached enrichment is still valid (within TTL)"""
607 |         age = datetime.utcnow() - enrichment.last_updated
    |               ^^^^^^^^^^^^^^^^^
608 |         return age < timedelta(days=self.CACHE_TTL_DAYS)
    |
help: Use `datetime.datetime.now(tz=...)` instead

ARG002 Unused method argument: `entity_name`
   --> server/services/entity_enrichment.py:610:52
    |
608 |         return age < timedelta(days=self.CACHE_TTL_DAYS)
609 |
610 |     async def get_enrichment(self, entity_id: str, entity_name: str) -> Optional[EntityEnrichment]:
    |                                                    ^^^^^^^^^^^
611 |         """Get cached enrichment if valid, otherwise return None"""
612 |         if entity_id in self.cache:
    |

UP006 Use `list` instead of `List` for type annotation
   --> server/services/entity_enrichment.py:735:19
    |
733 |     async def enrich_batch(
734 |         self,
735 |         entities: List[Dict[str, str]],
    |                   ^^^^
736 |         max_concurrent: int = 3
737 |     ) -> List[EntityEnrichment]:
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:735:24
    |
733 |     async def enrich_batch(
734 |         self,
735 |         entities: List[Dict[str, str]],
    |                        ^^^^
736 |         max_concurrent: int = 3
737 |     ) -> List[EntityEnrichment]:
    |
help: Replace with `dict`

UP006 Use `list` instead of `List` for type annotation
   --> server/services/entity_enrichment.py:737:10
    |
735 |         entities: List[Dict[str, str]],
736 |         max_concurrent: int = 3
737 |     ) -> List[EntityEnrichment]:
    |          ^^^^
738 |         """Enrich multiple entities concurrently with rate limiting.
    |
help: Replace with `list`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:749:42
    |
747 |         semaphore = asyncio.Semaphore(max_concurrent)
748 |
749 |         async def bounded_enrich(entity: Dict[str, str]) -> EntityEnrichment:
    |                                          ^^^^
750 |             async with semaphore:
751 |                 return await self.enrich_entity(
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:760:33
    |
758 |         ])
759 |
760 |     def get_statistics(self) -> Dict[str, Any]:
    |                                 ^^^^
761 |         """Get cache statistics for monitoring"""
762 |         total = len(self.cache)
    |
help: Replace with `dict`

UP006 Use `dict` instead of `Dict` for type annotation
   --> server/services/entity_enrichment.py:788:52
    |
786 | # ============================================================================
787 |
788 | def format_for_ui(enrichment: EntityEnrichment) -> Dict[str, Any]:
    |                                                    ^^^^
789 |     """Format enrichment data for frontend display.
    |
help: Replace with `dict`

UP035 `typing.List` is deprecated, use `list` instead
  --> server/services/suggestion_service.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | from pathlib import Path
21 | from typing import List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

SIM115 Use a context manager for opening files
  --> server/services/suggestion_service.py:85:13
   |
83 |         Prevents concurrent write corruption using fcntl.flock.
84 |         """
85 |         f = open(self.storage_path, mode)
   |             ^^^^
86 |         try:
87 |             fcntl.flock(f.fileno(), fcntl.LOCK_EX)
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> server/services/suggestion_service.py:85:13
   |
83 |         Prevents concurrent write corruption using fcntl.flock.
84 |         """
85 |         f = open(self.storage_path, mode)
   |             ^^^^
86 |         try:
87 |             fcntl.flock(f.fileno(), fcntl.LOCK_EX)
   |
help: Replace with `Path.open()`

UP006 Use `list` instead of `List` for type annotation
  --> server/services/suggestion_service.py:93:36
   |
91 |             f.close()
92 |
93 |     def _read_suggestions(self) -> List[SuggestedSource]:
   |                                    ^^^^
94 |         """Read all suggestions from storage
   |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
   --> server/services/suggestion_service.py:115:26
    |
113 |             if backup_path.exists():
114 |                 try:
115 |                     with open(backup_path) as f:
    |                          ^^^^
116 |                         data = json.load(f)
117 |                         return [SuggestedSource(**item) for item in data]
    |
help: Replace with `Path.open()`

PLC0415 `import` should be at the top-level of a file
   --> server/services/suggestion_service.py:121:13
    |
119 |                     pass
120 |             # Log error and return empty list
121 |             import logging
    |             ^^^^^^^^^^^^^^
122 |             logging.error(f"Corrupted suggestions file: {e}")
123 |             return []
    |

UP006 Use `list` instead of `List` for type annotation
   --> server/services/suggestion_service.py:125:47
    |
123 |             return []
124 |
125 |     def _write_suggestions(self, suggestions: List[SuggestedSource]) -> None:
    |                                               ^^^^
126 |         """Write suggestions to storage atomically
    |
help: Replace with `list`

PLC0415 `import` should be at the top-level of a file
   --> server/services/suggestion_service.py:139:13
    |
137 |         if self.storage_path.exists():
138 |             backup_path = self.storage_path.with_suffix(".json.bak")
139 |             import shutil
    |             ^^^^^^^^^^^^^
140 |             shutil.copy2(self.storage_path, backup_path)
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/services/suggestion_service.py:146:14
    |
144 |         data = [s.model_dump(mode="json") for s in suggestions]
145 |
146 |         with open(temp_path, "w") as f:
    |              ^^^^
147 |             json.dump(data, f, indent=2, default=str)
    |
help: Replace with `Path.open()`

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/suggestion_service.py:174:26
    |
172 |             **suggestion_data.model_dump(),
173 |             submitted_by=submitted_by,
174 |             submitted_at=datetime.utcnow()
    |                          ^^^^^^^^^^^^^^^^^
175 |         )
    |
help: Use `datetime.datetime.now(tz=...)` instead

UP006 Use `list` instead of `List` for type annotation
   --> server/services/suggestion_service.py:188:16
    |
186 |         limit: int = 100,
187 |         offset: int = 0
188 |     ) -> tuple[List[SuggestedSource], int]:
    |                ^^^^
189 |         """Get all suggestions with optional filtering
    |
help: Replace with `list`

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/suggestion_service.py:272:46
    |
270 |                 # Update review metadata if status changed
271 |                 if update_data.status and update_data.status != suggestion.status:
272 |                     suggestion.reviewed_at = datetime.utcnow()
    |                                              ^^^^^^^^^^^^^^^^^
273 |                     suggestion.reviewed_by = reviewed_by
    |
help: Use `datetime.datetime.now(tz=...)` instead

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/suggestion_service.py:277:56
    |
275 |                 # Update processing timestamps
276 |                 if update_data.status == SourceStatus.PROCESSING:
277 |                     suggestion.processing_started_at = datetime.utcnow()
    |                                                        ^^^^^^^^^^^^^^^^^
278 |                 elif update_data.status in [SourceStatus.COMPLETED, SourceStatus.FAILED]:
279 |                     suggestion.processing_completed_at = datetime.utcnow()
    |
help: Use `datetime.datetime.now(tz=...)` instead

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/suggestion_service.py:279:58
    |
277 |                     suggestion.processing_started_at = datetime.utcnow()
278 |                 elif update_data.status in [SourceStatus.COMPLETED, SourceStatus.FAILED]:
279 |                     suggestion.processing_completed_at = datetime.utcnow()
    |                                                          ^^^^^^^^^^^^^^^^^
280 |
281 |                 suggestions[i] = suggestion
    |
help: Use `datetime.datetime.now(tz=...)` instead

DTZ003 `datetime.datetime.utcnow()` used
   --> server/services/suggestion_service.py:331:26
    |
330 |         # Recent submissions (last 7 days)
331 |         seven_days_ago = datetime.utcnow() - timedelta(days=7)
    |                          ^^^^^^^^^^^^^^^^^
332 |         recent = sum(1 for s in suggestions if s.submitted_at >= seven_days_ago)
    |
help: Use `datetime.datetime.now(tz=...)` instead

PLR1722 Use `sys.exit()` instead of `exit`
   --> server/test_auth_flow.py:104:9
    |
102 |     if not token:
103 |         print("\n❌ Authentication flow test FAILED - login failed")
104 |         exit(1)
    |         ^^^^
105 |
106 |     # Test 3: Verify session
    |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
   --> server/test_auth_flow.py:109:9
    |
107 |     if not test_verify_session(token):
108 |         print("\n❌ Authentication flow test FAILED - session verification failed")
109 |         exit(1)
    |         ^^^^
110 |
111 |     # Test 4: Access protected endpoint (should fail without proper auth)
    |
help: Replace `exit` with `sys.exit()`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> server/test_endpoints.py:9:1
   |
 7 | import json
 8 | import sys
 9 | from typing import Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
10 |
11 | import requests
   |

PT028 Test function parameter `expected_keys` has default argument
  --> server/test_endpoints.py:32:42
   |
30 |     name: str,
31 |     endpoint: str,
32 |     expected_keys: Optional[list[str]] = None,
   |                                          ^^^^
33 |     method: str = "GET",
34 |     data: Optional[Dict] = None
   |
help: Remove default argument

PT028 Test function parameter `method` has default argument
  --> server/test_endpoints.py:33:19
   |
31 |     endpoint: str,
32 |     expected_keys: Optional[list[str]] = None,
33 |     method: str = "GET",
   |                   ^^^^^
34 |     data: Optional[Dict] = None
35 | ) -> bool:
   |
help: Remove default argument

UP006 Use `dict` instead of `Dict` for type annotation
  --> server/test_endpoints.py:34:20
   |
32 |     expected_keys: Optional[list[str]] = None,
33 |     method: str = "GET",
34 |     data: Optional[Dict] = None
   |                    ^^^^
35 | ) -> bool:
36 |     """Test a single API endpoint
   |
help: Replace with `dict`

PT028 Test function parameter `data` has default argument
  --> server/test_endpoints.py:34:28
   |
32 |     expected_keys: Optional[list[str]] = None,
33 |     method: str = "GET",
34 |     data: Optional[Dict] = None
   |                            ^^^^
35 | ) -> bool:
36 |     """Test a single API endpoint
   |
help: Remove default argument

PLR1714 Consider merging multiple comparisons: `response.status_code in {200, 201}`.
  --> server/test_endpoints.py:69:12
   |
68 |         # Check status code
69 |         if response.status_code == 200 or response.status_code == 201:
   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
70 |             print(f"   {Colors.GREEN}✓ Status: {response.status_code}{Colors.RESET}")
71 |         else:
   |
help: Merge multiple comparisons

PLR0915 Too many statements (85 > 60)
   --> server/test_endpoints.py:115:5
    |
115 | def main():
    |     ^^^^
116 |     """Run all endpoint tests"""
117 |     print("=" * 70)
    |

PLR0915 Too many statements (101 > 60)
  --> server/test_enrichment.py:25:11
   |
25 | async def test_enrichment():
   |           ^^^^^^^^^^^^^^^
26 |     """Test entity enrichment workflow"""
   |

PTH123 `open()` should be replaced by `Path.open()`
   --> server/test_enrichment.py:153:10
    |
151 |     }
152 |
153 |     with open(export_path, "w") as f:
    |          ^^^^
154 |         json.dump(export_data, f, indent=2, default=str)
    |
help: Replace with `Path.open()`

Found 733 errors (6 fixed, 727 remaining).
No fixes available (327 hidden fixes can be enabled with the `--unsafe-fixes` option).

Black Formatting Issues:
would reformat /Users/masa/Projects/epstein/scripts/analysis/build_knowledge_graph.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/verify_entity_filtering.py
would reformat /Users/masa/Projects/epstein/scripts/bump_version.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/timeline_builder.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/entity_disambiguator.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/build_unified_index.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/entity_network.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/analyze_giuffre_maxwell_pdfs.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/entity_statistics.py
would reformat /Users/masa/Projects/epstein/scripts/canonicalization/initialize_deduplication.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/rebuild_document_stats.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/rebuild_flight_network.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/enrich_entity_relationships.py
would reformat /Users/masa/Projects/epstein/scripts/canonicalization/canonicalize.py
would reformat /Users/masa/Projects/epstein/scripts/canonicalization/canonicalize_emails.py
would reformat /Users/masa/Projects/epstein/scripts/canonicalization/process_bulk_emails.py
would reformat /Users/masa/Projects/epstein/scripts/classification/classify_all_documents.py
would reformat /Users/masa/Projects/epstein/scripts/analysis/web_relationship_finder.py
would reformat /Users/masa/Projects/epstein/scripts/download/check_courtlistener_progress.py
would reformat /Users/masa/Projects/epstein/scripts/canonicalization/query_deduplication.py
would reformat /Users/masa/Projects/epstein/scripts/core/hasher.py
would reformat /Users/masa/Projects/epstein/scripts/download/summarize_courtlistener_download.py
would reformat /Users/masa/Projects/epstein/scripts/classification/document_classifier.py
would reformat /Users/masa/Projects/epstein/scripts/metadata/refresh_chatbot_index.py
would reformat /Users/masa/Projects/epstein/scripts/core/database.py
would reformat /Users/masa/Projects/epstein/scripts/classification/classify_emails.py
would reformat /Users/masa/Projects/epstein/scripts/core/ocr_quality.py
would reformat /Users/masa/Projects/epstein/scripts/extraction/check_ocr_status.py
would reformat /Users/masa/Projects/epstein/scripts/download/query_master_index.py
would reformat /Users/masa/Projects/epstein/scripts/reorganize_data.py
would reformat /Users/masa/Projects/epstein/scripts/test_openrouter.py
would reformat /Users/masa/Projects/epstein/scripts/download/download_courtlistener.py
would reformat /Users/masa/Projects/epstein/scripts/core/deduplicator.py
would reformat /Users/masa/Projects/epstein/scripts/git_commit_helper.py
would reformat /Users/masa/Projects/epstein/scripts/utils/entity_filtering.py
would reformat /Users/masa/Projects/epstein/server/models/__init__.py
would reformat /Users/masa/Projects/epstein/scripts/indexing/generate_summary_report.py
would reformat /Users/masa/Projects/epstein/server/services/__init__.py
would reformat /Users/masa/Projects/epstein/scripts/extraction/extract_emails_documentcloud_BACKUP.py
would reformat /Users/masa/Projects/epstein/scripts/update_changelog.py
would reformat /Users/masa/Projects/epstein/scripts/utils/build_entity_mappings.py
would reformat /Users/masa/Projects/epstein/server/models/suggested_source.py
would reformat /Users/masa/Projects/epstein/scripts/utils/entity_normalization.py
would reformat /Users/masa/Projects/epstein/scripts/validate_version.py
would reformat /Users/masa/Projects/epstein/scripts/indexing/build_unified_index.py
would reformat /Users/masa/Projects/epstein/scripts/search/entity_search.py
would reformat /Users/masa/Projects/epstein/scripts/extraction/extract_emails.py
would reformat /Users/masa/Projects/epstein/server/test_auth_flow.py
would reformat /Users/masa/Projects/epstein/scripts/extraction/ocr_house_oversight.py
would reformat /Users/masa/Projects/epstein/server/demo_fixes.py
would reformat /Users/masa/Projects/epstein/scripts/download/download_all_sources.py
would reformat /Users/masa/Projects/epstein/scripts/metadata/build_chatbot_knowledge_index.py
would reformat /Users/masa/Projects/epstein/server/services/suggestion_service.py
would reformat /Users/masa/Projects/epstein/server/services/entity_disambiguation.py
would reformat /Users/masa/Projects/epstein/server/test_enrichment.py
would reformat /Users/masa/Projects/epstein/server/test_endpoints.py
would reformat /Users/masa/Projects/epstein/server/services/audit_logger.py
would reformat /Users/masa/Projects/epstein/scripts/utilities/convert_emails_to_markdown.py
would reformat /Users/masa/Projects/epstein/server/services/entity_enrichment.py
would reformat /Users/masa/Projects/epstein/server/app.py

Oh no! 💥 💔 💥
60 files would be reformatted, 3 files would be left unchanged.

isort Import Sorting Issues:
ERROR: /Users/masa/Projects/epstein/scripts/test_openrouter.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/reorganize_data.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/classification/classify_all_documents.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/classification/classify_emails.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/database/init_audit_db.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/canonicalization/canonicalize_emails.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/canonicalization/canonicalize.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/canonicalization/initialize_deduplication.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/canonicalization/query_deduplication.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/canonicalization/process_bulk_emails.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/core/deduplicator.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/verify_entity_filtering.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/rebuild_document_stats.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/analyze_giuffre_maxwell_pdfs.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/web_relationship_finder.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/entity_statistics.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/rebuild_flight_network.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/timeline_builder.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/build_unified_index.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/enrich_entity_relationships.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/build_knowledge_graph.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/entity_disambiguator.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/analysis/entity_network.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/utils/verify_normalization.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/search/entity_search.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/download/download_all_sources.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/download/check_courtlistener_progress.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/download/download_courtlistener.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/indexing/generate_summary_report.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/indexing/build_unified_index.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/extraction/extract_emails_documentcloud_BACKUP.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/extraction/check_ocr_status.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/extraction/extract_emails.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/extraction/ocr_house_oversight.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/scripts/metadata/refresh_chatbot_index.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/demo_fixes.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/test_endpoints.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/app.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/test_auth_flow.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/test_enrichment.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/models/__init__.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/services/__init__.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/services/suggestion_service.py Imports are incorrectly sorted and/or formatted.
ERROR: /Users/masa/Projects/epstein/server/services/entity_enrichment.py Imports are incorrectly sorted and/or formatted.

mypy Type Checking:
scripts/canonicalization/canonicalize.py:405: error: Library stubs not installed for "yaml"  [import-untyped]
scripts/canonicalization/canonicalize.py:405: note: Hint: "python3 -m pip install types-PyYAML"
scripts/canonicalization/canonicalize.py:405: note: (or run "mypy --install-types" to install all missing stub packages)
scripts/canonicalization/canonicalize.py:405: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports
scripts/classification/document_classifier.py: error: Source file found twice under different module names: "document_classifier" and "classification.document_classifier"
scripts/classification/document_classifier.py: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#mapping-file-paths-to-modules for more info
scripts/classification/document_classifier.py: note: Common resolutions include: a) adding `__init__.py` somewhere, b) using `--explicit-package-bases` or adjusting MYPYPATH
Found 2 errors in 2 files (errors prevented further checking)

